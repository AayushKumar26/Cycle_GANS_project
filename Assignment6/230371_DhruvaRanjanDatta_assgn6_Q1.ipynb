{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47b425be-d50e-4ba5-a9f8-8d28ba246de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90d2361a-a8a2-4285-8204-9f854330532c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset from tensorflow\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "246af670-39dd-4ee0-845c-276938591955",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalising dataset between values [-1, 1]\n",
    "X_train = X_train.astype('float32')\n",
    "X_train = (X_train - 127.5)/127.5\n",
    "\n",
    "X_test = X_test.astype('float32')\n",
    "X_test = (X_test - 127.5)/127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53f75e90-6542-4b78-92d5-1eda541bad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2], 1))\n",
    "#reshaping to get images as (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b2b2e50-6fe7-4bed-9701-fd9ba7078a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_func():\n",
    "    labels = tf.keras.layers.Input(shape=(1,))\n",
    "    label_input = tf.keras.layers.Embedding(10, 50)(labels) #embedding layer to include the labels vector into the input along with images\n",
    "    n_nodes = X_train.shape[1] * X_train.shape[2] #28*28 nodes\n",
    "    label_input = tf.keras.layers.Dense(n_nodes)(label_input)\n",
    "    label_input = tf.keras.layers.Reshape((X_train.shape[1], X_train.shape[2], 1))(label_input) #(28, 28, 1) array for labels\n",
    "    input_image = tf.keras.layers.Input(shape=(28,28,1)) #(28, 28, 1) array for images\n",
    "    merge = tf.keras.layers.Concatenate()([input_image, label_input]) #concatenating the image array and the labels array to make it (28,28,2) array\n",
    "\n",
    "    #normal CNN implementation for binary classifier (as this is a discriminator)\n",
    "    cnn = tf.keras.layers.Conv2D(128, (3,3), strides=(2,2), padding='same')(merge)\n",
    "    cnn = tf.keras.layers.LeakyReLU(alpha=0.2)(cnn)\n",
    "    cnn = tf.keras.layers.Conv2D(128, (3,3), strides=(2,2), padding='same')(cnn)\n",
    "    cnn = tf.keras.layers.LeakyReLU(alpha=0.2)(cnn)\n",
    "    cnn = tf.keras.layers.Flatten()(cnn)\n",
    "    cnn = tf.keras.layers.Dropout(0.4)(cnn)\n",
    "    output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(cnn)\n",
    "\n",
    "    model = tf.keras.models.Model([input_image, labels], output_layer)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e487ba74-8943-4a40-88eb-fac464f111f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_func(latent_dim):\n",
    "\n",
    "    #creating labels and generated images arrays\n",
    "    \n",
    "    labels = tf.keras.layers.Input(shape=(1,))\n",
    "    label_input = tf.keras.layers.Embedding(10, 50)(labels)\n",
    "    n_nodes = 7 * 7\n",
    "    label_input = tf.keras.layers.Dense(n_nodes)(label_input)\n",
    "    label_input = tf.keras.layers.Reshape((7,7,1))(label_input) #by this definition, it will be easier to upsample to (28,28,1) shape of image\n",
    "    input_latent = tf.keras.layers.Input(shape=(latent_dim,))\n",
    "\n",
    "    n_nodes = 7 * 7 * 128\n",
    "    gen = tf.keras.layers.Dense(n_nodes)(input_latent)\n",
    "    gen = tf.keras.layers.LeakyReLU(alpha=0.2)(gen)\n",
    "    gen = tf.keras.layers.Reshape((7, 7, 128))(gen)\n",
    "\n",
    "    merge = tf.keras.layers.Concatenate()([gen, label_input]) #merging the two arrays of generated image and labels\n",
    "\n",
    "    #upsampling to (28,28,1)\n",
    "    \n",
    "    gen = tf.keras.layers.Conv2DTranspose(128, (2,2), strides=(1,1), padding='same')(merge)\n",
    "    gen = tf.keras.layers.LeakyReLU(alpha=0.2)(gen)\n",
    "    gen = tf.keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n",
    "    gen = tf.keras.layers.LeakyReLU(alpha=0.2)(gen)\n",
    "    gen = tf.keras.layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same')(gen)\n",
    "    gen = tf.keras.layers.LeakyReLU(alpha=0.2)(gen)\n",
    "\n",
    "    output_layer = tf.keras.layers.Conv2D(1, (7,7), activation='tanh', padding='same')(gen)\n",
    "    model = tf.keras.models.Model([input_latent, labels], output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fbd8bd9-3f8f-4987-92e7-2328438bea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_func(generator_model, discriminator_model):\n",
    "    #we are training discriminator separately\n",
    "    discriminator_model.trainable = False \n",
    "\n",
    "    #defining inputs and outputs variables\n",
    "    gen_noise, gen_labels = generator_model.input\n",
    "    gen_output = generator_model.output\n",
    "\n",
    "    gan_output = discriminator_model([gen_output, gen_labels])\n",
    "\n",
    "    #defining a model on the basis of the given inputs and outputs\n",
    "    model = tf.keras.models.Model([gen_noise, gen_labels], gan_output)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3019933e-d29d-40a4-8460-fe541c7a1449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator_model, discriminator_model, gan_model, dataset, latent_dim, epochs=100, batch_size=128):\n",
    "    batch_per_epoch = int(dataset[0].shape[0]/batch_size) #total/batchsize\n",
    "    half_batch = int(batch_size/2)\n",
    "    for i in range(epochs):\n",
    "        for j in range(batch_per_epoch):\n",
    "\n",
    "            #defining variables for generated fake and real samples and defining their losses\n",
    "            [X_real, labels_real], y_real = generate_real_samples(dataset, half_batch)\n",
    "            discriminator_loss1, _ = discriminator_model.train_on_batch([X_real, labels_real], y_real)\n",
    "            [X_fake, labels], y_fake = generate_fake_samples(generator_model, latent_dim, half_batch)\n",
    "            discriminator_loss2, _ = discriminator_model.train_on_batch([X_fake, labels], y_fake)\n",
    "\n",
    "            [z_input, labels_input] = generate_latent_points(latent_dim, batch_size)\n",
    "            y_gan = np.ones((batch_size, 1))\n",
    "\n",
    "            generator_loss = gan_model.train_on_batch([z_input, labels_input], y_gan)\n",
    "            print(f'Epoch: {i+1}, Batch: {j+1}/{batch_per_epoch}, discriminator loss real = {discriminator_loss1}, disciminator loss fake = {discriminator_loss2}, generator loss = {generator_loss}')\n",
    "        generator_model.save('mnist_conditional_generator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3934682-bf07-451b-860b-2fee9d39b09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_samples():\n",
    "    #load dataset as list of 2 arrays\n",
    "    return [X_train, y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dedbc7b4-e89e-4522-869c-523d27000658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, samples):\n",
    "    #returning real inputs and outputs\n",
    "    images, labels = dataset\n",
    "    ix = np.random.randint(0, images.shape[0], samples)\n",
    "    X, labels = images[ix], labels[ix]\n",
    "\n",
    "    y = np.ones((samples, 1))\n",
    "    return [X, labels], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ebe0b53-0d85-44da-8a9c-83eca3e6cb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_points(latent_dim, samples):\n",
    "    \n",
    "    X_input = np.random.randn(latent_dim * samples)\n",
    "    Z_input = X_input.reshape(samples, latent_dim)\n",
    "\n",
    "    labels = np.random.randint(0, 10, samples)\n",
    "    return [Z_input, labels]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19ee1e22-e94e-48bd-bde8-e03b8c7034f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_samples(generator, latent_dim, samples):\n",
    "    #returning fake inputs and outputs\n",
    "    Z_input, labels_input = generate_latent_points(latent_dim, samples)\n",
    "\n",
    "    images = generator.predict([Z_input, labels_input])\n",
    "\n",
    "    y = np.zeros((samples, 1))\n",
    "    return [images, labels_input], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17d32bb0-49a5-4d4c-a086-61f5154207fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 1, Batch: 1/468, discriminator loss real = 0.6881901025772095, disciminator loss fake = 0.7026859521865845, generator loss = 0.6864200830459595\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 1, Batch: 2/468, discriminator loss real = 0.32550129294395447, disciminator loss fake = 0.8217029571533203, generator loss = 0.5725339651107788\n",
      "2/2 [==============================] - 0s 39ms/step\n",
      "Epoch: 1, Batch: 3/468, discriminator loss real = 0.13367541134357452, disciminator loss fake = 1.287941575050354, generator loss = 0.3841692805290222\n",
      "2/2 [==============================] - 0s 35ms/step\n",
      "Epoch: 1, Batch: 4/468, discriminator loss real = 0.08931335806846619, disciminator loss fake = 1.6488834619522095, generator loss = 0.3252536952495575\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 1, Batch: 5/468, discriminator loss real = 0.12093643844127655, disciminator loss fake = 1.2530646324157715, generator loss = 0.5022646188735962\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 1, Batch: 6/468, discriminator loss real = 0.20491120219230652, disciminator loss fake = 0.7701714038848877, generator loss = 0.8122559785842896\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 1, Batch: 7/468, discriminator loss real = 0.2815556228160858, disciminator loss fake = 0.48040008544921875, generator loss = 1.182923674583435\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 1, Batch: 8/468, discriminator loss real = 0.321998655796051, disciminator loss fake = 0.30207306146621704, generator loss = 1.5871374607086182\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 1, Batch: 9/468, discriminator loss real = 0.34316444396972656, disciminator loss fake = 0.18855144083499908, generator loss = 2.018404960632324\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 1, Batch: 10/468, discriminator loss real = 0.27040037512779236, disciminator loss fake = 0.11451169848442078, generator loss = 2.4799489974975586\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 1, Batch: 11/468, discriminator loss real = 0.2665664851665497, disciminator loss fake = 0.07423724234104156, generator loss = 2.8931901454925537\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 1, Batch: 12/468, discriminator loss real = 0.24473237991333008, disciminator loss fake = 0.051824409514665604, generator loss = 3.177245616912842\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 1, Batch: 13/468, discriminator loss real = 0.20397324860095978, disciminator loss fake = 0.04066435247659683, generator loss = 3.338304042816162\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 1, Batch: 14/468, discriminator loss real = 0.07999177277088165, disciminator loss fake = 0.03469689190387726, generator loss = 3.478992462158203\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 1, Batch: 15/468, discriminator loss real = 0.07312700152397156, disciminator loss fake = 0.030702438205480576, generator loss = 3.6211280822753906\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 1, Batch: 16/468, discriminator loss real = 0.045631833374500275, disciminator loss fake = 0.026741335168480873, generator loss = 3.7582554817199707\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 1, Batch: 17/468, discriminator loss real = 0.06335493177175522, disciminator loss fake = 0.023196358233690262, generator loss = 3.87807559967041\n",
      "2/2 [==============================] - 0s 39ms/step\n",
      "Epoch: 1, Batch: 18/468, discriminator loss real = 0.021714426577091217, disciminator loss fake = 0.019903136417269707, generator loss = 3.961540699005127\n",
      "2/2 [==============================] - 0s 39ms/step\n",
      "Epoch: 1, Batch: 19/468, discriminator loss real = 0.013986988924443722, disciminator loss fake = 0.018693819642066956, generator loss = 4.107514381408691\n",
      "2/2 [==============================] - 0s 36ms/step\n",
      "Epoch: 1, Batch: 20/468, discriminator loss real = 0.008771408349275589, disciminator loss fake = 0.015678199008107185, generator loss = 4.3119120597839355\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 1, Batch: 21/468, discriminator loss real = 0.0032674744725227356, disciminator loss fake = 0.012065245769917965, generator loss = 4.507560729980469\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 1, Batch: 22/468, discriminator loss real = 0.00524323433637619, disciminator loss fake = 0.010459940880537033, generator loss = 4.761974334716797\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 1, Batch: 23/468, discriminator loss real = 0.06226644292473793, disciminator loss fake = 0.008070351555943489, generator loss = 4.881793022155762\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 1, Batch: 24/468, discriminator loss real = 0.06420819461345673, disciminator loss fake = 0.008122416213154793, generator loss = 4.941836357116699\n",
      "2/2 [==============================] - 0s 39ms/step\n",
      "Epoch: 1, Batch: 25/468, discriminator loss real = 0.03449380770325661, disciminator loss fake = 0.008649347350001335, generator loss = 4.909245014190674\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 1, Batch: 26/468, discriminator loss real = 0.0036620635073632, disciminator loss fake = 0.008384178392589092, generator loss = 4.853278160095215\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 1, Batch: 27/468, discriminator loss real = 0.0004510779108386487, disciminator loss fake = 0.008223752491176128, generator loss = 4.885647773742676\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 1, Batch: 28/468, discriminator loss real = 0.0010990409646183252, disciminator loss fake = 0.00793770607560873, generator loss = 4.968440055847168\n",
      "2/2 [==============================] - 0s 34ms/step\n",
      "Epoch: 1, Batch: 29/468, discriminator loss real = 0.0012907711789011955, disciminator loss fake = 0.0067712049931287766, generator loss = 5.091745376586914\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 1, Batch: 30/468, discriminator loss real = 0.015353056602180004, disciminator loss fake = 0.00626065069809556, generator loss = 5.2097673416137695\n",
      "2/2 [==============================] - 0s 39ms/step\n",
      "Epoch: 1, Batch: 31/468, discriminator loss real = 0.00038465013494715095, disciminator loss fake = 0.005654101725667715, generator loss = 5.329798221588135\n",
      "2/2 [==============================] - 0s 39ms/step\n",
      "Epoch: 1, Batch: 32/468, discriminator loss real = 0.006657422985881567, disciminator loss fake = 0.00465686060488224, generator loss = 5.386957168579102\n",
      "2/2 [==============================] - 0s 36ms/step\n",
      "Epoch: 1, Batch: 33/468, discriminator loss real = 0.000343929510563612, disciminator loss fake = 0.0049298545345664024, generator loss = 5.465002059936523\n",
      "2/2 [==============================] - 0s 39ms/step\n",
      "Epoch: 1, Batch: 34/468, discriminator loss real = 0.012279207818210125, disciminator loss fake = 0.003925028257071972, generator loss = 5.517446041107178\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 1, Batch: 35/468, discriminator loss real = 0.007130601909011602, disciminator loss fake = 0.004256680142134428, generator loss = 5.566067695617676\n",
      "2/2 [==============================] - 0s 36ms/step\n",
      "Epoch: 1, Batch: 36/468, discriminator loss real = 0.0006891245720908046, disciminator loss fake = 0.004331471398472786, generator loss = 5.55715274810791\n",
      "2/2 [==============================] - 0s 36ms/step\n",
      "Epoch: 1, Batch: 37/468, discriminator loss real = 0.00292194657959044, disciminator loss fake = 0.003692794358357787, generator loss = 5.725172996520996\n",
      "2/2 [==============================] - 0s 33ms/step\n",
      "Epoch: 1, Batch: 38/468, discriminator loss real = 0.003209297312423587, disciminator loss fake = 0.0037709525786340237, generator loss = 5.760408878326416\n",
      "2/2 [==============================] - 0s 35ms/step\n",
      "Epoch: 1, Batch: 39/468, discriminator loss real = 0.00013179822417441756, disciminator loss fake = 0.003566455328837037, generator loss = 5.851957321166992\n",
      "2/2 [==============================] - 0s 36ms/step\n",
      "Epoch: 1, Batch: 40/468, discriminator loss real = 0.00110822101123631, disciminator loss fake = 0.0031188311986625195, generator loss = 6.007208347320557\n",
      "2/2 [==============================] - 0s 36ms/step\n",
      "Epoch: 1, Batch: 41/468, discriminator loss real = 0.012730815447866917, disciminator loss fake = 0.002792610786855221, generator loss = 5.953982353210449\n",
      "2/2 [==============================] - 0s 35ms/step\n",
      "Epoch: 1, Batch: 42/468, discriminator loss real = 0.0004246705793775618, disciminator loss fake = 0.002623024396598339, generator loss = 6.089885711669922\n",
      "2/2 [==============================] - 0s 38ms/step\n",
      "Epoch: 1, Batch: 43/468, discriminator loss real = 0.000156883877934888, disciminator loss fake = 0.0024537385907024145, generator loss = 6.138540267944336\n",
      "2/2 [==============================] - 0s 36ms/step\n",
      "Epoch: 1, Batch: 44/468, discriminator loss real = 0.0002618557191453874, disciminator loss fake = 0.0023265485651791096, generator loss = 6.154296398162842\n",
      "2/2 [==============================] - 0s 35ms/step\n",
      "Epoch: 1, Batch: 45/468, discriminator loss real = 0.0010314957471564412, disciminator loss fake = 0.0021354001946747303, generator loss = 6.232761383056641\n",
      "2/2 [==============================] - 0s 36ms/step\n",
      "Epoch: 1, Batch: 46/468, discriminator loss real = 0.006556177511811256, disciminator loss fake = 0.0019272032659500837, generator loss = 6.253293991088867\n",
      "2/2 [==============================] - 0s 38ms/step\n",
      "Epoch: 1, Batch: 47/468, discriminator loss real = 0.0002550122735556215, disciminator loss fake = 0.001962286187335849, generator loss = 6.285841464996338\n",
      "2/2 [==============================] - 0s 33ms/step\n",
      "Epoch: 1, Batch: 48/468, discriminator loss real = 0.021320989355444908, disciminator loss fake = 0.0020953353960067034, generator loss = 6.201155662536621\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 1, Batch: 49/468, discriminator loss real = 0.002677963813766837, disciminator loss fake = 0.0022753344383090734, generator loss = 6.041715621948242\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 1, Batch: 50/468, discriminator loss real = 0.000567062059417367, disciminator loss fake = 0.0026418184861540794, generator loss = 5.988883972167969\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 1, Batch: 51/468, discriminator loss real = 0.00012187472748337314, disciminator loss fake = 0.0030029183253645897, generator loss = 6.031139373779297\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 1, Batch: 52/468, discriminator loss real = 0.00102394784335047, disciminator loss fake = 0.002959913108497858, generator loss = 6.0751447677612305\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 1, Batch: 53/468, discriminator loss real = 0.0025906201917678118, disciminator loss fake = 0.0026389514096081257, generator loss = 6.036357402801514\n",
      "2/2 [==============================] - 0s 39ms/step\n",
      "Epoch: 1, Batch: 54/468, discriminator loss real = 0.0001988274889299646, disciminator loss fake = 0.0023987654130905867, generator loss = 6.146006107330322\n",
      "2/2 [==============================] - 0s 37ms/step\n",
      "Epoch: 1, Batch: 55/468, discriminator loss real = 0.0010295805986970663, disciminator loss fake = 0.0020863432437181473, generator loss = 6.283629417419434\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 1, Batch: 56/468, discriminator loss real = 0.0016631066100671887, disciminator loss fake = 0.001843850128352642, generator loss = 6.286904335021973\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 1, Batch: 57/468, discriminator loss real = 6.885165203129873e-05, disciminator loss fake = 0.0018685333197936416, generator loss = 6.4608306884765625\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 1, Batch: 58/468, discriminator loss real = 0.002074627438560128, disciminator loss fake = 0.0016061816131696105, generator loss = 6.499094009399414\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 1, Batch: 59/468, discriminator loss real = 7.82721399446018e-05, disciminator loss fake = 0.0016435717698186636, generator loss = 6.579193115234375\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 1, Batch: 60/468, discriminator loss real = 0.0017280223546549678, disciminator loss fake = 0.001452597905881703, generator loss = 6.639560699462891\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 1, Batch: 61/468, discriminator loss real = 5.415218402049504e-05, disciminator loss fake = 0.0013931217836216092, generator loss = 6.692672252655029\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 1, Batch: 62/468, discriminator loss real = 0.00018528613145463169, disciminator loss fake = 0.0012475189287215471, generator loss = 6.831388473510742\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 1, Batch: 63/468, discriminator loss real = 0.0003890130901709199, disciminator loss fake = 0.0010075108148157597, generator loss = 6.943241596221924\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 1, Batch: 64/468, discriminator loss real = 0.00022038341558072716, disciminator loss fake = 0.0011004791595041752, generator loss = 6.984426021575928\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 1, Batch: 65/468, discriminator loss real = 3.309881503810175e-05, disciminator loss fake = 0.0010110975708812475, generator loss = 7.083306312561035\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 1, Batch: 66/468, discriminator loss real = 0.005271285306662321, disciminator loss fake = 0.0009477269486524165, generator loss = 7.007414817810059\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 1, Batch: 67/468, discriminator loss real = 1.7002079403027892e-05, disciminator loss fake = 0.0008955436060205102, generator loss = 7.096713066101074\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 1, Batch: 68/468, discriminator loss real = 0.025366855785250664, disciminator loss fake = 0.0009229362476617098, generator loss = 6.840856552124023\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 1, Batch: 69/468, discriminator loss real = 5.806877015857026e-05, disciminator loss fake = 0.001385052572004497, generator loss = 6.676133155822754\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 1, Batch: 70/468, discriminator loss real = 1.3168825717002619e-05, disciminator loss fake = 0.0015416761161759496, generator loss = 6.515132904052734\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 1, Batch: 71/468, discriminator loss real = 1.371859252685681e-05, disciminator loss fake = 0.0015495598781853914, generator loss = 6.391599178314209\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 1, Batch: 72/468, discriminator loss real = 0.022295475006103516, disciminator loss fake = 0.0019814542029052973, generator loss = 6.056018829345703\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 1, Batch: 73/468, discriminator loss real = 0.00022201107640285045, disciminator loss fake = 0.003047964768484235, generator loss = 5.858549118041992\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 1, Batch: 74/468, discriminator loss real = 7.920208008727059e-05, disciminator loss fake = 0.0032646427862346172, generator loss = 5.767192363739014\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 1, Batch: 75/468, discriminator loss real = 9.143219358520582e-05, disciminator loss fake = 0.0037876837886869907, generator loss = 5.996074199676514\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 1, Batch: 76/468, discriminator loss real = 0.00015305263514164835, disciminator loss fake = 0.003056034678593278, generator loss = 6.1552510261535645\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 1, Batch: 77/468, discriminator loss real = 8.685829925525468e-06, disciminator loss fake = 0.0021907095797359943, generator loss = 6.3224968910217285\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 1, Batch: 78/468, discriminator loss real = 0.0003388650366105139, disciminator loss fake = 0.0015470687067136168, generator loss = 6.496072292327881\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 1, Batch: 79/468, discriminator loss real = 1.2615897503565066e-05, disciminator loss fake = 0.0013639439130201936, generator loss = 6.6974897384643555\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 1, Batch: 80/468, discriminator loss real = 5.799967038910836e-05, disciminator loss fake = 0.0010753882816061378, generator loss = 6.9601874351501465\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 1, Batch: 81/468, discriminator loss real = 1.2677097402047366e-05, disciminator loss fake = 0.0010452347341924906, generator loss = 7.010435104370117\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 1, Batch: 82/468, discriminator loss real = 9.266258302886854e-07, disciminator loss fake = 0.000889030983671546, generator loss = 7.177457809448242\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 1, Batch: 83/468, discriminator loss real = 1.1250778698013164e-05, disciminator loss fake = 0.0007625165162608027, generator loss = 7.324398517608643\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 1, Batch: 84/468, discriminator loss real = 0.004121134988963604, disciminator loss fake = 0.0007188403978943825, generator loss = 7.389853477478027\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 1, Batch: 85/468, discriminator loss real = 0.00045515221427194774, disciminator loss fake = 0.0006492946413345635, generator loss = 7.453960418701172\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 1, Batch: 86/468, discriminator loss real = 2.1826854208484292e-05, disciminator loss fake = 0.0005820253281854093, generator loss = 7.4445037841796875\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 1, Batch: 87/468, discriminator loss real = 5.960687849437818e-05, disciminator loss fake = 0.0006110640824772418, generator loss = 7.621397495269775\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 1, Batch: 88/468, discriminator loss real = 0.0002894687931984663, disciminator loss fake = 0.0005878893425688148, generator loss = 7.529137134552002\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 1, Batch: 89/468, discriminator loss real = 0.000979588832706213, disciminator loss fake = 0.0005448178271763027, generator loss = 7.535610198974609\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 1, Batch: 90/468, discriminator loss real = 3.6353885661810637e-06, disciminator loss fake = 0.0005675168358720839, generator loss = 7.627458572387695\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 1, Batch: 91/468, discriminator loss real = 8.831615559756756e-05, disciminator loss fake = 0.0004993233596906066, generator loss = 7.537449836730957\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 1, Batch: 92/468, discriminator loss real = 4.111560701858252e-05, disciminator loss fake = 0.0005386203993111849, generator loss = 7.709502220153809\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 1, Batch: 93/468, discriminator loss real = 1.5649100532755256e-05, disciminator loss fake = 0.0004656994133256376, generator loss = 7.7453179359436035\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 1, Batch: 94/468, discriminator loss real = 1.9398514723434346e-06, disciminator loss fake = 0.0004278940032236278, generator loss = 7.80824089050293\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 1, Batch: 95/468, discriminator loss real = 2.9769860248052282e-06, disciminator loss fake = 0.0004067099071107805, generator loss = 7.88108491897583\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 1, Batch: 96/468, discriminator loss real = 3.2565867513767444e-06, disciminator loss fake = 0.0003874619142152369, generator loss = 7.850276947021484\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 1, Batch: 97/468, discriminator loss real = 0.027304675430059433, disciminator loss fake = 0.0005481333355419338, generator loss = 7.582792282104492\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 1, Batch: 98/468, discriminator loss real = 1.0790316764541785e-06, disciminator loss fake = 0.0006894735852256417, generator loss = 7.2094502449035645\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 1, Batch: 99/468, discriminator loss real = 8.41787550598383e-06, disciminator loss fake = 0.0009887090418487787, generator loss = 7.012416839599609\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 1, Batch: 100/468, discriminator loss real = 8.896722647477873e-06, disciminator loss fake = 0.0011035653296858072, generator loss = 6.884472846984863\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 1, Batch: 101/468, discriminator loss real = 2.8817371457989793e-06, disciminator loss fake = 0.001226636115461588, generator loss = 6.734190940856934\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 1, Batch: 102/468, discriminator loss real = 9.32143620957504e-07, disciminator loss fake = 0.0014371775323525071, generator loss = 6.735158920288086\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 1, Batch: 103/468, discriminator loss real = 8.184135680266991e-08, disciminator loss fake = 0.0015501512680202723, generator loss = 6.719940185546875\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 1, Batch: 104/468, discriminator loss real = 1.0789917723741382e-05, disciminator loss fake = 0.0015017050318419933, generator loss = 6.774872779846191\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 1, Batch: 105/468, discriminator loss real = 6.256412916627596e-07, disciminator loss fake = 0.0012031267397105694, generator loss = 6.956758499145508\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 1, Batch: 106/468, discriminator loss real = 5.609876652101775e-08, disciminator loss fake = 0.0011410386068746448, generator loss = 7.029821872711182\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 1, Batch: 107/468, discriminator loss real = 5.912809797337104e-07, disciminator loss fake = 0.0009575888980180025, generator loss = 7.230551242828369\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 1, Batch: 108/468, discriminator loss real = 2.9751799957011826e-05, disciminator loss fake = 0.0008128186454996467, generator loss = 7.331708908081055\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 1, Batch: 109/468, discriminator loss real = 2.778114503598772e-05, disciminator loss fake = 0.0007859383476898074, generator loss = 7.392838478088379\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 1, Batch: 110/468, discriminator loss real = 3.1995921290217666e-07, disciminator loss fake = 0.0007354835979640484, generator loss = 7.562961578369141\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 1, Batch: 111/468, discriminator loss real = 0.0014425781555473804, disciminator loss fake = 0.0005877729854546487, generator loss = 7.650270462036133\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 1, Batch: 112/468, discriminator loss real = 1.7601467334316112e-05, disciminator loss fake = 0.0006067174253985286, generator loss = 7.682991027832031\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 1, Batch: 113/468, discriminator loss real = 2.405543682471034e-06, disciminator loss fake = 0.00047303465544246137, generator loss = 7.8097405433654785\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 1, Batch: 114/468, discriminator loss real = 7.15562273398973e-05, disciminator loss fake = 0.0005004582926630974, generator loss = 7.802000045776367\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 1, Batch: 115/468, discriminator loss real = 3.540451871231198e-05, disciminator loss fake = 0.0004866862727794796, generator loss = 7.962054252624512\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 1, Batch: 116/468, discriminator loss real = 4.947515844833106e-05, disciminator loss fake = 0.000390882370993495, generator loss = 7.947953224182129\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 1, Batch: 117/468, discriminator loss real = 2.157181006623432e-05, disciminator loss fake = 0.00039938779082149267, generator loss = 7.997037887573242\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 1, Batch: 118/468, discriminator loss real = 2.7077583126811078e-06, disciminator loss fake = 0.00036314979661256075, generator loss = 8.037984848022461\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 1, Batch: 119/468, discriminator loss real = 0.00012809356849174947, disciminator loss fake = 0.0003524420317262411, generator loss = 8.24354076385498\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 1, Batch: 120/468, discriminator loss real = 7.049745818221709e-06, disciminator loss fake = 0.0003418169799260795, generator loss = 8.247865676879883\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 1, Batch: 121/468, discriminator loss real = 0.0003964314528275281, disciminator loss fake = 0.0002998863928951323, generator loss = 8.266402244567871\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 1, Batch: 122/468, discriminator loss real = 1.8861771877709543e-07, disciminator loss fake = 0.0002752247964963317, generator loss = 8.306198120117188\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 1, Batch: 123/468, discriminator loss real = 0.0004981316742487252, disciminator loss fake = 0.00026586337480694056, generator loss = 8.380794525146484\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 1, Batch: 124/468, discriminator loss real = 4.535185144050047e-05, disciminator loss fake = 0.0002140653959941119, generator loss = 8.45779800415039\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 1, Batch: 125/468, discriminator loss real = 0.00028541716164909303, disciminator loss fake = 0.0002424977719783783, generator loss = 8.379897117614746\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 1, Batch: 126/468, discriminator loss real = 8.873702427081298e-06, disciminator loss fake = 0.00025427344371564686, generator loss = 8.427701950073242\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 1, Batch: 127/468, discriminator loss real = 7.906986138550565e-05, disciminator loss fake = 0.00022414297563955188, generator loss = 8.482211112976074\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 1, Batch: 128/468, discriminator loss real = 1.0734270290413406e-05, disciminator loss fake = 0.0002421696699457243, generator loss = 8.388379096984863\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 1, Batch: 129/468, discriminator loss real = 0.00015100180462468415, disciminator loss fake = 0.00022944228840060532, generator loss = 8.548409461975098\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 1, Batch: 130/468, discriminator loss real = 0.0005700952606275678, disciminator loss fake = 0.00022920632909517735, generator loss = 8.4707670211792\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 1, Batch: 131/468, discriminator loss real = 3.0120911560516106e-06, disciminator loss fake = 0.00022948227706365287, generator loss = 8.538228988647461\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 1, Batch: 132/468, discriminator loss real = 8.153470844263211e-06, disciminator loss fake = 0.00023403849627356976, generator loss = 8.531864166259766\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 1, Batch: 133/468, discriminator loss real = 4.2242137965331494e-07, disciminator loss fake = 0.0002177893475163728, generator loss = 8.47001838684082\n",
      "2/2 [==============================] - 0s 39ms/step\n",
      "Epoch: 1, Batch: 134/468, discriminator loss real = 0.0010050281416624784, disciminator loss fake = 0.00022754947713110596, generator loss = 8.501012802124023\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 1, Batch: 135/468, discriminator loss real = 3.178797101099917e-07, disciminator loss fake = 0.000240092005697079, generator loss = 8.505640983581543\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 1, Batch: 136/468, discriminator loss real = 1.0463700164109468e-06, disciminator loss fake = 0.00020205293549224734, generator loss = 8.490981101989746\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 1, Batch: 137/468, discriminator loss real = 2.5806480152823497e-06, disciminator loss fake = 0.00024073637905530632, generator loss = 8.47626781463623\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 1, Batch: 138/468, discriminator loss real = 1.900358620332554e-05, disciminator loss fake = 0.00022763611923437566, generator loss = 8.56436538696289\n",
      "2/2 [==============================] - 0s 39ms/step\n",
      "Epoch: 1, Batch: 139/468, discriminator loss real = 1.0389554745415808e-06, disciminator loss fake = 0.00023221466108225286, generator loss = 8.59261703491211\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 1, Batch: 140/468, discriminator loss real = 1.987714028928167e-07, disciminator loss fake = 0.00019470597908366472, generator loss = 8.627758026123047\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 1, Batch: 141/468, discriminator loss real = 1.3378441508393735e-05, disciminator loss fake = 0.00022918560716789216, generator loss = 8.681495666503906\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 1, Batch: 142/468, discriminator loss real = 2.2535283278557472e-05, disciminator loss fake = 0.0002104048035107553, generator loss = 8.695173263549805\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 1, Batch: 143/468, discriminator loss real = 3.4682781802075624e-07, disciminator loss fake = 0.00020660123846028, generator loss = 8.729938507080078\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 1, Batch: 144/468, discriminator loss real = 6.207977548911003e-06, disciminator loss fake = 0.00019929205882363021, generator loss = 8.765913963317871\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 1, Batch: 145/468, discriminator loss real = 0.004327366128563881, disciminator loss fake = 0.00019846096984110773, generator loss = 8.668933868408203\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 1, Batch: 146/468, discriminator loss real = 0.0003503980697132647, disciminator loss fake = 0.00018767407163977623, generator loss = 8.512725830078125\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 1, Batch: 147/468, discriminator loss real = 6.569869128725259e-06, disciminator loss fake = 0.0002535890380386263, generator loss = 8.506917953491211\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 1, Batch: 148/468, discriminator loss real = 5.005884304409847e-06, disciminator loss fake = 0.00026349161635152996, generator loss = 8.406034469604492\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 1, Batch: 149/468, discriminator loss real = 0.001114186248742044, disciminator loss fake = 0.000292639626422897, generator loss = 8.205514907836914\n",
      "2/2 [==============================] - 0s 32ms/step\n",
      "Epoch: 1, Batch: 150/468, discriminator loss real = 0.0005819184589199722, disciminator loss fake = 0.00028360087890177965, generator loss = 8.226200103759766\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 1, Batch: 151/468, discriminator loss real = 0.00025546987308189273, disciminator loss fake = 0.0003332060296088457, generator loss = 8.135942459106445\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 1, Batch: 152/468, discriminator loss real = 1.9542751488188514e-06, disciminator loss fake = 0.00038483808748424053, generator loss = 8.195294380187988\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 1, Batch: 153/468, discriminator loss real = 2.756407582182874e-07, disciminator loss fake = 0.00037306416197679937, generator loss = 8.016319274902344\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 1, Batch: 154/468, discriminator loss real = 3.127230957034044e-05, disciminator loss fake = 0.00045159057481214404, generator loss = 8.131983757019043\n",
      "2/2 [==============================] - 0s 39ms/step\n",
      "Epoch: 1, Batch: 155/468, discriminator loss real = 0.00014652607205789536, disciminator loss fake = 0.000478459958685562, generator loss = 8.152629852294922\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 1, Batch: 156/468, discriminator loss real = 6.434071565308841e-06, disciminator loss fake = 0.00045045744627714157, generator loss = 8.118583679199219\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 1, Batch: 157/468, discriminator loss real = 2.1191482346694102e-07, disciminator loss fake = 0.0003672940656542778, generator loss = 8.257953643798828\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 1, Batch: 158/468, discriminator loss real = 4.4914622776559554e-07, disciminator loss fake = 0.0002912827767431736, generator loss = 8.216070175170898\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 1, Batch: 159/468, discriminator loss real = 7.034442205622327e-06, disciminator loss fake = 0.000297678227070719, generator loss = 8.332098960876465\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 1, Batch: 160/468, discriminator loss real = 4.2753796151373535e-05, disciminator loss fake = 0.0002928307803813368, generator loss = 8.343978881835938\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 1, Batch: 161/468, discriminator loss real = 1.553025867906399e-06, disciminator loss fake = 0.00029569477192126215, generator loss = 8.422037124633789\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 1, Batch: 162/468, discriminator loss real = 1.304824309045216e-06, disciminator loss fake = 0.00031282915733754635, generator loss = 8.489880561828613\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 1, Batch: 163/468, discriminator loss real = 3.3239401091123e-05, disciminator loss fake = 0.00020722640329040587, generator loss = 8.497095108032227\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 1, Batch: 164/468, discriminator loss real = 1.6468558214910445e-06, disciminator loss fake = 0.00020484384731389582, generator loss = 8.708982467651367\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 1, Batch: 165/468, discriminator loss real = 3.818110485553916e-07, disciminator loss fake = 0.00021041481522843242, generator loss = 8.726346015930176\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 1, Batch: 166/468, discriminator loss real = 3.742559556485503e-06, disciminator loss fake = 0.00018744092085398734, generator loss = 8.710841178894043\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 1, Batch: 167/468, discriminator loss real = 2.2833460207039025e-06, disciminator loss fake = 0.00019046456145588309, generator loss = 8.697875022888184\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 1, Batch: 168/468, discriminator loss real = 6.663607337031863e-07, disciminator loss fake = 0.00019045060616917908, generator loss = 8.878518104553223\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 1, Batch: 169/468, discriminator loss real = 2.6194424208370037e-05, disciminator loss fake = 0.00018254152382723987, generator loss = 8.90932846069336\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 1, Batch: 170/468, discriminator loss real = 4.197152520646341e-06, disciminator loss fake = 0.00016673540812917054, generator loss = 8.96650218963623\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 1, Batch: 171/468, discriminator loss real = 1.3820082358506625e-06, disciminator loss fake = 0.0001569727319292724, generator loss = 9.042571067810059\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 1, Batch: 172/468, discriminator loss real = 0.00011784520756918937, disciminator loss fake = 0.00015266411355696619, generator loss = 9.057485580444336\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 1, Batch: 173/468, discriminator loss real = 7.572555027479666e-09, disciminator loss fake = 0.00014282026677392423, generator loss = 9.026470184326172\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 1, Batch: 174/468, discriminator loss real = 7.531688424933236e-06, disciminator loss fake = 0.00011841285595437512, generator loss = 9.044478416442871\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 1, Batch: 175/468, discriminator loss real = 3.310848910587083e-07, disciminator loss fake = 0.00012535443238448352, generator loss = 9.080897331237793\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 1, Batch: 176/468, discriminator loss real = 3.1287311230698833e-06, disciminator loss fake = 0.00013459748879540712, generator loss = 9.179805755615234\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 1, Batch: 177/468, discriminator loss real = 3.584553996915929e-05, disciminator loss fake = 0.00012101967149646953, generator loss = 9.176614761352539\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 1, Batch: 178/468, discriminator loss real = 0.0005227997899055481, disciminator loss fake = 0.0001066227414412424, generator loss = 9.183618545532227\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 1, Batch: 179/468, discriminator loss real = 8.86399793671444e-05, disciminator loss fake = 0.0001217285607708618, generator loss = 9.148567199707031\n",
      "2/2 [==============================] - 0s 38ms/step\n",
      "Epoch: 1, Batch: 180/468, discriminator loss real = 1.6656218576827087e-05, disciminator loss fake = 0.00011622611782513559, generator loss = 9.229560852050781\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 1, Batch: 181/468, discriminator loss real = 2.1704178720938216e-07, disciminator loss fake = 0.00011473479389678687, generator loss = 9.196468353271484\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 1, Batch: 182/468, discriminator loss real = 2.0953812054358423e-05, disciminator loss fake = 0.00011021707905456424, generator loss = 9.220279693603516\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 1, Batch: 183/468, discriminator loss real = 2.3543458738117806e-08, disciminator loss fake = 0.00010929073323495686, generator loss = 9.200942993164062\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 1, Batch: 184/468, discriminator loss real = 1.8485345208318904e-05, disciminator loss fake = 9.838039113674313e-05, generator loss = 9.231060028076172\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 1, Batch: 185/468, discriminator loss real = 8.584932220401242e-05, disciminator loss fake = 0.00011675724817905575, generator loss = 9.333335876464844\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 1, Batch: 186/468, discriminator loss real = 1.1668193110381253e-05, disciminator loss fake = 0.0001051919607562013, generator loss = 9.238983154296875\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 1, Batch: 187/468, discriminator loss real = 4.275864557712339e-05, disciminator loss fake = 0.00010101722000399604, generator loss = 9.404817581176758\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 1, Batch: 188/468, discriminator loss real = 0.0018805372528731823, disciminator loss fake = 9.165586379822344e-05, generator loss = 9.208534240722656\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 1, Batch: 189/468, discriminator loss real = 2.2079511552419717e-07, disciminator loss fake = 0.00013175250205677003, generator loss = 9.224084854125977\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 1, Batch: 190/468, discriminator loss real = 9.256875728169689e-07, disciminator loss fake = 0.00015576956502627581, generator loss = 9.156782150268555\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 1, Batch: 191/468, discriminator loss real = 4.746380000142381e-06, disciminator loss fake = 0.00013898187899030745, generator loss = 9.148258209228516\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 1, Batch: 192/468, discriminator loss real = 1.343806388831581e-06, disciminator loss fake = 0.000132797344122082, generator loss = 9.062508583068848\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 1, Batch: 193/468, discriminator loss real = 1.3281006658871775e-06, disciminator loss fake = 0.00014924301649443805, generator loss = 9.022595405578613\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 1, Batch: 194/468, discriminator loss real = 0.0034178849309682846, disciminator loss fake = 0.00014351218123920262, generator loss = 8.906009674072266\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 1, Batch: 195/468, discriminator loss real = 0.0005070144543424249, disciminator loss fake = 0.00016505017993040383, generator loss = 8.709904670715332\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 1, Batch: 196/468, discriminator loss real = 2.1692217160307337e-06, disciminator loss fake = 0.0003252701717428863, generator loss = 8.527473449707031\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 1, Batch: 197/468, discriminator loss real = 9.86986833595438e-07, disciminator loss fake = 0.00031592269078828394, generator loss = 8.471923828125\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 1, Batch: 198/468, discriminator loss real = 7.348018016273272e-08, disciminator loss fake = 0.0003020045696757734, generator loss = 8.400603294372559\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 1, Batch: 199/468, discriminator loss real = 0.011318872682750225, disciminator loss fake = 0.000537040876224637, generator loss = 7.554206848144531\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 1, Batch: 200/468, discriminator loss real = 4.728483560256791e-08, disciminator loss fake = 0.0016153034521266818, generator loss = 7.053882598876953\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 1, Batch: 201/468, discriminator loss real = 9.192719403472438e-07, disciminator loss fake = 0.002688176231458783, generator loss = 6.781789779663086\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 1, Batch: 202/468, discriminator loss real = 2.3465854326332192e-07, disciminator loss fake = 0.002692974405363202, generator loss = 7.256272315979004\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 1, Batch: 203/468, discriminator loss real = 2.1822445432917448e-06, disciminator loss fake = 0.0010819933377206326, generator loss = 7.6918559074401855\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 1, Batch: 204/468, discriminator loss real = 2.7281235048803865e-08, disciminator loss fake = 0.0006192649016156793, generator loss = 7.98701810836792\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 1, Batch: 205/468, discriminator loss real = 5.491050387718133e-07, disciminator loss fake = 0.0004431478155311197, generator loss = 8.361202239990234\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 1, Batch: 206/468, discriminator loss real = 5.637959111481905e-05, disciminator loss fake = 0.00031548229162581265, generator loss = 8.44037914276123\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 1, Batch: 207/468, discriminator loss real = 3.6319222544989316e-06, disciminator loss fake = 0.00022945107775740325, generator loss = 8.728004455566406\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 1, Batch: 208/468, discriminator loss real = 9.175053037324687e-07, disciminator loss fake = 0.00017352709255646914, generator loss = 8.833015441894531\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 1, Batch: 209/468, discriminator loss real = 3.5918168439508236e-09, disciminator loss fake = 0.00015393958892673254, generator loss = 8.952570915222168\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 1, Batch: 210/468, discriminator loss real = 5.8893682819416426e-08, disciminator loss fake = 0.0001361631730105728, generator loss = 9.176913261413574\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 1, Batch: 211/468, discriminator loss real = 2.5393550373564722e-08, disciminator loss fake = 0.00013957990449853241, generator loss = 9.219230651855469\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 1, Batch: 212/468, discriminator loss real = 1.1509290942512962e-07, disciminator loss fake = 0.00013507509720511734, generator loss = 9.243138313293457\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 1, Batch: 213/468, discriminator loss real = 1.4810784421115386e-07, disciminator loss fake = 0.00014771404676139355, generator loss = 9.402584075927734\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 1, Batch: 214/468, discriminator loss real = 1.2254483294782403e-07, disciminator loss fake = 8.903926936909556e-05, generator loss = 9.449117660522461\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 1, Batch: 215/468, discriminator loss real = 2.24652740143938e-05, disciminator loss fake = 8.868752047419548e-05, generator loss = 9.449357986450195\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 1, Batch: 216/468, discriminator loss real = 4.775635898113251e-05, disciminator loss fake = 7.568080764031038e-05, generator loss = 9.592284202575684\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 1, Batch: 217/468, discriminator loss real = 5.407214302977081e-06, disciminator loss fake = 9.077856520889327e-05, generator loss = 9.669203758239746\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 1, Batch: 218/468, discriminator loss real = 2.130397547261964e-07, disciminator loss fake = 7.46321165934205e-05, generator loss = 9.708364486694336\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 1, Batch: 219/468, discriminator loss real = 0.00013047772517893463, disciminator loss fake = 8.049920870689675e-05, generator loss = 9.678596496582031\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 1, Batch: 220/468, discriminator loss real = 5.9384648920968175e-05, disciminator loss fake = 7.917980110505596e-05, generator loss = 9.804265022277832\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 1, Batch: 221/468, discriminator loss real = 2.8823475872741255e-07, disciminator loss fake = 6.369735638145357e-05, generator loss = 9.7859468460083\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 1, Batch: 222/468, discriminator loss real = 5.300436001220987e-08, disciminator loss fake = 7.491598080378026e-05, generator loss = 9.808878898620605\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 1, Batch: 223/468, discriminator loss real = 1.3551317579185707e-06, disciminator loss fake = 6.660995131824166e-05, generator loss = 9.780125617980957\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 1, Batch: 224/468, discriminator loss real = 6.307235889835283e-05, disciminator loss fake = 5.974207306280732e-05, generator loss = 9.800520896911621\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 1, Batch: 225/468, discriminator loss real = 0.00016453950956929475, disciminator loss fake = 6.686492270091549e-05, generator loss = 9.809610366821289\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 1, Batch: 226/468, discriminator loss real = 1.9328999769641086e-06, disciminator loss fake = 6.405872409231961e-05, generator loss = 9.847768783569336\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 1, Batch: 227/468, discriminator loss real = 4.6663711827932275e-07, disciminator loss fake = 6.101303733885288e-05, generator loss = 9.916977882385254\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 1, Batch: 228/468, discriminator loss real = 1.3251110431156121e-06, disciminator loss fake = 6.0659229347947985e-05, generator loss = 9.85562515258789\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 1, Batch: 229/468, discriminator loss real = 1.3518529158318415e-06, disciminator loss fake = 6.89963562763296e-05, generator loss = 9.84892749786377\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 1, Batch: 230/468, discriminator loss real = 0.0005421981913968921, disciminator loss fake = 6.935941928531975e-05, generator loss = 9.818246841430664\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 1, Batch: 231/468, discriminator loss real = 8.810516760604514e-08, disciminator loss fake = 7.123257091734558e-05, generator loss = 9.784082412719727\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 1, Batch: 232/468, discriminator loss real = 4.325531790527748e-06, disciminator loss fake = 7.673582149436697e-05, generator loss = 9.713508605957031\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 1, Batch: 233/468, discriminator loss real = 8.878103585630015e-07, disciminator loss fake = 6.236103945411742e-05, generator loss = 9.853408813476562\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 1, Batch: 234/468, discriminator loss real = 0.0010197438532486558, disciminator loss fake = 6.252065941225737e-05, generator loss = 9.798580169677734\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 1, Batch: 235/468, discriminator loss real = 1.6397964941461396e-07, disciminator loss fake = 7.495809404645115e-05, generator loss = 9.6357421875\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 1, Batch: 236/468, discriminator loss real = 6.39734665242031e-08, disciminator loss fake = 7.432916027028114e-05, generator loss = 9.592945098876953\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 1, Batch: 237/468, discriminator loss real = 2.1111080059199594e-05, disciminator loss fake = 7.468754483852535e-05, generator loss = 9.609145164489746\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 1, Batch: 238/468, discriminator loss real = 6.472911877608567e-07, disciminator loss fake = 7.543430547229946e-05, generator loss = 9.627991676330566\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 1, Batch: 239/468, discriminator loss real = 1.1998658010270447e-05, disciminator loss fake = 9.56085859797895e-05, generator loss = 9.645163536071777\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 1, Batch: 240/468, discriminator loss real = 1.3872632109723781e-07, disciminator loss fake = 8.239923045039177e-05, generator loss = 9.610061645507812\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 1, Batch: 241/468, discriminator loss real = 5.151754066901049e-06, disciminator loss fake = 7.700083369854838e-05, generator loss = 9.600027084350586\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 1, Batch: 242/468, discriminator loss real = 1.4658664440503344e-05, disciminator loss fake = 8.910470933187753e-05, generator loss = 9.582342147827148\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 1, Batch: 243/468, discriminator loss real = 6.313503490673611e-06, disciminator loss fake = 9.234967001248151e-05, generator loss = 9.67325210571289\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 1, Batch: 244/468, discriminator loss real = 6.731349276378751e-05, disciminator loss fake = 7.949271821416914e-05, generator loss = 9.658256530761719\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 1, Batch: 245/468, discriminator loss real = 9.303192200604826e-06, disciminator loss fake = 7.296130934264511e-05, generator loss = 9.669803619384766\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 1, Batch: 246/468, discriminator loss real = 1.1574113614187809e-06, disciminator loss fake = 7.572457252535969e-05, generator loss = 9.819938659667969\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 1, Batch: 247/468, discriminator loss real = 2.6397702868052875e-07, disciminator loss fake = 7.683997682761401e-05, generator loss = 9.667698860168457\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 1, Batch: 248/468, discriminator loss real = 1.5449963086666685e-08, disciminator loss fake = 6.46183398202993e-05, generator loss = 9.748319625854492\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 1, Batch: 249/468, discriminator loss real = 0.0017187154153361917, disciminator loss fake = 7.277607073774561e-05, generator loss = 9.59600830078125\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 1, Batch: 250/468, discriminator loss real = 0.0007564420811831951, disciminator loss fake = 7.8486671554856e-05, generator loss = 9.565213203430176\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 1, Batch: 251/468, discriminator loss real = 4.812204679183196e-07, disciminator loss fake = 8.820032235234976e-05, generator loss = 9.421220779418945\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 1, Batch: 252/468, discriminator loss real = 2.307954503066867e-07, disciminator loss fake = 0.0001117465944844298, generator loss = 9.300107955932617\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 1, Batch: 253/468, discriminator loss real = 1.0117716556123924e-05, disciminator loss fake = 0.00012310284364502877, generator loss = 9.19891357421875\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 1, Batch: 254/468, discriminator loss real = 9.233969649358187e-06, disciminator loss fake = 0.000128941610455513, generator loss = 9.214790344238281\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 1, Batch: 255/468, discriminator loss real = 2.1016376194893382e-06, disciminator loss fake = 0.000129398686112836, generator loss = 9.19172477722168\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 1, Batch: 256/468, discriminator loss real = 5.0384080907406315e-08, disciminator loss fake = 0.00013901344209443778, generator loss = 9.1251802444458\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 1, Batch: 257/468, discriminator loss real = 3.1655295629207103e-07, disciminator loss fake = 0.00013568192662205547, generator loss = 9.149055480957031\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 1, Batch: 258/468, discriminator loss real = 6.715969220749685e-07, disciminator loss fake = 0.00013845466310158372, generator loss = 9.193416595458984\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 1, Batch: 259/468, discriminator loss real = 1.916746050767415e-08, disciminator loss fake = 0.00012641650391742587, generator loss = 9.266790390014648\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 1, Batch: 260/468, discriminator loss real = 1.395468643750064e-06, disciminator loss fake = 0.00014506938168779016, generator loss = 9.20083999633789\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 1, Batch: 261/468, discriminator loss real = 4.410180736158509e-06, disciminator loss fake = 0.00014302280033007264, generator loss = 9.28719711303711\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 1, Batch: 262/468, discriminator loss real = 1.067165555923566e-07, disciminator loss fake = 0.00011550037743290886, generator loss = 9.333114624023438\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 1, Batch: 263/468, discriminator loss real = 2.0215301788084616e-07, disciminator loss fake = 0.00010479831689735875, generator loss = 9.145286560058594\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 1, Batch: 264/468, discriminator loss real = 5.280312052491354e-06, disciminator loss fake = 0.00011252406693529338, generator loss = 9.427206039428711\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 1, Batch: 265/468, discriminator loss real = 3.992656274931505e-05, disciminator loss fake = 0.00012139635509811342, generator loss = 9.295751571655273\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 1, Batch: 266/468, discriminator loss real = 1.015718908092822e-06, disciminator loss fake = 0.00012318587687332183, generator loss = 9.439334869384766\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 1, Batch: 267/468, discriminator loss real = 2.074232563487044e-09, disciminator loss fake = 0.00011301982158329338, generator loss = 9.337060928344727\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 1, Batch: 268/468, discriminator loss real = 4.5034644813313207e-07, disciminator loss fake = 0.00010671881318558007, generator loss = 9.29239273071289\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 1, Batch: 269/468, discriminator loss real = 2.0601512460416416e-06, disciminator loss fake = 9.609267726773396e-05, generator loss = 9.528024673461914\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 1, Batch: 270/468, discriminator loss real = 1.106726244870515e-06, disciminator loss fake = 9.317392687080428e-05, generator loss = 9.506599426269531\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 1, Batch: 271/468, discriminator loss real = 1.5740185972390464e-06, disciminator loss fake = 8.590897778049111e-05, generator loss = 9.51219367980957\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 1, Batch: 272/468, discriminator loss real = 1.1413958134198765e-07, disciminator loss fake = 8.500966941937804e-05, generator loss = 9.450621604919434\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 1, Batch: 273/468, discriminator loss real = 8.662642585477442e-07, disciminator loss fake = 7.913990702945739e-05, generator loss = 9.796903610229492\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 1, Batch: 274/468, discriminator loss real = 2.4294530476254295e-07, disciminator loss fake = 7.822448969818652e-05, generator loss = 9.694995880126953\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 1, Batch: 275/468, discriminator loss real = 4.810497244989165e-08, disciminator loss fake = 8.10129422461614e-05, generator loss = 9.660905838012695\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 1, Batch: 276/468, discriminator loss real = 9.459372085984796e-05, disciminator loss fake = 7.793237455189228e-05, generator loss = 9.688909530639648\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 1, Batch: 277/468, discriminator loss real = 2.5575345716788433e-06, disciminator loss fake = 7.257935067173094e-05, generator loss = 9.69291877746582\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 1, Batch: 278/468, discriminator loss real = 3.679492692754138e-07, disciminator loss fake = 7.867837848607451e-05, generator loss = 9.808576583862305\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 1, Batch: 279/468, discriminator loss real = 3.489683194857207e-06, disciminator loss fake = 7.094065949786454e-05, generator loss = 9.787983894348145\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 1, Batch: 280/468, discriminator loss real = 2.2415216349713774e-08, disciminator loss fake = 7.941963849589229e-05, generator loss = 9.91297721862793\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 1, Batch: 281/468, discriminator loss real = 7.774528785375878e-05, disciminator loss fake = 6.568111712113023e-05, generator loss = 9.909551620483398\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 1, Batch: 282/468, discriminator loss real = 3.718294010468526e-06, disciminator loss fake = 7.974440086400136e-05, generator loss = 9.86355209350586\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 1, Batch: 283/468, discriminator loss real = 2.9394968805718236e-06, disciminator loss fake = 5.844366387464106e-05, generator loss = 9.888830184936523\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 1, Batch: 284/468, discriminator loss real = 1.1915767572645564e-06, disciminator loss fake = 6.278790533542633e-05, generator loss = 9.883886337280273\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 1, Batch: 285/468, discriminator loss real = 1.669328412390314e-06, disciminator loss fake = 7.039311458356678e-05, generator loss = 9.866019248962402\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 1, Batch: 286/468, discriminator loss real = 3.743723027582746e-06, disciminator loss fake = 6.229978316696361e-05, generator loss = 9.99537467956543\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 1, Batch: 287/468, discriminator loss real = 6.988075256231241e-07, disciminator loss fake = 5.863050319021568e-05, generator loss = 9.90439224243164\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 1, Batch: 288/468, discriminator loss real = 0.000104907201603055, disciminator loss fake = 6.178497278597206e-05, generator loss = 9.944040298461914\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 1, Batch: 289/468, discriminator loss real = 5.595924790213758e-07, disciminator loss fake = 5.68883988307789e-05, generator loss = 9.916705131530762\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 1, Batch: 290/468, discriminator loss real = 2.9006423574173823e-06, disciminator loss fake = 6.28445268375799e-05, generator loss = 9.967180252075195\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 1, Batch: 291/468, discriminator loss real = 2.554777944752118e-09, disciminator loss fake = 5.951011917204596e-05, generator loss = 9.971851348876953\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 1, Batch: 292/468, discriminator loss real = 1.1539591326936716e-07, disciminator loss fake = 6.984723586356267e-05, generator loss = 9.90036678314209\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 1, Batch: 293/468, discriminator loss real = 2.9056852781650377e-06, disciminator loss fake = 5.48812240594998e-05, generator loss = 10.053581237792969\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 1, Batch: 294/468, discriminator loss real = 9.491777746006846e-07, disciminator loss fake = 5.088086618343368e-05, generator loss = 10.139497756958008\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 1, Batch: 295/468, discriminator loss real = 3.398392800590955e-05, disciminator loss fake = 5.04455019836314e-05, generator loss = 10.10116195678711\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 1, Batch: 296/468, discriminator loss real = 0.00026276876451447606, disciminator loss fake = 5.709799370379187e-05, generator loss = 10.080055236816406\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 1, Batch: 297/468, discriminator loss real = 1.1981899028512544e-08, disciminator loss fake = 5.651958053931594e-05, generator loss = 10.038524627685547\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 1, Batch: 298/468, discriminator loss real = 8.46675902721472e-06, disciminator loss fake = 5.412182508734986e-05, generator loss = 10.137060165405273\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 1, Batch: 299/468, discriminator loss real = 2.0774498921127815e-07, disciminator loss fake = 5.87760514463298e-05, generator loss = 10.053457260131836\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 1, Batch: 300/468, discriminator loss real = 5.795828110422008e-05, disciminator loss fake = 4.5515374949900433e-05, generator loss = 9.998311996459961\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 1, Batch: 301/468, discriminator loss real = 5.699197345165885e-07, disciminator loss fake = 4.639055623556487e-05, generator loss = 10.110952377319336\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 1, Batch: 302/468, discriminator loss real = 3.101994749954429e-08, disciminator loss fake = 5.683615381713025e-05, generator loss = 10.167099952697754\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 1, Batch: 303/468, discriminator loss real = 1.1259365237492602e-05, disciminator loss fake = 4.779358278028667e-05, generator loss = 10.115217208862305\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 1, Batch: 304/468, discriminator loss real = 4.970245572621934e-05, disciminator loss fake = 5.0837956223404035e-05, generator loss = 10.141279220581055\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 1, Batch: 305/468, discriminator loss real = 1.5123006278372486e-06, disciminator loss fake = 5.092441278975457e-05, generator loss = 10.14792251586914\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 1, Batch: 306/468, discriminator loss real = 3.6231838748790324e-05, disciminator loss fake = 5.026076905778609e-05, generator loss = 10.176472663879395\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 1, Batch: 307/468, discriminator loss real = 3.6718452065542806e-06, disciminator loss fake = 4.621079278877005e-05, generator loss = 10.079635620117188\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 1, Batch: 308/468, discriminator loss real = 2.962225948976993e-07, disciminator loss fake = 4.869543045060709e-05, generator loss = 10.227119445800781\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 1, Batch: 309/468, discriminator loss real = 6.674449105048552e-05, disciminator loss fake = 4.17704795836471e-05, generator loss = 10.105804443359375\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 1, Batch: 310/468, discriminator loss real = 8.315305603900924e-05, disciminator loss fake = 3.7955440348014235e-05, generator loss = 10.165326118469238\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 1, Batch: 311/468, discriminator loss real = 1.042656549543608e-06, disciminator loss fake = 4.548833385342732e-05, generator loss = 10.23896312713623\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 1, Batch: 312/468, discriminator loss real = 0.0010546318953856826, disciminator loss fake = 4.430469198268838e-05, generator loss = 10.06051254272461\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 1, Batch: 313/468, discriminator loss real = 7.531784262937435e-08, disciminator loss fake = 4.859044565819204e-05, generator loss = 9.981742858886719\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 1, Batch: 314/468, discriminator loss real = 4.382276529213414e-06, disciminator loss fake = 5.819164653075859e-05, generator loss = 9.930534362792969\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 1, Batch: 315/468, discriminator loss real = 8.136373799061403e-05, disciminator loss fake = 5.787322879768908e-05, generator loss = 9.878377914428711\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 1, Batch: 316/468, discriminator loss real = 5.735871582146501e-07, disciminator loss fake = 6.375048542395234e-05, generator loss = 9.844472885131836\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 1, Batch: 317/468, discriminator loss real = 4.268623342795763e-06, disciminator loss fake = 7.532130985055119e-05, generator loss = 9.877972602844238\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 1, Batch: 318/468, discriminator loss real = 8.685786667683715e-08, disciminator loss fake = 6.688392022624612e-05, generator loss = 9.88624095916748\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 1, Batch: 319/468, discriminator loss real = 2.876519578087766e-10, disciminator loss fake = 6.345133442664519e-05, generator loss = 9.911758422851562\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 1, Batch: 320/468, discriminator loss real = 1.1869429528132969e-07, disciminator loss fake = 6.745888094883412e-05, generator loss = 9.770469665527344\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 1, Batch: 321/468, discriminator loss real = 0.00021065809414722025, disciminator loss fake = 7.025097875157371e-05, generator loss = 9.90804672241211\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 1, Batch: 322/468, discriminator loss real = 5.120602054375922e-06, disciminator loss fake = 6.41747610643506e-05, generator loss = 9.81849479675293\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 1, Batch: 323/468, discriminator loss real = 0.0014826873084530234, disciminator loss fake = 7.630955951754004e-05, generator loss = 9.601556777954102\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 1, Batch: 324/468, discriminator loss real = 2.209724812018976e-07, disciminator loss fake = 8.756321767577901e-05, generator loss = 9.543378829956055\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 1, Batch: 325/468, discriminator loss real = 5.517758250306315e-09, disciminator loss fake = 0.00011008575529558584, generator loss = 9.441158294677734\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 1, Batch: 326/468, discriminator loss real = 2.9250474264941317e-10, disciminator loss fake = 0.00010780482261907309, generator loss = 9.321554183959961\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 1, Batch: 327/468, discriminator loss real = 1.0425902363664363e-09, disciminator loss fake = 0.00014330237172544003, generator loss = 9.347257614135742\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 1, Batch: 328/468, discriminator loss real = 1.6593925465713255e-05, disciminator loss fake = 0.00015527027426287532, generator loss = 9.240854263305664\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 1, Batch: 329/468, discriminator loss real = 1.1464989846388107e-08, disciminator loss fake = 0.0001321586751146242, generator loss = 9.323871612548828\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 1, Batch: 330/468, discriminator loss real = 8.436955249635503e-05, disciminator loss fake = 0.00014083767018746585, generator loss = 9.094528198242188\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 1, Batch: 331/468, discriminator loss real = 1.9855988284689374e-06, disciminator loss fake = 0.00014403020031750202, generator loss = 9.276301383972168\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 1, Batch: 332/468, discriminator loss real = 0.00014380572247318923, disciminator loss fake = 0.00013008428504690528, generator loss = 9.327205657958984\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 1, Batch: 333/468, discriminator loss real = 1.73383327251031e-07, disciminator loss fake = 0.0001464816596126184, generator loss = 9.414785385131836\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 1, Batch: 334/468, discriminator loss real = 9.304200830229092e-06, disciminator loss fake = 0.00013029493857175112, generator loss = 9.376463890075684\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 1, Batch: 335/468, discriminator loss real = 6.475907525782532e-07, disciminator loss fake = 0.00014925384311936796, generator loss = 9.294785499572754\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 1, Batch: 336/468, discriminator loss real = 2.031428536497515e-08, disciminator loss fake = 0.00013535165635403246, generator loss = 9.379125595092773\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 1, Batch: 337/468, discriminator loss real = 1.5249374882841948e-06, disciminator loss fake = 0.00012283555406611413, generator loss = 9.604706764221191\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 1, Batch: 338/468, discriminator loss real = 2.4562918810033807e-08, disciminator loss fake = 0.00011719929898390546, generator loss = 9.5690279006958\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 1, Batch: 339/468, discriminator loss real = 5.981069648441917e-07, disciminator loss fake = 0.00010411624680273235, generator loss = 9.746757507324219\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 1, Batch: 340/468, discriminator loss real = 1.721730313875014e-09, disciminator loss fake = 8.998106204671785e-05, generator loss = 9.707413673400879\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 1, Batch: 341/468, discriminator loss real = 5.745629749753789e-08, disciminator loss fake = 7.398161687888205e-05, generator loss = 9.594520568847656\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 1, Batch: 342/468, discriminator loss real = 8.911790416732401e-09, disciminator loss fake = 8.946816524257883e-05, generator loss = 9.767843246459961\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 1, Batch: 343/468, discriminator loss real = 3.833285120435903e-07, disciminator loss fake = 8.153790986398235e-05, generator loss = 9.845600128173828\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 1, Batch: 344/468, discriminator loss real = 0.00021819191169925034, disciminator loss fake = 6.624953675782308e-05, generator loss = 9.900577545166016\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 1, Batch: 345/468, discriminator loss real = 2.4483145466547285e-07, disciminator loss fake = 8.596970292273909e-05, generator loss = 9.826876640319824\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 1, Batch: 346/468, discriminator loss real = 8.794061727712688e-07, disciminator loss fake = 7.07395956851542e-05, generator loss = 9.767701148986816\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 1, Batch: 347/468, discriminator loss real = 3.002040784849669e-06, disciminator loss fake = 6.755733920726925e-05, generator loss = 9.875558853149414\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 1, Batch: 348/468, discriminator loss real = 6.745174374600538e-08, disciminator loss fake = 7.782240572851151e-05, generator loss = 9.866809844970703\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 1, Batch: 349/468, discriminator loss real = 8.838514808928721e-09, disciminator loss fake = 5.9309764765203e-05, generator loss = 10.117080688476562\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 1, Batch: 350/468, discriminator loss real = 4.716064694321176e-08, disciminator loss fake = 6.600157212233171e-05, generator loss = 10.0565767288208\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 1, Batch: 351/468, discriminator loss real = 6.031119426097575e-08, disciminator loss fake = 5.312847497407347e-05, generator loss = 9.910340309143066\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 1, Batch: 352/468, discriminator loss real = 7.328599060940633e-09, disciminator loss fake = 6.27213521511294e-05, generator loss = 10.023340225219727\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 1, Batch: 353/468, discriminator loss real = 1.4000902410771232e-06, disciminator loss fake = 5.612301538349129e-05, generator loss = 10.022600173950195\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 1, Batch: 354/468, discriminator loss real = 1.1273333655470452e-10, disciminator loss fake = 4.818842717213556e-05, generator loss = 10.092059135437012\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 1, Batch: 355/468, discriminator loss real = 3.1250149135075844e-09, disciminator loss fake = 5.879869786440395e-05, generator loss = 10.172143936157227\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 1, Batch: 356/468, discriminator loss real = 1.3752896848018281e-06, disciminator loss fake = 5.432146281236783e-05, generator loss = 10.16821575164795\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 1, Batch: 357/468, discriminator loss real = 3.7942732888041064e-05, disciminator loss fake = 5.0830061809392646e-05, generator loss = 10.199288368225098\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 1, Batch: 358/468, discriminator loss real = 0.001039224793203175, disciminator loss fake = 4.174039713689126e-05, generator loss = 10.142938613891602\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 1, Batch: 359/468, discriminator loss real = 0.0001596004149178043, disciminator loss fake = 6.224594835657626e-05, generator loss = 10.076654434204102\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 1, Batch: 360/468, discriminator loss real = 0.005461537279188633, disciminator loss fake = 8.967531903181225e-05, generator loss = 9.290980339050293\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 1, Batch: 361/468, discriminator loss real = 1.831667795215708e-08, disciminator loss fake = 0.00021991247194819152, generator loss = 8.551000595092773\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 1, Batch: 362/468, discriminator loss real = 2.9148819469249077e-10, disciminator loss fake = 0.0006336984224617481, generator loss = 8.059371948242188\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 1, Batch: 363/468, discriminator loss real = 1.348335331385897e-06, disciminator loss fake = 0.001418850850313902, generator loss = 7.846590995788574\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 1, Batch: 364/468, discriminator loss real = 1.2631312662492178e-11, disciminator loss fake = 0.0009732872131280601, generator loss = 7.895655632019043\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 1, Batch: 365/468, discriminator loss real = 1.636866159060446e-06, disciminator loss fake = 0.0010332248639315367, generator loss = 8.056815147399902\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 1, Batch: 366/468, discriminator loss real = 1.441912561572778e-10, disciminator loss fake = 0.0003319270326755941, generator loss = 8.769108772277832\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 1, Batch: 367/468, discriminator loss real = 7.337489643655104e-11, disciminator loss fake = 0.0002068904141196981, generator loss = 9.030462265014648\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 1, Batch: 368/468, discriminator loss real = 3.4024066053461866e-07, disciminator loss fake = 0.00018070416990667582, generator loss = 9.050652503967285\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 1, Batch: 369/468, discriminator loss real = 1.2030416662867083e-09, disciminator loss fake = 0.0001628987811272964, generator loss = 9.350883483886719\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 1, Batch: 370/468, discriminator loss real = 5.8880033293462475e-08, disciminator loss fake = 9.14139673113823e-05, generator loss = 9.660455703735352\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 1, Batch: 371/468, discriminator loss real = 4.132328612627134e-08, disciminator loss fake = 9.96488452074118e-05, generator loss = 9.800434112548828\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 1, Batch: 372/468, discriminator loss real = 1.2719098663183104e-08, disciminator loss fake = 7.254636147990823e-05, generator loss = 9.85641860961914\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 1, Batch: 373/468, discriminator loss real = 4.652393137405397e-09, disciminator loss fake = 6.153935828479007e-05, generator loss = 10.125261306762695\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 1, Batch: 374/468, discriminator loss real = 0.0003352358180563897, disciminator loss fake = 6.099501115386374e-05, generator loss = 10.07923412322998\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 1, Batch: 375/468, discriminator loss real = 1.3443098023646627e-10, disciminator loss fake = 5.862165562575683e-05, generator loss = 10.180403709411621\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 1, Batch: 376/468, discriminator loss real = 1.9123467254189563e-08, disciminator loss fake = 4.3955988076049834e-05, generator loss = 10.259140014648438\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 1, Batch: 377/468, discriminator loss real = 9.670136691397602e-09, disciminator loss fake = 4.3133757571922615e-05, generator loss = 10.218984603881836\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 1, Batch: 378/468, discriminator loss real = 1.160239349040637e-09, disciminator loss fake = 5.457330553326756e-05, generator loss = 10.294862747192383\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 1, Batch: 379/468, discriminator loss real = 2.100112617142713e-08, disciminator loss fake = 4.399177123559639e-05, generator loss = 10.312887191772461\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 1, Batch: 380/468, discriminator loss real = 9.03799612927969e-09, disciminator loss fake = 4.341297608334571e-05, generator loss = 10.527730941772461\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 1, Batch: 381/468, discriminator loss real = 3.274741970926698e-07, disciminator loss fake = 4.729985448648222e-05, generator loss = 10.381087303161621\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 1, Batch: 382/468, discriminator loss real = 7.861962103561382e-08, disciminator loss fake = 3.7388621421996504e-05, generator loss = 10.467950820922852\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 1, Batch: 383/468, discriminator loss real = 8.056079359164414e-09, disciminator loss fake = 4.2317369661759585e-05, generator loss = 10.356189727783203\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 1, Batch: 384/468, discriminator loss real = 1.4138865078727747e-10, disciminator loss fake = 4.050064671901055e-05, generator loss = 10.517339706420898\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 1, Batch: 385/468, discriminator loss real = 9.206657658467066e-11, disciminator loss fake = 3.270550587330945e-05, generator loss = 10.529312133789062\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 1, Batch: 386/468, discriminator loss real = 0.002218549605458975, disciminator loss fake = 3.7984355003573e-05, generator loss = 10.240622520446777\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 1, Batch: 387/468, discriminator loss real = 2.4053661284995087e-09, disciminator loss fake = 5.8758934756042436e-05, generator loss = 10.322793960571289\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 1, Batch: 388/468, discriminator loss real = 1.8642852239736385e-07, disciminator loss fake = 4.13070956710726e-05, generator loss = 10.108603477478027\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 1, Batch: 389/468, discriminator loss real = 7.119969041013974e-07, disciminator loss fake = 5.7866356655722484e-05, generator loss = 9.959141731262207\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 1, Batch: 390/468, discriminator loss real = 1.2913157654281804e-08, disciminator loss fake = 6.082551772124134e-05, generator loss = 9.903635025024414\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 1, Batch: 391/468, discriminator loss real = 6.074719038906551e-08, disciminator loss fake = 7.725095929345116e-05, generator loss = 9.794197082519531\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 1, Batch: 392/468, discriminator loss real = 5.1202340978218075e-11, disciminator loss fake = 6.83035104884766e-05, generator loss = 9.806697845458984\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 1, Batch: 393/468, discriminator loss real = 1.567090279763761e-08, disciminator loss fake = 7.362761243712157e-05, generator loss = 9.733688354492188\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 1, Batch: 394/468, discriminator loss real = 2.2533913579536602e-07, disciminator loss fake = 7.632582855876535e-05, generator loss = 9.776687622070312\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 1, Batch: 395/468, discriminator loss real = 1.0425930119239979e-09, disciminator loss fake = 8.697823795955628e-05, generator loss = 9.653721809387207\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 1, Batch: 396/468, discriminator loss real = 4.0347916119287675e-09, disciminator loss fake = 6.921723979758099e-05, generator loss = 9.738037109375\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 1, Batch: 397/468, discriminator loss real = 4.620319682402396e-10, disciminator loss fake = 6.409509660443291e-05, generator loss = 9.748849868774414\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 1, Batch: 398/468, discriminator loss real = 2.4520538488559396e-08, disciminator loss fake = 7.607696170452982e-05, generator loss = 9.879682540893555\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 1, Batch: 399/468, discriminator loss real = 6.513749184478002e-08, disciminator loss fake = 7.162837573559955e-05, generator loss = 9.858440399169922\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 1, Batch: 400/468, discriminator loss real = 3.6139522308076266e-07, disciminator loss fake = 6.107191438786685e-05, generator loss = 9.83342456817627\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 1, Batch: 401/468, discriminator loss real = 2.2345851391492033e-08, disciminator loss fake = 6.296239735092968e-05, generator loss = 9.852636337280273\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 1, Batch: 402/468, discriminator loss real = 4.379625806905096e-06, disciminator loss fake = 6.068193033570424e-05, generator loss = 9.96954345703125\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 1, Batch: 403/468, discriminator loss real = 4.2868137484219915e-08, disciminator loss fake = 5.598716961685568e-05, generator loss = 10.067312240600586\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 1, Batch: 404/468, discriminator loss real = 2.2782705855206586e-07, disciminator loss fake = 6.067458161851391e-05, generator loss = 10.012791633605957\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 1, Batch: 405/468, discriminator loss real = 2.1941648498113864e-09, disciminator loss fake = 5.606439299299382e-05, generator loss = 10.036852836608887\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 1, Batch: 406/468, discriminator loss real = 2.0653227739142466e-10, disciminator loss fake = 6.122852209955454e-05, generator loss = 9.975852966308594\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 1, Batch: 407/468, discriminator loss real = 1.242012643842827e-07, disciminator loss fake = 5.807269917568192e-05, generator loss = 10.09815502166748\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 1, Batch: 408/468, discriminator loss real = 1.5389394203424445e-09, disciminator loss fake = 4.6919034502934664e-05, generator loss = 10.156676292419434\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 1, Batch: 409/468, discriminator loss real = 7.53229249805809e-12, disciminator loss fake = 4.951233131578192e-05, generator loss = 10.160207748413086\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 1, Batch: 410/468, discriminator loss real = 2.0768269048954124e-10, disciminator loss fake = 4.7110621380852535e-05, generator loss = 10.124992370605469\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 1, Batch: 411/468, discriminator loss real = 1.4733536772837397e-06, disciminator loss fake = 4.7064277168828994e-05, generator loss = 10.40393352508545\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 1, Batch: 412/468, discriminator loss real = 1.1944105608563405e-05, disciminator loss fake = 4.3407242628745735e-05, generator loss = 10.332338333129883\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 1, Batch: 413/468, discriminator loss real = 2.686706634946745e-09, disciminator loss fake = 3.8663551094941795e-05, generator loss = 10.21391487121582\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 1, Batch: 414/468, discriminator loss real = 1.5087562132976018e-07, disciminator loss fake = 3.98743650293909e-05, generator loss = 10.286299705505371\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 1, Batch: 415/468, discriminator loss real = 4.6205347103978056e-08, disciminator loss fake = 4.267932672519237e-05, generator loss = 10.269145965576172\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 1, Batch: 416/468, discriminator loss real = 6.492022066595382e-07, disciminator loss fake = 4.30161708209198e-05, generator loss = 10.24236011505127\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 1, Batch: 417/468, discriminator loss real = 6.694102605564467e-09, disciminator loss fake = 3.9254737203009427e-05, generator loss = 10.496929168701172\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 1, Batch: 418/468, discriminator loss real = 7.144137365022729e-11, disciminator loss fake = 3.932401159545407e-05, generator loss = 10.398681640625\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 1, Batch: 419/468, discriminator loss real = 1.4875679577031065e-09, disciminator loss fake = 3.544725041138008e-05, generator loss = 10.481182098388672\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 1, Batch: 420/468, discriminator loss real = 1.5493379024178466e-08, disciminator loss fake = 3.800835111178458e-05, generator loss = 10.399086952209473\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 1, Batch: 421/468, discriminator loss real = 5.0694479725166275e-09, disciminator loss fake = 3.475795892882161e-05, generator loss = 10.443022727966309\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 1, Batch: 422/468, discriminator loss real = 1.3935624565419857e-06, disciminator loss fake = 4.022488428745419e-05, generator loss = 10.45936393737793\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 1, Batch: 423/468, discriminator loss real = 2.552044406911591e-07, disciminator loss fake = 2.7258760383119807e-05, generator loss = 10.488044738769531\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 1, Batch: 424/468, discriminator loss real = 1.9607696231105365e-06, disciminator loss fake = 3.311078398837708e-05, generator loss = 10.613950729370117\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 1, Batch: 425/468, discriminator loss real = 5.499359190253017e-08, disciminator loss fake = 3.2547744922339916e-05, generator loss = 10.661454200744629\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 1, Batch: 426/468, discriminator loss real = 5.0121698458305275e-11, disciminator loss fake = 3.4011074603768066e-05, generator loss = 10.634347915649414\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 1, Batch: 427/468, discriminator loss real = 7.496081089186646e-09, disciminator loss fake = 3.892241875291802e-05, generator loss = 10.548529624938965\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 1, Batch: 428/468, discriminator loss real = 1.3663226106075399e-08, disciminator loss fake = 2.9710925446124747e-05, generator loss = 10.599167823791504\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 1, Batch: 429/468, discriminator loss real = 5.2434884878493904e-08, disciminator loss fake = 3.4925207728520036e-05, generator loss = 10.699005126953125\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 1, Batch: 430/468, discriminator loss real = 4.2415299503772985e-06, disciminator loss fake = 3.2353582355426624e-05, generator loss = 10.689471244812012\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 1, Batch: 431/468, discriminator loss real = 3.436777251675238e-11, disciminator loss fake = 3.1499817850999534e-05, generator loss = 10.73373031616211\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 1, Batch: 432/468, discriminator loss real = 1.0917966086765318e-08, disciminator loss fake = 3.1426603527506813e-05, generator loss = 10.732431411743164\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 1, Batch: 433/468, discriminator loss real = 2.385600694765344e-08, disciminator loss fake = 2.9384851586655714e-05, generator loss = 10.845170974731445\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 1, Batch: 434/468, discriminator loss real = 3.4189255870842317e-08, disciminator loss fake = 2.6066549253300764e-05, generator loss = 10.70556640625\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 1, Batch: 435/468, discriminator loss real = 2.982629476733223e-09, disciminator loss fake = 2.7665017114486545e-05, generator loss = 10.833316802978516\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 1, Batch: 436/468, discriminator loss real = 6.350002195176785e-07, disciminator loss fake = 2.4993591068778187e-05, generator loss = 10.769201278686523\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 1, Batch: 437/468, discriminator loss real = 4.3243589264996274e-10, disciminator loss fake = 2.390085137449205e-05, generator loss = 10.724111557006836\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 1, Batch: 438/468, discriminator loss real = 1.1852999692862909e-09, disciminator loss fake = 2.5663714041002095e-05, generator loss = 10.834441184997559\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 1, Batch: 439/468, discriminator loss real = 2.0783556919923285e-07, disciminator loss fake = 2.483510979800485e-05, generator loss = 10.806081771850586\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 1, Batch: 440/468, discriminator loss real = 2.092264139719191e-08, disciminator loss fake = 2.151097942260094e-05, generator loss = 10.986074447631836\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 1, Batch: 441/468, discriminator loss real = 3.3078936212405097e-06, disciminator loss fake = 2.4752534955041483e-05, generator loss = 10.778587341308594\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 1, Batch: 442/468, discriminator loss real = 1.6450329098915972e-07, disciminator loss fake = 2.1745363483205438e-05, generator loss = 10.864676475524902\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 1, Batch: 443/468, discriminator loss real = 7.466203442163533e-07, disciminator loss fake = 2.249217141070403e-05, generator loss = 10.79374885559082\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 1, Batch: 444/468, discriminator loss real = 1.0020874130489688e-09, disciminator loss fake = 2.2080104827182367e-05, generator loss = 10.955944061279297\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 1, Batch: 445/468, discriminator loss real = 7.275870572698295e-09, disciminator loss fake = 2.4117278371704742e-05, generator loss = 10.993354797363281\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 1, Batch: 446/468, discriminator loss real = 8.977112803121301e-11, disciminator loss fake = 2.2539239580510184e-05, generator loss = 10.967659950256348\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 1, Batch: 447/468, discriminator loss real = 6.897634818869847e-08, disciminator loss fake = 1.809127388696652e-05, generator loss = 11.024314880371094\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 1, Batch: 448/468, discriminator loss real = 8.712264047971985e-07, disciminator loss fake = 2.0982299247407354e-05, generator loss = 11.039267539978027\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 1, Batch: 449/468, discriminator loss real = 1.1167670344036651e-08, disciminator loss fake = 1.8762118997983634e-05, generator loss = 10.858835220336914\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 1, Batch: 450/468, discriminator loss real = 5.712730288820467e-09, disciminator loss fake = 2.3897320716059767e-05, generator loss = 10.934574127197266\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 1, Batch: 451/468, discriminator loss real = 7.187271080510982e-07, disciminator loss fake = 2.4307753847097047e-05, generator loss = 11.071349143981934\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 1, Batch: 452/468, discriminator loss real = 1.2589657671924215e-07, disciminator loss fake = 1.9785416952800006e-05, generator loss = 11.082324028015137\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 1, Batch: 453/468, discriminator loss real = 7.330837661356782e-07, disciminator loss fake = 1.8202015780843794e-05, generator loss = 11.236273765563965\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 1, Batch: 454/468, discriminator loss real = 2.166098784073256e-05, disciminator loss fake = 2.1343466869439e-05, generator loss = 11.092691421508789\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 1, Batch: 455/468, discriminator loss real = 1.1372856434377354e-08, disciminator loss fake = 2.0090414182050154e-05, generator loss = 11.050724029541016\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 1, Batch: 456/468, discriminator loss real = 0.00022232743503991514, disciminator loss fake = 1.7686059436528012e-05, generator loss = 10.934324264526367\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 1, Batch: 457/468, discriminator loss real = 0.001079960959032178, disciminator loss fake = 2.5907316739903763e-05, generator loss = 10.832867622375488\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 1, Batch: 458/468, discriminator loss real = 1.5255793073265522e-07, disciminator loss fake = 2.6685840566642582e-05, generator loss = 10.733850479125977\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 1, Batch: 459/468, discriminator loss real = 4.2030628977229867e-10, disciminator loss fake = 3.389063203940168e-05, generator loss = 10.620960235595703\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 1, Batch: 460/468, discriminator loss real = 3.724387553916131e-08, disciminator loss fake = 3.149791155010462e-05, generator loss = 10.398815155029297\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 1, Batch: 461/468, discriminator loss real = 3.69906160813116e-06, disciminator loss fake = 4.397642260300927e-05, generator loss = 10.441749572753906\n",
      "2/2 [==============================] - 0s 38ms/step\n",
      "Epoch: 1, Batch: 462/468, discriminator loss real = 8.475555546283431e-07, disciminator loss fake = 4.286752300686203e-05, generator loss = 10.361034393310547\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 1, Batch: 463/468, discriminator loss real = 1.004089389758378e-12, disciminator loss fake = 4.687856198870577e-05, generator loss = 10.210500717163086\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 1, Batch: 464/468, discriminator loss real = 8.337344703512883e-12, disciminator loss fake = 4.6682514948770404e-05, generator loss = 10.253850936889648\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 1, Batch: 465/468, discriminator loss real = 1.2103736068969084e-10, disciminator loss fake = 4.613424971466884e-05, generator loss = 10.155760765075684\n",
      "2/2 [==============================] - 0s 31ms/step\n",
      "Epoch: 1, Batch: 466/468, discriminator loss real = 1.1405095617922356e-10, disciminator loss fake = 4.9536254664417356e-05, generator loss = 10.191219329833984\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 1, Batch: 467/468, discriminator loss real = 2.374580809760829e-10, disciminator loss fake = 4.961019294569269e-05, generator loss = 10.244850158691406\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 1, Batch: 468/468, discriminator loss real = 2.1395210256236474e-11, disciminator loss fake = 4.727144187199883e-05, generator loss = 10.308320045471191\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DHRUVA\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 2, Batch: 1/468, discriminator loss real = 1.977135261066465e-10, disciminator loss fake = 5.124264134792611e-05, generator loss = 10.15060806274414\n",
      "2/2 [==============================] - 0s 38ms/step\n",
      "Epoch: 2, Batch: 2/468, discriminator loss real = 8.522993075188445e-12, disciminator loss fake = 5.19503046234604e-05, generator loss = 10.232269287109375\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 2, Batch: 3/468, discriminator loss real = 1.298683161010672e-09, disciminator loss fake = 5.10554455104284e-05, generator loss = 10.319881439208984\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 2, Batch: 4/468, discriminator loss real = 6.272408703544841e-10, disciminator loss fake = 4.883181827608496e-05, generator loss = 10.349138259887695\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 2, Batch: 5/468, discriminator loss real = 1.8052864447781758e-07, disciminator loss fake = 3.72088179574348e-05, generator loss = 10.29405689239502\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 2, Batch: 6/468, discriminator loss real = 6.334204272206989e-08, disciminator loss fake = 4.221468043397181e-05, generator loss = 10.423097610473633\n",
      "2/2 [==============================] - 0s 37ms/step\n",
      "Epoch: 2, Batch: 7/468, discriminator loss real = 1.0789801763166906e-07, disciminator loss fake = 4.7828652895987034e-05, generator loss = 10.492884635925293\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 2, Batch: 8/468, discriminator loss real = 7.823020951036597e-07, disciminator loss fake = 3.8721169403288513e-05, generator loss = 10.419832229614258\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 2, Batch: 9/468, discriminator loss real = 1.1405503208550272e-09, disciminator loss fake = 4.5095628593117e-05, generator loss = 10.473453521728516\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 2, Batch: 10/468, discriminator loss real = 3.689894223501966e-10, disciminator loss fake = 4.065419125254266e-05, generator loss = 10.495620727539062\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 2, Batch: 11/468, discriminator loss real = 2.357572748135084e-10, disciminator loss fake = 3.58872493961826e-05, generator loss = 10.438445091247559\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 2, Batch: 12/468, discriminator loss real = 1.4501769229902095e-10, disciminator loss fake = 3.063412077608518e-05, generator loss = 10.459646224975586\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 2, Batch: 13/468, discriminator loss real = 1.0628051327898902e-08, disciminator loss fake = 2.865212081815116e-05, generator loss = 10.657333374023438\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 2, Batch: 14/468, discriminator loss real = 2.128021980851713e-09, disciminator loss fake = 3.7045661883894354e-05, generator loss = 10.521860122680664\n",
      "2/2 [==============================] - 0s 37ms/step\n",
      "Epoch: 2, Batch: 15/468, discriminator loss real = 5.430870260170195e-07, disciminator loss fake = 3.9574420952703804e-05, generator loss = 10.713326454162598\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 2, Batch: 16/468, discriminator loss real = 4.05077882348337e-09, disciminator loss fake = 3.397196269361302e-05, generator loss = 10.652048110961914\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 2, Batch: 17/468, discriminator loss real = 3.4033412532608054e-08, disciminator loss fake = 3.092770202783868e-05, generator loss = 10.82776165008545\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 2, Batch: 18/468, discriminator loss real = 1.0820887297313675e-08, disciminator loss fake = 2.409944499959238e-05, generator loss = 10.597217559814453\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 19/468, discriminator loss real = 4.1962898649217095e-06, disciminator loss fake = 2.8032722184434533e-05, generator loss = 10.78612232208252\n",
      "2/2 [==============================] - 0s 29ms/step\n",
      "Epoch: 2, Batch: 20/468, discriminator loss real = 3.337675380521432e-08, disciminator loss fake = 2.9063485271763057e-05, generator loss = 10.682666778564453\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 2, Batch: 21/468, discriminator loss real = 4.202920678153532e-08, disciminator loss fake = 3.0825081921648234e-05, generator loss = 10.721951484680176\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 2, Batch: 22/468, discriminator loss real = 2.20390302274609e-06, disciminator loss fake = 2.8618507712963037e-05, generator loss = 10.761885643005371\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 2, Batch: 23/468, discriminator loss real = 4.97041080169125e-12, disciminator loss fake = 2.61299737758236e-05, generator loss = 10.824586868286133\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 2, Batch: 24/468, discriminator loss real = 7.301916016277943e-11, disciminator loss fake = 3.002837547683157e-05, generator loss = 10.783473014831543\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 2, Batch: 25/468, discriminator loss real = 2.98593025305216e-11, disciminator loss fake = 2.615657285787165e-05, generator loss = 10.922179222106934\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 26/468, discriminator loss real = 2.3870334597830833e-09, disciminator loss fake = 2.2901876945979893e-05, generator loss = 10.896170616149902\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 2, Batch: 27/468, discriminator loss real = 2.967577572565716e-10, disciminator loss fake = 2.3380927814287134e-05, generator loss = 10.83375358581543\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 2, Batch: 28/468, discriminator loss real = 1.4795545344448158e-10, disciminator loss fake = 2.130127904820256e-05, generator loss = 10.915705680847168\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 2, Batch: 29/468, discriminator loss real = 2.245780876819481e-07, disciminator loss fake = 2.433920235489495e-05, generator loss = 10.978340148925781\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 2, Batch: 30/468, discriminator loss real = 8.125913382173167e-07, disciminator loss fake = 2.55564500548644e-05, generator loss = 10.842672348022461\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 2, Batch: 31/468, discriminator loss real = 1.663086751646503e-10, disciminator loss fake = 2.8457361622713506e-05, generator loss = 11.037303924560547\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 32/468, discriminator loss real = 3.8147661030052404e-07, disciminator loss fake = 2.2341646399581805e-05, generator loss = 10.957967758178711\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 2, Batch: 33/468, discriminator loss real = 4.755494609209876e-11, disciminator loss fake = 2.064158979919739e-05, generator loss = 10.964292526245117\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 2, Batch: 34/468, discriminator loss real = 5.388178436760427e-08, disciminator loss fake = 2.0954244973836467e-05, generator loss = 10.984210968017578\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 2, Batch: 35/468, discriminator loss real = 5.534117164529562e-08, disciminator loss fake = 2.166826743632555e-05, generator loss = 11.021340370178223\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 2, Batch: 36/468, discriminator loss real = 1.0306892228584275e-08, disciminator loss fake = 1.9770954168052413e-05, generator loss = 11.016963958740234\n",
      "2/2 [==============================] - 0s 32ms/step\n",
      "Epoch: 2, Batch: 37/468, discriminator loss real = 5.16253248861176e-06, disciminator loss fake = 2.1508487407118082e-05, generator loss = 11.148215293884277\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 2, Batch: 38/468, discriminator loss real = 2.47879916059901e-06, disciminator loss fake = 2.6995647203875706e-05, generator loss = 11.06158447265625\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 2, Batch: 39/468, discriminator loss real = 7.18326264177449e-05, disciminator loss fake = 2.2810072550782934e-05, generator loss = 11.009835243225098\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 2, Batch: 40/468, discriminator loss real = 2.5895923627672346e-08, disciminator loss fake = 1.9493432773742825e-05, generator loss = 10.995841026306152\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 2, Batch: 41/468, discriminator loss real = 1.2012858485732636e-09, disciminator loss fake = 2.247381053166464e-05, generator loss = 11.165851593017578\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 2, Batch: 42/468, discriminator loss real = 5.410666359395577e-10, disciminator loss fake = 2.06846852961462e-05, generator loss = 11.185094833374023\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 2, Batch: 43/468, discriminator loss real = 2.9366244991280155e-09, disciminator loss fake = 1.9353356037754565e-05, generator loss = 11.16049575805664\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 2, Batch: 44/468, discriminator loss real = 7.616498805873562e-06, disciminator loss fake = 1.7398408090230078e-05, generator loss = 11.038228988647461\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 2, Batch: 45/468, discriminator loss real = 1.3985420821427397e-07, disciminator loss fake = 2.1707161067752168e-05, generator loss = 11.06226634979248\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 2, Batch: 46/468, discriminator loss real = 1.816253671904633e-07, disciminator loss fake = 2.1799865862703882e-05, generator loss = 11.211363792419434\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 2, Batch: 47/468, discriminator loss real = 8.263451256596e-09, disciminator loss fake = 2.2223637643037364e-05, generator loss = 11.161092758178711\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 2, Batch: 48/468, discriminator loss real = 2.688361888658619e-08, disciminator loss fake = 1.9344306565471925e-05, generator loss = 11.151836395263672\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 49/468, discriminator loss real = 8.886134310159832e-06, disciminator loss fake = 1.5877729310886934e-05, generator loss = 11.251627922058105\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 2, Batch: 50/468, discriminator loss real = 0.0001619592512724921, disciminator loss fake = 1.9927607354475185e-05, generator loss = 11.207548141479492\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 2, Batch: 51/468, discriminator loss real = 7.070868264236196e-07, disciminator loss fake = 1.7726664736983366e-05, generator loss = 11.225461959838867\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 52/468, discriminator loss real = 5.719332989428949e-07, disciminator loss fake = 1.950600380951073e-05, generator loss = 11.205949783325195\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 2, Batch: 53/468, discriminator loss real = 7.749496877540452e-11, disciminator loss fake = 1.8635899323271587e-05, generator loss = 11.190458297729492\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 2, Batch: 54/468, discriminator loss real = 1.3460301317991252e-07, disciminator loss fake = 2.022630360443145e-05, generator loss = 11.260095596313477\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 2, Batch: 55/468, discriminator loss real = 5.601372699004514e-10, disciminator loss fake = 2.038352977251634e-05, generator loss = 11.116838455200195\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 2, Batch: 56/468, discriminator loss real = 3.0292758879113535e-07, disciminator loss fake = 2.2635522327618673e-05, generator loss = 11.071148872375488\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 2, Batch: 57/468, discriminator loss real = 5.020775462050153e-10, disciminator loss fake = 1.8746493879007176e-05, generator loss = 11.16080379486084\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 2, Batch: 58/468, discriminator loss real = 3.4016952099591435e-07, disciminator loss fake = 1.758465077728033e-05, generator loss = 11.143416404724121\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 2, Batch: 59/468, discriminator loss real = 5.472708952680705e-09, disciminator loss fake = 1.4356935935211368e-05, generator loss = 11.16110610961914\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 2, Batch: 60/468, discriminator loss real = 1.733852883489817e-08, disciminator loss fake = 1.5704046745668165e-05, generator loss = 11.112659454345703\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 2, Batch: 61/468, discriminator loss real = 2.3114148817171554e-08, disciminator loss fake = 1.8567181541584432e-05, generator loss = 11.253604888916016\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 2, Batch: 62/468, discriminator loss real = 6.542040242862868e-10, disciminator loss fake = 1.520130354037974e-05, generator loss = 11.21839427947998\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 2, Batch: 63/468, discriminator loss real = 2.968154433347081e-07, disciminator loss fake = 1.7563816072652116e-05, generator loss = 11.18039321899414\n",
      "2/2 [==============================] - 0s 37ms/step\n",
      "Epoch: 2, Batch: 64/468, discriminator loss real = 5.180012294658809e-07, disciminator loss fake = 1.8580314645078033e-05, generator loss = 11.130600929260254\n",
      "2/2 [==============================] - 0s 29ms/step\n",
      "Epoch: 2, Batch: 65/468, discriminator loss real = 5.137983372094368e-10, disciminator loss fake = 1.7411955923307687e-05, generator loss = 11.304206848144531\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 2, Batch: 66/468, discriminator loss real = 0.0007821515901014209, disciminator loss fake = 1.9149607396684587e-05, generator loss = 11.11072826385498\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 2, Batch: 67/468, discriminator loss real = 3.996318298504775e-08, disciminator loss fake = 2.3772452550474554e-05, generator loss = 10.982444763183594\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 2, Batch: 68/468, discriminator loss real = 8.952898866709802e-08, disciminator loss fake = 2.830328230629675e-05, generator loss = 11.007535934448242\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 2, Batch: 69/468, discriminator loss real = 1.4524978553254186e-08, disciminator loss fake = 3.0896269890945405e-05, generator loss = 10.909262657165527\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 2, Batch: 70/468, discriminator loss real = 1.5302423150842515e-07, disciminator loss fake = 2.9860573704354465e-05, generator loss = 10.794963836669922\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 71/468, discriminator loss real = 5.0875045417342335e-05, disciminator loss fake = 2.604211840662174e-05, generator loss = 10.77677059173584\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 2, Batch: 72/468, discriminator loss real = 1.3825772471331987e-10, disciminator loss fake = 3.24703250953462e-05, generator loss = 10.67786979675293\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 2, Batch: 73/468, discriminator loss real = 2.599815328296895e-11, disciminator loss fake = 3.245020707254298e-05, generator loss = 10.758745193481445\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 2, Batch: 74/468, discriminator loss real = 3.752954000901809e-07, disciminator loss fake = 3.3989585062954575e-05, generator loss = 10.670169830322266\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 2, Batch: 75/468, discriminator loss real = 1.0464458632952756e-08, disciminator loss fake = 3.0807219445705414e-05, generator loss = 10.690388679504395\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 2, Batch: 76/468, discriminator loss real = 1.7389131801159863e-10, disciminator loss fake = 2.720579504966736e-05, generator loss = 10.678088188171387\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 2, Batch: 77/468, discriminator loss real = 1.363706161328082e-07, disciminator loss fake = 3.408435804885812e-05, generator loss = 10.697297096252441\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 2, Batch: 78/468, discriminator loss real = 6.714302891452917e-09, disciminator loss fake = 3.4273438359377906e-05, generator loss = 10.635168075561523\n",
      "2/2 [==============================] - 0s 39ms/step\n",
      "Epoch: 2, Batch: 79/468, discriminator loss real = 5.5479325994367557e-11, disciminator loss fake = 2.4858320102794096e-05, generator loss = 10.766801834106445\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 2, Batch: 80/468, discriminator loss real = 1.040044272926366e-09, disciminator loss fake = 3.3337288186885417e-05, generator loss = 10.528919219970703\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 2, Batch: 81/468, discriminator loss real = 1.4771113221456744e-09, disciminator loss fake = 3.128817479591817e-05, generator loss = 10.829872131347656\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 2, Batch: 82/468, discriminator loss real = 1.1506047226106375e-09, disciminator loss fake = 2.817105269059539e-05, generator loss = 10.768272399902344\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 2, Batch: 83/468, discriminator loss real = 2.212222592612445e-12, disciminator loss fake = 2.3443401005351916e-05, generator loss = 10.682771682739258\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 2, Batch: 84/468, discriminator loss real = 4.2037612502099364e-08, disciminator loss fake = 3.152629142277874e-05, generator loss = 10.736932754516602\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 2, Batch: 85/468, discriminator loss real = 2.4535981424378406e-07, disciminator loss fake = 2.5326478862552904e-05, generator loss = 10.843923568725586\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 2, Batch: 86/468, discriminator loss real = 6.07782535411161e-09, disciminator loss fake = 2.726234197325539e-05, generator loss = 10.964218139648438\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 2, Batch: 87/468, discriminator loss real = 2.5710610529472433e-08, disciminator loss fake = 3.1791350920684636e-05, generator loss = 10.842103004455566\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 2, Batch: 88/468, discriminator loss real = 1.756931844454357e-08, disciminator loss fake = 2.26900156121701e-05, generator loss = 10.890314102172852\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 2, Batch: 89/468, discriminator loss real = 1.923282866300724e-09, disciminator loss fake = 2.7100051738671027e-05, generator loss = 10.932355880737305\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 90/468, discriminator loss real = 1.4896042177525715e-09, disciminator loss fake = 2.601776213850826e-05, generator loss = 10.88255786895752\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 2, Batch: 91/468, discriminator loss real = 7.465766893588466e-11, disciminator loss fake = 2.5165867555188015e-05, generator loss = 11.023993492126465\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 2, Batch: 92/468, discriminator loss real = 4.734723901833604e-08, disciminator loss fake = 1.9269702534074895e-05, generator loss = 10.908061027526855\n",
      "2/2 [==============================] - 0s 38ms/step\n",
      "Epoch: 2, Batch: 93/468, discriminator loss real = 1.839193686237195e-09, disciminator loss fake = 1.83132870006375e-05, generator loss = 11.015497207641602\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 2, Batch: 94/468, discriminator loss real = 1.5430863531396e-10, disciminator loss fake = 2.124346065102145e-05, generator loss = 11.092168807983398\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 2, Batch: 95/468, discriminator loss real = 1.7019496922898725e-08, disciminator loss fake = 2.4103890609694645e-05, generator loss = 11.136347770690918\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 2, Batch: 96/468, discriminator loss real = 2.8719279725919478e-05, disciminator loss fake = 2.1508334612008184e-05, generator loss = 10.989856719970703\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 2, Batch: 97/468, discriminator loss real = 0.0001405710499966517, disciminator loss fake = 2.1327094145817682e-05, generator loss = 11.017722129821777\n",
      "2/2 [==============================] - 0s 38ms/step\n",
      "Epoch: 2, Batch: 98/468, discriminator loss real = 0.0010562462266534567, disciminator loss fake = 2.4533759642508812e-05, generator loss = 10.830585479736328\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 2, Batch: 99/468, discriminator loss real = 1.6770531630072583e-08, disciminator loss fake = 3.669945363071747e-05, generator loss = 10.485048294067383\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 2, Batch: 100/468, discriminator loss real = 7.303920922935303e-13, disciminator loss fake = 4.511338920565322e-05, generator loss = 10.512250900268555\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 2, Batch: 101/468, discriminator loss real = 1.282985948591886e-07, disciminator loss fake = 4.854315920965746e-05, generator loss = 10.417560577392578\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 2, Batch: 102/468, discriminator loss real = 4.285496436884362e-12, disciminator loss fake = 5.609842264675535e-05, generator loss = 10.172985076904297\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 2, Batch: 103/468, discriminator loss real = 2.5153006344424966e-09, disciminator loss fake = 5.9551995946094394e-05, generator loss = 10.038018226623535\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 2, Batch: 104/468, discriminator loss real = 1.4346407617438217e-08, disciminator loss fake = 5.168604911887087e-05, generator loss = 10.093372344970703\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 2, Batch: 105/468, discriminator loss real = 3.6618552634593016e-09, disciminator loss fake = 7.773777178954333e-05, generator loss = 10.007884979248047\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 106/468, discriminator loss real = 7.603971619030148e-11, disciminator loss fake = 6.944707274669781e-05, generator loss = 10.019922256469727\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 2, Batch: 107/468, discriminator loss real = 1.832774998433706e-08, disciminator loss fake = 6.595926970476285e-05, generator loss = 9.915176391601562\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 2, Batch: 108/468, discriminator loss real = 3.056909747556347e-08, disciminator loss fake = 5.622406752081588e-05, generator loss = 10.101402282714844\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 2, Batch: 109/468, discriminator loss real = 3.447358067412698e-12, disciminator loss fake = 6.198776100063697e-05, generator loss = 10.227838516235352\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 110/468, discriminator loss real = 3.20871396120026e-09, disciminator loss fake = 5.37218147655949e-05, generator loss = 10.255027770996094\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 2, Batch: 111/468, discriminator loss real = 3.793300396015553e-11, disciminator loss fake = 5.216154386289418e-05, generator loss = 10.190008163452148\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 2, Batch: 112/468, discriminator loss real = 1.0291997809552811e-10, disciminator loss fake = 6.436007242882624e-05, generator loss = 10.255139350891113\n",
      "2/2 [==============================] - 0s 38ms/step\n",
      "Epoch: 2, Batch: 113/468, discriminator loss real = 2.648492861655194e-13, disciminator loss fake = 4.8749963752925396e-05, generator loss = 10.22685432434082\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 2, Batch: 114/468, discriminator loss real = 2.717172840893678e-11, disciminator loss fake = 5.653986590914428e-05, generator loss = 10.428290367126465\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 2, Batch: 115/468, discriminator loss real = 6.634943705563501e-10, disciminator loss fake = 5.080862683826126e-05, generator loss = 10.498705863952637\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 2, Batch: 116/468, discriminator loss real = 9.873463158172058e-11, disciminator loss fake = 4.03734520659782e-05, generator loss = 10.56543254852295\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 2, Batch: 117/468, discriminator loss real = 4.6075947501833525e-09, disciminator loss fake = 4.050735878990963e-05, generator loss = 10.51834774017334\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 2, Batch: 118/468, discriminator loss real = 4.060777269998539e-10, disciminator loss fake = 3.4362841688562185e-05, generator loss = 10.672442436218262\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 2, Batch: 119/468, discriminator loss real = 2.9531449854403036e-06, disciminator loss fake = 3.570210174075328e-05, generator loss = 10.715666770935059\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 2, Batch: 120/468, discriminator loss real = 1.6035748284792817e-09, disciminator loss fake = 2.9461636586347595e-05, generator loss = 10.739177703857422\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 2, Batch: 121/468, discriminator loss real = 1.8691551084693003e-10, disciminator loss fake = 3.869970532832667e-05, generator loss = 10.731629371643066\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 2, Batch: 122/468, discriminator loss real = 3.1902700481367674e-09, disciminator loss fake = 2.4882510842871852e-05, generator loss = 10.674088478088379\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 2, Batch: 123/468, discriminator loss real = 4.9346663644200817e-08, disciminator loss fake = 2.668468005140312e-05, generator loss = 11.036821365356445\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 2, Batch: 124/468, discriminator loss real = 2.753942074384952e-10, disciminator loss fake = 3.18406309816055e-05, generator loss = 10.929756164550781\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 2, Batch: 125/468, discriminator loss real = 3.8069697438913863e-07, disciminator loss fake = 2.4853688955772668e-05, generator loss = 10.892623901367188\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 126/468, discriminator loss real = 4.218179971982039e-11, disciminator loss fake = 2.4941331503214315e-05, generator loss = 11.02932071685791\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 2, Batch: 127/468, discriminator loss real = 3.155026934154037e-11, disciminator loss fake = 2.5358614948345348e-05, generator loss = 11.078973770141602\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 128/468, discriminator loss real = 1.566828359500505e-05, disciminator loss fake = 3.0300081562018022e-05, generator loss = 10.915687561035156\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 2, Batch: 129/468, discriminator loss real = 6.444009909012394e-11, disciminator loss fake = 2.2336629626806825e-05, generator loss = 11.122997283935547\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 2, Batch: 130/468, discriminator loss real = 5.499152244681227e-09, disciminator loss fake = 2.336851684958674e-05, generator loss = 11.14871883392334\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 2, Batch: 131/468, discriminator loss real = 1.7957511033728224e-08, disciminator loss fake = 1.887760663521476e-05, generator loss = 11.170751571655273\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 2, Batch: 132/468, discriminator loss real = 6.136497745501401e-07, disciminator loss fake = 1.9613691620179452e-05, generator loss = 11.078363418579102\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 2, Batch: 133/468, discriminator loss real = 2.1326894028561583e-08, disciminator loss fake = 2.063954707409721e-05, generator loss = 11.06963062286377\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 2, Batch: 134/468, discriminator loss real = 7.456254991211608e-08, disciminator loss fake = 1.5862227883189917e-05, generator loss = 11.188362121582031\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 2, Batch: 135/468, discriminator loss real = 1.451497428206494e-05, disciminator loss fake = 1.5662411897210404e-05, generator loss = 11.161453247070312\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 2, Batch: 136/468, discriminator loss real = 2.3306108778986534e-11, disciminator loss fake = 1.822490230551921e-05, generator loss = 11.377989768981934\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 2, Batch: 137/468, discriminator loss real = 2.438581834292991e-13, disciminator loss fake = 1.8394699509372003e-05, generator loss = 11.241025924682617\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 2, Batch: 138/468, discriminator loss real = 6.400439289677706e-09, disciminator loss fake = 1.759790029609576e-05, generator loss = 11.339886665344238\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 2, Batch: 139/468, discriminator loss real = 3.60326848749537e-05, disciminator loss fake = 2.000844688154757e-05, generator loss = 11.317296981811523\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 2, Batch: 140/468, discriminator loss real = 5.6499875888960105e-09, disciminator loss fake = 1.892236468847841e-05, generator loss = 11.239749908447266\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 2, Batch: 141/468, discriminator loss real = 6.978036282134781e-08, disciminator loss fake = 1.7441940144635737e-05, generator loss = 11.328109741210938\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 2, Batch: 142/468, discriminator loss real = 1.0937113614772898e-07, disciminator loss fake = 1.8754326447378844e-05, generator loss = 11.29984188079834\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 2, Batch: 143/468, discriminator loss real = 9.454821281451586e-08, disciminator loss fake = 1.4127513168205041e-05, generator loss = 11.303475379943848\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 2, Batch: 144/468, discriminator loss real = 2.923333575211018e-09, disciminator loss fake = 1.5898469428066164e-05, generator loss = 11.505615234375\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 2, Batch: 145/468, discriminator loss real = 2.5337100473254992e-11, disciminator loss fake = 1.844254438765347e-05, generator loss = 11.243356704711914\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 2, Batch: 146/468, discriminator loss real = 1.5028789324134095e-09, disciminator loss fake = 1.6672624042257667e-05, generator loss = 11.332889556884766\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 2, Batch: 147/468, discriminator loss real = 5.015833970389849e-09, disciminator loss fake = 1.9050210539717227e-05, generator loss = 11.352579116821289\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 2, Batch: 148/468, discriminator loss real = 1.8296226755865064e-08, disciminator loss fake = 1.7919439414981753e-05, generator loss = 11.625146865844727\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 2, Batch: 149/468, discriminator loss real = 2.4553123978421354e-09, disciminator loss fake = 1.7900089005706832e-05, generator loss = 11.512853622436523\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 2, Batch: 150/468, discriminator loss real = 1.134791913215416e-10, disciminator loss fake = 1.7310750990873203e-05, generator loss = 11.41196060180664\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 151/468, discriminator loss real = 6.005572150691307e-10, disciminator loss fake = 1.6646736185066402e-05, generator loss = 11.525161743164062\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 2, Batch: 152/468, discriminator loss real = 1.0328530253289614e-09, disciminator loss fake = 2.1189553081057966e-05, generator loss = 11.53402042388916\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 2, Batch: 153/468, discriminator loss real = 2.104017511328493e-07, disciminator loss fake = 1.600968425918836e-05, generator loss = 11.49203872680664\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 2, Batch: 154/468, discriminator loss real = 5.284359971824415e-08, disciminator loss fake = 1.1373336747055873e-05, generator loss = 11.413220405578613\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 2, Batch: 155/468, discriminator loss real = 9.890994334682546e-08, disciminator loss fake = 1.6731482901377603e-05, generator loss = 11.599918365478516\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 2, Batch: 156/468, discriminator loss real = 5.150299031697614e-08, disciminator loss fake = 1.3605665117211174e-05, generator loss = 11.666569709777832\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 2, Batch: 157/468, discriminator loss real = 2.6824473198239218e-11, disciminator loss fake = 1.2073736797901802e-05, generator loss = 11.57370376586914\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 158/468, discriminator loss real = 3.760926237106332e-09, disciminator loss fake = 1.507172237324994e-05, generator loss = 11.625547409057617\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 2, Batch: 159/468, discriminator loss real = 2.5686324178764153e-09, disciminator loss fake = 1.2238604540470988e-05, generator loss = 11.604757308959961\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 2, Batch: 160/468, discriminator loss real = 3.1456732330070736e-08, disciminator loss fake = 1.3410410247161053e-05, generator loss = 11.63424015045166\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 2, Batch: 161/468, discriminator loss real = 4.2298556324205094e-10, disciminator loss fake = 1.4376229046320077e-05, generator loss = 11.62574291229248\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 2, Batch: 162/468, discriminator loss real = 2.3263217741043007e-10, disciminator loss fake = 1.2563295967993326e-05, generator loss = 11.709848403930664\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 2, Batch: 163/468, discriminator loss real = 8.702175868791073e-09, disciminator loss fake = 1.3010607290198095e-05, generator loss = 11.75183391571045\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 2, Batch: 164/468, discriminator loss real = 1.4479584198312523e-10, disciminator loss fake = 8.608561984146945e-06, generator loss = 11.631645202636719\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 2, Batch: 165/468, discriminator loss real = 1.7927146473084576e-05, disciminator loss fake = 1.0722131264628842e-05, generator loss = 11.716592788696289\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 2, Batch: 166/468, discriminator loss real = 1.8670036627810305e-09, disciminator loss fake = 1.208160483656684e-05, generator loss = 11.690690994262695\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 2, Batch: 167/468, discriminator loss real = 1.9091568503881717e-07, disciminator loss fake = 1.3431885236059316e-05, generator loss = 11.691461563110352\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 168/468, discriminator loss real = 2.5169375264533222e-11, disciminator loss fake = 1.1266137335042004e-05, generator loss = 11.74732494354248\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 2, Batch: 169/468, discriminator loss real = 3.0859073629763145e-10, disciminator loss fake = 9.724968549562618e-06, generator loss = 11.800689697265625\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 2, Batch: 170/468, discriminator loss real = 2.3845505126018907e-08, disciminator loss fake = 1.1201696906937286e-05, generator loss = 11.69474983215332\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 2, Batch: 171/468, discriminator loss real = 2.810068053804571e-06, disciminator loss fake = 9.805871741264127e-06, generator loss = 11.741989135742188\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 2, Batch: 172/468, discriminator loss real = 1.2969370022375415e-10, disciminator loss fake = 9.852159564616159e-06, generator loss = 11.709572792053223\n",
      "2/2 [==============================] - 0s 35ms/step\n",
      "Epoch: 2, Batch: 173/468, discriminator loss real = 1.2983490671469866e-10, disciminator loss fake = 1.0301855581928976e-05, generator loss = 11.896798133850098\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 2, Batch: 174/468, discriminator loss real = 2.096600759671219e-08, disciminator loss fake = 1.3140394003130496e-05, generator loss = 11.687849044799805\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 2, Batch: 175/468, discriminator loss real = 0.000495362444780767, disciminator loss fake = 1.1970421837759204e-05, generator loss = 11.697185516357422\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 2, Batch: 176/468, discriminator loss real = 1.9572022225133878e-08, disciminator loss fake = 1.4361308785737492e-05, generator loss = 11.565957069396973\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 2, Batch: 177/468, discriminator loss real = 1.9765097891699668e-10, disciminator loss fake = 1.5763716874062084e-05, generator loss = 11.45185375213623\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 2, Batch: 178/468, discriminator loss real = 2.7446889205862135e-08, disciminator loss fake = 1.7486881915829144e-05, generator loss = 11.37054443359375\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 2, Batch: 179/468, discriminator loss real = 5.136057690258156e-10, disciminator loss fake = 2.0318027964094654e-05, generator loss = 11.31378173828125\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 2, Batch: 180/468, discriminator loss real = 2.55257970316336e-09, disciminator loss fake = 1.5754092601127923e-05, generator loss = 11.217547416687012\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 2, Batch: 181/468, discriminator loss real = 4.794231851790176e-12, disciminator loss fake = 1.5764122508699074e-05, generator loss = 11.252880096435547\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 2, Batch: 182/468, discriminator loss real = 1.6043441575241957e-10, disciminator loss fake = 1.7260283129871823e-05, generator loss = 11.359496116638184\n",
      "2/2 [==============================] - 0s 37ms/step\n",
      "Epoch: 2, Batch: 183/468, discriminator loss real = 1.2743334165676856e-10, disciminator loss fake = 2.1220259441179223e-05, generator loss = 11.316946029663086\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 2, Batch: 184/468, discriminator loss real = 1.164452889668155e-08, disciminator loss fake = 1.5193707440630533e-05, generator loss = 11.262615203857422\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 2, Batch: 185/468, discriminator loss real = 3.453602070990769e-09, disciminator loss fake = 2.201325332862325e-05, generator loss = 11.202630043029785\n",
      "2/2 [==============================] - 0s 37ms/step\n",
      "Epoch: 2, Batch: 186/468, discriminator loss real = 2.5579115214835468e-11, disciminator loss fake = 2.0162306100246496e-05, generator loss = 11.333137512207031\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 2, Batch: 187/468, discriminator loss real = 5.350073162269098e-10, disciminator loss fake = 1.823813909140881e-05, generator loss = 11.232099533081055\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 2, Batch: 188/468, discriminator loss real = 1.9695511888073725e-09, disciminator loss fake = 1.777214311005082e-05, generator loss = 11.21670150756836\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 2, Batch: 189/468, discriminator loss real = 5.11395725766306e-08, disciminator loss fake = 2.0263121768948622e-05, generator loss = 11.354778289794922\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 2, Batch: 190/468, discriminator loss real = 1.4590004759895692e-08, disciminator loss fake = 2.4245433451142162e-05, generator loss = 11.250240325927734\n",
      "2/2 [==============================] - 0s 32ms/step\n",
      "Epoch: 2, Batch: 191/468, discriminator loss real = 1.7534195206891923e-09, disciminator loss fake = 1.8098588043358177e-05, generator loss = 11.30777645111084\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 2, Batch: 192/468, discriminator loss real = 5.495887165501978e-12, disciminator loss fake = 1.5597612218698487e-05, generator loss = 11.34325885772705\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 2, Batch: 193/468, discriminator loss real = 2.046725421678275e-05, disciminator loss fake = 1.8276259652338922e-05, generator loss = 11.3842191696167\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 2, Batch: 194/468, discriminator loss real = 1.1324711168825274e-09, disciminator loss fake = 1.8965258277603425e-05, generator loss = 11.3038330078125\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 2, Batch: 195/468, discriminator loss real = 6.17598061580793e-08, disciminator loss fake = 1.672587859502528e-05, generator loss = 11.503899574279785\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 2, Batch: 196/468, discriminator loss real = 1.2950239769438099e-09, disciminator loss fake = 2.0265242710593157e-05, generator loss = 11.264690399169922\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 2, Batch: 197/468, discriminator loss real = 1.0292940721967625e-08, disciminator loss fake = 1.4571967767551541e-05, generator loss = 11.450481414794922\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 198/468, discriminator loss real = 2.5974051354182848e-08, disciminator loss fake = 1.2379635336401407e-05, generator loss = 11.360694885253906\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 2, Batch: 199/468, discriminator loss real = 1.912369071987996e-07, disciminator loss fake = 1.8841503333533183e-05, generator loss = 11.279499053955078\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 2, Batch: 200/468, discriminator loss real = 2.9746291829724214e-07, disciminator loss fake = 1.2264657016203273e-05, generator loss = 11.546348571777344\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 2, Batch: 201/468, discriminator loss real = 2.1046974926774986e-11, disciminator loss fake = 1.6463554857182316e-05, generator loss = 11.482284545898438\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 2, Batch: 202/468, discriminator loss real = 5.459115937078707e-10, disciminator loss fake = 1.5806348528712988e-05, generator loss = 11.335508346557617\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 2, Batch: 203/468, discriminator loss real = 4.311798562639524e-08, disciminator loss fake = 1.3356789168028627e-05, generator loss = 11.394224166870117\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 204/468, discriminator loss real = 2.366497275918533e-10, disciminator loss fake = 1.282973425986711e-05, generator loss = 11.520358085632324\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 2, Batch: 205/468, discriminator loss real = 2.119765734470702e-12, disciminator loss fake = 1.3318081983015873e-05, generator loss = 11.57872200012207\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 2, Batch: 206/468, discriminator loss real = 2.8852547018232144e-09, disciminator loss fake = 1.4201419617165811e-05, generator loss = 11.525367736816406\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 2, Batch: 207/468, discriminator loss real = 6.850128797530886e-10, disciminator loss fake = 1.5100878954399377e-05, generator loss = 11.665082931518555\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 2, Batch: 208/468, discriminator loss real = 1.1539410138539097e-07, disciminator loss fake = 1.1677786460495554e-05, generator loss = 11.469034194946289\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 2, Batch: 209/468, discriminator loss real = 7.419131725328043e-05, disciminator loss fake = 1.063735362549778e-05, generator loss = 11.716484069824219\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 2, Batch: 210/468, discriminator loss real = 1.5622282134586385e-08, disciminator loss fake = 1.4467621440417133e-05, generator loss = 11.638341903686523\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 2, Batch: 211/468, discriminator loss real = 7.78808545431886e-11, disciminator loss fake = 1.3109233805153053e-05, generator loss = 11.539369583129883\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 2, Batch: 212/468, discriminator loss real = 1.0127064742349035e-09, disciminator loss fake = 1.331480234512128e-05, generator loss = 11.655265808105469\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 2, Batch: 213/468, discriminator loss real = 7.361779239545285e-07, disciminator loss fake = 1.566151149745565e-05, generator loss = 11.738396644592285\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 2, Batch: 214/468, discriminator loss real = 0.0002493395877536386, disciminator loss fake = 1.5480676665902138e-05, generator loss = 11.632747650146484\n",
      "2/2 [==============================] - 0s 39ms/step\n",
      "Epoch: 2, Batch: 215/468, discriminator loss real = 1.6884871278932678e-09, disciminator loss fake = 1.4272101907408796e-05, generator loss = 11.52166748046875\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 2, Batch: 216/468, discriminator loss real = 2.8494104853393765e-08, disciminator loss fake = 1.2019303540000692e-05, generator loss = 11.549208641052246\n",
      "2/2 [==============================] - 0s 33ms/step\n",
      "Epoch: 2, Batch: 217/468, discriminator loss real = 1.962351114936922e-11, disciminator loss fake = 1.6721740394132212e-05, generator loss = 11.38046932220459\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 2, Batch: 218/468, discriminator loss real = 2.3566110868289414e-11, disciminator loss fake = 1.823304410208948e-05, generator loss = 11.442951202392578\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 2, Batch: 219/468, discriminator loss real = 5.132236413629698e-09, disciminator loss fake = 1.2635517123271711e-05, generator loss = 11.425891876220703\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 220/468, discriminator loss real = 1.4088775285303612e-11, disciminator loss fake = 1.3081291399430484e-05, generator loss = 11.337215423583984\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 2, Batch: 221/468, discriminator loss real = 1.1495031593256044e-09, disciminator loss fake = 1.5146758414630312e-05, generator loss = 11.436470985412598\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 2, Batch: 222/468, discriminator loss real = 3.786627900126405e-09, disciminator loss fake = 1.4956443919800222e-05, generator loss = 11.535895347595215\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 2, Batch: 223/468, discriminator loss real = 3.2889757584086965e-10, disciminator loss fake = 1.431843156751711e-05, generator loss = 11.488592147827148\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 2, Batch: 224/468, discriminator loss real = 1.329430177055002e-10, disciminator loss fake = 1.597822119947523e-05, generator loss = 11.472701072692871\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 2, Batch: 225/468, discriminator loss real = 7.972225546382106e-08, disciminator loss fake = 1.652208811719902e-05, generator loss = 11.493871688842773\n",
      "2/2 [==============================] - 0s 36ms/step\n",
      "Epoch: 2, Batch: 226/468, discriminator loss real = 1.3966795719966285e-08, disciminator loss fake = 1.6089446944533847e-05, generator loss = 11.471013069152832\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 2, Batch: 227/468, discriminator loss real = 8.773580820187199e-12, disciminator loss fake = 1.9419025193201378e-05, generator loss = 11.578968048095703\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 2, Batch: 228/468, discriminator loss real = 2.372539720241207e-09, disciminator loss fake = 1.535849332867656e-05, generator loss = 11.66453742980957\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 229/468, discriminator loss real = 4.447260653250851e-05, disciminator loss fake = 1.3445929653244093e-05, generator loss = 11.521214485168457\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 2, Batch: 230/468, discriminator loss real = 1.3941366887593176e-06, disciminator loss fake = 1.7980572010856122e-05, generator loss = 11.487298965454102\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 231/468, discriminator loss real = 1.596652055013692e-07, disciminator loss fake = 1.51714784806245e-05, generator loss = 11.750984191894531\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 2, Batch: 232/468, discriminator loss real = 4.43598793253841e-07, disciminator loss fake = 1.3279099221108481e-05, generator loss = 11.381991386413574\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 2, Batch: 233/468, discriminator loss real = 1.393613821348491e-13, disciminator loss fake = 1.585595600772649e-05, generator loss = 11.598587036132812\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 2, Batch: 234/468, discriminator loss real = 1.0155115637289214e-09, disciminator loss fake = 1.2442074876162224e-05, generator loss = 11.584236145019531\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 2, Batch: 235/468, discriminator loss real = 7.747945396374689e-09, disciminator loss fake = 1.2755050192936324e-05, generator loss = 11.611542701721191\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 2, Batch: 236/468, discriminator loss real = 5.7063718195138335e-09, disciminator loss fake = 1.3090999345877208e-05, generator loss = 11.656251907348633\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 2, Batch: 237/468, discriminator loss real = 2.6437971811787975e-08, disciminator loss fake = 1.2291590792301577e-05, generator loss = 11.50336742401123\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 2, Batch: 238/468, discriminator loss real = 8.676415141906091e-09, disciminator loss fake = 1.2834950211981777e-05, generator loss = 11.714340209960938\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 239/468, discriminator loss real = 2.4737193196622265e-11, disciminator loss fake = 1.2897848137072287e-05, generator loss = 11.70945930480957\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 2, Batch: 240/468, discriminator loss real = 5.7432558264736144e-08, disciminator loss fake = 1.01465348052443e-05, generator loss = 11.572288513183594\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 2, Batch: 241/468, discriminator loss real = 8.488448166588114e-09, disciminator loss fake = 1.1292780982330441e-05, generator loss = 11.783296585083008\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 242/468, discriminator loss real = 9.182282156849908e-10, disciminator loss fake = 1.1608213753788732e-05, generator loss = 11.71853256225586\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 243/468, discriminator loss real = 3.2387227122399054e-08, disciminator loss fake = 1.0112474228662904e-05, generator loss = 11.684732437133789\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 2, Batch: 244/468, discriminator loss real = 1.0763580027273179e-09, disciminator loss fake = 1.2451052498363424e-05, generator loss = 11.826162338256836\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 2, Batch: 245/468, discriminator loss real = 4.929999875002977e-08, disciminator loss fake = 1.1615668881859165e-05, generator loss = 11.834903717041016\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 2, Batch: 246/468, discriminator loss real = 4.108041018469066e-09, disciminator loss fake = 1.1215175618417561e-05, generator loss = 11.770898818969727\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 2, Batch: 247/468, discriminator loss real = 9.199974115858822e-12, disciminator loss fake = 1.15306847874308e-05, generator loss = 11.814387321472168\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 2, Batch: 248/468, discriminator loss real = 1.7000647556386639e-09, disciminator loss fake = 9.232264346792363e-06, generator loss = 11.809022903442383\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 2, Batch: 249/468, discriminator loss real = 3.817104410330785e-10, disciminator loss fake = 9.2311547632562e-06, generator loss = 11.778350830078125\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 2, Batch: 250/468, discriminator loss real = 2.4661796160785343e-08, disciminator loss fake = 1.0158426448469982e-05, generator loss = 11.990826606750488\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 2, Batch: 251/468, discriminator loss real = 3.5906588891521096e-05, disciminator loss fake = 1.0549084436206613e-05, generator loss = 11.89846420288086\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 2, Batch: 252/468, discriminator loss real = 6.204599334314054e-11, disciminator loss fake = 1.0058434781967662e-05, generator loss = 11.766324996948242\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 2, Batch: 253/468, discriminator loss real = 3.551080908437143e-06, disciminator loss fake = 1.0792175089591183e-05, generator loss = 11.923189163208008\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 2, Batch: 254/468, discriminator loss real = 4.365162453723315e-08, disciminator loss fake = 1.140836684498936e-05, generator loss = 11.831399917602539\n",
      "2/2 [==============================] - 0s 33ms/step\n",
      "Epoch: 2, Batch: 255/468, discriminator loss real = 1.8543543589544242e-08, disciminator loss fake = 1.045441058522556e-05, generator loss = 11.888540267944336\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 2, Batch: 256/468, discriminator loss real = 9.73145297678002e-09, disciminator loss fake = 8.645147318020463e-06, generator loss = 11.939934730529785\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 257/468, discriminator loss real = 6.281445621425519e-07, disciminator loss fake = 1.0210275831923354e-05, generator loss = 12.052324295043945\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 2, Batch: 258/468, discriminator loss real = 1.153655643237883e-11, disciminator loss fake = 9.621562639949843e-06, generator loss = 11.842460632324219\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 259/468, discriminator loss real = 4.251266449983859e-09, disciminator loss fake = 7.680089765926823e-06, generator loss = 11.915488243103027\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 2, Batch: 260/468, discriminator loss real = 9.929670974351268e-11, disciminator loss fake = 8.079736289801076e-06, generator loss = 11.867084503173828\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 2, Batch: 261/468, discriminator loss real = 1.7608992606069074e-12, disciminator loss fake = 1.0070776625070721e-05, generator loss = 12.11311149597168\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 2, Batch: 262/468, discriminator loss real = 8.807272422473034e-08, disciminator loss fake = 9.654338100517634e-06, generator loss = 11.910670280456543\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 263/468, discriminator loss real = 4.6840602507813855e-09, disciminator loss fake = 8.332019206136465e-06, generator loss = 11.924102783203125\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 2, Batch: 264/468, discriminator loss real = 3.70465158550104e-10, disciminator loss fake = 9.93064259091625e-06, generator loss = 12.031206130981445\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 2, Batch: 265/468, discriminator loss real = 1.551904958707606e-11, disciminator loss fake = 1.0039821063401178e-05, generator loss = 11.988447189331055\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 266/468, discriminator loss real = 7.436111448821947e-11, disciminator loss fake = 9.422112270840444e-06, generator loss = 11.883392333984375\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 2, Batch: 267/468, discriminator loss real = 1.5373330386481143e-09, disciminator loss fake = 9.408052392245736e-06, generator loss = 11.938261985778809\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 268/468, discriminator loss real = 2.847110784978679e-12, disciminator loss fake = 1.0318028216715902e-05, generator loss = 11.910747528076172\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 2, Batch: 269/468, discriminator loss real = 9.73589209252168e-10, disciminator loss fake = 8.539184818801004e-06, generator loss = 12.028491973876953\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 2, Batch: 270/468, discriminator loss real = 1.1821996714900251e-08, disciminator loss fake = 9.08063884708099e-06, generator loss = 12.053104400634766\n",
      "2/2 [==============================] - 0s 38ms/step\n",
      "Epoch: 2, Batch: 271/468, discriminator loss real = 1.2215997310938143e-11, disciminator loss fake = 1.0258596375933848e-05, generator loss = 11.968446731567383\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 2, Batch: 272/468, discriminator loss real = 6.225900506251492e-06, disciminator loss fake = 7.734190148767084e-06, generator loss = 12.08513355255127\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 2, Batch: 273/468, discriminator loss real = 1.3420805089481291e-07, disciminator loss fake = 9.809302355279215e-06, generator loss = 12.04964542388916\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 2, Batch: 274/468, discriminator loss real = 8.299263498656728e-10, disciminator loss fake = 8.359078492503613e-06, generator loss = 11.994871139526367\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 2, Batch: 275/468, discriminator loss real = 4.227867500539162e-10, disciminator loss fake = 8.589499884692486e-06, generator loss = 11.940973281860352\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 2, Batch: 276/468, discriminator loss real = 5.380897949436303e-10, disciminator loss fake = 7.368356818915345e-06, generator loss = 12.168899536132812\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 2, Batch: 277/468, discriminator loss real = 8.150147579044642e-08, disciminator loss fake = 8.55230973684229e-06, generator loss = 12.075313568115234\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 2, Batch: 278/468, discriminator loss real = 1.3215249339282309e-08, disciminator loss fake = 6.250534170249011e-06, generator loss = 12.090181350708008\n",
      "2/2 [==============================] - 0s 32ms/step\n",
      "Epoch: 2, Batch: 279/468, discriminator loss real = 1.086378720316361e-08, disciminator loss fake = 9.077501999854576e-06, generator loss = 12.073673248291016\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 2, Batch: 280/468, discriminator loss real = 8.155777209140069e-08, disciminator loss fake = 7.5683637987822294e-06, generator loss = 12.040359497070312\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 2, Batch: 281/468, discriminator loss real = 2.7516231515534173e-09, disciminator loss fake = 7.47172180126654e-06, generator loss = 12.15023422241211\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 2, Batch: 282/468, discriminator loss real = 6.829160383858834e-07, disciminator loss fake = 7.0591395342489704e-06, generator loss = 12.156087875366211\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 2, Batch: 283/468, discriminator loss real = 1.2546895966636384e-08, disciminator loss fake = 8.049925781961065e-06, generator loss = 12.275245666503906\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 2, Batch: 284/468, discriminator loss real = 3.0396725492209953e-07, disciminator loss fake = 6.319041858660057e-06, generator loss = 12.185564994812012\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 2, Batch: 285/468, discriminator loss real = 1.0475206813076454e-10, disciminator loss fake = 6.021338776918128e-06, generator loss = 12.292750358581543\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 2, Batch: 286/468, discriminator loss real = 3.7312278267087606e-10, disciminator loss fake = 6.62565253151115e-06, generator loss = 12.227910041809082\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 2, Batch: 287/468, discriminator loss real = 1.2744385408103298e-11, disciminator loss fake = 7.875242772570346e-06, generator loss = 12.261499404907227\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 2, Batch: 288/468, discriminator loss real = 1.307178649767593e-07, disciminator loss fake = 6.594997103093192e-06, generator loss = 12.184392929077148\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 289/468, discriminator loss real = 1.3374736040905333e-10, disciminator loss fake = 6.731844223395456e-06, generator loss = 12.146245956420898\n",
      "2/2 [==============================] - 0s 34ms/step\n",
      "Epoch: 2, Batch: 290/468, discriminator loss real = 5.669843761157978e-11, disciminator loss fake = 8.355274985660799e-06, generator loss = 12.37813949584961\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 291/468, discriminator loss real = 1.5882991102889044e-11, disciminator loss fake = 6.347189355437877e-06, generator loss = 12.192031860351562\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 2, Batch: 292/468, discriminator loss real = 1.978686769987803e-09, disciminator loss fake = 6.840478363301372e-06, generator loss = 12.171833038330078\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 2, Batch: 293/468, discriminator loss real = 9.112825494206334e-10, disciminator loss fake = 6.875360213598469e-06, generator loss = 12.330791473388672\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 2, Batch: 294/468, discriminator loss real = 6.352379955387732e-07, disciminator loss fake = 5.843638518854277e-06, generator loss = 12.271669387817383\n",
      "2/2 [==============================] - 0s 37ms/step\n",
      "Epoch: 2, Batch: 295/468, discriminator loss real = 6.339483604733687e-08, disciminator loss fake = 6.213889719219878e-06, generator loss = 12.386582374572754\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 2, Batch: 296/468, discriminator loss real = 1.5659640251186602e-09, disciminator loss fake = 6.139110155345406e-06, generator loss = 12.335041046142578\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 2, Batch: 297/468, discriminator loss real = 1.0057394916884732e-09, disciminator loss fake = 6.130451765784528e-06, generator loss = 12.327919960021973\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 2, Batch: 298/468, discriminator loss real = 2.520667294447776e-06, disciminator loss fake = 6.52162816550117e-06, generator loss = 12.33186149597168\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 2, Batch: 299/468, discriminator loss real = 2.8908934837090783e-05, disciminator loss fake = 5.841384790983284e-06, generator loss = 12.365331649780273\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 2, Batch: 300/468, discriminator loss real = 2.5047011131817953e-09, disciminator loss fake = 6.2746294133830816e-06, generator loss = 12.305231094360352\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 2, Batch: 301/468, discriminator loss real = 5.59301251146227e-11, disciminator loss fake = 6.1445703067875e-06, generator loss = 12.280258178710938\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 302/468, discriminator loss real = 7.957761560817289e-09, disciminator loss fake = 5.586645784205757e-06, generator loss = 12.505940437316895\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 2, Batch: 303/468, discriminator loss real = 3.384467012201853e-11, disciminator loss fake = 5.836757736688014e-06, generator loss = 12.360185623168945\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 2, Batch: 304/468, discriminator loss real = 3.1036429936487364e-12, disciminator loss fake = 6.898632818774786e-06, generator loss = 12.39979362487793\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 2, Batch: 305/468, discriminator loss real = 1.123028603444709e-08, disciminator loss fake = 6.483795914391521e-06, generator loss = 12.364727020263672\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 2, Batch: 306/468, discriminator loss real = 2.5335964437545044e-09, disciminator loss fake = 6.181816388561856e-06, generator loss = 12.453692436218262\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 2, Batch: 307/468, discriminator loss real = 5.1312435971340165e-05, disciminator loss fake = 6.474605470430106e-06, generator loss = 12.451882362365723\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 2, Batch: 308/468, discriminator loss real = 4.0166145964803945e-08, disciminator loss fake = 6.344950634229463e-06, generator loss = 12.327707290649414\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 2, Batch: 309/468, discriminator loss real = 7.850202621284552e-08, disciminator loss fake = 5.804158263345016e-06, generator loss = 12.343789100646973\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 2, Batch: 310/468, discriminator loss real = 1.014313741505568e-12, disciminator loss fake = 6.434342139982618e-06, generator loss = 12.169166564941406\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 2, Batch: 311/468, discriminator loss real = 2.1937642813441016e-09, disciminator loss fake = 7.883008038334083e-06, generator loss = 12.40456771850586\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 2, Batch: 312/468, discriminator loss real = 2.5258917180082108e-09, disciminator loss fake = 6.584975380974356e-06, generator loss = 12.192418098449707\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 2, Batch: 313/468, discriminator loss real = 2.048895124742711e-12, disciminator loss fake = 6.496574314951431e-06, generator loss = 12.363216400146484\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 2, Batch: 314/468, discriminator loss real = 1.5156823574002942e-09, disciminator loss fake = 5.9438425523694605e-06, generator loss = 12.278755187988281\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 2, Batch: 315/468, discriminator loss real = 2.295534207163996e-09, disciminator loss fake = 7.074393579387106e-06, generator loss = 12.348064422607422\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 2, Batch: 316/468, discriminator loss real = 5.481267439932935e-09, disciminator loss fake = 5.903525561734568e-06, generator loss = 12.288045883178711\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 2, Batch: 317/468, discriminator loss real = 4.119962593307491e-09, disciminator loss fake = 6.377785211952869e-06, generator loss = 12.329530715942383\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 318/468, discriminator loss real = 2.78885664561912e-11, disciminator loss fake = 5.479430910781957e-06, generator loss = 12.41052532196045\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 2, Batch: 319/468, discriminator loss real = 5.629322004097048e-06, disciminator loss fake = 6.793135526095284e-06, generator loss = 12.412717819213867\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 2, Batch: 320/468, discriminator loss real = 6.4767259573272895e-06, disciminator loss fake = 5.33418960912968e-06, generator loss = 12.340721130371094\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 2, Batch: 321/468, discriminator loss real = 5.906708455682974e-10, disciminator loss fake = 5.703384886146523e-06, generator loss = 12.353370666503906\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 2, Batch: 322/468, discriminator loss real = 1.8102024046395826e-10, disciminator loss fake = 5.404343028203584e-06, generator loss = 12.344945907592773\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 2, Batch: 323/468, discriminator loss real = 2.257901243751803e-08, disciminator loss fake = 5.972744475002401e-06, generator loss = 12.454216003417969\n",
      "2/2 [==============================] - 0s 39ms/step\n",
      "Epoch: 2, Batch: 324/468, discriminator loss real = 2.2576025457965443e-06, disciminator loss fake = 5.154661266715266e-06, generator loss = 12.369237899780273\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 2, Batch: 325/468, discriminator loss real = 1.6498657995356325e-10, disciminator loss fake = 5.445435817819089e-06, generator loss = 12.362869262695312\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 2, Batch: 326/468, discriminator loss real = 4.7402828190490354e-11, disciminator loss fake = 5.992204023641534e-06, generator loss = 12.351490020751953\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 2, Batch: 327/468, discriminator loss real = 1.216280520743851e-09, disciminator loss fake = 5.544391569856089e-06, generator loss = 12.326898574829102\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 2, Batch: 328/468, discriminator loss real = 4.951109033868306e-08, disciminator loss fake = 6.007409865560476e-06, generator loss = 12.477964401245117\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 2, Batch: 329/468, discriminator loss real = 3.3333594728901517e-07, disciminator loss fake = 5.435065759229474e-06, generator loss = 12.283588409423828\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 2, Batch: 330/468, discriminator loss real = 3.694733408110551e-08, disciminator loss fake = 5.278825028653955e-06, generator loss = 12.394840240478516\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 2, Batch: 331/468, discriminator loss real = 3.862963922074414e-07, disciminator loss fake = 6.177418981678784e-06, generator loss = 12.509110450744629\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 2, Batch: 332/468, discriminator loss real = 9.677030288202104e-10, disciminator loss fake = 4.976116542820819e-06, generator loss = 12.510932922363281\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 2, Batch: 333/468, discriminator loss real = 3.9947304361978575e-13, disciminator loss fake = 5.720968147215899e-06, generator loss = 12.48646354675293\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 2, Batch: 334/468, discriminator loss real = 3.044309526689659e-10, disciminator loss fake = 6.139026481832843e-06, generator loss = 12.320958137512207\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 2, Batch: 335/468, discriminator loss real = 1.095862810218673e-11, disciminator loss fake = 5.18530941917561e-06, generator loss = 12.515645980834961\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 336/468, discriminator loss real = 7.193842975539155e-06, disciminator loss fake = 4.912963504466461e-06, generator loss = 12.424052238464355\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 2, Batch: 337/468, discriminator loss real = 1.3300971435370457e-11, disciminator loss fake = 5.917199814575724e-06, generator loss = 12.48269271850586\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 2, Batch: 338/468, discriminator loss real = 1.9516437355093785e-09, disciminator loss fake = 5.692233116860734e-06, generator loss = 12.550911903381348\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 2, Batch: 339/468, discriminator loss real = 1.7000681751255797e-08, disciminator loss fake = 4.478433766053058e-06, generator loss = 12.440313339233398\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 2, Batch: 340/468, discriminator loss real = 3.20370006079429e-08, disciminator loss fake = 4.72791725769639e-06, generator loss = 12.417154312133789\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 2, Batch: 341/468, discriminator loss real = 3.512432122931841e-09, disciminator loss fake = 5.039935786044225e-06, generator loss = 12.544342041015625\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 2, Batch: 342/468, discriminator loss real = 5.546908488085478e-10, disciminator loss fake = 5.376530680223368e-06, generator loss = 12.4951171875\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 2, Batch: 343/468, discriminator loss real = 6.735487723119604e-09, disciminator loss fake = 4.418527169036679e-06, generator loss = 12.534783363342285\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 2, Batch: 344/468, discriminator loss real = 2.197432813488831e-08, disciminator loss fake = 5.087057161290431e-06, generator loss = 12.563143730163574\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 2, Batch: 345/468, discriminator loss real = 2.952258171262656e-07, disciminator loss fake = 4.597435236064484e-06, generator loss = 12.629074096679688\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 2, Batch: 346/468, discriminator loss real = 4.993742308556648e-08, disciminator loss fake = 5.047817467129789e-06, generator loss = 12.489944458007812\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 2, Batch: 347/468, discriminator loss real = 1.772655977561044e-08, disciminator loss fake = 4.91161881654989e-06, generator loss = 12.47585678100586\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 348/468, discriminator loss real = 9.410066476034373e-12, disciminator loss fake = 5.0544854275358375e-06, generator loss = 12.569132804870605\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 2, Batch: 349/468, discriminator loss real = 1.266272761313303e-06, disciminator loss fake = 4.4258745219849516e-06, generator loss = 12.435940742492676\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 2, Batch: 350/468, discriminator loss real = 5.131501994160015e-12, disciminator loss fake = 5.026941835239995e-06, generator loss = 12.491899490356445\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 2, Batch: 351/468, discriminator loss real = 3.843314061668934e-06, disciminator loss fake = 5.245624379313085e-06, generator loss = 12.73582649230957\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 2, Batch: 352/468, discriminator loss real = 8.341120292243431e-07, disciminator loss fake = 5.236845481704222e-06, generator loss = 12.588845252990723\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 2, Batch: 353/468, discriminator loss real = 3.0600851713691313e-12, disciminator loss fake = 4.566210463963216e-06, generator loss = 12.541622161865234\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 2, Batch: 354/468, discriminator loss real = 8.361810133195036e-10, disciminator loss fake = 5.009263077226933e-06, generator loss = 12.709190368652344\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 2, Batch: 355/468, discriminator loss real = 3.610431420497662e-08, disciminator loss fake = 5.371914085117169e-06, generator loss = 12.590415954589844\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 2, Batch: 356/468, discriminator loss real = 2.6371953509851664e-09, disciminator loss fake = 4.369097496237373e-06, generator loss = 12.546031951904297\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 2, Batch: 357/468, discriminator loss real = 1.1870956474757666e-11, disciminator loss fake = 4.704850198322674e-06, generator loss = 12.530523300170898\n",
      "2/2 [==============================] - 0s 37ms/step\n",
      "Epoch: 2, Batch: 358/468, discriminator loss real = 8.323603308338368e-13, disciminator loss fake = 4.538229404715821e-06, generator loss = 12.525993347167969\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 2, Batch: 359/468, discriminator loss real = 5.157963833823942e-09, disciminator loss fake = 4.782869837072212e-06, generator loss = 12.57896614074707\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 2, Batch: 360/468, discriminator loss real = 1.7060065582441553e-09, disciminator loss fake = 5.1037145567534026e-06, generator loss = 12.607160568237305\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 2, Batch: 361/468, discriminator loss real = 2.0228312678227667e-06, disciminator loss fake = 5.081963536213152e-06, generator loss = 12.514604568481445\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 2, Batch: 362/468, discriminator loss real = 3.585814170037338e-07, disciminator loss fake = 4.227997123962268e-06, generator loss = 12.570270538330078\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 2, Batch: 363/468, discriminator loss real = 3.1719202979729744e-06, disciminator loss fake = 4.094640189578058e-06, generator loss = 12.660685539245605\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 364/468, discriminator loss real = 2.4524540620518565e-08, disciminator loss fake = 4.75362821816816e-06, generator loss = 12.702157974243164\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 365/468, discriminator loss real = 6.575858022168923e-13, disciminator loss fake = 5.067205620434834e-06, generator loss = 12.62535285949707\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 2, Batch: 366/468, discriminator loss real = 2.0000136963238546e-11, disciminator loss fake = 5.260191755951382e-06, generator loss = 12.700840950012207\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 2, Batch: 367/468, discriminator loss real = 1.376108968997869e-07, disciminator loss fake = 4.3589416236500256e-06, generator loss = 12.686426162719727\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 2, Batch: 368/468, discriminator loss real = 8.671909412782952e-09, disciminator loss fake = 4.949981303070672e-06, generator loss = 12.659906387329102\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 2, Batch: 369/468, discriminator loss real = 2.681343480581688e-10, disciminator loss fake = 4.297608029446565e-06, generator loss = 12.886295318603516\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 2, Batch: 370/468, discriminator loss real = 2.5286168714444557e-09, disciminator loss fake = 3.5873285924026277e-06, generator loss = 12.531631469726562\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 2, Batch: 371/468, discriminator loss real = 9.602989237134096e-11, disciminator loss fake = 5.48087882634718e-06, generator loss = 12.75249195098877\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 2, Batch: 372/468, discriminator loss real = 1.7426696530264962e-08, disciminator loss fake = 4.214076398056932e-06, generator loss = 12.683280944824219\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 2, Batch: 373/468, discriminator loss real = 1.2219251388501107e-08, disciminator loss fake = 3.7753645756311016e-06, generator loss = 12.726926803588867\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 2, Batch: 374/468, discriminator loss real = 5.831852263327164e-07, disciminator loss fake = 4.470540261536371e-06, generator loss = 12.872762680053711\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 2, Batch: 375/468, discriminator loss real = 1.327747467527729e-09, disciminator loss fake = 3.5887801459466573e-06, generator loss = 12.830000877380371\n",
      "2/2 [==============================] - 0s 28ms/step\n",
      "Epoch: 2, Batch: 376/468, discriminator loss real = 2.069584297714755e-06, disciminator loss fake = 4.514959982770961e-06, generator loss = 12.76283073425293\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 377/468, discriminator loss real = 2.183663472266062e-09, disciminator loss fake = 4.893614914180944e-06, generator loss = 12.690528869628906\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 378/468, discriminator loss real = 6.777137739888417e-10, disciminator loss fake = 3.371344973857049e-06, generator loss = 12.802000999450684\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 2, Batch: 379/468, discriminator loss real = 3.3685942071315367e-06, disciminator loss fake = 3.5764028325502295e-06, generator loss = 12.67381763458252\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 2, Batch: 380/468, discriminator loss real = 0.00015610406990163028, disciminator loss fake = 4.147457730141468e-06, generator loss = 12.526994705200195\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 2, Batch: 381/468, discriminator loss real = 3.90588494880717e-09, disciminator loss fake = 4.669951522373594e-06, generator loss = 12.604936599731445\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 2, Batch: 382/468, discriminator loss real = 5.780918854725314e-08, disciminator loss fake = 3.827714863291476e-06, generator loss = 12.690803527832031\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 2, Batch: 383/468, discriminator loss real = 6.933021268196171e-09, disciminator loss fake = 4.4025837269145995e-06, generator loss = 12.579840660095215\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 384/468, discriminator loss real = 1.6954005907510172e-11, disciminator loss fake = 4.890948730462696e-06, generator loss = 12.421324729919434\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 2, Batch: 385/468, discriminator loss real = 9.119214155361988e-06, disciminator loss fake = 4.932770025334321e-06, generator loss = 12.531231880187988\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 2, Batch: 386/468, discriminator loss real = 2.9036764104262147e-08, disciminator loss fake = 6.1924165493110195e-06, generator loss = 12.448881149291992\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 2, Batch: 387/468, discriminator loss real = 2.4917337637653247e-10, disciminator loss fake = 4.984125553164631e-06, generator loss = 12.573378562927246\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 2, Batch: 388/468, discriminator loss real = 3.364619693968507e-10, disciminator loss fake = 4.039777195430361e-06, generator loss = 12.400337219238281\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 2, Batch: 389/468, discriminator loss real = 2.240107761508625e-07, disciminator loss fake = 5.702258931705728e-06, generator loss = 12.417213439941406\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 2, Batch: 390/468, discriminator loss real = 1.3398976150824637e-08, disciminator loss fake = 5.568423148361035e-06, generator loss = 12.63311767578125\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 391/468, discriminator loss real = 2.3797701587113806e-08, disciminator loss fake = 5.035344656789675e-06, generator loss = 12.46702766418457\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 2, Batch: 392/468, discriminator loss real = 2.9290803116310826e-10, disciminator loss fake = 5.714316557714483e-06, generator loss = 12.496759414672852\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 2, Batch: 393/468, discriminator loss real = 1.9768275905107657e-08, disciminator loss fake = 6.6860479819297325e-06, generator loss = 12.470108032226562\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 2, Batch: 394/468, discriminator loss real = 1.0002274564158142e-08, disciminator loss fake = 6.3582447182852775e-06, generator loss = 12.389152526855469\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 2, Batch: 395/468, discriminator loss real = 1.1319495341055585e-10, disciminator loss fake = 4.9752602535590995e-06, generator loss = 12.580419540405273\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 2, Batch: 396/468, discriminator loss real = 6.776113878004253e-05, disciminator loss fake = 5.725295523006935e-06, generator loss = 12.4652681350708\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 2, Batch: 397/468, discriminator loss real = 1.941939942184945e-09, disciminator loss fake = 5.337216407497181e-06, generator loss = 12.372589111328125\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 2, Batch: 398/468, discriminator loss real = 2.47335152359085e-09, disciminator loss fake = 6.208363629411906e-06, generator loss = 12.513448715209961\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 2, Batch: 399/468, discriminator loss real = 2.1401200256399022e-10, disciminator loss fake = 5.938208687439328e-06, generator loss = 12.533496856689453\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 2, Batch: 400/468, discriminator loss real = 2.9715706659771968e-06, disciminator loss fake = 4.8464289648109116e-06, generator loss = 12.498818397521973\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 2, Batch: 401/468, discriminator loss real = 4.111064353523597e-12, disciminator loss fake = 6.026988103258191e-06, generator loss = 12.363348007202148\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 2, Batch: 402/468, discriminator loss real = 8.087974179282753e-10, disciminator loss fake = 5.036356924392749e-06, generator loss = 12.446081161499023\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 2, Batch: 403/468, discriminator loss real = 5.974036412226269e-07, disciminator loss fake = 6.113091785664437e-06, generator loss = 12.402383804321289\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 2, Batch: 404/468, discriminator loss real = 8.49690695758909e-05, disciminator loss fake = 5.69291842111852e-06, generator loss = 12.48955249786377\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 2, Batch: 405/468, discriminator loss real = 4.68533380626468e-06, disciminator loss fake = 6.11438053965685e-06, generator loss = 12.301956176757812\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 2, Batch: 406/468, discriminator loss real = 1.5603272007780333e-09, disciminator loss fake = 7.363477379840333e-06, generator loss = 12.302427291870117\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 2, Batch: 407/468, discriminator loss real = 6.423141185596393e-11, disciminator loss fake = 6.756235961802304e-06, generator loss = 12.248957633972168\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 408/468, discriminator loss real = 8.31981505911017e-09, disciminator loss fake = 6.690592272207141e-06, generator loss = 12.343826293945312\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 2, Batch: 409/468, discriminator loss real = 7.406447366520297e-07, disciminator loss fake = 7.089312020980287e-06, generator loss = 12.279792785644531\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 2, Batch: 410/468, discriminator loss real = 5.322723598683021e-12, disciminator loss fake = 6.618068255193066e-06, generator loss = 12.343076705932617\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 2, Batch: 411/468, discriminator loss real = 3.2354730450379066e-08, disciminator loss fake = 5.1110127969877794e-06, generator loss = 12.427921295166016\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 2, Batch: 412/468, discriminator loss real = 3.5125728459206584e-07, disciminator loss fake = 5.89315868637641e-06, generator loss = 12.282175064086914\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 2, Batch: 413/468, discriminator loss real = 1.3284118249856647e-09, disciminator loss fake = 5.822329512739088e-06, generator loss = 12.180506706237793\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 2, Batch: 414/468, discriminator loss real = 1.338004151918426e-10, disciminator loss fake = 5.465004051075084e-06, generator loss = 12.373268127441406\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 2, Batch: 415/468, discriminator loss real = 1.0334428225178272e-05, disciminator loss fake = 6.332620614557527e-06, generator loss = 12.230679512023926\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 2, Batch: 416/468, discriminator loss real = 3.778592022607441e-11, disciminator loss fake = 5.4607371566817164e-06, generator loss = 12.338568687438965\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 417/468, discriminator loss real = 4.4460954029545974e-08, disciminator loss fake = 7.821981853339821e-06, generator loss = 12.297279357910156\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 2, Batch: 418/468, discriminator loss real = 2.5437680960749276e-05, disciminator loss fake = 6.3923662310116924e-06, generator loss = 12.205806732177734\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 2, Batch: 419/468, discriminator loss real = 4.453538167581428e-06, disciminator loss fake = 6.533982741530053e-06, generator loss = 12.262115478515625\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 2, Batch: 420/468, discriminator loss real = 5.812972325713872e-10, disciminator loss fake = 6.736958766850876e-06, generator loss = 12.344489097595215\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 2, Batch: 421/468, discriminator loss real = 5.2098447084203414e-11, disciminator loss fake = 5.811868504679296e-06, generator loss = 12.456799507141113\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 2, Batch: 422/468, discriminator loss real = 2.1101018710112385e-09, disciminator loss fake = 5.315633188729407e-06, generator loss = 12.270366668701172\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 2, Batch: 423/468, discriminator loss real = 1.0359547421290305e-12, disciminator loss fake = 6.781079264328582e-06, generator loss = 12.210382461547852\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 2, Batch: 424/468, discriminator loss real = 5.735501310000224e-11, disciminator loss fake = 5.216294994170312e-06, generator loss = 12.350439071655273\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 2, Batch: 425/468, discriminator loss real = 3.474669085790083e-08, disciminator loss fake = 8.449766937701497e-06, generator loss = 12.351320266723633\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 2, Batch: 426/468, discriminator loss real = 4.7899789024086203e-08, disciminator loss fake = 5.861303179699462e-06, generator loss = 12.315908432006836\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 2, Batch: 427/468, discriminator loss real = 1.7337157487418153e-08, disciminator loss fake = 6.7687897171708755e-06, generator loss = 12.331417083740234\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 2, Batch: 428/468, discriminator loss real = 2.0830654978709617e-09, disciminator loss fake = 6.000335815770086e-06, generator loss = 12.38765811920166\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 2, Batch: 429/468, discriminator loss real = 1.7761879078648235e-08, disciminator loss fake = 6.893486443004804e-06, generator loss = 12.331681251525879\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 2, Batch: 430/468, discriminator loss real = 3.814955018555111e-09, disciminator loss fake = 4.767169230035506e-06, generator loss = 12.320154190063477\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 2, Batch: 431/468, discriminator loss real = 2.2435740376636204e-08, disciminator loss fake = 6.900420885358471e-06, generator loss = 12.31360149383545\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 2, Batch: 432/468, discriminator loss real = 1.2317756814539393e-09, disciminator loss fake = 5.5630489441682585e-06, generator loss = 12.269989013671875\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 2, Batch: 433/468, discriminator loss real = 1.849189402491902e-06, disciminator loss fake = 6.008757281961152e-06, generator loss = 12.20730209350586\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 2, Batch: 434/468, discriminator loss real = 6.247418693483553e-10, disciminator loss fake = 6.024279628036311e-06, generator loss = 12.3878812789917\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 2, Batch: 435/468, discriminator loss real = 1.6986165252141916e-10, disciminator loss fake = 6.519669113913551e-06, generator loss = 12.432062149047852\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 2, Batch: 436/468, discriminator loss real = 7.458437423224495e-09, disciminator loss fake = 5.366897312342189e-06, generator loss = 12.492483139038086\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 2, Batch: 437/468, discriminator loss real = 2.3246151531486348e-11, disciminator loss fake = 6.1348491726676e-06, generator loss = 12.620464324951172\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 2, Batch: 438/468, discriminator loss real = 9.090191793736935e-11, disciminator loss fake = 5.400742338679265e-06, generator loss = 12.352953910827637\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 2, Batch: 439/468, discriminator loss real = 2.5999747776950244e-06, disciminator loss fake = 4.91588207296445e-06, generator loss = 12.502223014831543\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 2, Batch: 440/468, discriminator loss real = 7.558380588079672e-09, disciminator loss fake = 5.349891580408439e-06, generator loss = 12.510934829711914\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 2, Batch: 441/468, discriminator loss real = 3.698075374813925e-07, disciminator loss fake = 4.7433486543013714e-06, generator loss = 12.544937133789062\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 2, Batch: 442/468, discriminator loss real = 1.8966675270348787e-06, disciminator loss fake = 4.01180341214058e-06, generator loss = 12.461246490478516\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 2, Batch: 443/468, discriminator loss real = 1.4324107872054626e-11, disciminator loss fake = 5.331456577550853e-06, generator loss = 12.475489616394043\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 2, Batch: 444/468, discriminator loss real = 3.993045911282467e-12, disciminator loss fake = 6.235396540432703e-06, generator loss = 12.467281341552734\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 2, Batch: 445/468, discriminator loss real = 4.3725854642802375e-13, disciminator loss fake = 6.81312985761906e-06, generator loss = 12.513891220092773\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 446/468, discriminator loss real = 3.380087876259097e-12, disciminator loss fake = 4.3315658331266604e-06, generator loss = 12.546817779541016\n",
      "2/2 [==============================] - 0s 37ms/step\n",
      "Epoch: 2, Batch: 447/468, discriminator loss real = 6.694002990803583e-11, disciminator loss fake = 4.32411707151914e-06, generator loss = 12.617528915405273\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 2, Batch: 448/468, discriminator loss real = 2.534369286877336e-06, disciminator loss fake = 4.766203346662223e-06, generator loss = 12.490354537963867\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 2, Batch: 449/468, discriminator loss real = 1.4393981118132615e-08, disciminator loss fake = 5.70482461625943e-06, generator loss = 12.611398696899414\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 2, Batch: 450/468, discriminator loss real = 2.4484624397413945e-12, disciminator loss fake = 4.626370355254039e-06, generator loss = 12.498844146728516\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 2, Batch: 451/468, discriminator loss real = 5.4865512311153e-07, disciminator loss fake = 4.579428605211433e-06, generator loss = 12.669139862060547\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 452/468, discriminator loss real = 9.390288546740067e-11, disciminator loss fake = 4.256564352544956e-06, generator loss = 12.5927734375\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 2, Batch: 453/468, discriminator loss real = 3.673763515621431e-10, disciminator loss fake = 4.534061645244947e-06, generator loss = 12.554080963134766\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 2, Batch: 454/468, discriminator loss real = 3.599599784909202e-10, disciminator loss fake = 4.581811936077429e-06, generator loss = 12.668216705322266\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 2, Batch: 455/468, discriminator loss real = 2.0345870821447676e-11, disciminator loss fake = 4.293420715839602e-06, generator loss = 12.530939102172852\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 2, Batch: 456/468, discriminator loss real = 1.6352405651787194e-08, disciminator loss fake = 4.3941126932622865e-06, generator loss = 12.637479782104492\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 457/468, discriminator loss real = 1.0396766780829125e-09, disciminator loss fake = 4.27438271799474e-06, generator loss = 12.646053314208984\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 2, Batch: 458/468, discriminator loss real = 4.4650111385990954e-10, disciminator loss fake = 4.745748356071999e-06, generator loss = 12.59014892578125\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 2, Batch: 459/468, discriminator loss real = 2.2875366878505332e-10, disciminator loss fake = 4.539145720627857e-06, generator loss = 12.684412002563477\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 2, Batch: 460/468, discriminator loss real = 5.6845963491980456e-09, disciminator loss fake = 4.859321506955894e-06, generator loss = 12.745145797729492\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 2, Batch: 461/468, discriminator loss real = 1.7449760386645252e-11, disciminator loss fake = 4.660989816329675e-06, generator loss = 12.656258583068848\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 2, Batch: 462/468, discriminator loss real = 1.7077914603313982e-12, disciminator loss fake = 4.255937710695434e-06, generator loss = 12.662544250488281\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 2, Batch: 463/468, discriminator loss real = 8.421528363555808e-09, disciminator loss fake = 5.31497289557592e-06, generator loss = 12.526128768920898\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 2, Batch: 464/468, discriminator loss real = 5.658441922483382e-13, disciminator loss fake = 5.21378569828812e-06, generator loss = 12.663093566894531\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 2, Batch: 465/468, discriminator loss real = 1.9283468918884772e-11, disciminator loss fake = 4.453040673979558e-06, generator loss = 12.663352966308594\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 2, Batch: 466/468, discriminator loss real = 9.891199838352183e-12, disciminator loss fake = 3.927188117813785e-06, generator loss = 12.72076416015625\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 2, Batch: 467/468, discriminator loss real = 3.4274509630449757e-07, disciminator loss fake = 3.9122369344113395e-06, generator loss = 12.784011840820312\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 2, Batch: 468/468, discriminator loss real = 9.45884481851067e-11, disciminator loss fake = 3.9640012801100966e-06, generator loss = 12.722261428833008\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 3, Batch: 1/468, discriminator loss real = 6.50468637286572e-11, disciminator loss fake = 4.170077318121912e-06, generator loss = 12.720087051391602\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 3, Batch: 2/468, discriminator loss real = 4.017815810955505e-13, disciminator loss fake = 4.277606421965174e-06, generator loss = 12.554292678833008\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 3, Batch: 3/468, discriminator loss real = 1.6758050502829747e-10, disciminator loss fake = 3.73474267689744e-06, generator loss = 12.722038269042969\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 4/468, discriminator loss real = 3.0339188583639043e-07, disciminator loss fake = 5.003943442716263e-06, generator loss = 12.781961441040039\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 3, Batch: 5/468, discriminator loss real = 9.4664249772336e-09, disciminator loss fake = 5.033148681832245e-06, generator loss = 12.791072845458984\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 3, Batch: 6/468, discriminator loss real = 1.440208308167712e-08, disciminator loss fake = 3.85228395316517e-06, generator loss = 12.798315048217773\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 3, Batch: 7/468, discriminator loss real = 3.156032335027703e-06, disciminator loss fake = 4.274168077245122e-06, generator loss = 12.778009414672852\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 3, Batch: 8/468, discriminator loss real = 6.367569937992812e-08, disciminator loss fake = 4.1806133594946004e-06, generator loss = 12.647994995117188\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 3, Batch: 9/468, discriminator loss real = 7.450561834154712e-10, disciminator loss fake = 3.808067276622751e-06, generator loss = 12.830484390258789\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 3, Batch: 10/468, discriminator loss real = 1.9116594418555621e-10, disciminator loss fake = 3.6400028875505086e-06, generator loss = 12.746479034423828\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 3, Batch: 11/468, discriminator loss real = 1.5957354548845615e-07, disciminator loss fake = 3.9592914617969655e-06, generator loss = 12.713808059692383\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 12/468, discriminator loss real = 2.7299329019569996e-08, disciminator loss fake = 3.96537780034123e-06, generator loss = 12.74289321899414\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 3, Batch: 13/468, discriminator loss real = 1.0048331056111692e-09, disciminator loss fake = 3.532238679326838e-06, generator loss = 12.794200897216797\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 3, Batch: 14/468, discriminator loss real = 6.835645649516664e-08, disciminator loss fake = 3.5511493479134515e-06, generator loss = 12.887872695922852\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 3, Batch: 15/468, discriminator loss real = 2.7270132224414823e-13, disciminator loss fake = 3.3308979254798032e-06, generator loss = 12.800735473632812\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 3, Batch: 16/468, discriminator loss real = 3.022605562651333e-14, disciminator loss fake = 3.689572395160212e-06, generator loss = 12.799993515014648\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 3, Batch: 17/468, discriminator loss real = 2.30187129091064e-06, disciminator loss fake = 3.758706498047104e-06, generator loss = 12.897418975830078\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 3, Batch: 18/468, discriminator loss real = 5.338405828503312e-10, disciminator loss fake = 3.4631043490662705e-06, generator loss = 12.803905487060547\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 3, Batch: 19/468, discriminator loss real = 2.07935357821043e-08, disciminator loss fake = 4.181563781457953e-06, generator loss = 12.892507553100586\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 3, Batch: 20/468, discriminator loss real = 5.486407439470042e-10, disciminator loss fake = 3.1849026527197566e-06, generator loss = 12.872167587280273\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 3, Batch: 21/468, discriminator loss real = 2.548051769579729e-10, disciminator loss fake = 3.338055648782756e-06, generator loss = 13.004555702209473\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 3, Batch: 22/468, discriminator loss real = 1.59578994463061e-09, disciminator loss fake = 3.715035518325749e-06, generator loss = 12.910223007202148\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 3, Batch: 23/468, discriminator loss real = 1.0532885674763293e-10, disciminator loss fake = 3.232484687032411e-06, generator loss = 12.881335258483887\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 3, Batch: 24/468, discriminator loss real = 6.680209163612005e-10, disciminator loss fake = 3.920115887012798e-06, generator loss = 12.783977508544922\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 3, Batch: 25/468, discriminator loss real = 1.1389757581525828e-08, disciminator loss fake = 3.824268787866458e-06, generator loss = 12.849943161010742\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 3, Batch: 26/468, discriminator loss real = 1.4008982361701783e-05, disciminator loss fake = 3.1500808290729765e-06, generator loss = 12.867274284362793\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 3, Batch: 27/468, discriminator loss real = 2.525177549700386e-12, disciminator loss fake = 3.1899155601422535e-06, generator loss = 13.023931503295898\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 3, Batch: 28/468, discriminator loss real = 4.661754380956562e-13, disciminator loss fake = 3.267702140874462e-06, generator loss = 12.906885147094727\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 3, Batch: 29/468, discriminator loss real = 5.385011186964661e-11, disciminator loss fake = 3.249926976423012e-06, generator loss = 12.875463485717773\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 3, Batch: 30/468, discriminator loss real = 1.2988580211370504e-09, disciminator loss fake = 2.6840025384444743e-06, generator loss = 12.81983757019043\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 3, Batch: 31/468, discriminator loss real = 1.1072553718349809e-07, disciminator loss fake = 3.226719854865223e-06, generator loss = 12.858603477478027\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 3, Batch: 32/468, discriminator loss real = 1.3741915591558573e-12, disciminator loss fake = 3.6553751669998746e-06, generator loss = 12.849224090576172\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 3, Batch: 33/468, discriminator loss real = 3.534046584263706e-07, disciminator loss fake = 3.874821231875103e-06, generator loss = 12.942079544067383\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 3, Batch: 34/468, discriminator loss real = 6.2125486977038236e-09, disciminator loss fake = 3.2452239793201443e-06, generator loss = 12.896514892578125\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 35/468, discriminator loss real = 5.639143596525287e-10, disciminator loss fake = 2.8300755730015226e-06, generator loss = 12.953186988830566\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 3, Batch: 36/468, discriminator loss real = 8.292512509999739e-12, disciminator loss fake = 3.064238399019814e-06, generator loss = 12.907407760620117\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 3, Batch: 37/468, discriminator loss real = 5.563461868973718e-08, disciminator loss fake = 3.775243158088415e-06, generator loss = 12.958416938781738\n",
      "2/2 [==============================] - 0s 37ms/step\n",
      "Epoch: 3, Batch: 38/468, discriminator loss real = 9.577952320150018e-11, disciminator loss fake = 3.305524387542391e-06, generator loss = 12.991077423095703\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 3, Batch: 39/468, discriminator loss real = 2.661711505425046e-06, disciminator loss fake = 3.853904672723729e-06, generator loss = 13.036620140075684\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 3, Batch: 40/468, discriminator loss real = 2.5828165994834507e-11, disciminator loss fake = 3.2706529964343645e-06, generator loss = 12.937580108642578\n",
      "2/2 [==============================] - 0s 39ms/step\n",
      "Epoch: 3, Batch: 41/468, discriminator loss real = 2.0068795583694232e-11, disciminator loss fake = 2.8712756829918362e-06, generator loss = 12.91556167602539\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 3, Batch: 42/468, discriminator loss real = 1.9576421550482337e-07, disciminator loss fake = 3.076479288210976e-06, generator loss = 12.924110412597656\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 3, Batch: 43/468, discriminator loss real = 1.1988000002405297e-11, disciminator loss fake = 3.2244083740806673e-06, generator loss = 12.899988174438477\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 3, Batch: 44/468, discriminator loss real = 1.7878644484881079e-06, disciminator loss fake = 3.713245860126335e-06, generator loss = 12.89261245727539\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 3, Batch: 45/468, discriminator loss real = 1.05410130402106e-07, disciminator loss fake = 3.4964532460435294e-06, generator loss = 12.967778205871582\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 3, Batch: 46/468, discriminator loss real = 1.0669569394661238e-10, disciminator loss fake = 2.87284228761564e-06, generator loss = 12.943063735961914\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 3, Batch: 47/468, discriminator loss real = 7.283270653246632e-10, disciminator loss fake = 3.1136196412262507e-06, generator loss = 12.992995262145996\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 3, Batch: 48/468, discriminator loss real = 3.974078310875484e-08, disciminator loss fake = 3.2993250442814315e-06, generator loss = 13.070779800415039\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 3, Batch: 49/468, discriminator loss real = 4.593726787849306e-11, disciminator loss fake = 2.9091966098349076e-06, generator loss = 12.967506408691406\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 3, Batch: 50/468, discriminator loss real = 3.2634128732667023e-09, disciminator loss fake = 3.006127826665761e-06, generator loss = 13.075007438659668\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 3, Batch: 51/468, discriminator loss real = 3.19109186774566e-13, disciminator loss fake = 3.222166014893446e-06, generator loss = 12.922256469726562\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 3, Batch: 52/468, discriminator loss real = 1.7144576869299044e-09, disciminator loss fake = 2.802781637001317e-06, generator loss = 12.857425689697266\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 3, Batch: 53/468, discriminator loss real = 7.542275831662337e-12, disciminator loss fake = 2.6683933356252965e-06, generator loss = 13.117664337158203\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 3, Batch: 54/468, discriminator loss real = 1.1055607540555457e-09, disciminator loss fake = 3.1106033020478208e-06, generator loss = 13.132027626037598\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 3, Batch: 55/468, discriminator loss real = 4.322535824030638e-05, disciminator loss fake = 2.7663056698656874e-06, generator loss = 13.008387565612793\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 3, Batch: 56/468, discriminator loss real = 1.1866738702792645e-09, disciminator loss fake = 2.5424892555747647e-06, generator loss = 12.885708808898926\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 3, Batch: 57/468, discriminator loss real = 1.4400121720048453e-11, disciminator loss fake = 3.2163975447474513e-06, generator loss = 12.973184585571289\n",
      "2/2 [==============================] - 0s 39ms/step\n",
      "Epoch: 3, Batch: 58/468, discriminator loss real = 4.222303395806648e-09, disciminator loss fake = 3.441236913204193e-06, generator loss = 13.005380630493164\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 59/468, discriminator loss real = 1.9876720269706993e-09, disciminator loss fake = 3.91289904655423e-06, generator loss = 13.008493423461914\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 3, Batch: 60/468, discriminator loss real = 1.2818143204640364e-06, disciminator loss fake = 3.778751988647855e-06, generator loss = 12.904195785522461\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 3, Batch: 61/468, discriminator loss real = 0.00017871742602437735, disciminator loss fake = 3.5893972381018102e-06, generator loss = 12.917295455932617\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 3, Batch: 62/468, discriminator loss real = 2.1761967228250967e-10, disciminator loss fake = 3.349531198182376e-06, generator loss = 12.805023193359375\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 3, Batch: 63/468, discriminator loss real = 3.935159489931728e-12, disciminator loss fake = 3.664081305032596e-06, generator loss = 12.76436710357666\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 3, Batch: 64/468, discriminator loss real = 5.621000886968375e-10, disciminator loss fake = 3.907783593604108e-06, generator loss = 12.783333778381348\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 3, Batch: 65/468, discriminator loss real = 4.644441220502671e-10, disciminator loss fake = 4.484020792006049e-06, generator loss = 12.553983688354492\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 3, Batch: 66/468, discriminator loss real = 1.7214452519703771e-12, disciminator loss fake = 4.185430952929892e-06, generator loss = 12.632247924804688\n",
      "2/2 [==============================] - 0s 31ms/step\n",
      "Epoch: 3, Batch: 67/468, discriminator loss real = 3.286280414460663e-10, disciminator loss fake = 4.7712051127746236e-06, generator loss = 12.67318344116211\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 3, Batch: 68/468, discriminator loss real = 2.211129473961293e-10, disciminator loss fake = 4.510353392106481e-06, generator loss = 12.455940246582031\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 3, Batch: 69/468, discriminator loss real = 4.310447110356108e-09, disciminator loss fake = 4.750300831801724e-06, generator loss = 12.52841567993164\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 3, Batch: 70/468, discriminator loss real = 2.1462767563207308e-07, disciminator loss fake = 4.162704044574639e-06, generator loss = 12.623897552490234\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 3, Batch: 71/468, discriminator loss real = 2.4153357092160377e-09, disciminator loss fake = 5.322679953678744e-06, generator loss = 12.495885848999023\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 3, Batch: 72/468, discriminator loss real = 3.0158622994769235e-12, disciminator loss fake = 5.6143926485674456e-06, generator loss = 12.566154479980469\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 3, Batch: 73/468, discriminator loss real = 4.852836799074112e-09, disciminator loss fake = 4.426234681886854e-06, generator loss = 12.531068801879883\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 3, Batch: 74/468, discriminator loss real = 4.189682378807902e-09, disciminator loss fake = 4.7277794692490716e-06, generator loss = 12.611822128295898\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 3, Batch: 75/468, discriminator loss real = 8.868906477277338e-12, disciminator loss fake = 5.543308361666277e-06, generator loss = 12.506837844848633\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 3, Batch: 76/468, discriminator loss real = 4.2776797215537954e-08, disciminator loss fake = 5.143790076544974e-06, generator loss = 12.550710678100586\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 3, Batch: 77/468, discriminator loss real = 4.053491053923608e-08, disciminator loss fake = 4.17163073507254e-06, generator loss = 12.623327255249023\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 3, Batch: 78/468, discriminator loss real = 1.0271680424625562e-12, disciminator loss fake = 5.19808781973552e-06, generator loss = 12.650703430175781\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 3, Batch: 79/468, discriminator loss real = 6.717815637102831e-09, disciminator loss fake = 4.7319235818577e-06, generator loss = 12.556890487670898\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 3, Batch: 80/468, discriminator loss real = 8.177238747242299e-11, disciminator loss fake = 5.001385943614878e-06, generator loss = 12.588937759399414\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 3, Batch: 81/468, discriminator loss real = 1.103856064332831e-07, disciminator loss fake = 4.90263118990697e-06, generator loss = 12.533782958984375\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 3, Batch: 82/468, discriminator loss real = 2.928841336125032e-10, disciminator loss fake = 4.515860382525716e-06, generator loss = 12.683873176574707\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 3, Batch: 83/468, discriminator loss real = 5.1584302801499504e-11, disciminator loss fake = 4.361632818472572e-06, generator loss = 12.617793083190918\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 3, Batch: 84/468, discriminator loss real = 3.14253201239012e-09, disciminator loss fake = 5.192904154682765e-06, generator loss = 12.801868438720703\n",
      "2/2 [==============================] - 0s 34ms/step\n",
      "Epoch: 3, Batch: 85/468, discriminator loss real = 2.6750939241537708e-09, disciminator loss fake = 4.234426342009101e-06, generator loss = 12.632549285888672\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 3, Batch: 86/468, discriminator loss real = 1.6015412329650758e-09, disciminator loss fake = 4.089221420144895e-06, generator loss = 12.723673820495605\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 3, Batch: 87/468, discriminator loss real = 5.003364042521774e-12, disciminator loss fake = 4.948738023813348e-06, generator loss = 12.6611909866333\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 3, Batch: 88/468, discriminator loss real = 3.9616074309911653e-10, disciminator loss fake = 4.407209416967817e-06, generator loss = 12.628374099731445\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 89/468, discriminator loss real = 9.86821220294587e-08, disciminator loss fake = 5.4249330787570216e-06, generator loss = 12.761834144592285\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 3, Batch: 90/468, discriminator loss real = 2.703457466571302e-12, disciminator loss fake = 4.562074082059553e-06, generator loss = 12.751344680786133\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 3, Batch: 91/468, discriminator loss real = 3.0993612624291567e-12, disciminator loss fake = 4.350725248514209e-06, generator loss = 12.754217147827148\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 3, Batch: 92/468, discriminator loss real = 8.376956429856364e-06, disciminator loss fake = 4.531805643637199e-06, generator loss = 12.697086334228516\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 3, Batch: 93/468, discriminator loss real = 1.967635689797964e-12, disciminator loss fake = 5.404724106483627e-06, generator loss = 12.694847106933594\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 3, Batch: 94/468, discriminator loss real = 8.498769396569905e-12, disciminator loss fake = 3.912543434125837e-06, generator loss = 12.655303955078125\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 3, Batch: 95/468, discriminator loss real = 2.905955852838815e-06, disciminator loss fake = 4.250079200573964e-06, generator loss = 12.7753324508667\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 3, Batch: 96/468, discriminator loss real = 2.5189905716871408e-11, disciminator loss fake = 4.213736247038469e-06, generator loss = 12.82772445678711\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 3, Batch: 97/468, discriminator loss real = 8.256556245991864e-13, disciminator loss fake = 4.265829375071917e-06, generator loss = 12.828004837036133\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 3, Batch: 98/468, discriminator loss real = 6.077071290633285e-09, disciminator loss fake = 4.495957455219468e-06, generator loss = 12.750822067260742\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 3, Batch: 99/468, discriminator loss real = 3.0674858486623435e-11, disciminator loss fake = 3.7387605971161975e-06, generator loss = 12.84263801574707\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 100/468, discriminator loss real = 5.401118441383801e-10, disciminator loss fake = 2.9008788260398433e-06, generator loss = 12.835265159606934\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 3, Batch: 101/468, discriminator loss real = 2.396447825958603e-06, disciminator loss fake = 3.980592282459838e-06, generator loss = 12.818656921386719\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 3, Batch: 102/468, discriminator loss real = 4.6868830594348765e-08, disciminator loss fake = 4.557348802336492e-06, generator loss = 12.721902847290039\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 3, Batch: 103/468, discriminator loss real = 4.798368299918643e-12, disciminator loss fake = 5.228365807852242e-06, generator loss = 12.739858627319336\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 3, Batch: 104/468, discriminator loss real = 2.136450234502263e-07, disciminator loss fake = 3.6204328353051096e-06, generator loss = 12.903152465820312\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 3, Batch: 105/468, discriminator loss real = 1.932281223915311e-09, disciminator loss fake = 3.8691036934324075e-06, generator loss = 12.927939414978027\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 3, Batch: 106/468, discriminator loss real = 2.7959828896584327e-10, disciminator loss fake = 3.634105269156862e-06, generator loss = 12.905826568603516\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 3, Batch: 107/468, discriminator loss real = 5.058206024172174e-12, disciminator loss fake = 3.5759892398345983e-06, generator loss = 12.875236511230469\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 3, Batch: 108/468, discriminator loss real = 3.7594784924044333e-11, disciminator loss fake = 4.0989848457684275e-06, generator loss = 12.820902824401855\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 3, Batch: 109/468, discriminator loss real = 4.201537340264849e-09, disciminator loss fake = 3.8814719118818175e-06, generator loss = 12.93698501586914\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 3, Batch: 110/468, discriminator loss real = 3.9772923628333956e-05, disciminator loss fake = 4.393590188556118e-06, generator loss = 12.77906322479248\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 3, Batch: 111/468, discriminator loss real = 2.3268746929261397e-09, disciminator loss fake = 4.38810729974648e-06, generator loss = 12.757856369018555\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 3, Batch: 112/468, discriminator loss real = 3.4029232764964945e-09, disciminator loss fake = 4.145172169955913e-06, generator loss = 12.804526329040527\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 3, Batch: 113/468, discriminator loss real = 2.6149939102992903e-08, disciminator loss fake = 3.7173408600210678e-06, generator loss = 12.7210111618042\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 3, Batch: 114/468, discriminator loss real = 3.237802040367832e-11, disciminator loss fake = 3.7165712001296924e-06, generator loss = 12.728081703186035\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 115/468, discriminator loss real = 5.300126114902992e-13, disciminator loss fake = 3.638535872596549e-06, generator loss = 12.844732284545898\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 3, Batch: 116/468, discriminator loss real = 5.469266532720507e-13, disciminator loss fake = 3.048636699531926e-06, generator loss = 12.870872497558594\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 3, Batch: 117/468, discriminator loss real = 6.289384124613662e-09, disciminator loss fake = 4.048072241857881e-06, generator loss = 12.91528034210205\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 3, Batch: 118/468, discriminator loss real = 1.3892936800985467e-10, disciminator loss fake = 3.725491978912032e-06, generator loss = 12.771717071533203\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 119/468, discriminator loss real = 3.727940622866299e-09, disciminator loss fake = 4.563883976516081e-06, generator loss = 12.862588882446289\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 3, Batch: 120/468, discriminator loss real = 1.0243375592189352e-11, disciminator loss fake = 4.105436801182805e-06, generator loss = 12.788206100463867\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 3, Batch: 121/468, discriminator loss real = 2.9309180149539316e-07, disciminator loss fake = 3.449165205893223e-06, generator loss = 12.854880332946777\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 3, Batch: 122/468, discriminator loss real = 8.692249697794807e-11, disciminator loss fake = 3.6811668451264268e-06, generator loss = 12.752906799316406\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 3, Batch: 123/468, discriminator loss real = 5.065687219030224e-06, disciminator loss fake = 4.1377202251169365e-06, generator loss = 12.933390617370605\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 3, Batch: 124/468, discriminator loss real = 3.217520028186982e-09, disciminator loss fake = 3.6809733501286246e-06, generator loss = 12.901744842529297\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 3, Batch: 125/468, discriminator loss real = 6.424490717193976e-09, disciminator loss fake = 3.7004426758358022e-06, generator loss = 12.955460548400879\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 3, Batch: 126/468, discriminator loss real = 2.1253274140597966e-10, disciminator loss fake = 4.234765583532862e-06, generator loss = 12.915972709655762\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 3, Batch: 127/468, discriminator loss real = 7.790498912640942e-09, disciminator loss fake = 3.580439852157724e-06, generator loss = 12.78799057006836\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 3, Batch: 128/468, discriminator loss real = 1.0920958359861288e-08, disciminator loss fake = 3.440568889345741e-06, generator loss = 12.850824356079102\n",
      "2/2 [==============================] - 0s 38ms/step\n",
      "Epoch: 3, Batch: 129/468, discriminator loss real = 2.855798042489255e-09, disciminator loss fake = 3.7142744986340404e-06, generator loss = 12.8519926071167\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 3, Batch: 130/468, discriminator loss real = 2.4704578660550425e-11, disciminator loss fake = 3.468152499408461e-06, generator loss = 12.877908706665039\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 3, Batch: 131/468, discriminator loss real = 1.5221648594354598e-11, disciminator loss fake = 3.2827847462613136e-06, generator loss = 12.854894638061523\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 3, Batch: 132/468, discriminator loss real = 1.451205156044466e-09, disciminator loss fake = 3.6024971450387966e-06, generator loss = 12.97863483428955\n",
      "2/2 [==============================] - 0s 36ms/step\n",
      "Epoch: 3, Batch: 133/468, discriminator loss real = 5.597248775579544e-10, disciminator loss fake = 3.6038945836480707e-06, generator loss = 12.846931457519531\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 3, Batch: 134/468, discriminator loss real = 1.1095907126446036e-07, disciminator loss fake = 3.0506864732160466e-06, generator loss = 12.97476577758789\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 3, Batch: 135/468, discriminator loss real = 5.1326977390520057e-11, disciminator loss fake = 3.509646148813772e-06, generator loss = 12.968879699707031\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 3, Batch: 136/468, discriminator loss real = 1.1278384476343106e-10, disciminator loss fake = 3.1601612136000767e-06, generator loss = 12.91079330444336\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 3, Batch: 137/468, discriminator loss real = 1.3310220481344004e-08, disciminator loss fake = 3.1264796689356444e-06, generator loss = 12.844978332519531\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 138/468, discriminator loss real = 1.917394243378112e-09, disciminator loss fake = 3.4687809602473862e-06, generator loss = 12.979253768920898\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 3, Batch: 139/468, discriminator loss real = 2.7396652654831932e-11, disciminator loss fake = 2.9483578600775218e-06, generator loss = 12.982486724853516\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 3, Batch: 140/468, discriminator loss real = 1.629077298406778e-12, disciminator loss fake = 3.630568699009018e-06, generator loss = 13.052082061767578\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 3, Batch: 141/468, discriminator loss real = 2.2976178115641233e-06, disciminator loss fake = 3.1158722322288668e-06, generator loss = 12.875187873840332\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 3, Batch: 142/468, discriminator loss real = 1.3170262036510394e-07, disciminator loss fake = 4.121798156120349e-06, generator loss = 12.910503387451172\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 3, Batch: 143/468, discriminator loss real = 1.6119691692573213e-10, disciminator loss fake = 3.6510177778836805e-06, generator loss = 13.067276954650879\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 3, Batch: 144/468, discriminator loss real = 6.476308204994563e-12, disciminator loss fake = 3.0075095764914295e-06, generator loss = 12.783727645874023\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 3, Batch: 145/468, discriminator loss real = 6.452976322179893e-07, disciminator loss fake = 2.8332956389931496e-06, generator loss = 12.930301666259766\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 3, Batch: 146/468, discriminator loss real = 5.021571491958809e-10, disciminator loss fake = 2.9153848117857706e-06, generator loss = 12.958281517028809\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 3, Batch: 147/468, discriminator loss real = 2.063386267403544e-11, disciminator loss fake = 3.127553100057412e-06, generator loss = 13.01296615600586\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 3, Batch: 148/468, discriminator loss real = 4.394636050619738e-07, disciminator loss fake = 4.221450581098907e-06, generator loss = 13.05980110168457\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 3, Batch: 149/468, discriminator loss real = 6.556586595252156e-05, disciminator loss fake = 3.210191152902553e-06, generator loss = 12.975105285644531\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 150/468, discriminator loss real = 5.35155114667063e-11, disciminator loss fake = 2.7985224733129144e-06, generator loss = 13.06228256225586\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 3, Batch: 151/468, discriminator loss real = 3.6208576826950167e-13, disciminator loss fake = 4.518835339695215e-06, generator loss = 12.883719444274902\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 3, Batch: 152/468, discriminator loss real = 4.515097497270748e-12, disciminator loss fake = 3.6419651223695837e-06, generator loss = 13.057746887207031\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 153/468, discriminator loss real = 1.460479931436609e-10, disciminator loss fake = 3.4239519663969986e-06, generator loss = 12.787221908569336\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 3, Batch: 154/468, discriminator loss real = 1.0044759295169126e-11, disciminator loss fake = 3.2260638818115694e-06, generator loss = 12.831729888916016\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 3, Batch: 155/468, discriminator loss real = 3.1113926539372283e-12, disciminator loss fake = 3.3847691156552173e-06, generator loss = 12.898019790649414\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 3, Batch: 156/468, discriminator loss real = 6.220157310228569e-13, disciminator loss fake = 4.562475623970386e-06, generator loss = 12.920936584472656\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 3, Batch: 157/468, discriminator loss real = 3.272585907099874e-15, disciminator loss fake = 3.6380520214152057e-06, generator loss = 12.871198654174805\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 3, Batch: 158/468, discriminator loss real = 3.5761159116430574e-13, disciminator loss fake = 2.8302843020355795e-06, generator loss = 12.956565856933594\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 3, Batch: 159/468, discriminator loss real = 4.104240905467016e-11, disciminator loss fake = 3.283544629084645e-06, generator loss = 12.82879638671875\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 3, Batch: 160/468, discriminator loss real = 1.5306377693091733e-11, disciminator loss fake = 3.9220258258865215e-06, generator loss = 12.918109893798828\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 3, Batch: 161/468, discriminator loss real = 1.448624965642853e-12, disciminator loss fake = 3.289668256911682e-06, generator loss = 12.784063339233398\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 3, Batch: 162/468, discriminator loss real = 4.848023371639698e-11, disciminator loss fake = 4.108055236429209e-06, generator loss = 12.889866828918457\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 3, Batch: 163/468, discriminator loss real = 5.571509920088147e-10, disciminator loss fake = 3.4428387607476907e-06, generator loss = 12.87723159790039\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 3, Batch: 164/468, discriminator loss real = 1.1733120714157302e-13, disciminator loss fake = 3.702324193000095e-06, generator loss = 12.957727432250977\n",
      "2/2 [==============================] - 0s 38ms/step\n",
      "Epoch: 3, Batch: 165/468, discriminator loss real = 2.278716806358716e-07, disciminator loss fake = 3.7382953905762406e-06, generator loss = 13.001995086669922\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 3, Batch: 166/468, discriminator loss real = 3.323151531731128e-08, disciminator loss fake = 3.030379957635887e-06, generator loss = 13.103860855102539\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 3, Batch: 167/468, discriminator loss real = 2.1765955704466933e-09, disciminator loss fake = 3.6249916774977464e-06, generator loss = 12.917348861694336\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 3, Batch: 168/468, discriminator loss real = 1.6833333575050347e-05, disciminator loss fake = 3.6353637824504403e-06, generator loss = 12.911252975463867\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 3, Batch: 169/468, discriminator loss real = 3.394629577435637e-10, disciminator loss fake = 3.4621541544765932e-06, generator loss = 12.779692649841309\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 3, Batch: 170/468, discriminator loss real = 2.5724325780629442e-08, disciminator loss fake = 3.954085059376666e-06, generator loss = 12.955013275146484\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 3, Batch: 171/468, discriminator loss real = 3.0191706912319205e-08, disciminator loss fake = 3.830662535619922e-06, generator loss = 12.894247055053711\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 3, Batch: 172/468, discriminator loss real = 1.2039758079396279e-11, disciminator loss fake = 3.3175520002259873e-06, generator loss = 12.943623542785645\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 173/468, discriminator loss real = 8.498622812436185e-12, disciminator loss fake = 2.6503068966121646e-06, generator loss = 12.969759941101074\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 3, Batch: 174/468, discriminator loss real = 3.598983777663989e-09, disciminator loss fake = 3.439266038185451e-06, generator loss = 12.978157043457031\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 3, Batch: 175/468, discriminator loss real = 1.1606461569613202e-08, disciminator loss fake = 3.3406527109036688e-06, generator loss = 13.036063194274902\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 3, Batch: 176/468, discriminator loss real = 3.0607553167319446e-13, disciminator loss fake = 3.1520585253019817e-06, generator loss = 12.947351455688477\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 3, Batch: 177/468, discriminator loss real = 1.7881660596685833e-08, disciminator loss fake = 4.053697011840995e-06, generator loss = 13.023797988891602\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 178/468, discriminator loss real = 1.7210644021048438e-10, disciminator loss fake = 3.613165972637944e-06, generator loss = 12.986696243286133\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 3, Batch: 179/468, discriminator loss real = 3.3633082430206684e-10, disciminator loss fake = 2.8524850677058566e-06, generator loss = 12.90683650970459\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 3, Batch: 180/468, discriminator loss real = 2.376368790635297e-08, disciminator loss fake = 2.9548987185989972e-06, generator loss = 12.931320190429688\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 3, Batch: 181/468, discriminator loss real = 2.259933351567156e-09, disciminator loss fake = 3.853738235193305e-06, generator loss = 13.013524055480957\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 3, Batch: 182/468, discriminator loss real = 2.2121564302590713e-10, disciminator loss fake = 2.96814550893032e-06, generator loss = 12.927512168884277\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 3, Batch: 183/468, discriminator loss real = 3.765041750591891e-11, disciminator loss fake = 3.489694336167304e-06, generator loss = 13.118099212646484\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 3, Batch: 184/468, discriminator loss real = 9.179623033928053e-11, disciminator loss fake = 3.0529947707691463e-06, generator loss = 12.861709594726562\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 3, Batch: 185/468, discriminator loss real = 2.0084987839563695e-10, disciminator loss fake = 4.040681233163923e-06, generator loss = 12.98487377166748\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 3, Batch: 186/468, discriminator loss real = 1.5294358661488427e-12, disciminator loss fake = 3.3772184906410985e-06, generator loss = 13.1458101272583\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 3, Batch: 187/468, discriminator loss real = 2.995617737699095e-14, disciminator loss fake = 3.047655354748713e-06, generator loss = 12.917400360107422\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 3, Batch: 188/468, discriminator loss real = 9.532644673626578e-10, disciminator loss fake = 3.596010174078401e-06, generator loss = 12.968271255493164\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 3, Batch: 189/468, discriminator loss real = 3.932138035317445e-12, disciminator loss fake = 2.933493078671745e-06, generator loss = 13.141168594360352\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 3, Batch: 190/468, discriminator loss real = 1.2823335973535365e-14, disciminator loss fake = 3.310900410724571e-06, generator loss = 13.006546020507812\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 191/468, discriminator loss real = 4.049903964187251e-06, disciminator loss fake = 2.847979658326949e-06, generator loss = 13.045970916748047\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 3, Batch: 192/468, discriminator loss real = 8.599289683108857e-12, disciminator loss fake = 3.7365084608609322e-06, generator loss = 13.114948272705078\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 193/468, discriminator loss real = 1.7714649191979959e-13, disciminator loss fake = 2.2790691218688153e-06, generator loss = 13.165369033813477\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 3, Batch: 194/468, discriminator loss real = 4.901724642500382e-13, disciminator loss fake = 2.9084590096317697e-06, generator loss = 13.169777870178223\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 3, Batch: 195/468, discriminator loss real = 5.940880426491546e-11, disciminator loss fake = 2.841781224560691e-06, generator loss = 13.200862884521484\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 3, Batch: 196/468, discriminator loss real = 1.3640104670753495e-11, disciminator loss fake = 2.9489312964869896e-06, generator loss = 13.268987655639648\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 3, Batch: 197/468, discriminator loss real = 1.0467993832863343e-10, disciminator loss fake = 2.3886029794084607e-06, generator loss = 13.144365310668945\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 3, Batch: 198/468, discriminator loss real = 3.767267314075395e-12, disciminator loss fake = 2.721305463637691e-06, generator loss = 13.135594367980957\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 3, Batch: 199/468, discriminator loss real = 7.520279537986951e-12, disciminator loss fake = 2.939907972177025e-06, generator loss = 13.255136489868164\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 3, Batch: 200/468, discriminator loss real = 9.803581557665808e-13, disciminator loss fake = 2.7047283310821513e-06, generator loss = 13.230749130249023\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 3, Batch: 201/468, discriminator loss real = 1.1187501591791715e-08, disciminator loss fake = 3.0023734325368423e-06, generator loss = 13.295364379882812\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 202/468, discriminator loss real = 1.087720580272844e-08, disciminator loss fake = 3.00967212751857e-06, generator loss = 13.216407775878906\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 3, Batch: 203/468, discriminator loss real = 1.0745947182219315e-13, disciminator loss fake = 2.8985118660784792e-06, generator loss = 13.079647064208984\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 3, Batch: 204/468, discriminator loss real = 7.797198303682862e-11, disciminator loss fake = 2.8953745641047135e-06, generator loss = 13.239373207092285\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 3, Batch: 205/468, discriminator loss real = 7.612112051802455e-10, disciminator loss fake = 3.241664217057405e-06, generator loss = 13.263845443725586\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 206/468, discriminator loss real = 2.797502673956842e-09, disciminator loss fake = 3.027068032679381e-06, generator loss = 13.304788589477539\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 207/468, discriminator loss real = 7.600128304474651e-10, disciminator loss fake = 2.5330784865218448e-06, generator loss = 13.141780853271484\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 3, Batch: 208/468, discriminator loss real = 3.925243774460796e-08, disciminator loss fake = 3.005675353051629e-06, generator loss = 13.21708869934082\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 209/468, discriminator loss real = 7.651158827055686e-15, disciminator loss fake = 2.695643161132466e-06, generator loss = 13.074840545654297\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 3, Batch: 210/468, discriminator loss real = 5.019944963186029e-12, disciminator loss fake = 3.023689032488619e-06, generator loss = 13.234407424926758\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 3, Batch: 211/468, discriminator loss real = 1.2053937847866791e-09, disciminator loss fake = 2.501890321582323e-06, generator loss = 13.362825393676758\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 212/468, discriminator loss real = 8.092737036058395e-10, disciminator loss fake = 2.9160373742342927e-06, generator loss = 13.211443901062012\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 213/468, discriminator loss real = 3.436178008797697e-10, disciminator loss fake = 2.495689386705635e-06, generator loss = 13.378486633300781\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 3, Batch: 214/468, discriminator loss real = 2.096956450259313e-05, disciminator loss fake = 2.503709310985869e-06, generator loss = 13.353865623474121\n",
      "2/2 [==============================] - 0s 37ms/step\n",
      "Epoch: 3, Batch: 215/468, discriminator loss real = 5.336324715443652e-10, disciminator loss fake = 2.2229896785574965e-06, generator loss = 13.237665176391602\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 3, Batch: 216/468, discriminator loss real = 5.978708847442782e-12, disciminator loss fake = 2.996778675878886e-06, generator loss = 13.317564010620117\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 3, Batch: 217/468, discriminator loss real = 1.578682429226319e-08, disciminator loss fake = 2.2715796603733907e-06, generator loss = 13.40589714050293\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 3, Batch: 218/468, discriminator loss real = 9.475367050981731e-07, disciminator loss fake = 2.6290756522939773e-06, generator loss = 13.206979751586914\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 3, Batch: 219/468, discriminator loss real = 8.834337705820872e-09, disciminator loss fake = 2.4933740405685967e-06, generator loss = 13.12765121459961\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 3, Batch: 220/468, discriminator loss real = 3.2139386638152523e-12, disciminator loss fake = 2.1549983557633823e-06, generator loss = 13.25224494934082\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 3, Batch: 221/468, discriminator loss real = 2.3993115405573917e-07, disciminator loss fake = 3.415581204535556e-06, generator loss = 13.203214645385742\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 3, Batch: 222/468, discriminator loss real = 8.041724230967162e-11, disciminator loss fake = 2.5714170988067053e-06, generator loss = 13.347904205322266\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 3, Batch: 223/468, discriminator loss real = 8.41291409869882e-08, disciminator loss fake = 2.749450231931405e-06, generator loss = 13.212427139282227\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 3, Batch: 224/468, discriminator loss real = 4.4007856558891945e-06, disciminator loss fake = 2.4466405648126965e-06, generator loss = 13.238471984863281\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 3, Batch: 225/468, discriminator loss real = 2.0873793005193875e-07, disciminator loss fake = 2.1583800844382495e-06, generator loss = 13.257970809936523\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 3, Batch: 226/468, discriminator loss real = 2.5592221484377342e-12, disciminator loss fake = 2.614118784549646e-06, generator loss = 13.330342292785645\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 3, Batch: 227/468, discriminator loss real = 1.234797930571574e-09, disciminator loss fake = 2.003989266086137e-06, generator loss = 13.238383293151855\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 3, Batch: 228/468, discriminator loss real = 6.418670039920471e-10, disciminator loss fake = 2.4595319700893015e-06, generator loss = 13.377340316772461\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 3, Batch: 229/468, discriminator loss real = 9.357061792059085e-09, disciminator loss fake = 2.787866378639592e-06, generator loss = 13.269220352172852\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 230/468, discriminator loss real = 4.4883095142722595e-06, disciminator loss fake = 2.1663431652996223e-06, generator loss = 13.297553062438965\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 3, Batch: 231/468, discriminator loss real = 3.528947800646165e-08, disciminator loss fake = 2.7674302600644296e-06, generator loss = 13.33009147644043\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 3, Batch: 232/468, discriminator loss real = 5.908153966061036e-10, disciminator loss fake = 2.64608274846978e-06, generator loss = 13.272300720214844\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 3, Batch: 233/468, discriminator loss real = 3.581929197693512e-10, disciminator loss fake = 2.3066286303219385e-06, generator loss = 13.172865867614746\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 3, Batch: 234/468, discriminator loss real = 6.6823335059806865e-12, disciminator loss fake = 2.4614537323941477e-06, generator loss = 13.288224220275879\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 3, Batch: 235/468, discriminator loss real = 1.5428767204811455e-12, disciminator loss fake = 2.663027316884836e-06, generator loss = 13.217693328857422\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 3, Batch: 236/468, discriminator loss real = 3.5165425259220395e-12, disciminator loss fake = 2.730101641645888e-06, generator loss = 13.287010192871094\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 3, Batch: 237/468, discriminator loss real = 1.2116077238721878e-11, disciminator loss fake = 2.167183311030385e-06, generator loss = 13.340408325195312\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 3, Batch: 238/468, discriminator loss real = 4.707764178490947e-10, disciminator loss fake = 2.3843008420953993e-06, generator loss = 13.285619735717773\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 3, Batch: 239/468, discriminator loss real = 1.851253317308732e-10, disciminator loss fake = 1.8661679632714367e-06, generator loss = 13.299934387207031\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 3, Batch: 240/468, discriminator loss real = 1.8530021267393337e-12, disciminator loss fake = 2.1410492081486154e-06, generator loss = 13.356535911560059\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 3, Batch: 241/468, discriminator loss real = 1.858685566569207e-10, disciminator loss fake = 2.079849309666315e-06, generator loss = 13.251567840576172\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 3, Batch: 242/468, discriminator loss real = 4.802675903192721e-05, disciminator loss fake = 1.8610253391670994e-06, generator loss = 13.153326034545898\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 3, Batch: 243/468, discriminator loss real = 3.609923557995609e-12, disciminator loss fake = 2.256004336231854e-06, generator loss = 13.119446754455566\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 3, Batch: 244/468, discriminator loss real = 3.541822124475402e-08, disciminator loss fake = 2.4810242393868975e-06, generator loss = 13.264720916748047\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 3, Batch: 245/468, discriminator loss real = 4.8092334559157734e-09, disciminator loss fake = 3.4053427953040227e-06, generator loss = 13.300497055053711\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 3, Batch: 246/468, discriminator loss real = 5.489143821012406e-14, disciminator loss fake = 2.0053007574460935e-06, generator loss = 13.248298645019531\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 3, Batch: 247/468, discriminator loss real = 2.1437211381036825e-11, disciminator loss fake = 2.5327608454972506e-06, generator loss = 13.163806915283203\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 3, Batch: 248/468, discriminator loss real = 2.5307418383135882e-09, disciminator loss fake = 2.166164449590724e-06, generator loss = 13.304893493652344\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 3, Batch: 249/468, discriminator loss real = 2.7154469783852164e-09, disciminator loss fake = 2.853488240361912e-06, generator loss = 13.302190780639648\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 3, Batch: 250/468, discriminator loss real = 5.3375160194435445e-12, disciminator loss fake = 2.2111466932983603e-06, generator loss = 13.235055923461914\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 3, Batch: 251/468, discriminator loss real = 1.4202899478732434e-07, disciminator loss fake = 2.2027033992344514e-06, generator loss = 13.256134033203125\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 3, Batch: 252/468, discriminator loss real = 2.3067734788301264e-13, disciminator loss fake = 2.4239475351350848e-06, generator loss = 13.344661712646484\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 3, Batch: 253/468, discriminator loss real = 2.733633763796206e-09, disciminator loss fake = 2.1241062313492876e-06, generator loss = 13.1764497756958\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 3, Batch: 254/468, discriminator loss real = 1.0067138962732702e-11, disciminator loss fake = 2.105608473357279e-06, generator loss = 13.286724090576172\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 3, Batch: 255/468, discriminator loss real = 2.9693554282061996e-09, disciminator loss fake = 2.4776149984973017e-06, generator loss = 13.364556312561035\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 3, Batch: 256/468, discriminator loss real = 2.43571690594635e-10, disciminator loss fake = 2.853837941074744e-06, generator loss = 13.177284240722656\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 3, Batch: 257/468, discriminator loss real = 2.352675276817706e-10, disciminator loss fake = 2.1109381123096682e-06, generator loss = 13.061464309692383\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 3, Batch: 258/468, discriminator loss real = 9.531673228480031e-09, disciminator loss fake = 2.516874701541383e-06, generator loss = 13.28144645690918\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 3, Batch: 259/468, discriminator loss real = 3.5552531585381075e-07, disciminator loss fake = 2.6833135962078813e-06, generator loss = 13.241373062133789\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 3, Batch: 260/468, discriminator loss real = 9.527997946179312e-09, disciminator loss fake = 2.604267820061068e-06, generator loss = 13.361255645751953\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 3, Batch: 261/468, discriminator loss real = 8.846914867355338e-11, disciminator loss fake = 2.386063897574786e-06, generator loss = 13.248218536376953\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 3, Batch: 262/468, discriminator loss real = 7.022342234618006e-14, disciminator loss fake = 2.6110760700248647e-06, generator loss = 13.280698776245117\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 3, Batch: 263/468, discriminator loss real = 3.4187084586856376e-13, disciminator loss fake = 3.063913027290255e-06, generator loss = 13.23990249633789\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 3, Batch: 264/468, discriminator loss real = 7.461848916534564e-10, disciminator loss fake = 2.521375790820457e-06, generator loss = 13.233115196228027\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 3, Batch: 265/468, discriminator loss real = 3.471344825811684e-05, disciminator loss fake = 2.1970467969367746e-06, generator loss = 13.34421157836914\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 3, Batch: 266/468, discriminator loss real = 6.265259600013451e-08, disciminator loss fake = 2.3122238417272456e-06, generator loss = 13.321466445922852\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 3, Batch: 267/468, discriminator loss real = 4.818865306788211e-10, disciminator loss fake = 3.008919065905502e-06, generator loss = 13.206123352050781\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 3, Batch: 268/468, discriminator loss real = 5.622067481697579e-13, disciminator loss fake = 1.6015218307074974e-06, generator loss = 13.177154541015625\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 3, Batch: 269/468, discriminator loss real = 9.031919603330607e-07, disciminator loss fake = 2.238215529359877e-06, generator loss = 13.223438262939453\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 3, Batch: 270/468, discriminator loss real = 1.7638959259549556e-15, disciminator loss fake = 2.8979507078474853e-06, generator loss = 13.272629737854004\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 3, Batch: 271/468, discriminator loss real = 5.327622024098311e-11, disciminator loss fake = 2.2976994387136074e-06, generator loss = 13.306379318237305\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 3, Batch: 272/468, discriminator loss real = 1.3461073145037972e-08, disciminator loss fake = 2.3515444809163455e-06, generator loss = 13.240636825561523\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 3, Batch: 273/468, discriminator loss real = 9.261445776953536e-13, disciminator loss fake = 2.3157213036029134e-06, generator loss = 13.224090576171875\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 274/468, discriminator loss real = 1.383314351954823e-09, disciminator loss fake = 2.382135335210478e-06, generator loss = 13.214503288269043\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 3, Batch: 275/468, discriminator loss real = 6.211712477721676e-09, disciminator loss fake = 2.6163361326325685e-06, generator loss = 13.163948059082031\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 3, Batch: 276/468, discriminator loss real = 3.941463128098732e-11, disciminator loss fake = 2.5987753815570613e-06, generator loss = 13.383614540100098\n",
      "2/2 [==============================] - 0s 36ms/step\n",
      "Epoch: 3, Batch: 277/468, discriminator loss real = 1.0186559712063725e-12, disciminator loss fake = 2.938139687103103e-06, generator loss = 13.299696922302246\n",
      "2/2 [==============================] - 0s 38ms/step\n",
      "Epoch: 3, Batch: 278/468, discriminator loss real = 3.6563875482897856e-07, disciminator loss fake = 2.897813601521193e-06, generator loss = 13.285283088684082\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 279/468, discriminator loss real = 1.1433343855005162e-11, disciminator loss fake = 2.938293619081378e-06, generator loss = 13.302558898925781\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 3, Batch: 280/468, discriminator loss real = 1.0258615645852842e-07, disciminator loss fake = 2.6986526791006327e-06, generator loss = 13.380486488342285\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 3, Batch: 281/468, discriminator loss real = 1.4681079107958794e-07, disciminator loss fake = 2.192784450016916e-06, generator loss = 13.350761413574219\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 3, Batch: 282/468, discriminator loss real = 4.918915622043052e-11, disciminator loss fake = 2.3151310415414628e-06, generator loss = 13.34691333770752\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 3, Batch: 283/468, discriminator loss real = 4.851269125999425e-13, disciminator loss fake = 1.9066724235017318e-06, generator loss = 13.253271102905273\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 284/468, discriminator loss real = 1.0405131617430285e-11, disciminator loss fake = 2.5770914362510666e-06, generator loss = 13.158808708190918\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 3, Batch: 285/468, discriminator loss real = 1.3531649134534973e-09, disciminator loss fake = 2.832809059327701e-06, generator loss = 13.313213348388672\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 286/468, discriminator loss real = 8.305518772733222e-11, disciminator loss fake = 2.529585572119686e-06, generator loss = 13.341197967529297\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 3, Batch: 287/468, discriminator loss real = 3.472852430977391e-12, disciminator loss fake = 2.047158432105789e-06, generator loss = 13.301734924316406\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 3, Batch: 288/468, discriminator loss real = 2.3512726488039704e-11, disciminator loss fake = 2.023870820266893e-06, generator loss = 13.357704162597656\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 3, Batch: 289/468, discriminator loss real = 1.7684136099926917e-10, disciminator loss fake = 2.1834300696355058e-06, generator loss = 13.386019706726074\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 3, Batch: 290/468, discriminator loss real = 2.1703913666293317e-10, disciminator loss fake = 2.0179572857159656e-06, generator loss = 13.301294326782227\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 3, Batch: 291/468, discriminator loss real = 1.1468653311101987e-14, disciminator loss fake = 2.3664288164582103e-06, generator loss = 13.302830696105957\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 3, Batch: 292/468, discriminator loss real = 1.6986205775282315e-09, disciminator loss fake = 2.4311025299539324e-06, generator loss = 13.400039672851562\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 3, Batch: 293/468, discriminator loss real = 7.171242799586253e-08, disciminator loss fake = 2.0658771973103285e-06, generator loss = 13.413485527038574\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 3, Batch: 294/468, discriminator loss real = 5.409335826489503e-11, disciminator loss fake = 2.2085910131863784e-06, generator loss = 13.327783584594727\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 3, Batch: 295/468, discriminator loss real = 4.4776413687941385e-09, disciminator loss fake = 2.277680778206559e-06, generator loss = 13.403839111328125\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 3, Batch: 296/468, discriminator loss real = 6.393837824643367e-13, disciminator loss fake = 2.191806288465159e-06, generator loss = 13.397472381591797\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 3, Batch: 297/468, discriminator loss real = 8.920634370079839e-11, disciminator loss fake = 2.0737161321449094e-06, generator loss = 13.436038970947266\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 3, Batch: 298/468, discriminator loss real = 5.383172947404091e-07, disciminator loss fake = 1.7243939964828314e-06, generator loss = 13.348873138427734\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 3, Batch: 299/468, discriminator loss real = 6.483919623434531e-09, disciminator loss fake = 2.271427547384519e-06, generator loss = 13.415704727172852\n",
      "2/2 [==============================] - 0s 32ms/step\n",
      "Epoch: 3, Batch: 300/468, discriminator loss real = 3.609394172432445e-10, disciminator loss fake = 2.074881876978907e-06, generator loss = 13.49844741821289\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 3, Batch: 301/468, discriminator loss real = 1.909508662301107e-11, disciminator loss fake = 2.2717854335496668e-06, generator loss = 13.51148796081543\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 302/468, discriminator loss real = 2.5337039757933333e-11, disciminator loss fake = 2.000894028242328e-06, generator loss = 13.385736465454102\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 3, Batch: 303/468, discriminator loss real = 5.2348233386956267e-11, disciminator loss fake = 2.1189202925597783e-06, generator loss = 13.4966459274292\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 3, Batch: 304/468, discriminator loss real = 5.431846972214771e-08, disciminator loss fake = 2.164073976018699e-06, generator loss = 13.426918983459473\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 3, Batch: 305/468, discriminator loss real = 2.796597868837125e-07, disciminator loss fake = 2.1013638615841046e-06, generator loss = 13.398427963256836\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 3, Batch: 306/468, discriminator loss real = 2.1542572170574203e-09, disciminator loss fake = 2.200433300458826e-06, generator loss = 13.516926765441895\n",
      "2/2 [==============================] - 0s 38ms/step\n",
      "Epoch: 3, Batch: 307/468, discriminator loss real = 5.2581300424847655e-11, disciminator loss fake = 1.7575298443262e-06, generator loss = 13.523550033569336\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 3, Batch: 308/468, discriminator loss real = 4.210271714599756e-11, disciminator loss fake = 1.9097285530733643e-06, generator loss = 13.378364562988281\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 3, Batch: 309/468, discriminator loss real = 8.083014222393103e-07, disciminator loss fake = 1.8506674450691207e-06, generator loss = 13.359098434448242\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 3, Batch: 310/468, discriminator loss real = 4.78913353418875e-10, disciminator loss fake = 1.6771002719906392e-06, generator loss = 13.345821380615234\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 3, Batch: 311/468, discriminator loss real = 1.3333277190663573e-11, disciminator loss fake = 2.0781462808372453e-06, generator loss = 13.479236602783203\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 3, Batch: 312/468, discriminator loss real = 2.0750792750767744e-10, disciminator loss fake = 1.3102215916660498e-06, generator loss = 13.501113891601562\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 3, Batch: 313/468, discriminator loss real = 2.0520376509125526e-09, disciminator loss fake = 2.1546425159613136e-06, generator loss = 13.54234504699707\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 3, Batch: 314/468, discriminator loss real = 1.5980330392295627e-09, disciminator loss fake = 1.6117051018227357e-06, generator loss = 13.505891799926758\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 3, Batch: 315/468, discriminator loss real = 3.706853268781174e-09, disciminator loss fake = 1.444327040189819e-06, generator loss = 13.59002685546875\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 3, Batch: 316/468, discriminator loss real = 4.1077353324370236e-11, disciminator loss fake = 2.1810465113958344e-06, generator loss = 13.507980346679688\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 3, Batch: 317/468, discriminator loss real = 4.923362828535005e-10, disciminator loss fake = 1.8222322069050279e-06, generator loss = 13.43643569946289\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 3, Batch: 318/468, discriminator loss real = 3.466612760738563e-11, disciminator loss fake = 1.9924686966987792e-06, generator loss = 13.579473495483398\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 3, Batch: 319/468, discriminator loss real = 2.3370786948362365e-05, disciminator loss fake = 1.7072234186343849e-06, generator loss = 13.549548149108887\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 3, Batch: 320/468, discriminator loss real = 1.2972364515917434e-08, disciminator loss fake = 2.06228696697508e-06, generator loss = 13.574983596801758\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 3, Batch: 321/468, discriminator loss real = 1.8502676821241515e-11, disciminator loss fake = 2.356199047426344e-06, generator loss = 13.50086784362793\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 3, Batch: 322/468, discriminator loss real = 1.1829661694662263e-09, disciminator loss fake = 2.329545623069862e-06, generator loss = 13.498347282409668\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 3, Batch: 323/468, discriminator loss real = 9.38718325294019e-10, disciminator loss fake = 1.927843186422251e-06, generator loss = 13.522554397583008\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 3, Batch: 324/468, discriminator loss real = 1.389902877235727e-07, disciminator loss fake = 1.91157050721813e-06, generator loss = 13.457822799682617\n",
      "2/2 [==============================] - 0s 38ms/step\n",
      "Epoch: 3, Batch: 325/468, discriminator loss real = 2.475785132460828e-10, disciminator loss fake = 1.8140103748010006e-06, generator loss = 13.58414077758789\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 3, Batch: 326/468, discriminator loss real = 3.7294139131061055e-12, disciminator loss fake = 1.6762528503022622e-06, generator loss = 13.498214721679688\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 3, Batch: 327/468, discriminator loss real = 3.2855110299045975e-10, disciminator loss fake = 1.9414385405980283e-06, generator loss = 13.455446243286133\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 3, Batch: 328/468, discriminator loss real = 5.77326882589442e-14, disciminator loss fake = 1.973361122509232e-06, generator loss = 13.476564407348633\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 3, Batch: 329/468, discriminator loss real = 1.7380173966685675e-09, disciminator loss fake = 2.6117813831660897e-06, generator loss = 13.55963134765625\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 3, Batch: 330/468, discriminator loss real = 7.253576211896373e-11, disciminator loss fake = 1.7625191048864508e-06, generator loss = 13.400276184082031\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 3, Batch: 331/468, discriminator loss real = 2.2802284505019088e-08, disciminator loss fake = 1.8192789639215334e-06, generator loss = 13.574464797973633\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 332/468, discriminator loss real = 2.9416590052733227e-08, disciminator loss fake = 2.1352775547711644e-06, generator loss = 13.5737943649292\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 3, Batch: 333/468, discriminator loss real = 9.131533555565077e-15, disciminator loss fake = 2.0756820049427915e-06, generator loss = 13.425559997558594\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 3, Batch: 334/468, discriminator loss real = 2.6779011300104294e-11, disciminator loss fake = 1.7991272898143507e-06, generator loss = 13.508265495300293\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 3, Batch: 335/468, discriminator loss real = 1.108323571807901e-10, disciminator loss fake = 1.4825652669969713e-06, generator loss = 13.510358810424805\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 3, Batch: 336/468, discriminator loss real = 0.00028689499595202506, disciminator loss fake = 2.0248655800969573e-06, generator loss = 13.387470245361328\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 3, Batch: 337/468, discriminator loss real = 1.5640264194871634e-08, disciminator loss fake = 2.203346411988605e-06, generator loss = 12.981712341308594\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 3, Batch: 338/468, discriminator loss real = 1.1811674971440311e-09, disciminator loss fake = 2.9075472411932424e-06, generator loss = 13.086652755737305\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 3, Batch: 339/468, discriminator loss real = 9.471469866184634e-07, disciminator loss fake = 4.412924226926407e-06, generator loss = 12.982109069824219\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 3, Batch: 340/468, discriminator loss real = 1.1776496444682039e-11, disciminator loss fake = 3.5290800042275805e-06, generator loss = 12.875121116638184\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 341/468, discriminator loss real = 2.055025039027214e-09, disciminator loss fake = 3.7246984447847353e-06, generator loss = 12.73328971862793\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 3, Batch: 342/468, discriminator loss real = 4.810343204493528e-13, disciminator loss fake = 3.970704256062163e-06, generator loss = 12.71448802947998\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 3, Batch: 343/468, discriminator loss real = 5.053294898971217e-06, disciminator loss fake = 5.077713467471767e-06, generator loss = 12.614089965820312\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 3, Batch: 344/468, discriminator loss real = 3.9251457986666516e-13, disciminator loss fake = 5.668289304594509e-06, generator loss = 12.607284545898438\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 3, Batch: 345/468, discriminator loss real = 7.258285633767944e-14, disciminator loss fake = 4.85742657474475e-06, generator loss = 12.556451797485352\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 346/468, discriminator loss real = 4.741311306782382e-14, disciminator loss fake = 3.959797140851151e-06, generator loss = 12.595873832702637\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 3, Batch: 347/468, discriminator loss real = 3.6662957114685923e-09, disciminator loss fake = 4.908618848276092e-06, generator loss = 12.650607109069824\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 3, Batch: 348/468, discriminator loss real = 4.1406555267853307e-11, disciminator loss fake = 5.059589511802187e-06, generator loss = 12.610057830810547\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 3, Batch: 349/468, discriminator loss real = 8.438852394654361e-11, disciminator loss fake = 4.980480298399925e-06, generator loss = 12.576107025146484\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 3, Batch: 350/468, discriminator loss real = 8.981803495400342e-11, disciminator loss fake = 5.618761861114763e-06, generator loss = 12.537551879882812\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 3, Batch: 351/468, discriminator loss real = 4.624372716352521e-13, disciminator loss fake = 6.547117209265707e-06, generator loss = 12.731401443481445\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 3, Batch: 352/468, discriminator loss real = 6.906748239998706e-07, disciminator loss fake = 5.540711754292715e-06, generator loss = 12.636494636535645\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 3, Batch: 353/468, discriminator loss real = 4.0951388113885656e-11, disciminator loss fake = 4.362680556369014e-06, generator loss = 12.620426177978516\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 3, Batch: 354/468, discriminator loss real = 6.758114033666995e-14, disciminator loss fake = 4.008682481071446e-06, generator loss = 12.636407852172852\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 3, Batch: 355/468, discriminator loss real = 5.426347149395383e-10, disciminator loss fake = 4.953992629452841e-06, generator loss = 12.650177955627441\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 3, Batch: 356/468, discriminator loss real = 2.579087947651715e-07, disciminator loss fake = 4.300140972191002e-06, generator loss = 12.600391387939453\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 3, Batch: 357/468, discriminator loss real = 4.525916588119655e-13, disciminator loss fake = 4.523761163000017e-06, generator loss = 12.586200714111328\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 358/468, discriminator loss real = 1.0729845900669943e-09, disciminator loss fake = 6.859054792585084e-06, generator loss = 12.630370140075684\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 3, Batch: 359/468, discriminator loss real = 1.1547526478051465e-14, disciminator loss fake = 4.683739916799823e-06, generator loss = 12.632092475891113\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 3, Batch: 360/468, discriminator loss real = 5.6858320135466656e-12, disciminator loss fake = 4.596379767463077e-06, generator loss = 12.774116516113281\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 3, Batch: 361/468, discriminator loss real = 1.1521752790125822e-13, disciminator loss fake = 5.277766376821091e-06, generator loss = 12.802980422973633\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 3, Batch: 362/468, discriminator loss real = 1.9974719100979144e-10, disciminator loss fake = 5.225489985605236e-06, generator loss = 12.716058731079102\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 3, Batch: 363/468, discriminator loss real = 1.7557386100541805e-10, disciminator loss fake = 4.989854005543748e-06, generator loss = 12.860627174377441\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 3, Batch: 364/468, discriminator loss real = 9.496451541801676e-11, disciminator loss fake = 4.098922545381356e-06, generator loss = 12.792518615722656\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 3, Batch: 365/468, discriminator loss real = 4.5644391044596944e-11, disciminator loss fake = 3.5983593988930807e-06, generator loss = 12.80670166015625\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 3, Batch: 366/468, discriminator loss real = 4.659519731858852e-12, disciminator loss fake = 4.781152711075265e-06, generator loss = 12.839632034301758\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 3, Batch: 367/468, discriminator loss real = 5.078385628687343e-13, disciminator loss fake = 4.555723990051774e-06, generator loss = 12.850933074951172\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 3, Batch: 368/468, discriminator loss real = 3.97045418765174e-09, disciminator loss fake = 3.5903465231967857e-06, generator loss = 12.685528755187988\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 3, Batch: 369/468, discriminator loss real = 1.4195544045803032e-11, disciminator loss fake = 3.1231438697432168e-06, generator loss = 12.996992111206055\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 3, Batch: 370/468, discriminator loss real = 7.84242300006649e-13, disciminator loss fake = 4.368673216958996e-06, generator loss = 12.799368858337402\n",
      "2/2 [==============================] - 0s 37ms/step\n",
      "Epoch: 3, Batch: 371/468, discriminator loss real = 5.149420126415727e-11, disciminator loss fake = 2.711813522182638e-06, generator loss = 12.968742370605469\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 3, Batch: 372/468, discriminator loss real = 9.90070803119636e-10, disciminator loss fake = 3.4461588711565128e-06, generator loss = 12.955906867980957\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 373/468, discriminator loss real = 3.3109281917693967e-13, disciminator loss fake = 3.7607503600156633e-06, generator loss = 12.811448097229004\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 3, Batch: 374/468, discriminator loss real = 1.7946031149302343e-14, disciminator loss fake = 3.763673248613486e-06, generator loss = 13.024611473083496\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 3, Batch: 375/468, discriminator loss real = 1.3547692390147859e-07, disciminator loss fake = 3.2076686693471856e-06, generator loss = 12.852344512939453\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 376/468, discriminator loss real = 4.1987116561337245e-10, disciminator loss fake = 3.3756703032850055e-06, generator loss = 13.09897232055664\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 3, Batch: 377/468, discriminator loss real = 6.987091027282899e-13, disciminator loss fake = 3.2532191198697546e-06, generator loss = 12.854669570922852\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 3, Batch: 378/468, discriminator loss real = 6.955783646844793e-06, disciminator loss fake = 2.8003728402836714e-06, generator loss = 12.902812957763672\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 3, Batch: 379/468, discriminator loss real = 5.501210598168882e-12, disciminator loss fake = 3.349600319779711e-06, generator loss = 13.03073787689209\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 3, Batch: 380/468, discriminator loss real = 9.895851915686649e-10, disciminator loss fake = 2.8789074804080883e-06, generator loss = 13.027774810791016\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 3, Batch: 381/468, discriminator loss real = 1.0453379495345416e-08, disciminator loss fake = 3.5183329600840807e-06, generator loss = 13.106189727783203\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 3, Batch: 382/468, discriminator loss real = 2.0148399615393942e-10, disciminator loss fake = 2.8600038604054134e-06, generator loss = 13.002397537231445\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 3, Batch: 383/468, discriminator loss real = 5.783796495961724e-06, disciminator loss fake = 3.1015606509754434e-06, generator loss = 12.911855697631836\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 3, Batch: 384/468, discriminator loss real = 3.7297588628693035e-11, disciminator loss fake = 3.1002068681118544e-06, generator loss = 13.075977325439453\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 3, Batch: 385/468, discriminator loss real = 1.2309194462323259e-12, disciminator loss fake = 2.9274374355736654e-06, generator loss = 12.885513305664062\n",
      "2/2 [==============================] - 0s 38ms/step\n",
      "Epoch: 3, Batch: 386/468, discriminator loss real = 4.075338330689071e-11, disciminator loss fake = 3.1261781714420067e-06, generator loss = 12.873274803161621\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 3, Batch: 387/468, discriminator loss real = 3.732615952434237e-11, disciminator loss fake = 2.4589969598309835e-06, generator loss = 13.007169723510742\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 3, Batch: 388/468, discriminator loss real = 3.7972344713033124e-10, disciminator loss fake = 2.6808015718415845e-06, generator loss = 13.035722732543945\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 3, Batch: 389/468, discriminator loss real = 2.084312757111295e-11, disciminator loss fake = 3.5377715903450735e-06, generator loss = 13.040704727172852\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 3, Batch: 390/468, discriminator loss real = 5.300844918565417e-07, disciminator loss fake = 3.760650770345819e-06, generator loss = 13.14836311340332\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 3, Batch: 391/468, discriminator loss real = 1.1041611825161543e-13, disciminator loss fake = 2.9303380415512947e-06, generator loss = 13.003488540649414\n",
      "2/2 [==============================] - 0s 36ms/step\n",
      "Epoch: 3, Batch: 392/468, discriminator loss real = 4.880683964619825e-12, disciminator loss fake = 2.455977210047422e-06, generator loss = 13.150801658630371\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 3, Batch: 393/468, discriminator loss real = 1.4116051209878133e-11, disciminator loss fake = 3.200400215064292e-06, generator loss = 13.140769958496094\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 3, Batch: 394/468, discriminator loss real = 2.242621732762018e-08, disciminator loss fake = 2.642833806021372e-06, generator loss = 13.266489028930664\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 3, Batch: 395/468, discriminator loss real = 2.184171767061205e-11, disciminator loss fake = 2.527209971958655e-06, generator loss = 13.144145965576172\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 3, Batch: 396/468, discriminator loss real = 5.700679728617986e-13, disciminator loss fake = 2.8408212529029697e-06, generator loss = 13.150686264038086\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 3, Batch: 397/468, discriminator loss real = 3.108310137056591e-11, disciminator loss fake = 2.9791719953209395e-06, generator loss = 13.214397430419922\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 3, Batch: 398/468, discriminator loss real = 9.920228194459924e-07, disciminator loss fake = 2.634947577462299e-06, generator loss = 13.136635780334473\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 3, Batch: 399/468, discriminator loss real = 9.516320176317095e-08, disciminator loss fake = 2.4648009002703475e-06, generator loss = 13.236967086791992\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 3, Batch: 400/468, discriminator loss real = 1.9361507189175065e-11, disciminator loss fake = 2.9260709197842516e-06, generator loss = 13.206528663635254\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 3, Batch: 401/468, discriminator loss real = 6.249418760262415e-09, disciminator loss fake = 2.9320528938114876e-06, generator loss = 13.253622055053711\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 3, Batch: 402/468, discriminator loss real = 3.2196927229503425e-15, disciminator loss fake = 2.2675881155009847e-06, generator loss = 13.039236068725586\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 3, Batch: 403/468, discriminator loss real = 9.447019555519631e-11, disciminator loss fake = 2.4202020085795084e-06, generator loss = 13.398138046264648\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 3, Batch: 404/468, discriminator loss real = 8.46672154608541e-09, disciminator loss fake = 2.3266202333616093e-06, generator loss = 13.277364730834961\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 3, Batch: 405/468, discriminator loss real = 3.8986986510280985e-06, disciminator loss fake = 2.547494204918621e-06, generator loss = 13.120482444763184\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 3, Batch: 406/468, discriminator loss real = 7.664320733624663e-09, disciminator loss fake = 2.6340517251810525e-06, generator loss = 13.394582748413086\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 3, Batch: 407/468, discriminator loss real = 1.5151562730159052e-12, disciminator loss fake = 2.4012674657569733e-06, generator loss = 13.151171684265137\n",
      "2/2 [==============================] - 0s 37ms/step\n",
      "Epoch: 3, Batch: 408/468, discriminator loss real = 2.486338634977159e-10, disciminator loss fake = 2.824734565365361e-06, generator loss = 13.187187194824219\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 3, Batch: 409/468, discriminator loss real = 2.2992891146600414e-08, disciminator loss fake = 2.1427622414194047e-06, generator loss = 13.199400901794434\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 3, Batch: 410/468, discriminator loss real = 7.600933771279017e-10, disciminator loss fake = 2.5902925244736252e-06, generator loss = 13.327628135681152\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 3, Batch: 411/468, discriminator loss real = 4.415209531316577e-09, disciminator loss fake = 2.122506430168869e-06, generator loss = 13.194746017456055\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 3, Batch: 412/468, discriminator loss real = 9.061137257182494e-11, disciminator loss fake = 3.027524599019671e-06, generator loss = 13.3505277633667\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 3, Batch: 413/468, discriminator loss real = 2.6330870817048435e-10, disciminator loss fake = 2.023908109549666e-06, generator loss = 13.332575798034668\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 3, Batch: 414/468, discriminator loss real = 6.672268959562189e-09, disciminator loss fake = 2.7021815185435116e-06, generator loss = 13.351523399353027\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 3, Batch: 415/468, discriminator loss real = 5.7598118982649105e-12, disciminator loss fake = 2.368963350818376e-06, generator loss = 13.360442161560059\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 3, Batch: 416/468, discriminator loss real = 1.1190432261387606e-11, disciminator loss fake = 1.995459342651884e-06, generator loss = 13.352456092834473\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 3, Batch: 417/468, discriminator loss real = 9.654280153092998e-11, disciminator loss fake = 1.93640175893961e-06, generator loss = 13.364340782165527\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 3, Batch: 418/468, discriminator loss real = 1.1170668834381559e-09, disciminator loss fake = 2.1492191990546416e-06, generator loss = 13.486719131469727\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 3, Batch: 419/468, discriminator loss real = 2.0251562649065136e-09, disciminator loss fake = 2.951789383587311e-06, generator loss = 13.35628890991211\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 420/468, discriminator loss real = 6.550560649465353e-10, disciminator loss fake = 2.678269083844498e-06, generator loss = 13.33914566040039\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 3, Batch: 421/468, discriminator loss real = 7.127775702997496e-09, disciminator loss fake = 2.152787146769697e-06, generator loss = 13.345142364501953\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 3, Batch: 422/468, discriminator loss real = 9.055813876557295e-09, disciminator loss fake = 1.908634658320807e-06, generator loss = 13.464826583862305\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 3, Batch: 423/468, discriminator loss real = 1.1066537020099076e-08, disciminator loss fake = 2.535511157475412e-06, generator loss = 13.433277130126953\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 3, Batch: 424/468, discriminator loss real = 4.230460148857418e-10, disciminator loss fake = 2.307717977600987e-06, generator loss = 13.307222366333008\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 3, Batch: 425/468, discriminator loss real = 2.020656732215631e-11, disciminator loss fake = 1.9301719476061407e-06, generator loss = 13.440061569213867\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 3, Batch: 426/468, discriminator loss real = 9.393003817239828e-14, disciminator loss fake = 1.933574822032824e-06, generator loss = 13.362525939941406\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 3, Batch: 427/468, discriminator loss real = 2.9412643111001446e-13, disciminator loss fake = 2.06436470762128e-06, generator loss = 13.602608680725098\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 3, Batch: 428/468, discriminator loss real = 6.3843513089523185e-06, disciminator loss fake = 1.8645317823029472e-06, generator loss = 13.474922180175781\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 3, Batch: 429/468, discriminator loss real = 1.2183231090645563e-09, disciminator loss fake = 2.348549287489732e-06, generator loss = 13.410889625549316\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 3, Batch: 430/468, discriminator loss real = 1.374161114758854e-11, disciminator loss fake = 2.460515588609269e-06, generator loss = 13.375811576843262\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 3, Batch: 431/468, discriminator loss real = 4.97672974879293e-13, disciminator loss fake = 1.6991091342788422e-06, generator loss = 13.54152774810791\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 3, Batch: 432/468, discriminator loss real = 5.304613952955561e-12, disciminator loss fake = 2.2578124116989784e-06, generator loss = 13.46019172668457\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 3, Batch: 433/468, discriminator loss real = 1.1296417360556754e-12, disciminator loss fake = 1.8162797914555995e-06, generator loss = 13.495403289794922\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 3, Batch: 434/468, discriminator loss real = 5.239249138699886e-12, disciminator loss fake = 1.719158717605751e-06, generator loss = 13.443218231201172\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 3, Batch: 435/468, discriminator loss real = 6.2999089452120405e-12, disciminator loss fake = 2.0150630462012487e-06, generator loss = 13.422800064086914\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 3, Batch: 436/468, discriminator loss real = 1.554636302504575e-12, disciminator loss fake = 1.6560056792513933e-06, generator loss = 13.534805297851562\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 3, Batch: 437/468, discriminator loss real = 2.8985855937690985e-09, disciminator loss fake = 2.3900001906440593e-06, generator loss = 13.478857040405273\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 438/468, discriminator loss real = 1.9118390204297953e-10, disciminator loss fake = 2.254573246318614e-06, generator loss = 13.456914901733398\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 3, Batch: 439/468, discriminator loss real = 2.1595082666525656e-10, disciminator loss fake = 2.0364668671390973e-06, generator loss = 13.509654998779297\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 3, Batch: 440/468, discriminator loss real = 3.0045004706380496e-08, disciminator loss fake = 1.562457441650622e-06, generator loss = 13.514688491821289\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 3, Batch: 441/468, discriminator loss real = 6.630423749105774e-13, disciminator loss fake = 1.9868125491484534e-06, generator loss = 13.54757308959961\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 3, Batch: 442/468, discriminator loss real = 5.405731973162631e-10, disciminator loss fake = 1.9234198589401785e-06, generator loss = 13.57763385772705\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 3, Batch: 443/468, discriminator loss real = 4.365997494093499e-11, disciminator loss fake = 1.7132858829427278e-06, generator loss = 13.53347396850586\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 3, Batch: 444/468, discriminator loss real = 8.155572051027349e-11, disciminator loss fake = 1.5289691646103165e-06, generator loss = 13.470300674438477\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 3, Batch: 445/468, discriminator loss real = 7.169220512387442e-12, disciminator loss fake = 1.8427793975206441e-06, generator loss = 13.479592323303223\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 446/468, discriminator loss real = 1.502524241914216e-06, disciminator loss fake = 1.9296871869300958e-06, generator loss = 13.482305526733398\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 3, Batch: 447/468, discriminator loss real = 8.818817320843664e-08, disciminator loss fake = 1.3249564290163107e-06, generator loss = 13.475719451904297\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 3, Batch: 448/468, discriminator loss real = 2.076352867419473e-09, disciminator loss fake = 1.5626925460310304e-06, generator loss = 13.599703788757324\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 3, Batch: 449/468, discriminator loss real = 2.257855291620814e-10, disciminator loss fake = 1.8227633518108632e-06, generator loss = 13.535406112670898\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 3, Batch: 450/468, discriminator loss real = 1.6909588396174513e-08, disciminator loss fake = 1.8348912362853298e-06, generator loss = 13.570938110351562\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 3, Batch: 451/468, discriminator loss real = 7.951075561840604e-12, disciminator loss fake = 1.6518681604793528e-06, generator loss = 13.631942749023438\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 3, Batch: 452/468, discriminator loss real = 6.506212230306119e-06, disciminator loss fake = 1.2638058706215816e-06, generator loss = 13.586406707763672\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 3, Batch: 453/468, discriminator loss real = 2.990904468536115e-10, disciminator loss fake = 1.625677782612911e-06, generator loss = 13.52990436553955\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 3, Batch: 454/468, discriminator loss real = 3.093768459732499e-13, disciminator loss fake = 1.6599705077169347e-06, generator loss = 13.56640338897705\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 3, Batch: 455/468, discriminator loss real = 5.669294244128875e-13, disciminator loss fake = 1.7486654542153701e-06, generator loss = 13.56084156036377\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 3, Batch: 456/468, discriminator loss real = 1.1012214473637982e-09, disciminator loss fake = 1.9503706880641403e-06, generator loss = 13.565637588500977\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 3, Batch: 457/468, discriminator loss real = 4.622884974131436e-12, disciminator loss fake = 1.999283085751813e-06, generator loss = 13.516892433166504\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 3, Batch: 458/468, discriminator loss real = 8.875434566978091e-13, disciminator loss fake = 1.5852624528633896e-06, generator loss = 13.50703239440918\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 3, Batch: 459/468, discriminator loss real = 5.422898993856506e-06, disciminator loss fake = 1.8099797216564184e-06, generator loss = 13.512269020080566\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 3, Batch: 460/468, discriminator loss real = 6.882212577608016e-10, disciminator loss fake = 1.6167670082722907e-06, generator loss = 13.554679870605469\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 3, Batch: 461/468, discriminator loss real = 7.30457860864675e-10, disciminator loss fake = 1.620863372409076e-06, generator loss = 13.63320541381836\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 3, Batch: 462/468, discriminator loss real = 7.004841151569963e-11, disciminator loss fake = 1.7749562175595202e-06, generator loss = 13.464813232421875\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 3, Batch: 463/468, discriminator loss real = 9.889999409706807e-12, disciminator loss fake = 1.7028191905410495e-06, generator loss = 13.520195007324219\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 3, Batch: 464/468, discriminator loss real = 1.8276382629522914e-09, disciminator loss fake = 1.8054586234939052e-06, generator loss = 13.669646263122559\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 3, Batch: 465/468, discriminator loss real = 6.565658683399533e-09, disciminator loss fake = 1.655118012422463e-06, generator loss = 13.634146690368652\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 3, Batch: 466/468, discriminator loss real = 1.0064179489788216e-09, disciminator loss fake = 1.917678218887886e-06, generator loss = 13.711915969848633\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 3, Batch: 467/468, discriminator loss real = 2.8946582977806834e-11, disciminator loss fake = 1.54039912558801e-06, generator loss = 13.681462287902832\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 3, Batch: 468/468, discriminator loss real = 6.573765976014556e-09, disciminator loss fake = 1.4871818621031707e-06, generator loss = 13.563924789428711\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 4, Batch: 1/468, discriminator loss real = 6.195921553597827e-10, disciminator loss fake = 1.853479489000165e-06, generator loss = 13.603939056396484\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 4, Batch: 2/468, discriminator loss real = 3.923113126802491e-06, disciminator loss fake = 1.7165521057904698e-06, generator loss = 13.631612777709961\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 4, Batch: 3/468, discriminator loss real = 4.595853031474917e-09, disciminator loss fake = 1.4887937140883878e-06, generator loss = 13.661943435668945\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 4, Batch: 4/468, discriminator loss real = 8.73336816198389e-08, disciminator loss fake = 1.7113837884608074e-06, generator loss = 13.653951644897461\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 4, Batch: 5/468, discriminator loss real = 1.4725260655268357e-07, disciminator loss fake = 1.634113687032368e-06, generator loss = 13.557245254516602\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 4, Batch: 6/468, discriminator loss real = 4.534001646350205e-11, disciminator loss fake = 1.5636431953680585e-06, generator loss = 13.592796325683594\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 4, Batch: 7/468, discriminator loss real = 9.278161572368049e-12, disciminator loss fake = 1.2764395478370716e-06, generator loss = 13.590387344360352\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 4, Batch: 8/468, discriminator loss real = 2.135727663699072e-05, disciminator loss fake = 1.9713486381078837e-06, generator loss = 13.66181468963623\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 4, Batch: 9/468, discriminator loss real = 5.241499075048228e-12, disciminator loss fake = 1.636326715015457e-06, generator loss = 13.66299057006836\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 4, Batch: 10/468, discriminator loss real = 7.0215855885180645e-06, disciminator loss fake = 1.6396347746194806e-06, generator loss = 13.622315406799316\n",
      "2/2 [==============================] - 0s 35ms/step\n",
      "Epoch: 4, Batch: 11/468, discriminator loss real = 1.337068455953272e-09, disciminator loss fake = 1.659274857956916e-06, generator loss = 13.547469139099121\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 4, Batch: 12/468, discriminator loss real = 1.7696564214020327e-09, disciminator loss fake = 1.8321492234463221e-06, generator loss = 13.499180793762207\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 4, Batch: 13/468, discriminator loss real = 2.303084167820657e-09, disciminator loss fake = 1.951547346834559e-06, generator loss = 13.623191833496094\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 4, Batch: 14/468, discriminator loss real = 3.183264199110858e-13, disciminator loss fake = 1.7021977782860631e-06, generator loss = 13.501396179199219\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 4, Batch: 15/468, discriminator loss real = 3.305389850716267e-10, disciminator loss fake = 2.215803988292464e-06, generator loss = 13.545644760131836\n",
      "2/2 [==============================] - 0s 36ms/step\n",
      "Epoch: 4, Batch: 16/468, discriminator loss real = 1.6445834205569554e-07, disciminator loss fake = 1.7675984054221772e-06, generator loss = 13.66944694519043\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 4, Batch: 17/468, discriminator loss real = 5.773734268466058e-10, disciminator loss fake = 1.8303161368748988e-06, generator loss = 13.487710952758789\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 4, Batch: 18/468, discriminator loss real = 1.1753527318081325e-10, disciminator loss fake = 1.675388830335578e-06, generator loss = 13.494915008544922\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 4, Batch: 19/468, discriminator loss real = 4.165749942330876e-06, disciminator loss fake = 1.4142907502900925e-06, generator loss = 13.503728866577148\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 4, Batch: 20/468, discriminator loss real = 9.858456412326078e-11, disciminator loss fake = 1.6656580328344717e-06, generator loss = 13.636392593383789\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 4, Batch: 21/468, discriminator loss real = 2.38770678576139e-12, disciminator loss fake = 1.4611316601076396e-06, generator loss = 13.705373764038086\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 4, Batch: 22/468, discriminator loss real = 1.7105415395235468e-07, disciminator loss fake = 1.6728488390072016e-06, generator loss = 13.599207878112793\n",
      "2/2 [==============================] - 0s 37ms/step\n",
      "Epoch: 4, Batch: 23/468, discriminator loss real = 6.653335660189441e-10, disciminator loss fake = 1.7991297909247805e-06, generator loss = 13.544276237487793\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 4, Batch: 24/468, discriminator loss real = 5.721456197704811e-09, disciminator loss fake = 2.1346554603951517e-06, generator loss = 13.592696189880371\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 4, Batch: 25/468, discriminator loss real = 1.579821997665931e-07, disciminator loss fake = 1.3406831840256928e-06, generator loss = 13.513047218322754\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 4, Batch: 26/468, discriminator loss real = 2.7723017215208756e-09, disciminator loss fake = 1.5743599988127244e-06, generator loss = 13.662327766418457\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 4, Batch: 27/468, discriminator loss real = 1.0867145399696965e-13, disciminator loss fake = 1.589864723428036e-06, generator loss = 13.57400894165039\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 4, Batch: 28/468, discriminator loss real = 1.2966831384672584e-12, disciminator loss fake = 1.3967606946607702e-06, generator loss = 13.572013854980469\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 4, Batch: 29/468, discriminator loss real = 1.7731457413461271e-09, disciminator loss fake = 2.0082034097868018e-06, generator loss = 13.64945125579834\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 4, Batch: 30/468, discriminator loss real = 2.9437335815479804e-14, disciminator loss fake = 1.884508264993201e-06, generator loss = 13.573291778564453\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 4, Batch: 31/468, discriminator loss real = 2.275758147738966e-15, disciminator loss fake = 1.988692019949667e-06, generator loss = 13.589815139770508\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 4, Batch: 32/468, discriminator loss real = 5.896486640968868e-13, disciminator loss fake = 1.7537103076392668e-06, generator loss = 13.614861488342285\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 4, Batch: 33/468, discriminator loss real = 6.484025556058315e-12, disciminator loss fake = 1.654538891671109e-06, generator loss = 13.580913543701172\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 4, Batch: 34/468, discriminator loss real = 5.01356334919878e-12, disciminator loss fake = 1.5970047115843045e-06, generator loss = 13.67595386505127\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 4, Batch: 35/468, discriminator loss real = 6.410591241873265e-12, disciminator loss fake = 1.482758534621098e-06, generator loss = 13.723113059997559\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 4, Batch: 36/468, discriminator loss real = 4.251606289251697e-10, disciminator loss fake = 1.4143793123366777e-06, generator loss = 13.716123580932617\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 4, Batch: 37/468, discriminator loss real = 2.5858872820805345e-09, disciminator loss fake = 1.947730652318569e-06, generator loss = 13.51484489440918\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 4, Batch: 38/468, discriminator loss real = 9.110993903771458e-11, disciminator loss fake = 1.5815771803318057e-06, generator loss = 13.596372604370117\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 4, Batch: 39/468, discriminator loss real = 6.91401069730091e-09, disciminator loss fake = 1.3155859051039442e-06, generator loss = 13.549196243286133\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 4, Batch: 40/468, discriminator loss real = 5.8208378561630525e-08, disciminator loss fake = 1.5931286725390237e-06, generator loss = 13.678508758544922\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 4, Batch: 41/468, discriminator loss real = 8.995157917135455e-12, disciminator loss fake = 1.7291586118517444e-06, generator loss = 13.78475570678711\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 4, Batch: 42/468, discriminator loss real = 5.276170167434202e-09, disciminator loss fake = 1.7052377643267391e-06, generator loss = 13.691896438598633\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 4, Batch: 43/468, discriminator loss real = 2.3944059490124334e-14, disciminator loss fake = 1.6177002635231474e-06, generator loss = 13.682233810424805\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 4, Batch: 44/468, discriminator loss real = 2.201183013639252e-09, disciminator loss fake = 1.743289203659515e-06, generator loss = 13.739033699035645\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 4, Batch: 45/468, discriminator loss real = 4.7997848751091254e-11, disciminator loss fake = 1.3966977121526725e-06, generator loss = 13.726160049438477\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 4, Batch: 46/468, discriminator loss real = 2.2361783258428858e-10, disciminator loss fake = 1.3855573115506559e-06, generator loss = 13.658735275268555\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 4, Batch: 47/468, discriminator loss real = 2.6033323052843116e-08, disciminator loss fake = 1.5436664853041293e-06, generator loss = 13.697132110595703\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 4, Batch: 48/468, discriminator loss real = 1.554629619482384e-10, disciminator loss fake = 1.603676992090186e-06, generator loss = 13.729546546936035\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 4, Batch: 49/468, discriminator loss real = 2.645776930876309e-10, disciminator loss fake = 1.3594732308774837e-06, generator loss = 13.662012100219727\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 4, Batch: 50/468, discriminator loss real = 1.4258587199833528e-08, disciminator loss fake = 1.5062828424561303e-06, generator loss = 13.84602165222168\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 4, Batch: 51/468, discriminator loss real = 1.52112527018744e-08, disciminator loss fake = 1.8227199234388536e-06, generator loss = 13.796609878540039\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 4, Batch: 52/468, discriminator loss real = 5.70986762628696e-16, disciminator loss fake = 1.5738295360279153e-06, generator loss = 13.768292427062988\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 4, Batch: 53/468, discriminator loss real = 3.019285266248062e-09, disciminator loss fake = 1.349177864540252e-06, generator loss = 13.743955612182617\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 4, Batch: 54/468, discriminator loss real = 0.000352304195985198, disciminator loss fake = 1.4509349739455502e-06, generator loss = 13.44144058227539\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 4, Batch: 55/468, discriminator loss real = 3.1942644085347638e-09, disciminator loss fake = 1.9931987935706275e-06, generator loss = 13.147703170776367\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 4, Batch: 56/468, discriminator loss real = 3.23223159348629e-09, disciminator loss fake = 2.7641794986266177e-06, generator loss = 12.93331241607666\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 4, Batch: 57/468, discriminator loss real = 1.4380244772738138e-09, disciminator loss fake = 3.973274942836724e-06, generator loss = 12.779037475585938\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 4, Batch: 58/468, discriminator loss real = 2.584796439386583e-11, disciminator loss fake = 4.920561877952423e-06, generator loss = 12.661252975463867\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 4, Batch: 59/468, discriminator loss real = 1.5257052348935374e-12, disciminator loss fake = 4.177265509497374e-06, generator loss = 12.41311264038086\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 4, Batch: 60/468, discriminator loss real = 4.0072359319687223e-10, disciminator loss fake = 5.57490511710057e-06, generator loss = 12.365509033203125\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 4, Batch: 61/468, discriminator loss real = 1.314045618983073e-07, disciminator loss fake = 5.488454462465597e-06, generator loss = 12.450276374816895\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 4, Batch: 62/468, discriminator loss real = 1.038764768646061e-10, disciminator loss fake = 1.0133091564057395e-05, generator loss = 12.271649360656738\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 4, Batch: 63/468, discriminator loss real = 1.0075870259668163e-13, disciminator loss fake = 8.10425444797147e-06, generator loss = 12.14415168762207\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 4, Batch: 64/468, discriminator loss real = 1.1775367170230311e-07, disciminator loss fake = 7.848608220228925e-06, generator loss = 12.307319641113281\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 4, Batch: 65/468, discriminator loss real = 1.1355649753852504e-09, disciminator loss fake = 6.730540007993113e-06, generator loss = 12.041613578796387\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 4, Batch: 66/468, discriminator loss real = 7.29166380053492e-11, disciminator loss fake = 5.918804163229652e-06, generator loss = 12.279546737670898\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 4, Batch: 67/468, discriminator loss real = 1.1216221907413976e-13, disciminator loss fake = 9.208170013152994e-06, generator loss = 12.204488754272461\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 4, Batch: 68/468, discriminator loss real = 1.2264351860469258e-11, disciminator loss fake = 7.3784231062745675e-06, generator loss = 12.119239807128906\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 4, Batch: 69/468, discriminator loss real = 3.267928150307853e-08, disciminator loss fake = 5.477004378917627e-06, generator loss = 12.386531829833984\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 4, Batch: 70/468, discriminator loss real = 1.0243827487654844e-11, disciminator loss fake = 6.657481208094396e-06, generator loss = 12.334224700927734\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 4, Batch: 71/468, discriminator loss real = 3.2361845408307444e-12, disciminator loss fake = 8.243291631515604e-06, generator loss = 12.163284301757812\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 4, Batch: 72/468, discriminator loss real = 1.8161687431739182e-14, disciminator loss fake = 7.92336868471466e-06, generator loss = 12.322092056274414\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 4, Batch: 73/468, discriminator loss real = 8.323805644749882e-09, disciminator loss fake = 5.602677902061259e-06, generator loss = 12.411417007446289\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 4, Batch: 74/468, discriminator loss real = 6.672215704384143e-07, disciminator loss fake = 5.1719694056373555e-06, generator loss = 12.509456634521484\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 4, Batch: 75/468, discriminator loss real = 2.3030129235948604e-13, disciminator loss fake = 4.915188128506998e-06, generator loss = 12.517585754394531\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 4, Batch: 76/468, discriminator loss real = 4.488756588649778e-12, disciminator loss fake = 5.575293471338227e-06, generator loss = 12.462152481079102\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 4, Batch: 77/468, discriminator loss real = 3.0838009229539054e-11, disciminator loss fake = 5.249201421975158e-06, generator loss = 12.58089828491211\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 4, Batch: 78/468, discriminator loss real = 8.851582800062374e-10, disciminator loss fake = 4.2704405132099055e-06, generator loss = 12.559816360473633\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 4, Batch: 79/468, discriminator loss real = 6.29194960022339e-12, disciminator loss fake = 4.871829332842026e-06, generator loss = 12.777207374572754\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 4, Batch: 80/468, discriminator loss real = 5.194751746817605e-12, disciminator loss fake = 4.420242930791574e-06, generator loss = 12.667621612548828\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 4, Batch: 81/468, discriminator loss real = 3.102614302627482e-12, disciminator loss fake = 4.848998742090771e-06, generator loss = 12.665642738342285\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 4, Batch: 82/468, discriminator loss real = 1.4915747803545543e-10, disciminator loss fake = 3.7924587559245992e-06, generator loss = 12.621179580688477\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 4, Batch: 83/468, discriminator loss real = 1.1721522190366596e-12, disciminator loss fake = 4.096454176760744e-06, generator loss = 12.646873474121094\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 4, Batch: 84/468, discriminator loss real = 3.7367435534729765e-12, disciminator loss fake = 4.283383532310836e-06, generator loss = 12.832700729370117\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 4, Batch: 85/468, discriminator loss real = 7.076642050130033e-10, disciminator loss fake = 3.935679160349537e-06, generator loss = 12.824978828430176\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 4, Batch: 86/468, discriminator loss real = 5.831289227528624e-14, disciminator loss fake = 3.623463726398768e-06, generator loss = 12.86581802368164\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 4, Batch: 87/468, discriminator loss real = 3.776136736632907e-09, disciminator loss fake = 3.462133463472128e-06, generator loss = 12.723052978515625\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 4, Batch: 88/468, discriminator loss real = 4.352296734816408e-12, disciminator loss fake = 3.036270072698244e-06, generator loss = 12.925006866455078\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 4, Batch: 89/468, discriminator loss real = 1.2542591097675082e-11, disciminator loss fake = 3.936776465707226e-06, generator loss = 12.888774871826172\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 4, Batch: 90/468, discriminator loss real = 8.29267557400648e-11, disciminator loss fake = 3.338284386700252e-06, generator loss = 12.906822204589844\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 4, Batch: 91/468, discriminator loss real = 6.830308020566722e-12, disciminator loss fake = 2.9960626761749154e-06, generator loss = 12.860499382019043\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 4, Batch: 92/468, discriminator loss real = 1.7379795380634278e-08, disciminator loss fake = 3.974570063292049e-06, generator loss = 13.064720153808594\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 4, Batch: 93/468, discriminator loss real = 1.6073471763647373e-12, disciminator loss fake = 3.0520795917254873e-06, generator loss = 12.725890159606934\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 4, Batch: 94/468, discriminator loss real = 2.385114024686108e-12, disciminator loss fake = 3.843052581942175e-06, generator loss = 12.968548774719238\n",
      "2/2 [==============================] - 0s 31ms/step\n",
      "Epoch: 4, Batch: 95/468, discriminator loss real = 1.4508232115684194e-10, disciminator loss fake = 3.3129808798548765e-06, generator loss = 12.911371231079102\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 4, Batch: 96/468, discriminator loss real = 9.058088811016315e-16, disciminator loss fake = 3.243969558752724e-06, generator loss = 13.004523277282715\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 4, Batch: 97/468, discriminator loss real = 4.1035966091840237e-07, disciminator loss fake = 3.062297764699906e-06, generator loss = 13.03497314453125\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 4, Batch: 98/468, discriminator loss real = 1.027008922349637e-09, disciminator loss fake = 3.3328105928376317e-06, generator loss = 13.058900833129883\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 4, Batch: 99/468, discriminator loss real = 8.389589467583392e-09, disciminator loss fake = 3.1445651984540746e-06, generator loss = 13.08236312866211\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 4, Batch: 100/468, discriminator loss real = 3.62748059942828e-14, disciminator loss fake = 3.1770352961757453e-06, generator loss = 13.010186195373535\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 4, Batch: 101/468, discriminator loss real = 7.449860173203149e-12, disciminator loss fake = 2.989398126373999e-06, generator loss = 13.177982330322266\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 4, Batch: 102/468, discriminator loss real = 5.09645936563885e-10, disciminator loss fake = 2.807932105497457e-06, generator loss = 13.193531036376953\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 4, Batch: 103/468, discriminator loss real = 3.350283917478991e-13, disciminator loss fake = 2.903588892877451e-06, generator loss = 13.213828086853027\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 4, Batch: 104/468, discriminator loss real = 1.449051989510508e-09, disciminator loss fake = 2.715814389375737e-06, generator loss = 13.102998733520508\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 4, Batch: 105/468, discriminator loss real = 3.278558674546517e-11, disciminator loss fake = 2.559862423368031e-06, generator loss = 13.253676414489746\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 4, Batch: 106/468, discriminator loss real = 3.5703280609755694e-11, disciminator loss fake = 2.940964350273134e-06, generator loss = 13.373022079467773\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 4, Batch: 107/468, discriminator loss real = 1.1399966526326466e-09, disciminator loss fake = 2.798672539938707e-06, generator loss = 13.201009750366211\n",
      "2/2 [==============================] - 0s 34ms/step\n",
      "Epoch: 4, Batch: 108/468, discriminator loss real = 3.096653836132113e-11, disciminator loss fake = 2.690355813683709e-06, generator loss = 13.286890029907227\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 4, Batch: 109/468, discriminator loss real = 3.9416514496792843e-10, disciminator loss fake = 2.39826476899907e-06, generator loss = 13.178430557250977\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 4, Batch: 110/468, discriminator loss real = 1.722446199892147e-06, disciminator loss fake = 2.542049287512782e-06, generator loss = 13.191490173339844\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 4, Batch: 111/468, discriminator loss real = 2.1974985036938427e-13, disciminator loss fake = 2.8153383482276695e-06, generator loss = 13.283994674682617\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 4, Batch: 112/468, discriminator loss real = 1.9817928548215846e-11, disciminator loss fake = 2.197806225012755e-06, generator loss = 13.293230056762695\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 4, Batch: 113/468, discriminator loss real = 2.477305166559418e-11, disciminator loss fake = 2.242099299110123e-06, generator loss = 13.210861206054688\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 4, Batch: 114/468, discriminator loss real = 6.114812822755056e-11, disciminator loss fake = 2.764419150480535e-06, generator loss = 13.277142524719238\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 4, Batch: 115/468, discriminator loss real = 3.0345632673345335e-09, disciminator loss fake = 1.9764947865041904e-06, generator loss = 13.255953788757324\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 4, Batch: 116/468, discriminator loss real = 1.3141206872679945e-11, disciminator loss fake = 1.843169457060867e-06, generator loss = 13.331415176391602\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 4, Batch: 117/468, discriminator loss real = 4.526525820836014e-09, disciminator loss fake = 2.893949840654386e-06, generator loss = 13.401378631591797\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 4, Batch: 118/468, discriminator loss real = 2.5823493343679615e-10, disciminator loss fake = 2.1979321900289506e-06, generator loss = 13.34895133972168\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 4, Batch: 119/468, discriminator loss real = 1.3073633842175525e-10, disciminator loss fake = 2.2876561160956044e-06, generator loss = 13.334928512573242\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 4, Batch: 120/468, discriminator loss real = 2.713524127617717e-10, disciminator loss fake = 1.9072344912274275e-06, generator loss = 13.276455879211426\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 4, Batch: 121/468, discriminator loss real = 1.1135248268161896e-13, disciminator loss fake = 2.1102646314830054e-06, generator loss = 13.32695198059082\n",
      "2/2 [==============================] - 0s 33ms/step\n",
      "Epoch: 4, Batch: 122/468, discriminator loss real = 1.2174110963769635e-07, disciminator loss fake = 2.0523716557363514e-06, generator loss = 13.4456205368042\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 4, Batch: 123/468, discriminator loss real = 5.373223199711674e-09, disciminator loss fake = 2.044879693130497e-06, generator loss = 13.453839302062988\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 4, Batch: 124/468, discriminator loss real = 3.039185916819953e-11, disciminator loss fake = 2.0749139366671443e-06, generator loss = 13.398561477661133\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 4, Batch: 125/468, discriminator loss real = 2.2366197782730524e-10, disciminator loss fake = 1.8633826357472572e-06, generator loss = 13.47327995300293\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 4, Batch: 126/468, discriminator loss real = 2.2039930991368806e-10, disciminator loss fake = 2.1217454104771605e-06, generator loss = 13.528371810913086\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 4, Batch: 127/468, discriminator loss real = 6.242891759100644e-10, disciminator loss fake = 1.5875573353696382e-06, generator loss = 13.483867645263672\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 4, Batch: 128/468, discriminator loss real = 1.546417182675397e-12, disciminator loss fake = 1.6943170066952007e-06, generator loss = 13.45545768737793\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 4, Batch: 129/468, discriminator loss real = 3.850783841102823e-12, disciminator loss fake = 1.9635883745650062e-06, generator loss = 13.443094253540039\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 4, Batch: 130/468, discriminator loss real = 2.668502788530369e-12, disciminator loss fake = 2.034962108155014e-06, generator loss = 13.44039535522461\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 4, Batch: 131/468, discriminator loss real = 2.354862616016362e-08, disciminator loss fake = 2.1472610569617245e-06, generator loss = 13.515810012817383\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 4, Batch: 132/468, discriminator loss real = 1.4151226024328167e-10, disciminator loss fake = 1.7867073438537773e-06, generator loss = 13.569124221801758\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 4, Batch: 133/468, discriminator loss real = 1.3592803271844645e-10, disciminator loss fake = 1.7721195035846904e-06, generator loss = 13.404220581054688\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 4, Batch: 134/468, discriminator loss real = 1.3432896461829102e-10, disciminator loss fake = 1.987771611311473e-06, generator loss = 13.601675033569336\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 4, Batch: 135/468, discriminator loss real = 1.0473941713939894e-09, disciminator loss fake = 1.886522795757628e-06, generator loss = 13.369804382324219\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 4, Batch: 136/468, discriminator loss real = 2.5127014358083954e-10, disciminator loss fake = 1.958677330549108e-06, generator loss = 13.595573425292969\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 4, Batch: 137/468, discriminator loss real = 2.377965024891182e-08, disciminator loss fake = 1.7681222743703984e-06, generator loss = 13.656366348266602\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 4, Batch: 138/468, discriminator loss real = 7.774302035468139e-13, disciminator loss fake = 1.9636322576843668e-06, generator loss = 13.53911018371582\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 4, Batch: 139/468, discriminator loss real = 1.3476129367973044e-07, disciminator loss fake = 1.973752205230994e-06, generator loss = 13.651606559753418\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 4, Batch: 140/468, discriminator loss real = 2.018916978041574e-10, disciminator loss fake = 1.256956693396205e-06, generator loss = 13.620100021362305\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 4, Batch: 141/468, discriminator loss real = 9.403750293648233e-14, disciminator loss fake = 1.483542291680351e-06, generator loss = 13.480587005615234\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 4, Batch: 142/468, discriminator loss real = 2.3063699838843377e-09, disciminator loss fake = 1.5241807886923198e-06, generator loss = 13.66987419128418\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 4, Batch: 143/468, discriminator loss real = 3.9647901932046703e-13, disciminator loss fake = 1.849612090154551e-06, generator loss = 13.629247665405273\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 4, Batch: 144/468, discriminator loss real = 1.341747823957462e-09, disciminator loss fake = 1.5278174032573588e-06, generator loss = 13.503782272338867\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 4, Batch: 145/468, discriminator loss real = 1.4750829002707633e-08, disciminator loss fake = 1.5320225656978437e-06, generator loss = 13.624175071716309\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 4, Batch: 146/468, discriminator loss real = 2.6363265208579657e-14, disciminator loss fake = 1.464477350054949e-06, generator loss = 13.736143112182617\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 4, Batch: 147/468, discriminator loss real = 3.84128242103543e-07, disciminator loss fake = 1.7650024801696418e-06, generator loss = 13.59242057800293\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 4, Batch: 148/468, discriminator loss real = 2.0665007227626002e-16, disciminator loss fake = 1.3822618711856194e-06, generator loss = 13.714973449707031\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 4, Batch: 149/468, discriminator loss real = 4.63917615434184e-08, disciminator loss fake = 1.3779158507531974e-06, generator loss = 13.65838623046875\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 4, Batch: 150/468, discriminator loss real = 1.5640538994152187e-12, disciminator loss fake = 1.6512325373696513e-06, generator loss = 13.692132949829102\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 4, Batch: 151/468, discriminator loss real = 1.8611478935781633e-07, disciminator loss fake = 1.5929959999994026e-06, generator loss = 13.689778327941895\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 4, Batch: 152/468, discriminator loss real = 6.836563259948747e-11, disciminator loss fake = 1.5531658164036344e-06, generator loss = 13.822281837463379\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 4, Batch: 153/468, discriminator loss real = 6.072396925571599e-12, disciminator loss fake = 1.2258831247891067e-06, generator loss = 13.570592880249023\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 4, Batch: 154/468, discriminator loss real = 2.34665047810223e-11, disciminator loss fake = 1.2370149988782941e-06, generator loss = 13.740464210510254\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 4, Batch: 155/468, discriminator loss real = 2.6440312694830936e-07, disciminator loss fake = 1.2611371857929043e-06, generator loss = 13.689458847045898\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 4, Batch: 156/468, discriminator loss real = 6.741291826983797e-07, disciminator loss fake = 1.4438055586651899e-06, generator loss = 13.639995574951172\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 4, Batch: 157/468, discriminator loss real = 4.600518642254581e-13, disciminator loss fake = 1.2899361081508687e-06, generator loss = 13.728409767150879\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 4, Batch: 158/468, discriminator loss real = 2.7252158862900444e-10, disciminator loss fake = 1.6457270248793066e-06, generator loss = 13.703815460205078\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 4, Batch: 159/468, discriminator loss real = 3.134350634939609e-12, disciminator loss fake = 1.2593932297022548e-06, generator loss = 13.771768569946289\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 4, Batch: 160/468, discriminator loss real = 1.6699078372265502e-13, disciminator loss fake = 1.4461683122135582e-06, generator loss = 13.74882698059082\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 4, Batch: 161/468, discriminator loss real = 3.251522654097207e-14, disciminator loss fake = 1.3072225328869536e-06, generator loss = 13.806714057922363\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 4, Batch: 162/468, discriminator loss real = 4.3544237660064766e-10, disciminator loss fake = 1.338857600785559e-06, generator loss = 13.69792652130127\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 4, Batch: 163/468, discriminator loss real = 2.0598119476744614e-07, disciminator loss fake = 1.351424771200982e-06, generator loss = 13.676460266113281\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 4, Batch: 164/468, discriminator loss real = 3.234252102246593e-11, disciminator loss fake = 1.3330632100405637e-06, generator loss = 13.820178985595703\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 4, Batch: 165/468, discriminator loss real = 4.919715676510172e-12, disciminator loss fake = 1.5879402326390846e-06, generator loss = 13.76518440246582\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 4, Batch: 166/468, discriminator loss real = 1.2302225016469492e-08, disciminator loss fake = 1.8596324480313342e-06, generator loss = 13.698948860168457\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 4, Batch: 167/468, discriminator loss real = 7.002174041330703e-14, disciminator loss fake = 1.2506159237091197e-06, generator loss = 13.72304916381836\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 4, Batch: 168/468, discriminator loss real = 8.362015073426488e-12, disciminator loss fake = 1.4857657788525103e-06, generator loss = 13.707691192626953\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 4, Batch: 169/468, discriminator loss real = 2.1700352625941832e-09, disciminator loss fake = 1.1643907100733486e-06, generator loss = 13.886070251464844\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 4, Batch: 170/468, discriminator loss real = 5.5831225864722e-08, disciminator loss fake = 1.4755875099581317e-06, generator loss = 13.822613716125488\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 4, Batch: 171/468, discriminator loss real = 3.2839253912746516e-14, disciminator loss fake = 1.4471247595793102e-06, generator loss = 13.814447402954102\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 4, Batch: 172/468, discriminator loss real = 1.5448598888849474e-13, disciminator loss fake = 1.2554164641187526e-06, generator loss = 13.823240280151367\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 4, Batch: 173/468, discriminator loss real = 7.1834673626147705e-12, disciminator loss fake = 1.2435452845238615e-06, generator loss = 13.783459663391113\n",
      "2/2 [==============================] - 0s 39ms/step\n",
      "Epoch: 4, Batch: 174/468, discriminator loss real = 4.163542288715405e-10, disciminator loss fake = 1.5372602319985162e-06, generator loss = 13.758810043334961\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 4, Batch: 175/468, discriminator loss real = 2.1353446788552333e-10, disciminator loss fake = 1.185136284220789e-06, generator loss = 13.808195114135742\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 4, Batch: 176/468, discriminator loss real = 7.323206432374718e-07, disciminator loss fake = 1.269155063710059e-06, generator loss = 13.837804794311523\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 4, Batch: 177/468, discriminator loss real = 1.383791952552782e-12, disciminator loss fake = 1.1461582971605822e-06, generator loss = 13.748759269714355\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 4, Batch: 178/468, discriminator loss real = 2.6655153778643026e-13, disciminator loss fake = 1.336247237304633e-06, generator loss = 13.762781143188477\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 4, Batch: 179/468, discriminator loss real = 2.7859028417509535e-09, disciminator loss fake = 1.2052792044414673e-06, generator loss = 13.73901653289795\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 4, Batch: 180/468, discriminator loss real = 3.0999311206869606e-07, disciminator loss fake = 1.0087651389767416e-06, generator loss = 13.844056129455566\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 4, Batch: 181/468, discriminator loss real = 1.9071622059385618e-09, disciminator loss fake = 1.482098582528124e-06, generator loss = 13.800804138183594\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 4, Batch: 182/468, discriminator loss real = 1.2914231587324992e-13, disciminator loss fake = 1.3043523949818336e-06, generator loss = 13.879325866699219\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 4, Batch: 183/468, discriminator loss real = 1.6463694014860752e-13, disciminator loss fake = 1.4479214769380633e-06, generator loss = 13.96026611328125\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 4, Batch: 184/468, discriminator loss real = 1.9401882411784754e-07, disciminator loss fake = 1.2662126209761482e-06, generator loss = 13.878591537475586\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 4, Batch: 185/468, discriminator loss real = 5.1088338203983397e-14, disciminator loss fake = 1.4444134421864874e-06, generator loss = 13.892646789550781\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 4, Batch: 186/468, discriminator loss real = 9.76559874632521e-11, disciminator loss fake = 1.1823701697721845e-06, generator loss = 13.861869812011719\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 4, Batch: 187/468, discriminator loss real = 7.635465176791811e-11, disciminator loss fake = 1.0196182529398357e-06, generator loss = 13.843871116638184\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 4, Batch: 188/468, discriminator loss real = 1.7300566534927952e-09, disciminator loss fake = 1.0327059953851858e-06, generator loss = 13.867294311523438\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 4, Batch: 189/468, discriminator loss real = 2.0241025522338418e-10, disciminator loss fake = 1.2311529644648544e-06, generator loss = 13.938838005065918\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 4, Batch: 190/468, discriminator loss real = 8.593937193823731e-13, disciminator loss fake = 1.0898088476096746e-06, generator loss = 13.959661483764648\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 4, Batch: 191/468, discriminator loss real = 9.566053904563887e-07, disciminator loss fake = 1.123283254855778e-06, generator loss = 14.01622486114502\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 4, Batch: 192/468, discriminator loss real = 4.827376020623275e-13, disciminator loss fake = 1.1395061392249772e-06, generator loss = 13.915811538696289\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 4, Batch: 193/468, discriminator loss real = 9.596979461123922e-12, disciminator loss fake = 1.187568614113843e-06, generator loss = 13.844598770141602\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 4, Batch: 194/468, discriminator loss real = 4.370797127006831e-11, disciminator loss fake = 1.0864634987228783e-06, generator loss = 13.884965896606445\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 4, Batch: 195/468, discriminator loss real = 5.1699328845744574e-11, disciminator loss fake = 9.458694307795668e-07, generator loss = 14.158689498901367\n",
      "2/2 [==============================] - 0s 37ms/step\n",
      "Epoch: 4, Batch: 196/468, discriminator loss real = 2.615627441200641e-13, disciminator loss fake = 1.103560521187319e-06, generator loss = 13.762548446655273\n",
      "2/2 [==============================] - 0s 33ms/step\n",
      "Epoch: 4, Batch: 197/468, discriminator loss real = 1.9582419019670283e-10, disciminator loss fake = 1.079767798728426e-06, generator loss = 13.852025032043457\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 4, Batch: 198/468, discriminator loss real = 1.9612022075787827e-11, disciminator loss fake = 1.32311822653719e-06, generator loss = 13.991342544555664\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 4, Batch: 199/468, discriminator loss real = 1.8895102496530036e-12, disciminator loss fake = 1.2167367913207272e-06, generator loss = 14.068331718444824\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 4, Batch: 200/468, discriminator loss real = 7.982200713740895e-07, disciminator loss fake = 1.2505098538895254e-06, generator loss = 13.981651306152344\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 4, Batch: 201/468, discriminator loss real = 2.0763213370855738e-09, disciminator loss fake = 1.0558800340731977e-06, generator loss = 13.90902042388916\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 4, Batch: 202/468, discriminator loss real = 5.26654139321181e-06, disciminator loss fake = 1.2337759471847676e-06, generator loss = 13.864888191223145\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 4, Batch: 203/468, discriminator loss real = 1.6183660314639248e-11, disciminator loss fake = 1.2012366141789244e-06, generator loss = 13.946467399597168\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 4, Batch: 204/468, discriminator loss real = 1.0124920208909316e-06, disciminator loss fake = 1.277860519621754e-06, generator loss = 13.94113540649414\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 4, Batch: 205/468, discriminator loss real = 1.619832573851454e-06, disciminator loss fake = 9.947389116859995e-07, generator loss = 13.951312065124512\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 4, Batch: 206/468, discriminator loss real = 1.9219442703999334e-10, disciminator loss fake = 1.2503882089731633e-06, generator loss = 13.987180709838867\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 4, Batch: 207/468, discriminator loss real = 3.002559978426689e-08, disciminator loss fake = 1.4191348327585729e-06, generator loss = 13.869945526123047\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 4, Batch: 208/468, discriminator loss real = 2.629653092500739e-11, disciminator loss fake = 1.0563305750110885e-06, generator loss = 13.968337059020996\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 4, Batch: 209/468, discriminator loss real = 6.522897673388872e-12, disciminator loss fake = 1.2926378758493229e-06, generator loss = 13.938602447509766\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 4, Batch: 210/468, discriminator loss real = 1.0716732189164357e-11, disciminator loss fake = 8.672870990267256e-07, generator loss = 13.963775634765625\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 4, Batch: 211/468, discriminator loss real = 1.3281181487911908e-08, disciminator loss fake = 1.0192177342105424e-06, generator loss = 13.948695182800293\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 4, Batch: 212/468, discriminator loss real = 1.159998312683097e-12, disciminator loss fake = 9.666108553574304e-07, generator loss = 13.99160385131836\n",
      "2/2 [==============================] - 0s 38ms/step\n",
      "Epoch: 4, Batch: 213/468, discriminator loss real = 4.459691638203367e-08, disciminator loss fake = 1.1435613487265073e-06, generator loss = 13.880011558532715\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 4, Batch: 214/468, discriminator loss real = 4.721150137498853e-09, disciminator loss fake = 1.090599312192353e-06, generator loss = 14.09855842590332\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 4, Batch: 215/468, discriminator loss real = 3.3254315642307353e-13, disciminator loss fake = 9.812667940423125e-07, generator loss = 13.948309898376465\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 4, Batch: 216/468, discriminator loss real = 1.6801887881001676e-08, disciminator loss fake = 9.811794825509423e-07, generator loss = 14.036539077758789\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 4, Batch: 217/468, discriminator loss real = 6.7728028625424486e-06, disciminator loss fake = 1.128114831772109e-06, generator loss = 13.97996997833252\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 4, Batch: 218/468, discriminator loss real = 1.4388341906812485e-10, disciminator loss fake = 1.0797987215482863e-06, generator loss = 14.043397903442383\n",
      "2/2 [==============================] - 0s 36ms/step\n",
      "Epoch: 4, Batch: 219/468, discriminator loss real = 1.2957957551407162e-06, disciminator loss fake = 1.0899498192884494e-06, generator loss = 13.998497009277344\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 4, Batch: 220/468, discriminator loss real = 1.3446849970316643e-13, disciminator loss fake = 1.121360241995717e-06, generator loss = 13.932777404785156\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 4, Batch: 221/468, discriminator loss real = 6.7888206167765475e-09, disciminator loss fake = 1.088703584173345e-06, generator loss = 14.058075904846191\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 4, Batch: 222/468, discriminator loss real = 5.821198557909302e-12, disciminator loss fake = 1.1572321909625316e-06, generator loss = 13.975618362426758\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 4, Batch: 223/468, discriminator loss real = 4.947768583729584e-11, disciminator loss fake = 1.1136600051031564e-06, generator loss = 13.987060546875\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 4, Batch: 224/468, discriminator loss real = 2.2943176221715267e-13, disciminator loss fake = 8.795773283054586e-07, generator loss = 13.966327667236328\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 4, Batch: 225/468, discriminator loss real = 1.401280892536494e-13, disciminator loss fake = 9.735617823025677e-07, generator loss = 14.0974702835083\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 4, Batch: 226/468, discriminator loss real = 1.876807910472511e-11, disciminator loss fake = 1.1317961252643727e-06, generator loss = 13.964774131774902\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 4, Batch: 227/468, discriminator loss real = 5.953610949507512e-14, disciminator loss fake = 1.163845809060149e-06, generator loss = 14.048070907592773\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 4, Batch: 228/468, discriminator loss real = 4.292333155575534e-10, disciminator loss fake = 9.797797702049138e-07, generator loss = 14.096826553344727\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 4, Batch: 229/468, discriminator loss real = 8.637227599805897e-10, disciminator loss fake = 1.2484641729315626e-06, generator loss = 14.065412521362305\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 4, Batch: 230/468, discriminator loss real = 1.6425952154008883e-08, disciminator loss fake = 9.677984280642704e-07, generator loss = 13.972299575805664\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 4, Batch: 231/468, discriminator loss real = 9.040476700583611e-10, disciminator loss fake = 1.1064740874644485e-06, generator loss = 13.983789443969727\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 4, Batch: 232/468, discriminator loss real = 1.3249645824942036e-08, disciminator loss fake = 1.142159476330562e-06, generator loss = 14.071352005004883\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 4, Batch: 233/468, discriminator loss real = 1.8624568554059806e-07, disciminator loss fake = 1.093563355425431e-06, generator loss = 14.05662727355957\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 4, Batch: 234/468, discriminator loss real = 2.7360524956776544e-09, disciminator loss fake = 9.802321301322081e-07, generator loss = 13.996811866760254\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 4, Batch: 235/468, discriminator loss real = 1.9529269312812403e-09, disciminator loss fake = 1.205991566166631e-06, generator loss = 14.066951751708984\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 4, Batch: 236/468, discriminator loss real = 2.7507068622867337e-08, disciminator loss fake = 1.092108277589432e-06, generator loss = 14.117009162902832\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 4, Batch: 237/468, discriminator loss real = 3.0643662520674075e-12, disciminator loss fake = 1.0111551773661631e-06, generator loss = 13.98369312286377\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 4, Batch: 238/468, discriminator loss real = 3.8734992990896444e-10, disciminator loss fake = 1.0137766821571859e-06, generator loss = 14.190332412719727\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 4, Batch: 239/468, discriminator loss real = 1.0575980369242899e-10, disciminator loss fake = 9.365894015900267e-07, generator loss = 14.046972274780273\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 4, Batch: 240/468, discriminator loss real = 3.430969675033424e-10, disciminator loss fake = 1.0385376754129538e-06, generator loss = 14.086373329162598\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 4, Batch: 241/468, discriminator loss real = 2.0082768781293225e-09, disciminator loss fake = 9.80931758931547e-07, generator loss = 13.989001274108887\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 4, Batch: 242/468, discriminator loss real = 1.1028635782395213e-07, disciminator loss fake = 1.013179144138121e-06, generator loss = 14.1732177734375\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 4, Batch: 243/468, discriminator loss real = 4.774265982554482e-10, disciminator loss fake = 9.93828052742174e-07, generator loss = 14.079099655151367\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 4, Batch: 244/468, discriminator loss real = 3.056153108360604e-10, disciminator loss fake = 9.494466439718963e-07, generator loss = 14.136100769042969\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 4, Batch: 245/468, discriminator loss real = 4.155203958688958e-11, disciminator loss fake = 9.957558404494193e-07, generator loss = 14.167881965637207\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 4, Batch: 246/468, discriminator loss real = 1.6967421798087454e-14, disciminator loss fake = 9.012855457513069e-07, generator loss = 14.156916618347168\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 4, Batch: 247/468, discriminator loss real = 1.811774688609269e-11, disciminator loss fake = 9.552134088153252e-07, generator loss = 14.064919471740723\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 4, Batch: 248/468, discriminator loss real = 2.9566049608575895e-10, disciminator loss fake = 9.884125802273047e-07, generator loss = 14.035812377929688\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 4, Batch: 249/468, discriminator loss real = 4.875002068693846e-10, disciminator loss fake = 9.627531198930228e-07, generator loss = 14.106810569763184\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 4, Batch: 250/468, discriminator loss real = 3.8879677255465594e-10, disciminator loss fake = 1.1555132459761808e-06, generator loss = 14.15743350982666\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 4, Batch: 251/468, discriminator loss real = 7.014501479662982e-11, disciminator loss fake = 8.645517937111435e-07, generator loss = 14.076723098754883\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 4, Batch: 252/468, discriminator loss real = 3.128300027875619e-13, disciminator loss fake = 8.774370598985115e-07, generator loss = 14.10853385925293\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 4, Batch: 253/468, discriminator loss real = 2.3420896013703896e-06, disciminator loss fake = 8.76631133905903e-07, generator loss = 14.189013481140137\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 4, Batch: 254/468, discriminator loss real = 2.2991415628975664e-12, disciminator loss fake = 9.46873115026392e-07, generator loss = 14.049548149108887\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 4, Batch: 255/468, discriminator loss real = 2.8172275960969273e-06, disciminator loss fake = 9.821867479331559e-07, generator loss = 14.05240249633789\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 4, Batch: 256/468, discriminator loss real = 2.597429582073922e-14, disciminator loss fake = 9.908335414365865e-07, generator loss = 14.135526657104492\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 4, Batch: 257/468, discriminator loss real = 1.483663127251067e-12, disciminator loss fake = 8.545813443561201e-07, generator loss = 14.102011680603027\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 4, Batch: 258/468, discriminator loss real = 5.316072582139952e-10, disciminator loss fake = 1.0944640962406993e-06, generator loss = 14.283452987670898\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 4, Batch: 259/468, discriminator loss real = 1.354010306653386e-11, disciminator loss fake = 1.0610194749460788e-06, generator loss = 14.189699172973633\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 4, Batch: 260/468, discriminator loss real = 2.893060127462377e-06, disciminator loss fake = 1.154853180196369e-06, generator loss = 13.98794174194336\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 4, Batch: 261/468, discriminator loss real = 7.976669672005166e-12, disciminator loss fake = 9.263572451345681e-07, generator loss = 14.2935152053833\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 4, Batch: 262/468, discriminator loss real = 1.0697298602480032e-09, disciminator loss fake = 7.732622862022254e-07, generator loss = 14.145601272583008\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 4, Batch: 263/468, discriminator loss real = 2.1835605545916792e-10, disciminator loss fake = 8.752958819968626e-07, generator loss = 14.078813552856445\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 4, Batch: 264/468, discriminator loss real = 2.9506207047981514e-13, disciminator loss fake = 8.321276254719123e-07, generator loss = 14.096834182739258\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 4, Batch: 265/468, discriminator loss real = 3.844311479393736e-13, disciminator loss fake = 9.353591394756222e-07, generator loss = 14.084897994995117\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 4, Batch: 266/468, discriminator loss real = 2.803435705800439e-09, disciminator loss fake = 1.1254855962761212e-06, generator loss = 14.211931228637695\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 4, Batch: 267/468, discriminator loss real = 2.1988657561422542e-09, disciminator loss fake = 9.26655388866493e-07, generator loss = 14.05770206451416\n",
      "2/2 [==============================] - 0s 34ms/step\n",
      "Epoch: 4, Batch: 268/468, discriminator loss real = 1.018837103572423e-08, disciminator loss fake = 1.2092471024516271e-06, generator loss = 14.072389602661133\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 4, Batch: 269/468, discriminator loss real = 9.418718027731643e-10, disciminator loss fake = 9.312044539910858e-07, generator loss = 14.203987121582031\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 4, Batch: 270/468, discriminator loss real = 8.248227621743265e-12, disciminator loss fake = 8.664452479933971e-07, generator loss = 14.177682876586914\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 4, Batch: 271/468, discriminator loss real = 3.053874167435744e-11, disciminator loss fake = 1.00999170626892e-06, generator loss = 14.171142578125\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 4, Batch: 272/468, discriminator loss real = 2.1260763982677844e-11, disciminator loss fake = 8.059994343057042e-07, generator loss = 14.180412292480469\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 4, Batch: 273/468, discriminator loss real = 7.801445341788175e-15, disciminator loss fake = 1.0034207207354484e-06, generator loss = 14.074593544006348\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 4, Batch: 274/468, discriminator loss real = 1.9191433164866822e-11, disciminator loss fake = 8.501124284521211e-07, generator loss = 14.089651107788086\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 4, Batch: 275/468, discriminator loss real = 3.1903499841945404e-09, disciminator loss fake = 9.321078664470406e-07, generator loss = 14.310100555419922\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 4, Batch: 276/468, discriminator loss real = 9.976005438394608e-11, disciminator loss fake = 9.062116532732034e-07, generator loss = 14.144786834716797\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 4, Batch: 277/468, discriminator loss real = 2.6774788983163766e-12, disciminator loss fake = 8.517491778547992e-07, generator loss = 14.241658210754395\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 4, Batch: 278/468, discriminator loss real = 3.6700475991580106e-11, disciminator loss fake = 9.637446964916307e-07, generator loss = 14.168187141418457\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 4, Batch: 279/468, discriminator loss real = 4.705015890782427e-11, disciminator loss fake = 1.0778483101603342e-06, generator loss = 14.204376220703125\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 4, Batch: 280/468, discriminator loss real = 9.876581685830388e-08, disciminator loss fake = 1.0970011317112949e-06, generator loss = 14.331422805786133\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 4, Batch: 281/468, discriminator loss real = 1.1519643017265935e-09, disciminator loss fake = 8.447456139037968e-07, generator loss = 14.269369125366211\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 4, Batch: 282/468, discriminator loss real = 3.1273659877040227e-12, disciminator loss fake = 7.297829256458499e-07, generator loss = 14.354912757873535\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 4, Batch: 283/468, discriminator loss real = 5.282231185788078e-08, disciminator loss fake = 8.015706498554209e-07, generator loss = 14.27999496459961\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 4, Batch: 284/468, discriminator loss real = 6.643237071557451e-10, disciminator loss fake = 9.194911854137899e-07, generator loss = 14.18812370300293\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 4, Batch: 285/468, discriminator loss real = 7.020432013504774e-10, disciminator loss fake = 8.028977731555642e-07, generator loss = 14.245747566223145\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 4, Batch: 286/468, discriminator loss real = 1.0306958953008383e-16, disciminator loss fake = 8.445623507213895e-07, generator loss = 14.314077377319336\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 4, Batch: 287/468, discriminator loss real = 1.0655197427503205e-13, disciminator loss fake = 9.608481832401594e-07, generator loss = 14.364179611206055\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 4, Batch: 288/468, discriminator loss real = 5.201815422850586e-09, disciminator loss fake = 8.43696398078464e-07, generator loss = 14.225777626037598\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 4, Batch: 289/468, discriminator loss real = 1.0908274816756602e-06, disciminator loss fake = 1.153325456471066e-06, generator loss = 14.239921569824219\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 4, Batch: 290/468, discriminator loss real = 2.7284894829615602e-11, disciminator loss fake = 8.971421721071238e-07, generator loss = 14.43661117553711\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 4, Batch: 291/468, discriminator loss real = 9.983638915578297e-12, disciminator loss fake = 9.620716809877194e-07, generator loss = 14.235271453857422\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 4, Batch: 292/468, discriminator loss real = 9.141164127868251e-07, disciminator loss fake = 8.125492740873597e-07, generator loss = 14.130195617675781\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 4, Batch: 293/468, discriminator loss real = 1.8564327158854255e-11, disciminator loss fake = 7.422964358738682e-07, generator loss = 14.30263900756836\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 4, Batch: 294/468, discriminator loss real = 3.0950766927162476e-07, disciminator loss fake = 7.607887937410851e-07, generator loss = 14.278135299682617\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 4, Batch: 295/468, discriminator loss real = 7.748934133244845e-11, disciminator loss fake = 9.58447458287992e-07, generator loss = 14.415950775146484\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 4, Batch: 296/468, discriminator loss real = 1.5130436833987737e-11, disciminator loss fake = 7.363572649410344e-07, generator loss = 14.363664627075195\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 4, Batch: 297/468, discriminator loss real = 9.77630754128711e-10, disciminator loss fake = 9.001877288028481e-07, generator loss = 14.325462341308594\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 4, Batch: 298/468, discriminator loss real = 7.995105688607396e-10, disciminator loss fake = 7.703055189267616e-07, generator loss = 14.269294738769531\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 4, Batch: 299/468, discriminator loss real = 7.180236223300329e-13, disciminator loss fake = 6.749191356902884e-07, generator loss = 14.303182601928711\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 4, Batch: 300/468, discriminator loss real = 5.674199599070562e-08, disciminator loss fake = 8.799913757684408e-07, generator loss = 14.192113876342773\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 4, Batch: 301/468, discriminator loss real = 1.0373965575460886e-10, disciminator loss fake = 8.280769634438911e-07, generator loss = 14.388871192932129\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 4, Batch: 302/468, discriminator loss real = 2.559072953545183e-10, disciminator loss fake = 8.660882713229512e-07, generator loss = 14.16567611694336\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 4, Batch: 303/468, discriminator loss real = 8.365197423643167e-11, disciminator loss fake = 8.130045330290159e-07, generator loss = 14.21125316619873\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 4, Batch: 304/468, discriminator loss real = 6.702184109346615e-14, disciminator loss fake = 9.484853080721223e-07, generator loss = 14.362510681152344\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 4, Batch: 305/468, discriminator loss real = 2.9175759030941606e-12, disciminator loss fake = 9.507342610959313e-07, generator loss = 14.237001419067383\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 4, Batch: 306/468, discriminator loss real = 6.947388844769087e-12, disciminator loss fake = 9.80681761575397e-07, generator loss = 14.286187171936035\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 4, Batch: 307/468, discriminator loss real = 9.764050679095249e-12, disciminator loss fake = 9.697528184915427e-07, generator loss = 14.362410545349121\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 4, Batch: 308/468, discriminator loss real = 8.800878775749865e-11, disciminator loss fake = 8.329844263244013e-07, generator loss = 14.311836242675781\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 4, Batch: 309/468, discriminator loss real = 5.2567334166142565e-12, disciminator loss fake = 8.313785428981646e-07, generator loss = 14.324018478393555\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 4, Batch: 310/468, discriminator loss real = 7.843459388923169e-12, disciminator loss fake = 6.687700988550205e-07, generator loss = 14.369393348693848\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 4, Batch: 311/468, discriminator loss real = 1.899520957193701e-10, disciminator loss fake = 7.266715442710847e-07, generator loss = 14.43808364868164\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 4, Batch: 312/468, discriminator loss real = 0.00013076666800770909, disciminator loss fake = 8.019088681976427e-07, generator loss = 14.132575035095215\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 4, Batch: 313/468, discriminator loss real = 1.4734345299416418e-08, disciminator loss fake = 9.501605404693692e-07, generator loss = 13.961481094360352\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 4, Batch: 314/468, discriminator loss real = 3.512102934866146e-12, disciminator loss fake = 1.2052930742356693e-06, generator loss = 13.98511028289795\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 4, Batch: 315/468, discriminator loss real = 2.4064718967542476e-11, disciminator loss fake = 1.3887733985029627e-06, generator loss = 13.853229522705078\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 4, Batch: 316/468, discriminator loss real = 4.2494830571060405e-11, disciminator loss fake = 1.5645864550606348e-06, generator loss = 13.705815315246582\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 4, Batch: 317/468, discriminator loss real = 6.430209012822652e-13, disciminator loss fake = 1.8524136748965248e-06, generator loss = 13.561832427978516\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 4, Batch: 318/468, discriminator loss real = 3.104534858355823e-13, disciminator loss fake = 1.5570367395412177e-06, generator loss = 13.588194847106934\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 4, Batch: 319/468, discriminator loss real = 1.504587253398082e-11, disciminator loss fake = 1.8311093299416825e-06, generator loss = 13.603315353393555\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 4, Batch: 320/468, discriminator loss real = 4.025329874111916e-13, disciminator loss fake = 1.6036452734624618e-06, generator loss = 13.543386459350586\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 4, Batch: 321/468, discriminator loss real = 1.2411680927471025e-07, disciminator loss fake = 1.649203795750509e-06, generator loss = 13.61552906036377\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 4, Batch: 322/468, discriminator loss real = 6.405763031125389e-08, disciminator loss fake = 2.0311781554482877e-06, generator loss = 13.388428688049316\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 4, Batch: 323/468, discriminator loss real = 8.084327651758372e-11, disciminator loss fake = 1.7406578081136104e-06, generator loss = 13.449976921081543\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 4, Batch: 324/468, discriminator loss real = 1.9632780734468724e-08, disciminator loss fake = 1.8912402310888865e-06, generator loss = 13.510021209716797\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 4, Batch: 325/468, discriminator loss real = 3.232225888306038e-14, disciminator loss fake = 2.1920200197200757e-06, generator loss = 13.581318855285645\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 4, Batch: 326/468, discriminator loss real = 1.4383495262892954e-11, disciminator loss fake = 2.234138264611829e-06, generator loss = 13.59628677368164\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 4, Batch: 327/468, discriminator loss real = 4.1967763899503074e-13, disciminator loss fake = 1.9612609776231693e-06, generator loss = 13.529930114746094\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 4, Batch: 328/468, discriminator loss real = 2.116840367273956e-15, disciminator loss fake = 1.9415269889577758e-06, generator loss = 13.460920333862305\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 4, Batch: 329/468, discriminator loss real = 2.0801487268795604e-11, disciminator loss fake = 2.365060026932042e-06, generator loss = 13.438924789428711\n",
      "2/2 [==============================] - 0s 39ms/step\n",
      "Epoch: 4, Batch: 330/468, discriminator loss real = 4.4219199157348454e-14, disciminator loss fake = 2.190575060012634e-06, generator loss = 13.442436218261719\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 4, Batch: 331/468, discriminator loss real = 1.1080684286790543e-10, disciminator loss fake = 2.4506030058546457e-06, generator loss = 13.59908676147461\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 4, Batch: 332/468, discriminator loss real = 4.0693757391574437e-11, disciminator loss fake = 1.8380155779595952e-06, generator loss = 13.525758743286133\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 4, Batch: 333/468, discriminator loss real = 6.059314562687629e-15, disciminator loss fake = 1.819511908252025e-06, generator loss = 13.530682563781738\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 4, Batch: 334/468, discriminator loss real = 1.1960088475149178e-10, disciminator loss fake = 1.884972562038456e-06, generator loss = 13.520044326782227\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 4, Batch: 335/468, discriminator loss real = 1.3057426667684169e-11, disciminator loss fake = 1.6824760677991435e-06, generator loss = 13.73836612701416\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 4, Batch: 336/468, discriminator loss real = 2.361339457301881e-10, disciminator loss fake = 1.4814697806286858e-06, generator loss = 13.53816032409668\n",
      "2/2 [==============================] - 0s 35ms/step\n",
      "Epoch: 4, Batch: 337/468, discriminator loss real = 1.1940760880069234e-11, disciminator loss fake = 2.243202288809698e-06, generator loss = 13.534509658813477\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 4, Batch: 338/468, discriminator loss real = 3.1844329690527973e-13, disciminator loss fake = 1.7658251181273954e-06, generator loss = 13.46418571472168\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 4, Batch: 339/468, discriminator loss real = 1.3621181006034933e-12, disciminator loss fake = 1.6675400047461153e-06, generator loss = 13.663997650146484\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 4, Batch: 340/468, discriminator loss real = 1.2658443182544943e-09, disciminator loss fake = 1.577020725562761e-06, generator loss = 13.616175651550293\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 4, Batch: 341/468, discriminator loss real = 5.8047313622466845e-09, disciminator loss fake = 2.0688294171122834e-06, generator loss = 13.583269119262695\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 4, Batch: 342/468, discriminator loss real = 4.084453608665939e-10, disciminator loss fake = 1.3399975387073937e-06, generator loss = 13.582043647766113\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 4, Batch: 343/468, discriminator loss real = 2.612026595016914e-09, disciminator loss fake = 1.4792217370995786e-06, generator loss = 13.714648246765137\n",
      "2/2 [==============================] - 0s 39ms/step\n",
      "Epoch: 4, Batch: 344/468, discriminator loss real = 1.8808583579499327e-09, disciminator loss fake = 1.5686673577874899e-06, generator loss = 13.704736709594727\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 4, Batch: 345/468, discriminator loss real = 1.5488184736470179e-12, disciminator loss fake = 1.729997165966779e-06, generator loss = 13.723428726196289\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 4, Batch: 346/468, discriminator loss real = 8.813273631128483e-15, disciminator loss fake = 1.3455417047225637e-06, generator loss = 13.777796745300293\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 4, Batch: 347/468, discriminator loss real = 1.3338706007781642e-11, disciminator loss fake = 1.4822967386862729e-06, generator loss = 13.74799633026123\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 4, Batch: 348/468, discriminator loss real = 1.3730956649471437e-10, disciminator loss fake = 1.4604881926061353e-06, generator loss = 13.665600776672363\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 4, Batch: 349/468, discriminator loss real = 8.523860506315373e-10, disciminator loss fake = 1.4731565443071304e-06, generator loss = 13.7786226272583\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 4, Batch: 350/468, discriminator loss real = 4.3687688015825454e-13, disciminator loss fake = 1.386499434374855e-06, generator loss = 13.764418601989746\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 4, Batch: 351/468, discriminator loss real = 6.342321806629414e-11, disciminator loss fake = 1.6070836181825143e-06, generator loss = 13.700428009033203\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 4, Batch: 352/468, discriminator loss real = 2.110296382085153e-09, disciminator loss fake = 1.6330918697349261e-06, generator loss = 13.757004737854004\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 4, Batch: 353/468, discriminator loss real = 1.6048834483584073e-09, disciminator loss fake = 1.5041498500067974e-06, generator loss = 13.635285377502441\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 4, Batch: 354/468, discriminator loss real = 5.381208811883198e-10, disciminator loss fake = 1.4160450518829748e-06, generator loss = 13.83281421661377\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 4, Batch: 355/468, discriminator loss real = 1.036395191889028e-09, disciminator loss fake = 1.764845592333586e-06, generator loss = 13.859040260314941\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 4, Batch: 356/468, discriminator loss real = 1.4343649532011504e-11, disciminator loss fake = 1.4328402357932646e-06, generator loss = 13.82788372039795\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 4, Batch: 357/468, discriminator loss real = 4.6524118108362544e-14, disciminator loss fake = 1.2031031246806378e-06, generator loss = 13.91364860534668\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 4, Batch: 358/468, discriminator loss real = 1.470975286022025e-10, disciminator loss fake = 1.3128353657521075e-06, generator loss = 13.697439193725586\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 4, Batch: 359/468, discriminator loss real = 4.785411975537224e-13, disciminator loss fake = 9.988857527787331e-07, generator loss = 13.758535385131836\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 4, Batch: 360/468, discriminator loss real = 1.395669495772578e-12, disciminator loss fake = 1.3074397884338396e-06, generator loss = 13.921294212341309\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 4, Batch: 361/468, discriminator loss real = 3.2466645474502065e-13, disciminator loss fake = 1.3733812238569953e-06, generator loss = 13.847640991210938\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 4, Batch: 362/468, discriminator loss real = 2.2971089006645906e-13, disciminator loss fake = 1.5465476508325082e-06, generator loss = 13.98645305633545\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 4, Batch: 363/468, discriminator loss real = 2.552768922896992e-13, disciminator loss fake = 1.1631848337856354e-06, generator loss = 13.865920066833496\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 4, Batch: 364/468, discriminator loss real = 2.253100817029008e-09, disciminator loss fake = 1.2868715657532448e-06, generator loss = 13.887924194335938\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 4, Batch: 365/468, discriminator loss real = 1.0577224429653143e-06, disciminator loss fake = 1.4503893908113241e-06, generator loss = 13.939863204956055\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 4, Batch: 366/468, discriminator loss real = 1.7218577952338165e-10, disciminator loss fake = 1.1565109616640257e-06, generator loss = 13.860431671142578\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 4, Batch: 367/468, discriminator loss real = 5.022867677340059e-10, disciminator loss fake = 1.4404511148313759e-06, generator loss = 13.93855094909668\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 4, Batch: 368/468, discriminator loss real = 1.564736635373265e-06, disciminator loss fake = 1.224285028911254e-06, generator loss = 13.996023178100586\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 4, Batch: 369/468, discriminator loss real = 5.109305201145276e-10, disciminator loss fake = 1.1154139656355255e-06, generator loss = 13.93504524230957\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 4, Batch: 370/468, discriminator loss real = 3.821874332597875e-16, disciminator loss fake = 1.4034803825779818e-06, generator loss = 13.831165313720703\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 4, Batch: 371/468, discriminator loss real = 8.284789743129295e-09, disciminator loss fake = 1.0214820349574438e-06, generator loss = 14.052066802978516\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 4, Batch: 372/468, discriminator loss real = 1.1242271003020221e-11, disciminator loss fake = 1.1210971706532291e-06, generator loss = 13.994911193847656\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 4, Batch: 373/468, discriminator loss real = 2.407148924632452e-10, disciminator loss fake = 8.642226703159395e-07, generator loss = 14.040450096130371\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 4, Batch: 374/468, discriminator loss real = 5.7264763597686397e-08, disciminator loss fake = 1.0356641269027023e-06, generator loss = 14.055604934692383\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 4, Batch: 375/468, discriminator loss real = 7.75682781894993e-11, disciminator loss fake = 1.036184471558954e-06, generator loss = 13.904033660888672\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 4, Batch: 376/468, discriminator loss real = 1.015084544198075e-11, disciminator loss fake = 1.3620926893054275e-06, generator loss = 13.889578819274902\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 4, Batch: 377/468, discriminator loss real = 1.7374365834932348e-10, disciminator loss fake = 1.2876228083769092e-06, generator loss = 13.965312004089355\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 4, Batch: 378/468, discriminator loss real = 3.5715430612981436e-11, disciminator loss fake = 1.0520880096009932e-06, generator loss = 14.020593643188477\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 4, Batch: 379/468, discriminator loss real = 6.175393313032074e-13, disciminator loss fake = 1.0764642865979113e-06, generator loss = 14.004351615905762\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 4, Batch: 380/468, discriminator loss real = 3.815455330152817e-12, disciminator loss fake = 1.0841291668839403e-06, generator loss = 13.916821479797363\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 4, Batch: 381/468, discriminator loss real = 6.829900645044518e-09, disciminator loss fake = 1.0191608907916816e-06, generator loss = 13.917102813720703\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 4, Batch: 382/468, discriminator loss real = 1.3073491399694104e-13, disciminator loss fake = 1.1389852261345368e-06, generator loss = 14.04789924621582\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 4, Batch: 383/468, discriminator loss real = 9.055684296237296e-15, disciminator loss fake = 9.71648432823713e-07, generator loss = 14.029178619384766\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 4, Batch: 384/468, discriminator loss real = 2.553747258104977e-08, disciminator loss fake = 1.0515568646951579e-06, generator loss = 13.94289493560791\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 4, Batch: 385/468, discriminator loss real = 8.166116394203726e-11, disciminator loss fake = 1.1152523029522854e-06, generator loss = 13.918866157531738\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 4, Batch: 386/468, discriminator loss real = 3.901142520135181e-08, disciminator loss fake = 1.1271746416241513e-06, generator loss = 14.130680084228516\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 4, Batch: 387/468, discriminator loss real = 6.877673985883348e-10, disciminator loss fake = 1.18611524158041e-06, generator loss = 14.042320251464844\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 4, Batch: 388/468, discriminator loss real = 1.1009414950871599e-12, disciminator loss fake = 1.0169608231080929e-06, generator loss = 14.053821563720703\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 4, Batch: 389/468, discriminator loss real = 2.5758144062137944e-08, disciminator loss fake = 9.133715366260731e-07, generator loss = 14.11093521118164\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 4, Batch: 390/468, discriminator loss real = 4.861061029259872e-07, disciminator loss fake = 9.11604104203434e-07, generator loss = 14.23759651184082\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 4, Batch: 391/468, discriminator loss real = 2.114291901278431e-11, disciminator loss fake = 7.677710982534336e-07, generator loss = 14.061986923217773\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 4, Batch: 392/468, discriminator loss real = 2.251886732640429e-10, disciminator loss fake = 1.196133666780952e-06, generator loss = 14.270987510681152\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 4, Batch: 393/468, discriminator loss real = 8.616017621587702e-12, disciminator loss fake = 8.961126241047168e-07, generator loss = 14.063475608825684\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 4, Batch: 394/468, discriminator loss real = 4.1611252221684936e-09, disciminator loss fake = 8.405368134845048e-07, generator loss = 14.184331893920898\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 4, Batch: 395/468, discriminator loss real = 1.52971097122645e-07, disciminator loss fake = 1.228441078637843e-06, generator loss = 14.15050983428955\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 4, Batch: 396/468, discriminator loss real = 1.008091610188444e-09, disciminator loss fake = 1.0539270078879781e-06, generator loss = 14.061506271362305\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 4, Batch: 397/468, discriminator loss real = 7.30281999494764e-06, disciminator loss fake = 1.0720920045059756e-06, generator loss = 14.085355758666992\n",
      "2/2 [==============================] - 0s 36ms/step\n",
      "Epoch: 4, Batch: 398/468, discriminator loss real = 5.896180765851966e-10, disciminator loss fake = 1.3158488627595943e-06, generator loss = 14.129201889038086\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 4, Batch: 399/468, discriminator loss real = 2.572970170255928e-10, disciminator loss fake = 9.030169962898071e-07, generator loss = 14.164918899536133\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 4, Batch: 400/468, discriminator loss real = 7.971096493974983e-08, disciminator loss fake = 1.1264122576903901e-06, generator loss = 14.011147499084473\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 4, Batch: 401/468, discriminator loss real = 1.8148967029750496e-13, disciminator loss fake = 1.0730185522334068e-06, generator loss = 14.118645668029785\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 4, Batch: 402/468, discriminator loss real = 1.699584650793895e-08, disciminator loss fake = 1.0879118690354517e-06, generator loss = 14.252433776855469\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 4, Batch: 403/468, discriminator loss real = 3.1021962776378587e-10, disciminator loss fake = 1.0723163086368004e-06, generator loss = 13.983617782592773\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 4, Batch: 404/468, discriminator loss real = 4.085017124566548e-08, disciminator loss fake = 1.3485155250236858e-06, generator loss = 13.988808631896973\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 4, Batch: 405/468, discriminator loss real = 1.144642713946098e-11, disciminator loss fake = 9.619682259653928e-07, generator loss = 14.10430908203125\n",
      "2/2 [==============================] - 0s 38ms/step\n",
      "Epoch: 4, Batch: 406/468, discriminator loss real = 4.890747007380014e-08, disciminator loss fake = 1.264741740669706e-06, generator loss = 14.096434593200684\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 4, Batch: 407/468, discriminator loss real = 2.0654644661277644e-10, disciminator loss fake = 8.885896249921643e-07, generator loss = 14.08657455444336\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 4, Batch: 408/468, discriminator loss real = 2.095478060818931e-13, disciminator loss fake = 9.750112894835183e-07, generator loss = 14.182598114013672\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 4, Batch: 409/468, discriminator loss real = 1.675218056179477e-14, disciminator loss fake = 1.251980165761779e-06, generator loss = 14.01257038116455\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 4, Batch: 410/468, discriminator loss real = 5.915954393032052e-09, disciminator loss fake = 1.1014457186320215e-06, generator loss = 14.107288360595703\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 4, Batch: 411/468, discriminator loss real = 3.2710127584323345e-07, disciminator loss fake = 1.23976508348278e-06, generator loss = 14.085502624511719\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 4, Batch: 412/468, discriminator loss real = 2.6570867901754003e-12, disciminator loss fake = 8.236963822128018e-07, generator loss = 14.221121788024902\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 4, Batch: 413/468, discriminator loss real = 1.543444885787615e-11, disciminator loss fake = 8.026794944271387e-07, generator loss = 14.189630508422852\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 4, Batch: 414/468, discriminator loss real = 1.1416249889872887e-10, disciminator loss fake = 8.570758609494078e-07, generator loss = 14.070068359375\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 4, Batch: 415/468, discriminator loss real = 3.811434794442903e-07, disciminator loss fake = 8.379849418815866e-07, generator loss = 14.074783325195312\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 4, Batch: 416/468, discriminator loss real = 7.8543716669488e-12, disciminator loss fake = 8.847370054354542e-07, generator loss = 14.101533889770508\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 4, Batch: 417/468, discriminator loss real = 8.465120515666058e-08, disciminator loss fake = 9.215476666213362e-07, generator loss = 14.24327278137207\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 4, Batch: 418/468, discriminator loss real = 3.2368649183515605e-14, disciminator loss fake = 1.0343818530600402e-06, generator loss = 14.144817352294922\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 4, Batch: 419/468, discriminator loss real = 8.778050286650796e-09, disciminator loss fake = 1.0666133221093332e-06, generator loss = 14.127307891845703\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 4, Batch: 420/468, discriminator loss real = 2.212011018798421e-09, disciminator loss fake = 9.923477364282007e-07, generator loss = 14.182846069335938\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 4, Batch: 421/468, discriminator loss real = 3.5588379465600894e-10, disciminator loss fake = 1.0152380127692595e-06, generator loss = 14.25760269165039\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 4, Batch: 422/468, discriminator loss real = 2.000774898406124e-13, disciminator loss fake = 8.401319746553781e-07, generator loss = 14.088409423828125\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 4, Batch: 423/468, discriminator loss real = 4.0971706027903565e-08, disciminator loss fake = 1.147568468695681e-06, generator loss = 14.363765716552734\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 4, Batch: 424/468, discriminator loss real = 5.228583611536185e-14, disciminator loss fake = 8.732340575079434e-07, generator loss = 14.288518905639648\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 4, Batch: 425/468, discriminator loss real = 1.7935087442966235e-11, disciminator loss fake = 7.79273818807269e-07, generator loss = 14.268850326538086\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 4, Batch: 426/468, discriminator loss real = 2.976260663162082e-14, disciminator loss fake = 9.726524012876325e-07, generator loss = 14.32297134399414\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 4, Batch: 427/468, discriminator loss real = 1.1560625503767574e-13, disciminator loss fake = 8.692145456734579e-07, generator loss = 14.162033081054688\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 4, Batch: 428/468, discriminator loss real = 7.041170979604772e-10, disciminator loss fake = 8.607955805928214e-07, generator loss = 14.289634704589844\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 4, Batch: 429/468, discriminator loss real = 3.666747114272617e-11, disciminator loss fake = 9.070581086234597e-07, generator loss = 14.254608154296875\n",
      "2/2 [==============================] - 0s 36ms/step\n",
      "Epoch: 4, Batch: 430/468, discriminator loss real = 2.778369978528872e-09, disciminator loss fake = 7.127496246539522e-07, generator loss = 14.36203384399414\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 4, Batch: 431/468, discriminator loss real = 1.1652222589586536e-11, disciminator loss fake = 8.039921794988913e-07, generator loss = 14.253144264221191\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 4, Batch: 432/468, discriminator loss real = 2.7516604550470447e-09, disciminator loss fake = 1.049206161951588e-06, generator loss = 14.294931411743164\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 4, Batch: 433/468, discriminator loss real = 6.1658114169915734e-09, disciminator loss fake = 7.038141802695463e-07, generator loss = 14.225598335266113\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 4, Batch: 434/468, discriminator loss real = 9.133389045068441e-10, disciminator loss fake = 9.485297596256714e-07, generator loss = 14.419614791870117\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 4, Batch: 435/468, discriminator loss real = 2.186076653032387e-09, disciminator loss fake = 1.0434841897222213e-06, generator loss = 14.342081069946289\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 4, Batch: 436/468, discriminator loss real = 6.021643184084269e-09, disciminator loss fake = 7.954535590215528e-07, generator loss = 14.298694610595703\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 4, Batch: 437/468, discriminator loss real = 4.400851594255073e-08, disciminator loss fake = 8.054179261307581e-07, generator loss = 14.152181625366211\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 4, Batch: 438/468, discriminator loss real = 2.6491973220167664e-13, disciminator loss fake = 9.190339937958925e-07, generator loss = 14.373506546020508\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 4, Batch: 439/468, discriminator loss real = 1.3557450717627262e-09, disciminator loss fake = 7.929061212053057e-07, generator loss = 14.347841262817383\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 4, Batch: 440/468, discriminator loss real = 8.715570921761541e-16, disciminator loss fake = 8.105432698357617e-07, generator loss = 14.191593170166016\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 4, Batch: 441/468, discriminator loss real = 3.6360543163027614e-06, disciminator loss fake = 8.408044323005015e-07, generator loss = 14.33541488647461\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 4, Batch: 442/468, discriminator loss real = 4.402389910951321e-12, disciminator loss fake = 8.056582601057016e-07, generator loss = 14.325056076049805\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 4, Batch: 443/468, discriminator loss real = 3.71216363204141e-10, disciminator loss fake = 1.0221964430456865e-06, generator loss = 14.263872146606445\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 4, Batch: 444/468, discriminator loss real = 4.0141093227141766e-10, disciminator loss fake = 8.546430194655841e-07, generator loss = 14.252511978149414\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 4, Batch: 445/468, discriminator loss real = 5.375335593305053e-12, disciminator loss fake = 8.571926741751668e-07, generator loss = 14.324793815612793\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 4, Batch: 446/468, discriminator loss real = 1.949754919149116e-13, disciminator loss fake = 8.45648060021631e-07, generator loss = 14.301032066345215\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 4, Batch: 447/468, discriminator loss real = 4.858513764915973e-13, disciminator loss fake = 8.429326499026502e-07, generator loss = 14.282819747924805\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 4, Batch: 448/468, discriminator loss real = 6.390131979117086e-09, disciminator loss fake = 7.190711812654627e-07, generator loss = 14.392412185668945\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 4, Batch: 449/468, discriminator loss real = 6.922410644705224e-09, disciminator loss fake = 9.083535132958787e-07, generator loss = 14.511484146118164\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 4, Batch: 450/468, discriminator loss real = 2.2380223217190187e-13, disciminator loss fake = 1.0755159109976375e-06, generator loss = 14.35165786743164\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 4, Batch: 451/468, discriminator loss real = 6.465523103883764e-13, disciminator loss fake = 7.372918844339438e-07, generator loss = 14.527233123779297\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 4, Batch: 452/468, discriminator loss real = 2.398274148163182e-07, disciminator loss fake = 7.169463742684457e-07, generator loss = 14.366937637329102\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 4, Batch: 453/468, discriminator loss real = 4.642420614597853e-10, disciminator loss fake = 7.642685204700683e-07, generator loss = 14.369909286499023\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 4, Batch: 454/468, discriminator loss real = 2.122386467962034e-11, disciminator loss fake = 8.595359304308658e-07, generator loss = 14.426597595214844\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 4, Batch: 455/468, discriminator loss real = 4.651396601218494e-09, disciminator loss fake = 6.449544116549077e-07, generator loss = 14.309747695922852\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 4, Batch: 456/468, discriminator loss real = 1.2805607962906862e-10, disciminator loss fake = 7.676009659007832e-07, generator loss = 14.481476783752441\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 4, Batch: 457/468, discriminator loss real = 3.9853200739514705e-09, disciminator loss fake = 8.999457463687577e-07, generator loss = 14.447001457214355\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 4, Batch: 458/468, discriminator loss real = 2.382194485076039e-12, disciminator loss fake = 7.653572993149282e-07, generator loss = 14.312705993652344\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 4, Batch: 459/468, discriminator loss real = 7.463165641041769e-10, disciminator loss fake = 8.209588600038842e-07, generator loss = 14.37628173828125\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 4, Batch: 460/468, discriminator loss real = 2.4942208021183632e-11, disciminator loss fake = 8.250475502791232e-07, generator loss = 14.461105346679688\n",
      "2/2 [==============================] - 0s 31ms/step\n",
      "Epoch: 4, Batch: 461/468, discriminator loss real = 2.3569317070953888e-12, disciminator loss fake = 8.007440328583471e-07, generator loss = 14.531059265136719\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 4, Batch: 462/468, discriminator loss real = 1.4009690976757305e-11, disciminator loss fake = 7.160017503338167e-07, generator loss = 14.42718505859375\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 4, Batch: 463/468, discriminator loss real = 5.776879863361728e-09, disciminator loss fake = 7.18547084943566e-07, generator loss = 14.636104583740234\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 4, Batch: 464/468, discriminator loss real = 6.152154480298933e-11, disciminator loss fake = 7.410230864479672e-07, generator loss = 14.373382568359375\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 4, Batch: 465/468, discriminator loss real = 2.0815880130697906e-09, disciminator loss fake = 5.971178325125948e-07, generator loss = 14.437541007995605\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 4, Batch: 466/468, discriminator loss real = 2.204725524325088e-13, disciminator loss fake = 6.966752152948175e-07, generator loss = 14.283367156982422\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 4, Batch: 467/468, discriminator loss real = 1.3935043341462006e-08, disciminator loss fake = 7.604461416121922e-07, generator loss = 14.513684272766113\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 4, Batch: 468/468, discriminator loss real = 1.1346380723864513e-08, disciminator loss fake = 6.199575750542863e-07, generator loss = 14.37551212310791\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 5, Batch: 1/468, discriminator loss real = 1.0337401074034247e-11, disciminator loss fake = 6.221432045094843e-07, generator loss = 14.561290740966797\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 5, Batch: 2/468, discriminator loss real = 3.5386657493141627e-10, disciminator loss fake = 7.541337936345371e-07, generator loss = 14.33868408203125\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 5, Batch: 3/468, discriminator loss real = 1.5760296889766323e-07, disciminator loss fake = 8.088101139946957e-07, generator loss = 14.480484962463379\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 5, Batch: 4/468, discriminator loss real = 7.460491946442716e-11, disciminator loss fake = 7.514140065723041e-07, generator loss = 14.505744934082031\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 5, Batch: 5/468, discriminator loss real = 9.28953025614021e-10, disciminator loss fake = 7.704469453528873e-07, generator loss = 14.410390853881836\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 5, Batch: 6/468, discriminator loss real = 2.9725812089598236e-11, disciminator loss fake = 7.178516625572229e-07, generator loss = 14.502870559692383\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 5, Batch: 7/468, discriminator loss real = 2.3692488942961276e-12, disciminator loss fake = 5.722079663428303e-07, generator loss = 14.541231155395508\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 5, Batch: 8/468, discriminator loss real = 5.189316316066284e-13, disciminator loss fake = 6.056748134142254e-07, generator loss = 14.555608749389648\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 5, Batch: 9/468, discriminator loss real = 5.254342028138126e-08, disciminator loss fake = 8.872945045368397e-07, generator loss = 14.489541053771973\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 5, Batch: 10/468, discriminator loss real = 3.508680498920391e-11, disciminator loss fake = 8.142068850247597e-07, generator loss = 14.496435165405273\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 5, Batch: 11/468, discriminator loss real = 1.254069504491584e-11, disciminator loss fake = 7.226508387248032e-07, generator loss = 14.51679801940918\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 5, Batch: 12/468, discriminator loss real = 1.5452066293164535e-09, disciminator loss fake = 6.663553335783945e-07, generator loss = 14.559673309326172\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 5, Batch: 13/468, discriminator loss real = 2.2199787581139718e-13, disciminator loss fake = 5.904278168600285e-07, generator loss = 14.591337203979492\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 5, Batch: 14/468, discriminator loss real = 1.9204041135090222e-11, disciminator loss fake = 6.787304300814867e-07, generator loss = 14.560253143310547\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 5, Batch: 15/468, discriminator loss real = 2.999670956072009e-09, disciminator loss fake = 6.37573236872413e-07, generator loss = 14.568957328796387\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 5, Batch: 16/468, discriminator loss real = 2.364287610134852e-08, disciminator loss fake = 5.935598892392591e-07, generator loss = 14.588424682617188\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 5, Batch: 17/468, discriminator loss real = 5.3644522851614695e-11, disciminator loss fake = 6.957747586966434e-07, generator loss = 14.594263076782227\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 5, Batch: 18/468, discriminator loss real = 1.9355154631806037e-11, disciminator loss fake = 5.543729457713198e-07, generator loss = 14.441675186157227\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 5, Batch: 19/468, discriminator loss real = 1.6883846853943396e-07, disciminator loss fake = 5.69590383747709e-07, generator loss = 14.612436294555664\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 5, Batch: 20/468, discriminator loss real = 4.935470782063689e-11, disciminator loss fake = 5.868039352208143e-07, generator loss = 14.540067672729492\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 5, Batch: 21/468, discriminator loss real = 2.4340240543097025e-06, disciminator loss fake = 7.184823971329024e-07, generator loss = 14.48906135559082\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 5, Batch: 22/468, discriminator loss real = 1.892044160234363e-11, disciminator loss fake = 5.568618917095591e-07, generator loss = 14.56982135772705\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 5, Batch: 23/468, discriminator loss real = 2.080423200823134e-06, disciminator loss fake = 6.728830044266942e-07, generator loss = 14.489145278930664\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 5, Batch: 24/468, discriminator loss real = 4.311070944673645e-11, disciminator loss fake = 6.796225306970882e-07, generator loss = 14.569149017333984\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 5, Batch: 25/468, discriminator loss real = 1.177674190805389e-11, disciminator loss fake = 6.728737389494199e-07, generator loss = 14.527883529663086\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 5, Batch: 26/468, discriminator loss real = 1.6930810919912886e-11, disciminator loss fake = 7.076336032696418e-07, generator loss = 14.474626541137695\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 5, Batch: 27/468, discriminator loss real = 2.6434618938253607e-09, disciminator loss fake = 7.082310276018688e-07, generator loss = 14.48734188079834\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 5, Batch: 28/468, discriminator loss real = 2.5133047074632486e-06, disciminator loss fake = 6.906118983351917e-07, generator loss = 14.617820739746094\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 5, Batch: 29/468, discriminator loss real = 1.000227989322866e-08, disciminator loss fake = 7.005082807154395e-07, generator loss = 14.461881637573242\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 5, Batch: 30/468, discriminator loss real = 6.132202656772279e-08, disciminator loss fake = 7.557838443972287e-07, generator loss = 14.605331420898438\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 5, Batch: 31/468, discriminator loss real = 2.488584061044463e-10, disciminator loss fake = 7.011174716353707e-07, generator loss = 14.655638694763184\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 5, Batch: 32/468, discriminator loss real = 2.1873231004221338e-10, disciminator loss fake = 5.684259463123453e-07, generator loss = 14.68796443939209\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 5, Batch: 33/468, discriminator loss real = 2.490645467645436e-10, disciminator loss fake = 6.151261686682119e-07, generator loss = 14.536510467529297\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 5, Batch: 34/468, discriminator loss real = 2.7154642978644006e-08, disciminator loss fake = 6.219600550139148e-07, generator loss = 14.521477699279785\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 5, Batch: 35/468, discriminator loss real = 9.009607282450816e-09, disciminator loss fake = 6.399485528163495e-07, generator loss = 14.650842666625977\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 5, Batch: 36/468, discriminator loss real = 1.527004656054487e-08, disciminator loss fake = 7.259667995640484e-07, generator loss = 14.615527153015137\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 5, Batch: 37/468, discriminator loss real = 4.819840273423415e-13, disciminator loss fake = 6.9588520545949e-07, generator loss = 14.576879501342773\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 5, Batch: 38/468, discriminator loss real = 7.007380786738793e-10, disciminator loss fake = 6.053439278730366e-07, generator loss = 14.54412841796875\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 5, Batch: 39/468, discriminator loss real = 2.9982680227469416e-10, disciminator loss fake = 5.502579369931482e-07, generator loss = 14.590080261230469\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 5, Batch: 40/468, discriminator loss real = 1.1075556444195556e-10, disciminator loss fake = 5.016449335926154e-07, generator loss = 14.505375862121582\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 5, Batch: 41/468, discriminator loss real = 3.4201156040580827e-07, disciminator loss fake = 5.927097959101957e-07, generator loss = 14.566680908203125\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 5, Batch: 42/468, discriminator loss real = 8.520648379570228e-13, disciminator loss fake = 6.37848870610469e-07, generator loss = 14.574519157409668\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 5, Batch: 43/468, discriminator loss real = 2.201292099990315e-12, disciminator loss fake = 7.806577855262731e-07, generator loss = 14.553262710571289\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 5, Batch: 44/468, discriminator loss real = 4.0860307137791096e-08, disciminator loss fake = 6.569027846126119e-07, generator loss = 14.490348815917969\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 5, Batch: 45/468, discriminator loss real = 5.447741216468849e-12, disciminator loss fake = 6.23322762294265e-07, generator loss = 14.528886795043945\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 5, Batch: 46/468, discriminator loss real = 1.0234317837642948e-09, disciminator loss fake = 6.39184690953698e-07, generator loss = 14.67706298828125\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 5, Batch: 47/468, discriminator loss real = 4.298681233194657e-08, disciminator loss fake = 5.675475449606893e-07, generator loss = 14.537875175476074\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 5, Batch: 48/468, discriminator loss real = 2.2793733046866382e-12, disciminator loss fake = 5.201604835747276e-07, generator loss = 14.65399169921875\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 5, Batch: 49/468, discriminator loss real = 1.0457994192858422e-10, disciminator loss fake = 7.60471948524355e-07, generator loss = 14.603065490722656\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 5, Batch: 50/468, discriminator loss real = 5.910481387086039e-14, disciminator loss fake = 5.852581921317324e-07, generator loss = 14.698978424072266\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 5, Batch: 51/468, discriminator loss real = 2.2978881020208064e-09, disciminator loss fake = 8.019896426958439e-07, generator loss = 14.684493064880371\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 5, Batch: 52/468, discriminator loss real = 5.057756879978115e-09, disciminator loss fake = 4.716673345228628e-07, generator loss = 14.629206657409668\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 5, Batch: 53/468, discriminator loss real = 1.5157473054472348e-09, disciminator loss fake = 7.328180231525039e-07, generator loss = 14.627067565917969\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 5, Batch: 54/468, discriminator loss real = 5.4697513879320425e-12, disciminator loss fake = 5.88257478284504e-07, generator loss = 14.687460899353027\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 5, Batch: 55/468, discriminator loss real = 2.3037383556356872e-08, disciminator loss fake = 6.183937557580066e-07, generator loss = 14.610816955566406\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 5, Batch: 56/468, discriminator loss real = 5.359974616925278e-12, disciminator loss fake = 5.679484047504957e-07, generator loss = 14.623551368713379\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 5, Batch: 57/468, discriminator loss real = 5.588420837199237e-10, disciminator loss fake = 5.950194008619292e-07, generator loss = 14.66146469116211\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 5, Batch: 58/468, discriminator loss real = 2.852089224514298e-11, disciminator loss fake = 5.232005264588224e-07, generator loss = 14.738645553588867\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 5, Batch: 59/468, discriminator loss real = 2.116296915488647e-09, disciminator loss fake = 5.569339691646746e-07, generator loss = 14.71988296508789\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 5, Batch: 60/468, discriminator loss real = 5.388260948535617e-10, disciminator loss fake = 5.883931635253248e-07, generator loss = 14.646915435791016\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 5, Batch: 61/468, discriminator loss real = 1.4247978664949645e-11, disciminator loss fake = 4.943715907756996e-07, generator loss = 14.622126579284668\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 5, Batch: 62/468, discriminator loss real = 1.8803408607936944e-08, disciminator loss fake = 6.290121064012055e-07, generator loss = 14.769484519958496\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 5, Batch: 63/468, discriminator loss real = 1.2103699986720784e-11, disciminator loss fake = 5.630972736980766e-07, generator loss = 14.57858657836914\n",
      "2/2 [==============================] - 0s 34ms/step\n",
      "Epoch: 5, Batch: 64/468, discriminator loss real = 3.902556144907976e-08, disciminator loss fake = 5.680307140210061e-07, generator loss = 14.736612319946289\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 5, Batch: 65/468, discriminator loss real = 3.553391034107761e-13, disciminator loss fake = 4.259374293269502e-07, generator loss = 14.621014595031738\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 5, Batch: 66/468, discriminator loss real = 6.183794312164537e-07, disciminator loss fake = 5.220163643571141e-07, generator loss = 14.678695678710938\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 5, Batch: 67/468, discriminator loss real = 4.8739668272901326e-05, disciminator loss fake = 5.828079565617372e-07, generator loss = 14.636040687561035\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 5, Batch: 68/468, discriminator loss real = 9.092879227345918e-11, disciminator loss fake = 6.276918611547444e-07, generator loss = 14.464306831359863\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 5, Batch: 69/468, discriminator loss real = 3.055887765057719e-10, disciminator loss fake = 8.61477303715219e-07, generator loss = 14.516301155090332\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 5, Batch: 70/468, discriminator loss real = 7.392302450170973e-07, disciminator loss fake = 7.596241857754649e-07, generator loss = 14.389101028442383\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 5, Batch: 71/468, discriminator loss real = 3.4973024476414594e-11, disciminator loss fake = 8.555393264941813e-07, generator loss = 14.460649490356445\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 5, Batch: 72/468, discriminator loss real = 1.2808562804139667e-12, disciminator loss fake = 7.466820761692361e-07, generator loss = 14.255651473999023\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 5, Batch: 73/468, discriminator loss real = 3.7398201868654724e-08, disciminator loss fake = 9.713762665342074e-07, generator loss = 14.242883682250977\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 5, Batch: 74/468, discriminator loss real = 5.4498393353696883e-08, disciminator loss fake = 7.851512009438011e-07, generator loss = 14.22430419921875\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 5, Batch: 75/468, discriminator loss real = 9.941392847823138e-11, disciminator loss fake = 8.07680407888256e-07, generator loss = 14.237357139587402\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 5, Batch: 76/468, discriminator loss real = 1.8802170487219882e-08, disciminator loss fake = 8.221675216191215e-07, generator loss = 14.319864273071289\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 5, Batch: 77/468, discriminator loss real = 8.542723820004205e-13, disciminator loss fake = 8.178485586540774e-07, generator loss = 14.327167510986328\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 5, Batch: 78/468, discriminator loss real = 5.320213158910292e-10, disciminator loss fake = 1.1939936257476802e-06, generator loss = 14.18873405456543\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 5, Batch: 79/468, discriminator loss real = 6.547510472167117e-13, disciminator loss fake = 8.261203561232833e-07, generator loss = 14.290573120117188\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 5, Batch: 80/468, discriminator loss real = 5.772065117537473e-12, disciminator loss fake = 8.556935426895507e-07, generator loss = 14.15241813659668\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 5, Batch: 81/468, discriminator loss real = 7.969602755508731e-09, disciminator loss fake = 1.099068754228938e-06, generator loss = 14.213733673095703\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 5, Batch: 82/468, discriminator loss real = 1.2028306173306191e-07, disciminator loss fake = 7.85893689680961e-07, generator loss = 14.148638725280762\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 5, Batch: 83/468, discriminator loss real = 3.9197937024048127e-14, disciminator loss fake = 1.0198559721175116e-06, generator loss = 14.23989200592041\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 5, Batch: 84/468, discriminator loss real = 3.743698684388619e-10, disciminator loss fake = 9.696050256025046e-07, generator loss = 14.298772811889648\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 5, Batch: 85/468, discriminator loss real = 5.998740393309276e-10, disciminator loss fake = 9.091346555578639e-07, generator loss = 14.195432662963867\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 5, Batch: 86/468, discriminator loss real = 1.0157077401373726e-09, disciminator loss fake = 8.684325507601898e-07, generator loss = 14.203887939453125\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 5, Batch: 87/468, discriminator loss real = 1.2940093874896919e-12, disciminator loss fake = 7.96772155808867e-07, generator loss = 14.266618728637695\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 5, Batch: 88/468, discriminator loss real = 1.9452701168626296e-12, disciminator loss fake = 9.767518349690363e-07, generator loss = 14.345544815063477\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 5, Batch: 89/468, discriminator loss real = 8.106452176193102e-10, disciminator loss fake = 9.466423307458172e-07, generator loss = 14.238636016845703\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 5, Batch: 90/468, discriminator loss real = 3.645793389406293e-11, disciminator loss fake = 8.264399866675376e-07, generator loss = 14.396463394165039\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 5, Batch: 91/468, discriminator loss real = 6.450080747288922e-11, disciminator loss fake = 9.606137609807774e-07, generator loss = 14.221384048461914\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 5, Batch: 92/468, discriminator loss real = 5.3915066855481086e-11, disciminator loss fake = 8.915262696973514e-07, generator loss = 14.274620056152344\n",
      "2/2 [==============================] - 0s 34ms/step\n",
      "Epoch: 5, Batch: 93/468, discriminator loss real = 1.0698499031125408e-10, disciminator loss fake = 7.338863952099928e-07, generator loss = 14.269783020019531\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 5, Batch: 94/468, discriminator loss real = 2.494102773198392e-07, disciminator loss fake = 8.06880791515141e-07, generator loss = 14.298003196716309\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 5, Batch: 95/468, discriminator loss real = 1.115610858901106e-12, disciminator loss fake = 9.065117865247885e-07, generator loss = 14.364709854125977\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 5, Batch: 96/468, discriminator loss real = 2.1602272054499494e-11, disciminator loss fake = 9.336603170595481e-07, generator loss = 14.289603233337402\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 5, Batch: 97/468, discriminator loss real = 3.42025609223473e-11, disciminator loss fake = 9.873112958302954e-07, generator loss = 14.390617370605469\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 5, Batch: 98/468, discriminator loss real = 6.269160537919483e-14, disciminator loss fake = 8.217743925342802e-07, generator loss = 14.194892883300781\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 5, Batch: 99/468, discriminator loss real = 1.354391859081927e-12, disciminator loss fake = 7.312022489713854e-07, generator loss = 14.258644104003906\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 5, Batch: 100/468, discriminator loss real = 6.868312425467593e-07, disciminator loss fake = 9.114057775150286e-07, generator loss = 14.304866790771484\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 5, Batch: 101/468, discriminator loss real = 4.221551060112905e-12, disciminator loss fake = 9.16109343052085e-07, generator loss = 14.26738452911377\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 5, Batch: 102/468, discriminator loss real = 3.699866368833682e-08, disciminator loss fake = 8.210265605157474e-07, generator loss = 14.404260635375977\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 5, Batch: 103/468, discriminator loss real = 2.937676415060847e-13, disciminator loss fake = 7.693310521972307e-07, generator loss = 14.253074645996094\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 5, Batch: 104/468, discriminator loss real = 7.807551263491752e-14, disciminator loss fake = 8.172266916517401e-07, generator loss = 14.282662391662598\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 5, Batch: 105/468, discriminator loss real = 5.668206348730109e-09, disciminator loss fake = 8.413011300945072e-07, generator loss = 14.443833351135254\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 5, Batch: 106/468, discriminator loss real = 2.7610889269391592e-11, disciminator loss fake = 7.979098199939472e-07, generator loss = 14.274383544921875\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 5, Batch: 107/468, discriminator loss real = 1.1072900544606759e-13, disciminator loss fake = 8.440435976808658e-07, generator loss = 14.520655632019043\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 5, Batch: 108/468, discriminator loss real = 1.1354532591933975e-10, disciminator loss fake = 8.106285918074718e-07, generator loss = 14.501529693603516\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 5, Batch: 109/468, discriminator loss real = 7.412389635419459e-08, disciminator loss fake = 7.114174422895303e-07, generator loss = 14.426896095275879\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 5, Batch: 110/468, discriminator loss real = 1.1021045881465241e-10, disciminator loss fake = 1.000701104203472e-06, generator loss = 14.465614318847656\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 5, Batch: 111/468, discriminator loss real = 1.4083078453408504e-11, disciminator loss fake = 8.866914527061454e-07, generator loss = 14.458166122436523\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 5, Batch: 112/468, discriminator loss real = 1.0531612908148968e-11, disciminator loss fake = 7.546764209109824e-07, generator loss = 14.371877670288086\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 5, Batch: 113/468, discriminator loss real = 2.623522059319594e-12, disciminator loss fake = 6.558681207025074e-07, generator loss = 14.403510093688965\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 5, Batch: 114/468, discriminator loss real = 1.0578096976132656e-07, disciminator loss fake = 6.849889473414805e-07, generator loss = 14.440567016601562\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 5, Batch: 115/468, discriminator loss real = 2.1263791508824292e-12, disciminator loss fake = 6.815106416979688e-07, generator loss = 14.349258422851562\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 5, Batch: 116/468, discriminator loss real = 1.5420898065443556e-12, disciminator loss fake = 6.931916232133517e-07, generator loss = 14.5392484664917\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 5, Batch: 117/468, discriminator loss real = 2.6973017461066895e-13, disciminator loss fake = 6.36359914096829e-07, generator loss = 14.424575805664062\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 5, Batch: 118/468, discriminator loss real = 8.245708532205603e-14, disciminator loss fake = 7.024755177553743e-07, generator loss = 14.320796966552734\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 5, Batch: 119/468, discriminator loss real = 3.3724032342196363e-15, disciminator loss fake = 7.204364464996615e-07, generator loss = 14.52750301361084\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 5, Batch: 120/468, discriminator loss real = 2.051527392410435e-09, disciminator loss fake = 8.335841243933828e-07, generator loss = 14.535633087158203\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 5, Batch: 121/468, discriminator loss real = 8.274039786648757e-11, disciminator loss fake = 8.89222746991436e-07, generator loss = 14.407173156738281\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 5, Batch: 122/468, discriminator loss real = 4.903551658686292e-14, disciminator loss fake = 7.984044714248739e-07, generator loss = 14.606311798095703\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 5, Batch: 123/468, discriminator loss real = 2.9015762947892654e-07, disciminator loss fake = 6.61274043523008e-07, generator loss = 14.59490966796875\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 5, Batch: 124/468, discriminator loss real = 2.751955022368968e-13, disciminator loss fake = 7.779902944093919e-07, generator loss = 14.56655502319336\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 5, Batch: 125/468, discriminator loss real = 7.033095893865804e-13, disciminator loss fake = 7.642483978997916e-07, generator loss = 14.51296615600586\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 5, Batch: 126/468, discriminator loss real = 5.4940708232864566e-11, disciminator loss fake = 7.024101478236844e-07, generator loss = 14.572616577148438\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 5, Batch: 127/468, discriminator loss real = 9.617016985430382e-06, disciminator loss fake = 6.687681093353604e-07, generator loss = 14.420130729675293\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 5, Batch: 128/468, discriminator loss real = 2.000593050596744e-12, disciminator loss fake = 7.517517133237561e-07, generator loss = 14.495266914367676\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 5, Batch: 129/468, discriminator loss real = 1.2211750499702134e-09, disciminator loss fake = 7.175349878707493e-07, generator loss = 14.47247314453125\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 5, Batch: 130/468, discriminator loss real = 1.5452252810632672e-09, disciminator loss fake = 5.90758816088055e-07, generator loss = 14.555092811584473\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 5, Batch: 131/468, discriminator loss real = 7.135597002161376e-09, disciminator loss fake = 7.694038686167914e-07, generator loss = 14.487985610961914\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 5, Batch: 132/468, discriminator loss real = 5.824055193670574e-08, disciminator loss fake = 6.914438017702196e-07, generator loss = 14.389119148254395\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 5, Batch: 133/468, discriminator loss real = 1.1102861251915952e-12, disciminator loss fake = 6.664701572844933e-07, generator loss = 14.541515350341797\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 5, Batch: 134/468, discriminator loss real = 6.864500721320832e-12, disciminator loss fake = 6.366409479596769e-07, generator loss = 14.480618476867676\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 5, Batch: 135/468, discriminator loss real = 1.1206730855806146e-11, disciminator loss fake = 7.278051157300069e-07, generator loss = 14.43691635131836\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 5, Batch: 136/468, discriminator loss real = 1.562556507794799e-12, disciminator loss fake = 7.384276727862016e-07, generator loss = 14.459892272949219\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 5, Batch: 137/468, discriminator loss real = 5.783231373310141e-15, disciminator loss fake = 7.06738717326516e-07, generator loss = 14.49007797241211\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 5, Batch: 138/468, discriminator loss real = 7.766973175726832e-11, disciminator loss fake = 7.839290674382937e-07, generator loss = 14.452903747558594\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 5, Batch: 139/468, discriminator loss real = 4.10837683317844e-12, disciminator loss fake = 6.54216819384601e-07, generator loss = 14.578155517578125\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 5, Batch: 140/468, discriminator loss real = 4.4588509967580237e-11, disciminator loss fake = 6.518767463603581e-07, generator loss = 14.387068748474121\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 5, Batch: 141/468, discriminator loss real = 1.3056614456274929e-08, disciminator loss fake = 5.656410735355166e-07, generator loss = 14.466548919677734\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 5, Batch: 142/468, discriminator loss real = 7.712485164401706e-13, disciminator loss fake = 8.173067271854961e-07, generator loss = 14.621553421020508\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 5, Batch: 143/468, discriminator loss real = 6.563490527987381e-13, disciminator loss fake = 9.13226585907978e-07, generator loss = 14.490805625915527\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 5, Batch: 144/468, discriminator loss real = 1.4560624927995036e-09, disciminator loss fake = 7.77931063566939e-07, generator loss = 14.424293518066406\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 5, Batch: 145/468, discriminator loss real = 3.150173177868254e-10, disciminator loss fake = 7.659576226615172e-07, generator loss = 14.643203735351562\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 5, Batch: 146/468, discriminator loss real = 4.2340168372213827e-14, disciminator loss fake = 6.505554779323575e-07, generator loss = 14.621580123901367\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 5, Batch: 147/468, discriminator loss real = 4.399317688570312e-14, disciminator loss fake = 5.331589818524662e-07, generator loss = 14.454057693481445\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 5, Batch: 148/468, discriminator loss real = 3.115908410195739e-13, disciminator loss fake = 6.227880362530414e-07, generator loss = 14.423358917236328\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 5, Batch: 149/468, discriminator loss real = 1.5733099545389706e-10, disciminator loss fake = 6.224511253094533e-07, generator loss = 14.45749282836914\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 5, Batch: 150/468, discriminator loss real = 7.408310076506552e-14, disciminator loss fake = 5.640779932036821e-07, generator loss = 14.522676467895508\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 5, Batch: 151/468, discriminator loss real = 9.09994952655313e-13, disciminator loss fake = 6.849386977592076e-07, generator loss = 14.588215827941895\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 5, Batch: 152/468, discriminator loss real = 1.0070081704269263e-12, disciminator loss fake = 6.032368560227042e-07, generator loss = 14.574817657470703\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 5, Batch: 153/468, discriminator loss real = 2.3316490405100865e-10, disciminator loss fake = 7.218854989332613e-07, generator loss = 14.580818176269531\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 5, Batch: 154/468, discriminator loss real = 1.159475212239927e-13, disciminator loss fake = 6.823159992563887e-07, generator loss = 14.5440034866333\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 5, Batch: 155/468, discriminator loss real = 7.587553849108808e-12, disciminator loss fake = 8.120878192130476e-07, generator loss = 14.389869689941406\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 5, Batch: 156/468, discriminator loss real = 7.545397466557358e-12, disciminator loss fake = 5.681760057996144e-07, generator loss = 14.542786598205566\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 5, Batch: 157/468, discriminator loss real = 5.0767810094720645e-12, disciminator loss fake = 5.751520575358882e-07, generator loss = 14.654325485229492\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 5, Batch: 158/468, discriminator loss real = 3.447155616509434e-10, disciminator loss fake = 6.004714805385447e-07, generator loss = 14.480081558227539\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 5, Batch: 159/468, discriminator loss real = 4.2430218138902326e-14, disciminator loss fake = 7.2015609475784e-07, generator loss = 14.547149658203125\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 5, Batch: 160/468, discriminator loss real = 4.686856458491206e-10, disciminator loss fake = 6.987979759287555e-07, generator loss = 14.625592231750488\n",
      "2/2 [==============================] - 0s 35ms/step\n",
      "Epoch: 5, Batch: 161/468, discriminator loss real = 1.526903936621693e-08, disciminator loss fake = 7.187044275269727e-07, generator loss = 14.5936279296875\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 5, Batch: 162/468, discriminator loss real = 1.376093239358056e-09, disciminator loss fake = 6.073180429666536e-07, generator loss = 14.554719924926758\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 5, Batch: 163/468, discriminator loss real = 3.2816149797554317e-09, disciminator loss fake = 6.088437203288777e-07, generator loss = 14.507506370544434\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 5, Batch: 164/468, discriminator loss real = 1.5625065370860757e-15, disciminator loss fake = 5.463497245727922e-07, generator loss = 14.577295303344727\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 5, Batch: 165/468, discriminator loss real = 2.9179201277429456e-09, disciminator loss fake = 6.194348998178612e-07, generator loss = 14.586562156677246\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 5, Batch: 166/468, discriminator loss real = 6.387370188321029e-09, disciminator loss fake = 5.467121013680298e-07, generator loss = 14.617104530334473\n",
      "2/2 [==============================] - 0s 37ms/step\n",
      "Epoch: 5, Batch: 167/468, discriminator loss real = 1.815718064790417e-08, disciminator loss fake = 6.174315103635308e-07, generator loss = 14.477317810058594\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 5, Batch: 168/468, discriminator loss real = 3.492583826314455e-13, disciminator loss fake = 5.28365490026772e-07, generator loss = 14.657474517822266\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 5, Batch: 169/468, discriminator loss real = 7.032310389391838e-13, disciminator loss fake = 5.557520807997207e-07, generator loss = 14.74079418182373\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 5, Batch: 170/468, discriminator loss real = 3.3890643763578865e-11, disciminator loss fake = 5.941233212070074e-07, generator loss = 14.61799430847168\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 5, Batch: 171/468, discriminator loss real = 5.534258381428847e-12, disciminator loss fake = 4.925249186271685e-07, generator loss = 14.768983840942383\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 5, Batch: 172/468, discriminator loss real = 1.3304957721498034e-13, disciminator loss fake = 5.695579829989583e-07, generator loss = 14.734387397766113\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 5, Batch: 173/468, discriminator loss real = 1.4575413098683043e-10, disciminator loss fake = 5.649133072438417e-07, generator loss = 14.766056060791016\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 5, Batch: 174/468, discriminator loss real = 1.2442952224134274e-10, disciminator loss fake = 5.109390031066141e-07, generator loss = 14.758912086486816\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 5, Batch: 175/468, discriminator loss real = 1.8509732626625919e-06, disciminator loss fake = 5.516701548913261e-07, generator loss = 14.627447128295898\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 5, Batch: 176/468, discriminator loss real = 2.0109863774209202e-10, disciminator loss fake = 5.069993562756281e-07, generator loss = 14.735010147094727\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 5, Batch: 177/468, discriminator loss real = 1.9594727229677034e-10, disciminator loss fake = 6.703528470097808e-07, generator loss = 14.755648612976074\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 5, Batch: 178/468, discriminator loss real = 9.553843430758864e-16, disciminator loss fake = 6.964602334846859e-07, generator loss = 14.658092498779297\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 5, Batch: 179/468, discriminator loss real = 2.814476651735731e-09, disciminator loss fake = 5.481048219735385e-07, generator loss = 14.511892318725586\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 5, Batch: 180/468, discriminator loss real = 4.475564450295844e-12, disciminator loss fake = 5.952935566710948e-07, generator loss = 14.700644493103027\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 5, Batch: 181/468, discriminator loss real = 1.145513127713202e-13, disciminator loss fake = 5.332186674422701e-07, generator loss = 14.702713966369629\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 5, Batch: 182/468, discriminator loss real = 1.4938212125614747e-11, disciminator loss fake = 5.847948614245979e-07, generator loss = 14.66909408569336\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 5, Batch: 183/468, discriminator loss real = 2.3801099979792184e-13, disciminator loss fake = 7.153687420213828e-07, generator loss = 14.79024887084961\n",
      "2/2 [==============================] - 0s 39ms/step\n",
      "Epoch: 5, Batch: 184/468, discriminator loss real = 3.983607221869079e-09, disciminator loss fake = 4.970390818925807e-07, generator loss = 14.749868392944336\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 5, Batch: 185/468, discriminator loss real = 1.5708517819845724e-11, disciminator loss fake = 5.814118821945158e-07, generator loss = 14.709651947021484\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 5, Batch: 186/468, discriminator loss real = 2.7160204966146517e-13, disciminator loss fake = 5.328026873030467e-07, generator loss = 14.737951278686523\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 5, Batch: 187/468, discriminator loss real = 1.9384674487810116e-07, disciminator loss fake = 5.395691005105618e-07, generator loss = 14.703649520874023\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 5, Batch: 188/468, discriminator loss real = 7.844676514282001e-13, disciminator loss fake = 5.852663775840483e-07, generator loss = 14.597024917602539\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 5, Batch: 189/468, discriminator loss real = 2.8278743791076977e-09, disciminator loss fake = 5.622073331323918e-07, generator loss = 14.736528396606445\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 5, Batch: 190/468, discriminator loss real = 1.7120237449930187e-09, disciminator loss fake = 5.056490408605896e-07, generator loss = 14.890573501586914\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 5, Batch: 191/468, discriminator loss real = 2.3253996062067017e-08, disciminator loss fake = 5.466537800202786e-07, generator loss = 14.688081741333008\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 5, Batch: 192/468, discriminator loss real = 1.0341877094283136e-12, disciminator loss fake = 6.912068215569889e-07, generator loss = 14.650646209716797\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 5, Batch: 193/468, discriminator loss real = 2.4078155025364367e-09, disciminator loss fake = 6.041613005436375e-07, generator loss = 14.738252639770508\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 5, Batch: 194/468, discriminator loss real = 6.8230741057107025e-09, disciminator loss fake = 4.855456836594385e-07, generator loss = 14.725048065185547\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 5, Batch: 195/468, discriminator loss real = 3.0092588143570964e-11, disciminator loss fake = 5.163001901564712e-07, generator loss = 14.848329544067383\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 5, Batch: 196/468, discriminator loss real = 5.52671908238267e-10, disciminator loss fake = 5.763893113908125e-07, generator loss = 14.681009292602539\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 5, Batch: 197/468, discriminator loss real = 5.642697680635633e-13, disciminator loss fake = 5.48934849575744e-07, generator loss = 14.871271133422852\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 5, Batch: 198/468, discriminator loss real = 8.049708455359905e-09, disciminator loss fake = 4.934336175210774e-07, generator loss = 14.689262390136719\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 5, Batch: 199/468, discriminator loss real = 1.0752571793018473e-12, disciminator loss fake = 5.02929481172032e-07, generator loss = 14.933652877807617\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 5, Batch: 200/468, discriminator loss real = 5.767419430924292e-09, disciminator loss fake = 5.603916974905587e-07, generator loss = 14.897642135620117\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 5, Batch: 201/468, discriminator loss real = 8.757215438914834e-12, disciminator loss fake = 4.899981718153867e-07, generator loss = 14.86771011352539\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 5, Batch: 202/468, discriminator loss real = 3.2159181567736894e-11, disciminator loss fake = 4.601520799951686e-07, generator loss = 14.72088623046875\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 5, Batch: 203/468, discriminator loss real = 1.228871115976915e-09, disciminator loss fake = 5.39767086138454e-07, generator loss = 14.811128616333008\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 5, Batch: 204/468, discriminator loss real = 3.462901840278754e-11, disciminator loss fake = 5.27803138083982e-07, generator loss = 14.815927505493164\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 5, Batch: 205/468, discriminator loss real = 9.576853754467152e-10, disciminator loss fake = 4.255430212651845e-07, generator loss = 14.852067947387695\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 5, Batch: 206/468, discriminator loss real = 7.245632479419006e-12, disciminator loss fake = 5.097376742924098e-07, generator loss = 14.945509910583496\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 5, Batch: 207/468, discriminator loss real = 6.311126732327921e-09, disciminator loss fake = 5.346090574676055e-07, generator loss = 14.926640510559082\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 5, Batch: 208/468, discriminator loss real = 1.1048161083909713e-12, disciminator loss fake = 4.838303766518948e-07, generator loss = 14.868380546569824\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 5, Batch: 209/468, discriminator loss real = 3.572597790935106e-07, disciminator loss fake = 4.578974426294735e-07, generator loss = 14.866083145141602\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 5, Batch: 210/468, discriminator loss real = 1.0439698942010483e-16, disciminator loss fake = 4.6305973455673666e-07, generator loss = 14.827493667602539\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 5, Batch: 211/468, discriminator loss real = 8.141443630371725e-10, disciminator loss fake = 4.6645004658785183e-07, generator loss = 14.77963924407959\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 5, Batch: 212/468, discriminator loss real = 2.2516695452612367e-10, disciminator loss fake = 4.86348767481104e-07, generator loss = 14.897829055786133\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 5, Batch: 213/468, discriminator loss real = 1.7345362479659343e-08, disciminator loss fake = 4.698197813013394e-07, generator loss = 14.88547420501709\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 5, Batch: 214/468, discriminator loss real = 3.993885911768302e-06, disciminator loss fake = 5.801549605166656e-07, generator loss = 14.919872283935547\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 5, Batch: 215/468, discriminator loss real = 3.141810000096418e-13, disciminator loss fake = 4.11335633998533e-07, generator loss = 14.840039253234863\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 5, Batch: 216/468, discriminator loss real = 7.1024111036877e-08, disciminator loss fake = 5.431420504464768e-07, generator loss = 14.829780578613281\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 5, Batch: 217/468, discriminator loss real = 9.09832376105868e-10, disciminator loss fake = 6.587080179087934e-07, generator loss = 14.959005355834961\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 5, Batch: 218/468, discriminator loss real = 8.302009746330441e-08, disciminator loss fake = 5.035909680373152e-07, generator loss = 14.887494087219238\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 5, Batch: 219/468, discriminator loss real = 2.012109446072885e-12, disciminator loss fake = 4.254973191564204e-07, generator loss = 14.828287124633789\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 5, Batch: 220/468, discriminator loss real = 4.0258480576982336e-11, disciminator loss fake = 5.177446951165621e-07, generator loss = 14.757329940795898\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 5, Batch: 221/468, discriminator loss real = 5.3234396091284e-07, disciminator loss fake = 4.1499421854496177e-07, generator loss = 14.840988159179688\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 5, Batch: 222/468, discriminator loss real = 3.180287522046299e-13, disciminator loss fake = 5.326731979948818e-07, generator loss = 14.968607902526855\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 5, Batch: 223/468, discriminator loss real = 7.77321523121044e-12, disciminator loss fake = 5.284757094159431e-07, generator loss = 14.87352180480957\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 5, Batch: 224/468, discriminator loss real = 6.089797000008446e-10, disciminator loss fake = 6.739871878380654e-07, generator loss = 15.077924728393555\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 5, Batch: 225/468, discriminator loss real = 4.826666478064019e-15, disciminator loss fake = 4.292515427550825e-07, generator loss = 14.923919677734375\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 5, Batch: 226/468, discriminator loss real = 3.023276740066194e-09, disciminator loss fake = 4.5353954192250967e-07, generator loss = 14.91292953491211\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 5, Batch: 227/468, discriminator loss real = 5.051398743738389e-10, disciminator loss fake = 4.912917574984021e-07, generator loss = 14.970693588256836\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 5, Batch: 228/468, discriminator loss real = 2.2503304775156607e-11, disciminator loss fake = 4.2521457999100676e-07, generator loss = 14.867081642150879\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 5, Batch: 229/468, discriminator loss real = 1.5493204592528786e-12, disciminator loss fake = 4.725182805032091e-07, generator loss = 14.921149253845215\n",
      "2/2 [==============================] - 0s 36ms/step\n",
      "Epoch: 5, Batch: 230/468, discriminator loss real = 4.692459094901569e-12, disciminator loss fake = 3.7847075873287395e-07, generator loss = 14.995970726013184\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 5, Batch: 231/468, discriminator loss real = 1.966756979498996e-09, disciminator loss fake = 4.881086965724535e-07, generator loss = 14.855388641357422\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 5, Batch: 232/468, discriminator loss real = 2.0387474694572028e-11, disciminator loss fake = 4.338055248354067e-07, generator loss = 14.80669116973877\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 5, Batch: 233/468, discriminator loss real = 1.4151331148570812e-11, disciminator loss fake = 5.852539288753178e-07, generator loss = 14.81679916381836\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 5, Batch: 234/468, discriminator loss real = 5.32781631312762e-12, disciminator loss fake = 4.076363211424905e-07, generator loss = 14.969449996948242\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 5, Batch: 235/468, discriminator loss real = 4.849523005390211e-10, disciminator loss fake = 5.207687649999571e-07, generator loss = 14.860335350036621\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 5, Batch: 236/468, discriminator loss real = 1.7334288518466856e-11, disciminator loss fake = 4.2636344232960255e-07, generator loss = 14.977289199829102\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 5, Batch: 237/468, discriminator loss real = 1.5304150835504515e-08, disciminator loss fake = 5.080397613710375e-07, generator loss = 14.921735763549805\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 5, Batch: 238/468, discriminator loss real = 1.9725669014869496e-11, disciminator loss fake = 4.179013899374695e-07, generator loss = 14.92296028137207\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 5, Batch: 239/468, discriminator loss real = 1.4747777221657543e-08, disciminator loss fake = 4.3692668327821593e-07, generator loss = 14.918956756591797\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 5, Batch: 240/468, discriminator loss real = 3.2325603305238815e-10, disciminator loss fake = 4.2306228920097055e-07, generator loss = 14.920282363891602\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 5, Batch: 241/468, discriminator loss real = 5.2815758710966776e-11, disciminator loss fake = 4.637290942355321e-07, generator loss = 14.848308563232422\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 5, Batch: 242/468, discriminator loss real = 8.616552804596722e-09, disciminator loss fake = 4.117402738756937e-07, generator loss = 14.848872184753418\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 5, Batch: 243/468, discriminator loss real = 1.7454754308587894e-09, disciminator loss fake = 5.03737226154044e-07, generator loss = 14.904891967773438\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 5, Batch: 244/468, discriminator loss real = 2.1166499542674133e-14, disciminator loss fake = 4.979621621714614e-07, generator loss = 15.041071891784668\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 5, Batch: 245/468, discriminator loss real = 5.894507972004082e-12, disciminator loss fake = 4.1527613348080195e-07, generator loss = 14.883377075195312\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 5, Batch: 246/468, discriminator loss real = 1.438057312119767e-10, disciminator loss fake = 4.464278049454151e-07, generator loss = 14.966316223144531\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 5, Batch: 247/468, discriminator loss real = 4.348323656699904e-08, disciminator loss fake = 4.3192085286136717e-07, generator loss = 14.954837799072266\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 5, Batch: 248/468, discriminator loss real = 2.65603739002529e-09, disciminator loss fake = 3.543371462910727e-07, generator loss = 14.976112365722656\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 5, Batch: 249/468, discriminator loss real = 4.0052700739368063e-11, disciminator loss fake = 4.090087202257564e-07, generator loss = 15.004035949707031\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 5, Batch: 250/468, discriminator loss real = 3.156547379035146e-08, disciminator loss fake = 5.551862045649614e-07, generator loss = 14.918724060058594\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 5, Batch: 251/468, discriminator loss real = 6.396925632430606e-14, disciminator loss fake = 4.753553071168426e-07, generator loss = 14.908357620239258\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 5, Batch: 252/468, discriminator loss real = 4.303312263823078e-13, disciminator loss fake = 5.208236757425766e-07, generator loss = 14.917412757873535\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 5, Batch: 253/468, discriminator loss real = 1.8705039295241477e-08, disciminator loss fake = 4.142489444802777e-07, generator loss = 14.955501556396484\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 5, Batch: 254/468, discriminator loss real = 9.0274971742757e-13, disciminator loss fake = 4.11962105317798e-07, generator loss = 14.893381118774414\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 5, Batch: 255/468, discriminator loss real = 8.343759691342711e-05, disciminator loss fake = 4.826871986551851e-07, generator loss = 14.714658737182617\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 5, Batch: 256/468, discriminator loss real = 2.0903519529474196e-13, disciminator loss fake = 5.362644515116699e-07, generator loss = 14.638333320617676\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 5, Batch: 257/468, discriminator loss real = 2.557425105020883e-10, disciminator loss fake = 5.92003971178201e-07, generator loss = 14.516048431396484\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 5, Batch: 258/468, discriminator loss real = 3.0948509532890967e-08, disciminator loss fake = 8.152602504196693e-07, generator loss = 14.42599868774414\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 5, Batch: 259/468, discriminator loss real = 5.4681055690342095e-12, disciminator loss fake = 1.2093166787963128e-06, generator loss = 14.290610313415527\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 5, Batch: 260/468, discriminator loss real = 6.500347889422235e-16, disciminator loss fake = 1.0158998975384748e-06, generator loss = 14.18006420135498\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 5, Batch: 261/468, discriminator loss real = 5.260774454951544e-13, disciminator loss fake = 1.5028311963760643e-06, generator loss = 14.096022605895996\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 5, Batch: 262/468, discriminator loss real = 9.840180970402401e-14, disciminator loss fake = 1.3131317473380477e-06, generator loss = 14.030049324035645\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 5, Batch: 263/468, discriminator loss real = 9.166092499813053e-14, disciminator loss fake = 1.3437421557682683e-06, generator loss = 13.844066619873047\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 5, Batch: 264/468, discriminator loss real = 1.3091311888702162e-12, disciminator loss fake = 1.1477300176920835e-06, generator loss = 14.043191909790039\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 5, Batch: 265/468, discriminator loss real = 4.4046065622929675e-13, disciminator loss fake = 1.4390454907697858e-06, generator loss = 14.064106941223145\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 5, Batch: 266/468, discriminator loss real = 7.770637906463589e-15, disciminator loss fake = 1.4666127299278742e-06, generator loss = 13.978163719177246\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 5, Batch: 267/468, discriminator loss real = 1.5106649264851058e-10, disciminator loss fake = 1.4204206308932044e-06, generator loss = 13.947845458984375\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 5, Batch: 268/468, discriminator loss real = 6.050423451142706e-08, disciminator loss fake = 1.3063890946796164e-06, generator loss = 14.080642700195312\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 5, Batch: 269/468, discriminator loss real = 2.386854602853816e-10, disciminator loss fake = 1.6811834484542487e-06, generator loss = 13.858646392822266\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 5, Batch: 270/468, discriminator loss real = 1.2556895800930334e-10, disciminator loss fake = 1.0873834526137216e-06, generator loss = 14.11854362487793\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 5, Batch: 271/468, discriminator loss real = 4.043686718802064e-09, disciminator loss fake = 3.3067535696318373e-06, generator loss = 13.985361099243164\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 5, Batch: 272/468, discriminator loss real = 2.801664678031557e-09, disciminator loss fake = 1.8453854409017367e-06, generator loss = 13.961002349853516\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 5, Batch: 273/468, discriminator loss real = 2.9667482121138733e-13, disciminator loss fake = 1.7770330487110186e-06, generator loss = 14.103802680969238\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 5, Batch: 274/468, discriminator loss real = 4.1069481149236253e-11, disciminator loss fake = 2.3190825686469907e-06, generator loss = 14.013716697692871\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 5, Batch: 275/468, discriminator loss real = 1.9247390140031406e-11, disciminator loss fake = 1.8197440567746526e-06, generator loss = 14.026140213012695\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 5, Batch: 276/468, discriminator loss real = 3.9686479880174375e-08, disciminator loss fake = 1.4025114296600805e-06, generator loss = 14.052523612976074\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 5, Batch: 277/468, discriminator loss real = 6.536117203026492e-10, disciminator loss fake = 1.528091388536268e-06, generator loss = 14.100089073181152\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 5, Batch: 278/468, discriminator loss real = 4.288521848836574e-13, disciminator loss fake = 8.961121693573659e-07, generator loss = 14.207014083862305\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 5, Batch: 279/468, discriminator loss real = 2.955770597354822e-14, disciminator loss fake = 1.4140368875814602e-06, generator loss = 14.110920906066895\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 5, Batch: 280/468, discriminator loss real = 5.38050826115466e-10, disciminator loss fake = 1.2953335044585401e-06, generator loss = 14.073173522949219\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 5, Batch: 281/468, discriminator loss real = 3.0616420856888205e-12, disciminator loss fake = 1.030283783620689e-06, generator loss = 14.134459495544434\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 5, Batch: 282/468, discriminator loss real = 2.0217874249772727e-11, disciminator loss fake = 8.600127898716892e-07, generator loss = 14.059135437011719\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 5, Batch: 283/468, discriminator loss real = 1.9097874323636965e-12, disciminator loss fake = 1.2305929431022378e-06, generator loss = 14.12158489227295\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 5, Batch: 284/468, discriminator loss real = 1.7719672951166388e-10, disciminator loss fake = 8.028228535295057e-07, generator loss = 14.118474960327148\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 5, Batch: 285/468, discriminator loss real = 7.22398212360531e-08, disciminator loss fake = 1.1101238897026633e-06, generator loss = 14.194717407226562\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 5, Batch: 286/468, discriminator loss real = 4.7811828281230095e-12, disciminator loss fake = 1.1758266964534414e-06, generator loss = 14.223286628723145\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 5, Batch: 287/468, discriminator loss real = 6.9116032896943125e-09, disciminator loss fake = 9.982433084587683e-07, generator loss = 14.15966510772705\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 5, Batch: 288/468, discriminator loss real = 8.019542061671325e-13, disciminator loss fake = 1.114884071284905e-06, generator loss = 14.19491195678711\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 5, Batch: 289/468, discriminator loss real = 5.933598230811743e-12, disciminator loss fake = 8.423288591075107e-07, generator loss = 14.122133255004883\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 5, Batch: 290/468, discriminator loss real = 9.967877218075571e-13, disciminator loss fake = 1.058827592714806e-06, generator loss = 14.19250774383545\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 5, Batch: 291/468, discriminator loss real = 1.6876944068002354e-15, disciminator loss fake = 1.0755064749901067e-06, generator loss = 14.40829849243164\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 5, Batch: 292/468, discriminator loss real = 3.740140724797607e-14, disciminator loss fake = 9.95357822830556e-07, generator loss = 14.320074081420898\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 5, Batch: 293/468, discriminator loss real = 9.89307052078059e-13, disciminator loss fake = 9.764963806446758e-07, generator loss = 14.255587577819824\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 5, Batch: 294/468, discriminator loss real = 1.1825951459418227e-12, disciminator loss fake = 9.651666914578527e-07, generator loss = 14.21619987487793\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 5, Batch: 295/468, discriminator loss real = 2.631446796574899e-11, disciminator loss fake = 9.139607755059842e-07, generator loss = 14.444192886352539\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 5, Batch: 296/468, discriminator loss real = 1.2797480663397342e-16, disciminator loss fake = 8.975795822152577e-07, generator loss = 14.417215347290039\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 5, Batch: 297/468, discriminator loss real = 1.5623758953253741e-09, disciminator loss fake = 8.357030765182571e-07, generator loss = 14.377450942993164\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 5, Batch: 298/468, discriminator loss real = 9.550547019898659e-10, disciminator loss fake = 1.2620807865459938e-06, generator loss = 14.358878135681152\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 5, Batch: 299/468, discriminator loss real = 1.6155746185297915e-10, disciminator loss fake = 1.062640649251989e-06, generator loss = 14.438243865966797\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 5, Batch: 300/468, discriminator loss real = 4.124317901088581e-11, disciminator loss fake = 9.141698456005543e-07, generator loss = 14.363401412963867\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 5, Batch: 301/468, discriminator loss real = 6.397254687789955e-13, disciminator loss fake = 9.146071420218504e-07, generator loss = 14.512441635131836\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 5, Batch: 302/468, discriminator loss real = 1.0183581408695908e-11, disciminator loss fake = 7.950760618768982e-07, generator loss = 14.339118003845215\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 5, Batch: 303/468, discriminator loss real = 7.392525786941058e-15, disciminator loss fake = 8.931529009714723e-07, generator loss = 14.489063262939453\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 5, Batch: 304/468, discriminator loss real = 1.0805343504173039e-14, disciminator loss fake = 6.208571221577586e-07, generator loss = 14.440101623535156\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 5, Batch: 305/468, discriminator loss real = 8.451780074414383e-12, disciminator loss fake = 6.844317681498069e-07, generator loss = 14.488269805908203\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 5, Batch: 306/468, discriminator loss real = 8.59390406060534e-11, disciminator loss fake = 7.754990747343982e-07, generator loss = 14.617595672607422\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 5, Batch: 307/468, discriminator loss real = 5.084617449302442e-11, disciminator loss fake = 8.01672285888344e-07, generator loss = 14.516965866088867\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 5, Batch: 308/468, discriminator loss real = 8.017091879253258e-09, disciminator loss fake = 6.760847099940293e-07, generator loss = 14.593460083007812\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 5, Batch: 309/468, discriminator loss real = 7.360046599957926e-12, disciminator loss fake = 9.294962524108996e-07, generator loss = 14.514379501342773\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 5, Batch: 310/468, discriminator loss real = 3.001006561309527e-13, disciminator loss fake = 7.241281423375767e-07, generator loss = 14.585774421691895\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 5, Batch: 311/468, discriminator loss real = 7.80667530619894e-10, disciminator loss fake = 6.961405460970127e-07, generator loss = 14.592745780944824\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 5, Batch: 312/468, discriminator loss real = 2.997228507051197e-11, disciminator loss fake = 7.11705069988966e-07, generator loss = 14.573761940002441\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 5, Batch: 313/468, discriminator loss real = 7.120353728851114e-08, disciminator loss fake = 7.008170541666914e-07, generator loss = 14.528928756713867\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 5, Batch: 314/468, discriminator loss real = 5.536800795712777e-16, disciminator loss fake = 7.599911668876302e-07, generator loss = 14.697998046875\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 5, Batch: 315/468, discriminator loss real = 3.0006177098584885e-08, disciminator loss fake = 6.781542651879136e-07, generator loss = 14.551623344421387\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 5, Batch: 316/468, discriminator loss real = 7.117965071523624e-12, disciminator loss fake = 5.260349098534789e-07, generator loss = 14.805890083312988\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 5, Batch: 317/468, discriminator loss real = 6.070977189931784e-14, disciminator loss fake = 7.20946331966843e-07, generator loss = 14.411689758300781\n",
      "2/2 [==============================] - 0s 35ms/step\n",
      "Epoch: 5, Batch: 318/468, discriminator loss real = 5.812811169902954e-13, disciminator loss fake = 7.955978276186215e-07, generator loss = 14.574628829956055\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 5, Batch: 319/468, discriminator loss real = 1.0071667055910893e-08, disciminator loss fake = 6.875606004541623e-07, generator loss = 14.642925262451172\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 5, Batch: 320/468, discriminator loss real = 9.633770343964176e-12, disciminator loss fake = 5.459172598420992e-07, generator loss = 14.678537368774414\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 5, Batch: 321/468, discriminator loss real = 8.718067500551596e-13, disciminator loss fake = 7.527839329668495e-07, generator loss = 14.557003021240234\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 5, Batch: 322/468, discriminator loss real = 1.2708857299870147e-09, disciminator loss fake = 6.484559662567335e-07, generator loss = 14.421958923339844\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 5, Batch: 323/468, discriminator loss real = 1.2905250327578666e-13, disciminator loss fake = 9.597431471775053e-07, generator loss = 14.725160598754883\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 5, Batch: 324/468, discriminator loss real = 7.792545227798195e-14, disciminator loss fake = 5.152870130586962e-07, generator loss = 14.60010051727295\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 5, Batch: 325/468, discriminator loss real = 2.0460902069863174e-11, disciminator loss fake = 5.928022233092634e-07, generator loss = 14.49226188659668\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 5, Batch: 326/468, discriminator loss real = 1.025851512705166e-14, disciminator loss fake = 7.05935462974594e-07, generator loss = 14.49633502960205\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 5, Batch: 327/468, discriminator loss real = 1.2064526378177047e-15, disciminator loss fake = 5.851341029483592e-07, generator loss = 14.740657806396484\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 5, Batch: 328/468, discriminator loss real = 2.9346465453272685e-06, disciminator loss fake = 7.379090334325156e-07, generator loss = 14.669567108154297\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 5, Batch: 329/468, discriminator loss real = 1.6238360211594943e-13, disciminator loss fake = 6.451387548622733e-07, generator loss = 14.78084945678711\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 5, Batch: 330/468, discriminator loss real = 1.776657163402029e-12, disciminator loss fake = 6.323448360490147e-07, generator loss = 14.610549926757812\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 5, Batch: 331/468, discriminator loss real = 3.776357837548261e-10, disciminator loss fake = 5.388334898270841e-07, generator loss = 14.676813125610352\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 5, Batch: 332/468, discriminator loss real = 2.0659899138686377e-11, disciminator loss fake = 7.376786470558727e-07, generator loss = 14.721518516540527\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 5, Batch: 333/468, discriminator loss real = 5.991616195532158e-16, disciminator loss fake = 5.904640829612617e-07, generator loss = 14.634323120117188\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 5, Batch: 334/468, discriminator loss real = 5.884642079179159e-11, disciminator loss fake = 6.452110028476454e-07, generator loss = 14.776103973388672\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 5, Batch: 335/468, discriminator loss real = 3.784127958900152e-13, disciminator loss fake = 4.0890080299504916e-07, generator loss = 14.705867767333984\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 5, Batch: 336/468, discriminator loss real = 5.186910101429021e-08, disciminator loss fake = 5.623549554911733e-07, generator loss = 14.667680740356445\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 5, Batch: 337/468, discriminator loss real = 3.0463302991279306e-09, disciminator loss fake = 7.022661066002911e-07, generator loss = 14.646402359008789\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 5, Batch: 338/468, discriminator loss real = 3.637923295940482e-11, disciminator loss fake = 4.932636556986836e-07, generator loss = 14.704910278320312\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 5, Batch: 339/468, discriminator loss real = 3.9747760638420004e-09, disciminator loss fake = 6.562426051459624e-07, generator loss = 14.84022331237793\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 5, Batch: 340/468, discriminator loss real = 3.2167148718981187e-12, disciminator loss fake = 5.939268703514244e-07, generator loss = 14.851036071777344\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 5, Batch: 341/468, discriminator loss real = 7.019698156085497e-10, disciminator loss fake = 6.754065680070198e-07, generator loss = 14.759054183959961\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 5, Batch: 342/468, discriminator loss real = 3.0563152009221994e-09, disciminator loss fake = 5.411182542047754e-07, generator loss = 14.932682037353516\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 5, Batch: 343/468, discriminator loss real = 6.132553354021297e-10, disciminator loss fake = 7.348644999183307e-07, generator loss = 14.648368835449219\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 5, Batch: 344/468, discriminator loss real = 5.053097263535422e-12, disciminator loss fake = 5.333484978109482e-07, generator loss = 14.643677711486816\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 5, Batch: 345/468, discriminator loss real = 2.2644671985520663e-14, disciminator loss fake = 5.775184490630636e-07, generator loss = 14.783418655395508\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 5, Batch: 346/468, discriminator loss real = 4.2738004107922833e-11, disciminator loss fake = 5.170834924683732e-07, generator loss = 14.605856895446777\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 5, Batch: 347/468, discriminator loss real = 6.584258745861993e-12, disciminator loss fake = 5.220932735028327e-07, generator loss = 14.685044288635254\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 5, Batch: 348/468, discriminator loss real = 1.5756413535017444e-11, disciminator loss fake = 4.86104568153678e-07, generator loss = 14.754066467285156\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 5, Batch: 349/468, discriminator loss real = 2.8076516805919383e-12, disciminator loss fake = 7.750101076453575e-07, generator loss = 14.791040420532227\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 5, Batch: 350/468, discriminator loss real = 2.077661027705298e-14, disciminator loss fake = 5.605999149338459e-07, generator loss = 14.731679916381836\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 5, Batch: 351/468, discriminator loss real = 4.2302250591319535e-08, disciminator loss fake = 6.242328254302265e-07, generator loss = 14.90031623840332\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 5, Batch: 352/468, discriminator loss real = 2.0260456181676878e-13, disciminator loss fake = 5.414104862211389e-07, generator loss = 14.839773178100586\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 5, Batch: 353/468, discriminator loss real = 5.025920235546266e-10, disciminator loss fake = 5.575524255618802e-07, generator loss = 14.784076690673828\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 5, Batch: 354/468, discriminator loss real = 5.420372484188363e-10, disciminator loss fake = 6.172458597575314e-07, generator loss = 14.884163856506348\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 5, Batch: 355/468, discriminator loss real = 5.974049380186308e-12, disciminator loss fake = 5.105446234665578e-07, generator loss = 14.818397521972656\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 5, Batch: 356/468, discriminator loss real = 1.4718434804272817e-11, disciminator loss fake = 4.843790293307393e-07, generator loss = 15.002976417541504\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 5, Batch: 357/468, discriminator loss real = 2.6096896865723807e-10, disciminator loss fake = 5.635000661641243e-07, generator loss = 14.953912734985352\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 5, Batch: 358/468, discriminator loss real = 2.3433655371718487e-07, disciminator loss fake = 4.757666260957194e-07, generator loss = 14.733087539672852\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 5, Batch: 359/468, discriminator loss real = 9.472449136183059e-08, disciminator loss fake = 5.449414857139345e-07, generator loss = 14.78621768951416\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 5, Batch: 360/468, discriminator loss real = 4.853798266091225e-11, disciminator loss fake = 4.7380422074638773e-07, generator loss = 14.909905433654785\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 5, Batch: 361/468, discriminator loss real = 7.478494906676403e-11, disciminator loss fake = 4.1567699327060836e-07, generator loss = 15.015331268310547\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 5, Batch: 362/468, discriminator loss real = 1.2100783049195929e-11, disciminator loss fake = 4.6807699050077645e-07, generator loss = 14.921758651733398\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 5, Batch: 363/468, discriminator loss real = 7.179992017602999e-11, disciminator loss fake = 4.362056245099666e-07, generator loss = 14.964813232421875\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 5, Batch: 364/468, discriminator loss real = 1.7448014144605395e-09, disciminator loss fake = 4.843038254875864e-07, generator loss = 14.849178314208984\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 5, Batch: 365/468, discriminator loss real = 6.856866203303058e-12, disciminator loss fake = 4.6693224931004806e-07, generator loss = 15.09827995300293\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 5, Batch: 366/468, discriminator loss real = 1.1016523804308065e-10, disciminator loss fake = 5.082512188891997e-07, generator loss = 14.854573249816895\n",
      "2/2 [==============================] - 0s 39ms/step\n",
      "Epoch: 5, Batch: 367/468, discriminator loss real = 7.075768329546303e-14, disciminator loss fake = 4.6933428166084923e-07, generator loss = 14.87208080291748\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 5, Batch: 368/468, discriminator loss real = 1.4141321794114425e-11, disciminator loss fake = 4.801037789547991e-07, generator loss = 14.862007141113281\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 5, Batch: 369/468, discriminator loss real = 1.3653755903675346e-10, disciminator loss fake = 4.060028686581063e-07, generator loss = 15.017200469970703\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 5, Batch: 370/468, discriminator loss real = 2.376664420822294e-10, disciminator loss fake = 4.6165723688318394e-07, generator loss = 14.892478942871094\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 5, Batch: 371/468, discriminator loss real = 7.589957308484774e-12, disciminator loss fake = 6.245406325433578e-07, generator loss = 14.932762145996094\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 5, Batch: 372/468, discriminator loss real = 2.613690097685861e-10, disciminator loss fake = 4.5558178385363135e-07, generator loss = 14.92959213256836\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 5, Batch: 373/468, discriminator loss real = 3.186734653937151e-09, disciminator loss fake = 5.001440968044335e-07, generator loss = 14.968420028686523\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 5, Batch: 374/468, discriminator loss real = 1.088718958736079e-12, disciminator loss fake = 6.059809720682097e-07, generator loss = 14.8800048828125\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 5, Batch: 375/468, discriminator loss real = 1.0590704979662746e-09, disciminator loss fake = 4.654362157907599e-07, generator loss = 15.094382286071777\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 5, Batch: 376/468, discriminator loss real = 2.959841790065032e-12, disciminator loss fake = 3.3092581475102634e-07, generator loss = 15.022473335266113\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 5, Batch: 377/468, discriminator loss real = 1.9298386673416434e-12, disciminator loss fake = 5.489265504365903e-07, generator loss = 15.023894309997559\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 5, Batch: 378/468, discriminator loss real = 9.2846279275971e-11, disciminator loss fake = 4.2832220970012713e-07, generator loss = 14.995966911315918\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 5, Batch: 379/468, discriminator loss real = 3.530870908152739e-12, disciminator loss fake = 3.920848712368752e-07, generator loss = 15.081607818603516\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 5, Batch: 380/468, discriminator loss real = 1.7316251210708344e-10, disciminator loss fake = 4.7679674253231497e-07, generator loss = 14.851983070373535\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 5, Batch: 381/468, discriminator loss real = 1.9139780906007875e-12, disciminator loss fake = 3.846346885438834e-07, generator loss = 15.086647033691406\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 5, Batch: 382/468, discriminator loss real = 1.9971455045286746e-12, disciminator loss fake = 4.5595942310683313e-07, generator loss = 15.129295349121094\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 5, Batch: 383/468, discriminator loss real = 6.110305946112338e-13, disciminator loss fake = 5.108897767058806e-07, generator loss = 15.066549301147461\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 5, Batch: 384/468, discriminator loss real = 5.203437467571348e-06, disciminator loss fake = 4.3630888058032724e-07, generator loss = 15.12733268737793\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 5, Batch: 385/468, discriminator loss real = 7.796703016538231e-07, disciminator loss fake = 4.516911928931222e-07, generator loss = 14.922126770019531\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 5, Batch: 386/468, discriminator loss real = 2.516582275902124e-09, disciminator loss fake = 6.081160108806216e-07, generator loss = 14.970447540283203\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 5, Batch: 387/468, discriminator loss real = 4.9959945035149556e-12, disciminator loss fake = 4.903355375063256e-07, generator loss = 15.02614974975586\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 5, Batch: 388/468, discriminator loss real = 8.820441044221639e-10, disciminator loss fake = 4.003335902780236e-07, generator loss = 15.111953735351562\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 5, Batch: 389/468, discriminator loss real = 4.196318639793084e-12, disciminator loss fake = 4.3591964526967786e-07, generator loss = 14.871272087097168\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 5, Batch: 390/468, discriminator loss real = 1.2660782144902072e-10, disciminator loss fake = 4.924439735987107e-07, generator loss = 14.803643226623535\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 5, Batch: 391/468, discriminator loss real = 9.866067652523208e-14, disciminator loss fake = 5.643644840347406e-07, generator loss = 15.043989181518555\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 5, Batch: 392/468, discriminator loss real = 1.729243105045436e-13, disciminator loss fake = 5.08720290781639e-07, generator loss = 14.993402481079102\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 5, Batch: 393/468, discriminator loss real = 2.8997569861792527e-13, disciminator loss fake = 4.599465341925679e-07, generator loss = 14.976210594177246\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 5, Batch: 394/468, discriminator loss real = 1.3808328092057565e-10, disciminator loss fake = 4.389454488773481e-07, generator loss = 14.96084213256836\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 5, Batch: 395/468, discriminator loss real = 1.7666789142722905e-09, disciminator loss fake = 3.7597504842779017e-07, generator loss = 14.92091178894043\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 5, Batch: 396/468, discriminator loss real = 1.6375475628271907e-11, disciminator loss fake = 5.160676437299117e-07, generator loss = 14.946798324584961\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 5, Batch: 397/468, discriminator loss real = 2.238652514231776e-14, disciminator loss fake = 6.610485456803872e-07, generator loss = 15.025592803955078\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 5, Batch: 398/468, discriminator loss real = 5.586594622780834e-14, disciminator loss fake = 5.280807613416982e-07, generator loss = 15.018891334533691\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 5, Batch: 399/468, discriminator loss real = 3.7291303129228376e-14, disciminator loss fake = 4.589197146742663e-07, generator loss = 14.950172424316406\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 5, Batch: 400/468, discriminator loss real = 9.593623673254115e-10, disciminator loss fake = 3.784489308600314e-07, generator loss = 15.033036231994629\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 5, Batch: 401/468, discriminator loss real = 1.5632974515594755e-12, disciminator loss fake = 3.589036339235463e-07, generator loss = 14.892820358276367\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 5, Batch: 402/468, discriminator loss real = 2.918274732977011e-09, disciminator loss fake = 4.3293408680256107e-07, generator loss = 15.018136978149414\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 5, Batch: 403/468, discriminator loss real = 1.6690912616468268e-06, disciminator loss fake = 4.721590585177182e-07, generator loss = 14.960444450378418\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 5, Batch: 404/468, discriminator loss real = 8.248214888872951e-10, disciminator loss fake = 4.342230113252299e-07, generator loss = 15.182109832763672\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 5, Batch: 405/468, discriminator loss real = 1.5774924699840653e-09, disciminator loss fake = 3.9282952002395177e-07, generator loss = 15.053346633911133\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 5, Batch: 406/468, discriminator loss real = 6.151668801093746e-13, disciminator loss fake = 5.155155236025166e-07, generator loss = 14.962316513061523\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 5, Batch: 407/468, discriminator loss real = 2.0039227438886642e-13, disciminator loss fake = 4.087325748969306e-07, generator loss = 15.063621520996094\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 5, Batch: 408/468, discriminator loss real = 3.486703148425363e-10, disciminator loss fake = 4.088819594016968e-07, generator loss = 15.083885192871094\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 5, Batch: 409/468, discriminator loss real = 1.4454185626178173e-09, disciminator loss fake = 4.5931707859381277e-07, generator loss = 15.138693809509277\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 5, Batch: 410/468, discriminator loss real = 1.60540677973664e-12, disciminator loss fake = 5.017387252337357e-07, generator loss = 14.993729591369629\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 5, Batch: 411/468, discriminator loss real = 1.0131641374755418e-06, disciminator loss fake = 4.7101860900511383e-07, generator loss = 14.95357894897461\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 5, Batch: 412/468, discriminator loss real = 8.266109151333634e-12, disciminator loss fake = 3.556297656359675e-07, generator loss = 15.123263359069824\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 5, Batch: 413/468, discriminator loss real = 1.3657013887835578e-12, disciminator loss fake = 3.7593537172142533e-07, generator loss = 15.161032676696777\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 5, Batch: 414/468, discriminator loss real = 3.476671424709754e-12, disciminator loss fake = 3.9031169762893114e-07, generator loss = 15.083332061767578\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 5, Batch: 415/468, discriminator loss real = 8.199381618112511e-09, disciminator loss fake = 3.1749655704516044e-07, generator loss = 15.121719360351562\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 5, Batch: 416/468, discriminator loss real = 4.366253469889614e-10, disciminator loss fake = 3.8662204815409495e-07, generator loss = 15.024288177490234\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 5, Batch: 417/468, discriminator loss real = 1.408928440582713e-08, disciminator loss fake = 3.608616907513351e-07, generator loss = 15.085086822509766\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 5, Batch: 418/468, discriminator loss real = 1.0958688817508389e-11, disciminator loss fake = 4.5155877614888595e-07, generator loss = 15.038390159606934\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 5, Batch: 419/468, discriminator loss real = 3.582395068525007e-14, disciminator loss fake = 3.9977516053113504e-07, generator loss = 15.1268310546875\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 5, Batch: 420/468, discriminator loss real = 4.783724527612776e-10, disciminator loss fake = 4.215257831674535e-07, generator loss = 15.115100860595703\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 5, Batch: 421/468, discriminator loss real = 3.659201414096813e-12, disciminator loss fake = 4.4946932575840037e-07, generator loss = 15.217634201049805\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 5, Batch: 422/468, discriminator loss real = 7.912665864751034e-07, disciminator loss fake = 4.136171867230587e-07, generator loss = 15.198812484741211\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 5, Batch: 423/468, discriminator loss real = 7.146829239523811e-10, disciminator loss fake = 3.862247126562579e-07, generator loss = 15.151443481445312\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 5, Batch: 424/468, discriminator loss real = 5.945705624892106e-13, disciminator loss fake = 4.898885208604042e-07, generator loss = 15.089576721191406\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 5, Batch: 425/468, discriminator loss real = 2.948037092220801e-10, disciminator loss fake = 3.8090348652985995e-07, generator loss = 15.19530963897705\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 5, Batch: 426/468, discriminator loss real = 1.0574023210849215e-12, disciminator loss fake = 4.388699039736821e-07, generator loss = 15.027141571044922\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 5, Batch: 427/468, discriminator loss real = 7.465580345762668e-14, disciminator loss fake = 3.6959474414288707e-07, generator loss = 15.261407852172852\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 5, Batch: 428/468, discriminator loss real = 3.777274716967871e-13, disciminator loss fake = 4.4708397695103486e-07, generator loss = 15.32397747039795\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 5, Batch: 429/468, discriminator loss real = 2.253886232381555e-14, disciminator loss fake = 3.8292751014523674e-07, generator loss = 15.072757720947266\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 5, Batch: 430/468, discriminator loss real = 1.9757730607833368e-13, disciminator loss fake = 4.0673842249816516e-07, generator loss = 15.09061336517334\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 5, Batch: 431/468, discriminator loss real = 1.207565381022846e-09, disciminator loss fake = 2.7229509669268737e-07, generator loss = 15.204338073730469\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 5, Batch: 432/468, discriminator loss real = 2.6254911439371753e-11, disciminator loss fake = 3.5179488122594194e-07, generator loss = 15.147893905639648\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 5, Batch: 433/468, discriminator loss real = 2.4552906582875345e-11, disciminator loss fake = 4.4805989318774664e-07, generator loss = 15.163148880004883\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 5, Batch: 434/468, discriminator loss real = 3.3452003833644994e-08, disciminator loss fake = 3.6484388488133845e-07, generator loss = 15.132911682128906\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 5, Batch: 435/468, discriminator loss real = 1.1930922916292275e-08, disciminator loss fake = 3.549756115717173e-07, generator loss = 15.151779174804688\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 5, Batch: 436/468, discriminator loss real = 1.4424946792601645e-09, disciminator loss fake = 3.738187501767243e-07, generator loss = 15.191579818725586\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 5, Batch: 437/468, discriminator loss real = 2.4079685090327985e-07, disciminator loss fake = 3.5647283880280156e-07, generator loss = 15.071798324584961\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 5, Batch: 438/468, discriminator loss real = 1.6143711367710978e-11, disciminator loss fake = 3.906820325028093e-07, generator loss = 15.226301193237305\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 5, Batch: 439/468, discriminator loss real = 1.5044752553136642e-13, disciminator loss fake = 4.156632940066629e-07, generator loss = 15.092606544494629\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 5, Batch: 440/468, discriminator loss real = 8.588268940457056e-08, disciminator loss fake = 4.073035313467699e-07, generator loss = 15.277727127075195\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 5, Batch: 441/468, discriminator loss real = 1.6695850160296927e-13, disciminator loss fake = 4.176771426500636e-07, generator loss = 15.170328140258789\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 5, Batch: 442/468, discriminator loss real = 8.237532631385526e-15, disciminator loss fake = 4.0607142182125244e-07, generator loss = 15.190916061401367\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 5, Batch: 443/468, discriminator loss real = 7.619025965688309e-10, disciminator loss fake = 3.576014364625735e-07, generator loss = 15.103460311889648\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 5, Batch: 444/468, discriminator loss real = 2.6089523336852993e-12, disciminator loss fake = 2.85748768646954e-07, generator loss = 15.139656066894531\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 5, Batch: 445/468, discriminator loss real = 9.803405309760649e-11, disciminator loss fake = 3.887994353135582e-07, generator loss = 15.169438362121582\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 5, Batch: 446/468, discriminator loss real = 1.5244836504280102e-09, disciminator loss fake = 3.346315224916907e-07, generator loss = 15.17036247253418\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 5, Batch: 447/468, discriminator loss real = 1.2253136283391086e-08, disciminator loss fake = 3.390720166862593e-07, generator loss = 15.390251159667969\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 5, Batch: 448/468, discriminator loss real = 8.42840294085212e-12, disciminator loss fake = 3.812287445725815e-07, generator loss = 15.09381103515625\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 5, Batch: 449/468, discriminator loss real = 1.0221614136704527e-12, disciminator loss fake = 3.7244467421260197e-07, generator loss = 15.232053756713867\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 5, Batch: 450/468, discriminator loss real = 9.077404106161424e-11, disciminator loss fake = 3.4856756769841013e-07, generator loss = 15.300432205200195\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 5, Batch: 451/468, discriminator loss real = 5.12683428696703e-13, disciminator loss fake = 3.2829595397743105e-07, generator loss = 15.293144226074219\n",
      "2/2 [==============================] - 0s 38ms/step\n",
      "Epoch: 5, Batch: 452/468, discriminator loss real = 8.830627895584087e-11, disciminator loss fake = 3.6436460959521355e-07, generator loss = 15.334068298339844\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 5, Batch: 453/468, discriminator loss real = 1.2352473210963666e-11, disciminator loss fake = 3.563727659638971e-07, generator loss = 15.28948974609375\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 5, Batch: 454/468, discriminator loss real = 9.66091830557729e-14, disciminator loss fake = 3.6100800571148284e-07, generator loss = 15.205223083496094\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 5, Batch: 455/468, discriminator loss real = 1.4234240175436952e-10, disciminator loss fake = 4.0745436535871704e-07, generator loss = 15.334300994873047\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 5, Batch: 456/468, discriminator loss real = 1.2962450557374439e-10, disciminator loss fake = 3.716531296049652e-07, generator loss = 15.258750915527344\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 5, Batch: 457/468, discriminator loss real = 4.415268931717842e-12, disciminator loss fake = 3.47056612781671e-07, generator loss = 15.231264114379883\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 5, Batch: 458/468, discriminator loss real = 2.3599400428633843e-13, disciminator loss fake = 3.156498848966294e-07, generator loss = 15.205225944519043\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 5, Batch: 459/468, discriminator loss real = 3.6941040504334666e-11, disciminator loss fake = 3.1951975643096375e-07, generator loss = 15.314221382141113\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 5, Batch: 460/468, discriminator loss real = 3.3213840566759245e-08, disciminator loss fake = 3.129422339043231e-07, generator loss = 15.31446647644043\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 5, Batch: 461/468, discriminator loss real = 8.523540095950466e-09, disciminator loss fake = 3.253567228966858e-07, generator loss = 15.275806427001953\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 5, Batch: 462/468, discriminator loss real = 1.0890372804939208e-12, disciminator loss fake = 3.3674422184049035e-07, generator loss = 15.323511123657227\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 5, Batch: 463/468, discriminator loss real = 1.6224093712935428e-07, disciminator loss fake = 2.7583658379626286e-07, generator loss = 15.292519569396973\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 5, Batch: 464/468, discriminator loss real = 2.405988186460206e-10, disciminator loss fake = 3.738531688668445e-07, generator loss = 15.380220413208008\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 5, Batch: 465/468, discriminator loss real = 9.017535524714904e-13, disciminator loss fake = 3.5681853205460357e-07, generator loss = 15.22404670715332\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 5, Batch: 466/468, discriminator loss real = 9.066348474924546e-13, disciminator loss fake = 3.2845133546288707e-07, generator loss = 15.378206253051758\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 5, Batch: 467/468, discriminator loss real = 3.7705358244834696e-15, disciminator loss fake = 3.385189870641625e-07, generator loss = 15.378952026367188\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 5, Batch: 468/468, discriminator loss real = 7.392966654151678e-05, disciminator loss fake = 5.22004938829923e-07, generator loss = 15.098491668701172\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 6, Batch: 1/468, discriminator loss real = 2.945597392845119e-14, disciminator loss fake = 4.667852238071646e-07, generator loss = 14.690316200256348\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 6, Batch: 2/468, discriminator loss real = 7.45765143975001e-14, disciminator loss fake = 5.89132241657353e-07, generator loss = 14.508749008178711\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 6, Batch: 3/468, discriminator loss real = 1.1669137878200786e-10, disciminator loss fake = 9.586690339347115e-07, generator loss = 14.41624641418457\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 6, Batch: 4/468, discriminator loss real = 1.7471339045643797e-12, disciminator loss fake = 1.2651723864109954e-06, generator loss = 14.429340362548828\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 6, Batch: 5/468, discriminator loss real = 2.019802944688842e-12, disciminator loss fake = 1.431205760127341e-06, generator loss = 14.283498764038086\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 6, Batch: 6/468, discriminator loss real = 5.3465690208476246e-11, disciminator loss fake = 1.9259211967437295e-06, generator loss = 14.317719459533691\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 6, Batch: 7/468, discriminator loss real = 2.51724205715953e-12, disciminator loss fake = 2.365210775678861e-06, generator loss = 14.070964813232422\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 6, Batch: 8/468, discriminator loss real = 4.860993954025616e-07, disciminator loss fake = 2.3686152417212725e-06, generator loss = 14.07525634765625\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 6, Batch: 9/468, discriminator loss real = 2.1592751892063333e-11, disciminator loss fake = 2.0193238015053794e-06, generator loss = 13.985518455505371\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 6, Batch: 10/468, discriminator loss real = 6.929457109841868e-15, disciminator loss fake = 2.4875355393305654e-06, generator loss = 13.987838745117188\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 6, Batch: 11/468, discriminator loss real = 2.762451942542321e-12, disciminator loss fake = 1.6170907883861219e-06, generator loss = 14.310258865356445\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 6, Batch: 12/468, discriminator loss real = 6.560529029753237e-14, disciminator loss fake = 3.5379666769586038e-06, generator loss = 13.959495544433594\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 6, Batch: 13/468, discriminator loss real = 3.804419019398653e-12, disciminator loss fake = 3.7339930258895038e-06, generator loss = 14.099267959594727\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 6, Batch: 14/468, discriminator loss real = 2.018902081103724e-13, disciminator loss fake = 1.8519556306273444e-06, generator loss = 14.181642532348633\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 6, Batch: 15/468, discriminator loss real = 1.290413224408829e-13, disciminator loss fake = 1.9096789856121177e-06, generator loss = 14.303966522216797\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 6, Batch: 16/468, discriminator loss real = 1.651189086718588e-14, disciminator loss fake = 2.385010702710133e-06, generator loss = 14.279003143310547\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 6, Batch: 17/468, discriminator loss real = 3.258345165674161e-15, disciminator loss fake = 9.096880830838927e-07, generator loss = 14.229208946228027\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 6, Batch: 18/468, discriminator loss real = 1.866970391218442e-13, disciminator loss fake = 2.702722440517391e-06, generator loss = 14.228515625\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 6, Batch: 19/468, discriminator loss real = 8.125656519712178e-15, disciminator loss fake = 2.5673739401099738e-06, generator loss = 14.475652694702148\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 6, Batch: 20/468, discriminator loss real = 2.3856207807815277e-12, disciminator loss fake = 1.3853180007572519e-06, generator loss = 14.406715393066406\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 6, Batch: 21/468, discriminator loss real = 9.525042430139075e-13, disciminator loss fake = 1.115277768803935e-06, generator loss = 14.414203643798828\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 6, Batch: 22/468, discriminator loss real = 6.0331018575854236e-15, disciminator loss fake = 1.3707764310311177e-06, generator loss = 14.5076904296875\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 6, Batch: 23/468, discriminator loss real = 1.5525184833907306e-16, disciminator loss fake = 1.5835743170100613e-06, generator loss = 14.608552932739258\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 6, Batch: 24/468, discriminator loss real = 2.9109648949088296e-06, disciminator loss fake = 1.0847437579286634e-06, generator loss = 14.387285232543945\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 6, Batch: 25/468, discriminator loss real = 5.4521915004686686e-14, disciminator loss fake = 1.173493387796043e-06, generator loss = 14.48891544342041\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 6, Batch: 26/468, discriminator loss real = 9.26418840187411e-14, disciminator loss fake = 1.2614939350896748e-06, generator loss = 14.614509582519531\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 6, Batch: 27/468, discriminator loss real = 8.653809613345942e-11, disciminator loss fake = 1.1105048542958684e-06, generator loss = 14.641036033630371\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 6, Batch: 28/468, discriminator loss real = 7.201504670373282e-11, disciminator loss fake = 7.182462695709546e-07, generator loss = 14.823966026306152\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 6, Batch: 29/468, discriminator loss real = 2.3326191672667917e-11, disciminator loss fake = 1.2111709111195523e-06, generator loss = 14.652246475219727\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 6, Batch: 30/468, discriminator loss real = 1.9777055495118386e-14, disciminator loss fake = 6.628141022702039e-07, generator loss = 14.585512161254883\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 6, Batch: 31/468, discriminator loss real = 3.939624321214197e-11, disciminator loss fake = 5.472493285196833e-07, generator loss = 14.691862106323242\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 6, Batch: 32/468, discriminator loss real = 5.937659652149874e-12, disciminator loss fake = 6.736823365827149e-07, generator loss = 14.683757781982422\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 6, Batch: 33/468, discriminator loss real = 1.2499996870918295e-10, disciminator loss fake = 7.098225296431337e-07, generator loss = 14.83894157409668\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 6, Batch: 34/468, discriminator loss real = 8.347953947031306e-13, disciminator loss fake = 9.812556527322158e-07, generator loss = 14.836767196655273\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 6, Batch: 35/468, discriminator loss real = 4.266653697015954e-10, disciminator loss fake = 6.437208526222093e-07, generator loss = 14.599023818969727\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 6, Batch: 36/468, discriminator loss real = 3.5701172573787687e-10, disciminator loss fake = 9.212369604938431e-07, generator loss = 14.863337516784668\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 6, Batch: 37/468, discriminator loss real = 1.1456940539507354e-13, disciminator loss fake = 6.7491805566533e-07, generator loss = 14.922733306884766\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 6, Batch: 38/468, discriminator loss real = 1.7914773831062547e-11, disciminator loss fake = 3.5044718060817104e-07, generator loss = 14.875822067260742\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 6, Batch: 39/468, discriminator loss real = 6.263151347378482e-14, disciminator loss fake = 7.6354092470865e-07, generator loss = 14.762617111206055\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 6, Batch: 40/468, discriminator loss real = 4.487544558173795e-09, disciminator loss fake = 1.0108858532476006e-06, generator loss = 14.752381324768066\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 6, Batch: 41/468, discriminator loss real = 7.818277136806273e-10, disciminator loss fake = 6.48995637675398e-07, generator loss = 14.793489456176758\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 6, Batch: 42/468, discriminator loss real = 4.51998638170692e-12, disciminator loss fake = 8.584781880927039e-07, generator loss = 14.886906623840332\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 6, Batch: 43/468, discriminator loss real = 1.250957718218048e-14, disciminator loss fake = 7.653972033949685e-07, generator loss = 14.917129516601562\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 6, Batch: 44/468, discriminator loss real = 1.211933886580141e-10, disciminator loss fake = 6.792211024730932e-07, generator loss = 14.968294143676758\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 6, Batch: 45/468, discriminator loss real = 9.080045743070642e-13, disciminator loss fake = 6.426809022741509e-07, generator loss = 14.906600952148438\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 6, Batch: 46/468, discriminator loss real = 2.4145310750789406e-10, disciminator loss fake = 8.597603482485283e-07, generator loss = 14.861594200134277\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 6, Batch: 47/468, discriminator loss real = 8.247572763631084e-12, disciminator loss fake = 6.73723548061389e-07, generator loss = 14.84701156616211\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 6, Batch: 48/468, discriminator loss real = 2.0039803150240232e-11, disciminator loss fake = 4.88225282424537e-07, generator loss = 14.857646942138672\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 6, Batch: 49/468, discriminator loss real = 2.540565143243495e-13, disciminator loss fake = 4.526552288552921e-07, generator loss = 14.95021915435791\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 6, Batch: 50/468, discriminator loss real = 3.549802812807812e-11, disciminator loss fake = 6.222489901119843e-07, generator loss = 15.025957107543945\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 6, Batch: 51/468, discriminator loss real = 5.683302407247931e-14, disciminator loss fake = 7.27675626421842e-07, generator loss = 15.018243789672852\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 6, Batch: 52/468, discriminator loss real = 1.2154762703872179e-14, disciminator loss fake = 4.960212436344591e-07, generator loss = 14.963600158691406\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 6, Batch: 53/468, discriminator loss real = 3.767362422024689e-09, disciminator loss fake = 6.445530971177504e-07, generator loss = 15.113771438598633\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 6, Batch: 54/468, discriminator loss real = 1.3892696021367001e-11, disciminator loss fake = 4.6866796310496284e-07, generator loss = 15.107866287231445\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 6, Batch: 55/468, discriminator loss real = 6.060696649407005e-13, disciminator loss fake = 8.794652330834651e-07, generator loss = 15.103184700012207\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 6, Batch: 56/468, discriminator loss real = 2.4670518405933706e-10, disciminator loss fake = 5.58364376956888e-07, generator loss = 15.156440734863281\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 6, Batch: 57/468, discriminator loss real = 3.430063646851257e-14, disciminator loss fake = 6.926036348886555e-07, generator loss = 15.017107009887695\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 6, Batch: 58/468, discriminator loss real = 9.64609378904433e-16, disciminator loss fake = 5.943387577644899e-07, generator loss = 14.910026550292969\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 6, Batch: 59/468, discriminator loss real = 4.851303278367858e-15, disciminator loss fake = 4.932376214128453e-07, generator loss = 15.060527801513672\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 6, Batch: 60/468, discriminator loss real = 2.8154678588521165e-10, disciminator loss fake = 3.5545986065699253e-07, generator loss = 15.050300598144531\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 6, Batch: 61/468, discriminator loss real = 1.9986105215252792e-08, disciminator loss fake = 4.061641334374144e-07, generator loss = 15.100537300109863\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 6, Batch: 62/468, discriminator loss real = 2.770508228757719e-14, disciminator loss fake = 5.074066393717658e-07, generator loss = 14.977478981018066\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 6, Batch: 63/468, discriminator loss real = 6.436062620351901e-12, disciminator loss fake = 4.902919954474783e-07, generator loss = 15.00317668914795\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 6, Batch: 64/468, discriminator loss real = 3.784843057995542e-14, disciminator loss fake = 7.025691957096569e-07, generator loss = 15.099589347839355\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 6, Batch: 65/468, discriminator loss real = 2.0473564250195198e-13, disciminator loss fake = 4.3222223666816717e-07, generator loss = 15.254182815551758\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 6, Batch: 66/468, discriminator loss real = 3.715442450230588e-12, disciminator loss fake = 3.664163727989944e-07, generator loss = 15.008337020874023\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 6, Batch: 67/468, discriminator loss real = 4.336087424446772e-13, disciminator loss fake = 3.673306707696611e-07, generator loss = 15.24221420288086\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 6, Batch: 68/468, discriminator loss real = 8.623557978815199e-10, disciminator loss fake = 2.783042987175577e-07, generator loss = 15.19918155670166\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 6, Batch: 69/468, discriminator loss real = 3.2318893655042258e-12, disciminator loss fake = 3.053605723835062e-07, generator loss = 15.072193145751953\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 6, Batch: 70/468, discriminator loss real = 1.3069447325590733e-14, disciminator loss fake = 3.8121601164675667e-07, generator loss = 15.105903625488281\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 6, Batch: 71/468, discriminator loss real = 1.459268816894621e-11, disciminator loss fake = 3.3779195973693277e-07, generator loss = 15.224283218383789\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 6, Batch: 72/468, discriminator loss real = 1.6802502098012262e-11, disciminator loss fake = 3.3967938861678704e-07, generator loss = 15.231253623962402\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 6, Batch: 73/468, discriminator loss real = 1.6765137889063197e-11, disciminator loss fake = 3.7343247072385566e-07, generator loss = 15.313956260681152\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 6, Batch: 74/468, discriminator loss real = 4.130986752670651e-08, disciminator loss fake = 6.280852744566801e-07, generator loss = 15.152769088745117\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 6, Batch: 75/468, discriminator loss real = 5.297090979183849e-07, disciminator loss fake = 5.935162903369928e-07, generator loss = 15.13926887512207\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 6, Batch: 76/468, discriminator loss real = 2.071930715885628e-08, disciminator loss fake = 5.39501229468442e-07, generator loss = 15.26371955871582\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 6, Batch: 77/468, discriminator loss real = 9.433694936333836e-10, disciminator loss fake = 5.224440542406228e-07, generator loss = 15.131926536560059\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 6, Batch: 78/468, discriminator loss real = 1.0443317217945225e-13, disciminator loss fake = 3.3201263249793556e-07, generator loss = 15.198567390441895\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 6, Batch: 79/468, discriminator loss real = 4.1020128960234103e-10, disciminator loss fake = 4.486271905079775e-07, generator loss = 15.221067428588867\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 6, Batch: 80/468, discriminator loss real = 4.017876962499132e-17, disciminator loss fake = 4.481822202251351e-07, generator loss = 15.348038673400879\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 6, Batch: 81/468, discriminator loss real = 1.3824636990733552e-09, disciminator loss fake = 5.033600132264837e-07, generator loss = 15.373235702514648\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 6, Batch: 82/468, discriminator loss real = 1.970159604035293e-13, disciminator loss fake = 4.073139336924214e-07, generator loss = 15.138195991516113\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 6, Batch: 83/468, discriminator loss real = 4.7470816340322575e-12, disciminator loss fake = 4.09124254474591e-07, generator loss = 15.204648971557617\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 6, Batch: 84/468, discriminator loss real = 8.220002456482689e-11, disciminator loss fake = 4.968398457094736e-07, generator loss = 15.079468727111816\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 6, Batch: 85/468, discriminator loss real = 1.7271036156785158e-08, disciminator loss fake = 3.212749675185478e-07, generator loss = 15.101081848144531\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 6, Batch: 86/468, discriminator loss real = 1.7995119283575889e-12, disciminator loss fake = 4.921276968161692e-07, generator loss = 15.314891815185547\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 6, Batch: 87/468, discriminator loss real = 4.0068998466424866e-12, disciminator loss fake = 5.07932156779134e-07, generator loss = 15.289579391479492\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 6, Batch: 88/468, discriminator loss real = 1.3768129865365797e-11, disciminator loss fake = 4.4712146518577356e-07, generator loss = 15.17869758605957\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 6, Batch: 89/468, discriminator loss real = 4.843824451782053e-13, disciminator loss fake = 4.746073045680532e-07, generator loss = 15.326629638671875\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 6, Batch: 90/468, discriminator loss real = 6.267562423917239e-13, disciminator loss fake = 4.439687018020777e-07, generator loss = 15.243330955505371\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 6, Batch: 91/468, discriminator loss real = 2.2699444754414877e-11, disciminator loss fake = 3.4484139632695587e-07, generator loss = 15.377135276794434\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 6, Batch: 92/468, discriminator loss real = 2.1596218857666827e-07, disciminator loss fake = 2.7108359290650696e-07, generator loss = 15.251201629638672\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 6, Batch: 93/468, discriminator loss real = 1.3851715781332263e-11, disciminator loss fake = 3.4404490634187823e-07, generator loss = 15.387864112854004\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 6, Batch: 94/468, discriminator loss real = 1.5419633625501916e-10, disciminator loss fake = 3.520641485010856e-07, generator loss = 15.287738800048828\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 6, Batch: 95/468, discriminator loss real = 6.305504349993912e-14, disciminator loss fake = 3.0167242925926985e-07, generator loss = 15.341842651367188\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 6, Batch: 96/468, discriminator loss real = 8.4546996959034e-08, disciminator loss fake = 3.5070689818894607e-07, generator loss = 15.45821762084961\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 6, Batch: 97/468, discriminator loss real = 4.9757992864885026e-12, disciminator loss fake = 3.8783889522164827e-07, generator loss = 15.295854568481445\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 6, Batch: 98/468, discriminator loss real = 2.442432256444249e-09, disciminator loss fake = 3.872078195854556e-07, generator loss = 15.256857872009277\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 6, Batch: 99/468, discriminator loss real = 5.483620827383129e-13, disciminator loss fake = 4.183941371138644e-07, generator loss = 15.477975845336914\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 6, Batch: 100/468, discriminator loss real = 9.518157746343792e-13, disciminator loss fake = 4.02661214593536e-07, generator loss = 15.322319030761719\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 6, Batch: 101/468, discriminator loss real = 1.3016645920849168e-11, disciminator loss fake = 5.28065356775187e-07, generator loss = 15.474729537963867\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 6, Batch: 102/468, discriminator loss real = 1.613146991985559e-06, disciminator loss fake = 3.240818955418945e-07, generator loss = 15.437023162841797\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 6, Batch: 103/468, discriminator loss real = 2.1846817432370769e-13, disciminator loss fake = 2.911669980676379e-07, generator loss = 15.34343433380127\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 6, Batch: 104/468, discriminator loss real = 1.5383801800120762e-16, disciminator loss fake = 2.9051699357296457e-07, generator loss = 15.524568557739258\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 6, Batch: 105/468, discriminator loss real = 7.314237757127806e-12, disciminator loss fake = 3.6886700627292157e-07, generator loss = 15.245950698852539\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 6, Batch: 106/468, discriminator loss real = 1.5719579096185043e-06, disciminator loss fake = 3.2109136327562737e-07, generator loss = 15.287015914916992\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 6, Batch: 107/468, discriminator loss real = 1.4847635450222947e-14, disciminator loss fake = 5.342169515643036e-07, generator loss = 15.231040954589844\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 6, Batch: 108/468, discriminator loss real = 1.2951225378601827e-12, disciminator loss fake = 4.168166469753487e-07, generator loss = 15.300660133361816\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 6, Batch: 109/468, discriminator loss real = 5.4420809763970623e-14, disciminator loss fake = 3.923339022549044e-07, generator loss = 15.327751159667969\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 6, Batch: 110/468, discriminator loss real = 8.136734663821699e-08, disciminator loss fake = 2.6270802777617064e-07, generator loss = 15.450202941894531\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 6, Batch: 111/468, discriminator loss real = 2.544734995386786e-16, disciminator loss fake = 2.6477954406800563e-07, generator loss = 15.235511779785156\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 6, Batch: 112/468, discriminator loss real = 1.2164768324607333e-11, disciminator loss fake = 3.984574163951038e-07, generator loss = 15.31842041015625\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 6, Batch: 113/468, discriminator loss real = 9.666073686907459e-14, disciminator loss fake = 2.942379921933025e-07, generator loss = 15.316080093383789\n",
      "2/2 [==============================] - 0s 35ms/step\n",
      "Epoch: 6, Batch: 114/468, discriminator loss real = 2.968101459055461e-11, disciminator loss fake = 4.404708420224779e-07, generator loss = 15.418790817260742\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 6, Batch: 115/468, discriminator loss real = 7.211674291594805e-13, disciminator loss fake = 2.676761710063147e-07, generator loss = 15.492304801940918\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 6, Batch: 116/468, discriminator loss real = 4.5365177356870845e-06, disciminator loss fake = 5.483959739649436e-07, generator loss = 15.369644165039062\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 6, Batch: 117/468, discriminator loss real = 2.2123167352423347e-14, disciminator loss fake = 3.484351793758833e-07, generator loss = 15.26304817199707\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 6, Batch: 118/468, discriminator loss real = 8.533400097654464e-10, disciminator loss fake = 2.583008722467639e-07, generator loss = 15.341720581054688\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 6, Batch: 119/468, discriminator loss real = 9.577057896725805e-12, disciminator loss fake = 3.237847181480902e-07, generator loss = 15.4337797164917\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 6, Batch: 120/468, discriminator loss real = 3.0222084058430243e-13, disciminator loss fake = 3.1425383895111736e-07, generator loss = 15.292831420898438\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 6, Batch: 121/468, discriminator loss real = 1.0516092337209404e-11, disciminator loss fake = 3.5478888094075955e-07, generator loss = 15.309263229370117\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 6, Batch: 122/468, discriminator loss real = 5.2599959977917e-12, disciminator loss fake = 3.8906654253878514e-07, generator loss = 15.469799041748047\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 6, Batch: 123/468, discriminator loss real = 5.4089571932536273e-08, disciminator loss fake = 2.5798868819038034e-07, generator loss = 15.37501335144043\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 6, Batch: 124/468, discriminator loss real = 6.734321433832235e-11, disciminator loss fake = 3.2079904599413567e-07, generator loss = 15.465219497680664\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 6, Batch: 125/468, discriminator loss real = 7.590067761581096e-14, disciminator loss fake = 4.677363278915436e-07, generator loss = 15.282855987548828\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 6, Batch: 126/468, discriminator loss real = 2.3504646579769473e-13, disciminator loss fake = 2.859271432953392e-07, generator loss = 15.32491683959961\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 6, Batch: 127/468, discriminator loss real = 1.613833233715667e-10, disciminator loss fake = 3.5443110846244963e-07, generator loss = 15.31251335144043\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 6, Batch: 128/468, discriminator loss real = 1.6393623958332881e-10, disciminator loss fake = 2.56421259337003e-07, generator loss = 15.22326374053955\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 6, Batch: 129/468, discriminator loss real = 2.9282075502123917e-06, disciminator loss fake = 3.6898376265526167e-07, generator loss = 15.362605094909668\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 6, Batch: 130/468, discriminator loss real = 6.78432693464557e-17, disciminator loss fake = 5.190186129766516e-07, generator loss = 15.286725997924805\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 6, Batch: 131/468, discriminator loss real = 3.2339859956653783e-12, disciminator loss fake = 3.6037607742400724e-07, generator loss = 15.374799728393555\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 6, Batch: 132/468, discriminator loss real = 2.798471232523525e-09, disciminator loss fake = 3.4704299878285383e-07, generator loss = 15.355040550231934\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 6, Batch: 133/468, discriminator loss real = 6.193317716042101e-15, disciminator loss fake = 3.003581241500797e-07, generator loss = 15.343008041381836\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 6, Batch: 134/468, discriminator loss real = 4.2498692282358363e-14, disciminator loss fake = 3.1018660706649825e-07, generator loss = 15.285067558288574\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 6, Batch: 135/468, discriminator loss real = 7.337924762396142e-05, disciminator loss fake = 4.3958658579867915e-07, generator loss = 15.14731216430664\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 6, Batch: 136/468, discriminator loss real = 1.1288718404500742e-08, disciminator loss fake = 3.9377039229293587e-07, generator loss = 14.759480476379395\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 6, Batch: 137/468, discriminator loss real = 7.701468802967515e-12, disciminator loss fake = 1.0008918707171688e-06, generator loss = 14.770976066589355\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 6, Batch: 138/468, discriminator loss real = 1.468441155338951e-07, disciminator loss fake = 7.745982202322921e-07, generator loss = 14.440681457519531\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 6, Batch: 139/468, discriminator loss real = 1.2601938589873463e-11, disciminator loss fake = 8.468707619613269e-07, generator loss = 14.512969017028809\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 6, Batch: 140/468, discriminator loss real = 3.4928396980271614e-11, disciminator loss fake = 1.8131177057512105e-06, generator loss = 14.215880393981934\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 6, Batch: 141/468, discriminator loss real = 7.0747119100544875e-12, disciminator loss fake = 2.456100446579512e-06, generator loss = 14.10659408569336\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 6, Batch: 142/468, discriminator loss real = 2.0278452528277313e-10, disciminator loss fake = 3.0949697702453705e-06, generator loss = 14.049379348754883\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 6, Batch: 143/468, discriminator loss real = 1.6266089846826563e-16, disciminator loss fake = 1.0082165999847348e-06, generator loss = 14.117742538452148\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 6, Batch: 144/468, discriminator loss real = 1.700989137741728e-19, disciminator loss fake = 2.0727547962451354e-06, generator loss = 14.064061164855957\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 6, Batch: 145/468, discriminator loss real = 2.752845174036622e-10, disciminator loss fake = 1.7240680563190836e-06, generator loss = 13.934459686279297\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 6, Batch: 146/468, discriminator loss real = 1.5211287091032588e-11, disciminator loss fake = 1.4793147329328349e-06, generator loss = 14.107385635375977\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 6, Batch: 147/468, discriminator loss real = 2.2286155126199914e-14, disciminator loss fake = 1.27805981264828e-06, generator loss = 14.181272506713867\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 6, Batch: 148/468, discriminator loss real = 1.7301495347510354e-08, disciminator loss fake = 1.8078054608849925e-06, generator loss = 14.02412223815918\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 6, Batch: 149/468, discriminator loss real = 1.6172113764790184e-14, disciminator loss fake = 1.4291896377471858e-06, generator loss = 14.129549026489258\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 6, Batch: 150/468, discriminator loss real = 1.8249239467672818e-13, disciminator loss fake = 1.6448909718747018e-06, generator loss = 14.13354206085205\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 6, Batch: 151/468, discriminator loss real = 5.041958170415306e-12, disciminator loss fake = 1.2242221600899938e-06, generator loss = 14.358560562133789\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 6, Batch: 152/468, discriminator loss real = 4.80213936852685e-15, disciminator loss fake = 1.8809093944582855e-06, generator loss = 14.193082809448242\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 6, Batch: 153/468, discriminator loss real = 1.2461175754457932e-12, disciminator loss fake = 1.3664867992702057e-06, generator loss = 14.244194030761719\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 6, Batch: 154/468, discriminator loss real = 2.2712462119378607e-11, disciminator loss fake = 1.2688448123299167e-06, generator loss = 14.461099624633789\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 6, Batch: 155/468, discriminator loss real = 4.196552827462341e-11, disciminator loss fake = 1.3499118267645827e-06, generator loss = 14.13003921508789\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 6, Batch: 156/468, discriminator loss real = 1.9220882663262273e-09, disciminator loss fake = 1.5143951941354317e-06, generator loss = 14.471041679382324\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 6, Batch: 157/468, discriminator loss real = 1.5115607333512915e-12, disciminator loss fake = 1.5586156223434955e-06, generator loss = 14.493379592895508\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 6, Batch: 158/468, discriminator loss real = 3.1522766168190497e-13, disciminator loss fake = 1.0475462204340147e-06, generator loss = 14.49934196472168\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 6, Batch: 159/468, discriminator loss real = 3.0372579451487525e-12, disciminator loss fake = 1.3253800261736615e-06, generator loss = 14.427818298339844\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 6, Batch: 160/468, discriminator loss real = 5.463524598015024e-13, disciminator loss fake = 1.0313461871191976e-06, generator loss = 14.454715728759766\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 6, Batch: 161/468, discriminator loss real = 7.863320590365333e-14, disciminator loss fake = 1.1938158195334836e-06, generator loss = 14.479984283447266\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 6, Batch: 162/468, discriminator loss real = 5.930981834129101e-12, disciminator loss fake = 7.822400220902637e-07, generator loss = 14.66151237487793\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 6, Batch: 163/468, discriminator loss real = 2.093466233699104e-10, disciminator loss fake = 9.292723461840069e-07, generator loss = 14.393940925598145\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 6, Batch: 164/468, discriminator loss real = 5.759111856027191e-14, disciminator loss fake = 1.0417086286906851e-06, generator loss = 14.678115844726562\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 6, Batch: 165/468, discriminator loss real = 3.5551509652842483e-13, disciminator loss fake = 1.1073429959651548e-06, generator loss = 14.726911544799805\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 6, Batch: 166/468, discriminator loss real = 3.5347511593078473e-13, disciminator loss fake = 8.956144483818207e-07, generator loss = 14.757125854492188\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 6, Batch: 167/468, discriminator loss real = 8.661550209704272e-14, disciminator loss fake = 7.501407708332408e-07, generator loss = 14.695131301879883\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 6, Batch: 168/468, discriminator loss real = 2.095875454796465e-15, disciminator loss fake = 8.671555633554817e-07, generator loss = 14.598936080932617\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 6, Batch: 169/468, discriminator loss real = 4.0584423842415784e-12, disciminator loss fake = 7.649483677596436e-07, generator loss = 14.856597900390625\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 6, Batch: 170/468, discriminator loss real = 3.1383305676424555e-11, disciminator loss fake = 6.201377118486562e-07, generator loss = 14.570223808288574\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 6, Batch: 171/468, discriminator loss real = 4.036107385807508e-12, disciminator loss fake = 7.493173370676232e-07, generator loss = 14.882614135742188\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 6, Batch: 172/468, discriminator loss real = 2.6032079053148194e-13, disciminator loss fake = 6.934939165148535e-07, generator loss = 14.791603088378906\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 6, Batch: 173/468, discriminator loss real = 5.730055915430937e-14, disciminator loss fake = 6.952030844331603e-07, generator loss = 14.742774963378906\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 6, Batch: 174/468, discriminator loss real = 9.670508751419282e-13, disciminator loss fake = 8.092483199106937e-07, generator loss = 14.74880599975586\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 6, Batch: 175/468, discriminator loss real = 8.382523841721223e-12, disciminator loss fake = 6.986595053604105e-07, generator loss = 14.93941879272461\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 6, Batch: 176/468, discriminator loss real = 3.2461311199813436e-14, disciminator loss fake = 6.702741188746586e-07, generator loss = 14.727546691894531\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 6, Batch: 177/468, discriminator loss real = 4.3514335608093105e-15, disciminator loss fake = 5.250519734545378e-07, generator loss = 14.801078796386719\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 6, Batch: 178/468, discriminator loss real = 1.069050230284585e-12, disciminator loss fake = 7.691131145293184e-07, generator loss = 14.871976852416992\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 6, Batch: 179/468, discriminator loss real = 1.5042632070527695e-11, disciminator loss fake = 5.292840796755627e-07, generator loss = 14.808963775634766\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 6, Batch: 180/468, discriminator loss real = 1.1313763814690958e-10, disciminator loss fake = 6.16756778981653e-07, generator loss = 14.903444290161133\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 6, Batch: 181/468, discriminator loss real = 1.7664379958759469e-09, disciminator loss fake = 6.709873332511052e-07, generator loss = 14.840534210205078\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 6, Batch: 182/468, discriminator loss real = 4.727632868517517e-11, disciminator loss fake = 5.100950488667877e-07, generator loss = 14.957048416137695\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 6, Batch: 183/468, discriminator loss real = 2.201335684917649e-12, disciminator loss fake = 4.6682808374498563e-07, generator loss = 14.96243667602539\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 6, Batch: 184/468, discriminator loss real = 1.4699480781893426e-12, disciminator loss fake = 6.91425668719603e-07, generator loss = 14.962886810302734\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 6, Batch: 185/468, discriminator loss real = 1.8063532406778406e-15, disciminator loss fake = 5.583718802881776e-07, generator loss = 14.965553283691406\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 6, Batch: 186/468, discriminator loss real = 3.9563443667012255e-12, disciminator loss fake = 5.086106966700754e-07, generator loss = 15.05982494354248\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 6, Batch: 187/468, discriminator loss real = 5.54981338662941e-11, disciminator loss fake = 5.527026587515138e-07, generator loss = 15.083945274353027\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 6, Batch: 188/468, discriminator loss real = 4.504689590095756e-12, disciminator loss fake = 4.2602141547831707e-07, generator loss = 14.992916107177734\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 6, Batch: 189/468, discriminator loss real = 5.884485585945802e-16, disciminator loss fake = 8.661695574119221e-07, generator loss = 15.113353729248047\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 6, Batch: 190/468, discriminator loss real = 7.851929662017199e-10, disciminator loss fake = 5.163475975678011e-07, generator loss = 15.19521713256836\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 6, Batch: 191/468, discriminator loss real = 1.1741054024741286e-14, disciminator loss fake = 4.172850651684712e-07, generator loss = 15.111322402954102\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 6, Batch: 192/468, discriminator loss real = 2.250298933859085e-07, disciminator loss fake = 4.855613155996252e-07, generator loss = 14.982768058776855\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 6, Batch: 193/468, discriminator loss real = 2.5879808448440057e-15, disciminator loss fake = 4.668776796279417e-07, generator loss = 15.024904251098633\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 6, Batch: 194/468, discriminator loss real = 1.9817754946416244e-05, disciminator loss fake = 4.898016072729661e-07, generator loss = 14.973423957824707\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 6, Batch: 195/468, discriminator loss real = 2.295746344316285e-05, disciminator loss fake = 6.138595836091554e-07, generator loss = 14.918726921081543\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 6, Batch: 196/468, discriminator loss real = 9.022635611734275e-14, disciminator loss fake = 9.325538030680036e-07, generator loss = 14.521690368652344\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 6, Batch: 197/468, discriminator loss real = 2.055504724762791e-11, disciminator loss fake = 1.0200078577327076e-06, generator loss = 14.44778060913086\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 6, Batch: 198/468, discriminator loss real = 2.6422403354891058e-14, disciminator loss fake = 8.405057769778068e-07, generator loss = 14.377402305603027\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 6, Batch: 199/468, discriminator loss real = 1.0448829301790141e-12, disciminator loss fake = 1.156753796749399e-06, generator loss = 14.230900764465332\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 6, Batch: 200/468, discriminator loss real = 6.839995692238532e-14, disciminator loss fake = 1.185005203296896e-06, generator loss = 14.226187705993652\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 6, Batch: 201/468, discriminator loss real = 3.0776597936821304e-10, disciminator loss fake = 1.753744982124772e-06, generator loss = 14.375789642333984\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 6, Batch: 202/468, discriminator loss real = 1.3857965990016208e-11, disciminator loss fake = 1.141551365435589e-06, generator loss = 14.003911972045898\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 6, Batch: 203/468, discriminator loss real = 2.8730394070888366e-16, disciminator loss fake = 1.1047324051105534e-06, generator loss = 14.30742073059082\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 6, Batch: 204/468, discriminator loss real = 3.2466493686197917e-13, disciminator loss fake = 1.2733578387269517e-06, generator loss = 14.098297119140625\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 6, Batch: 205/468, discriminator loss real = 3.9069861929030836e-11, disciminator loss fake = 1.4319836054710322e-06, generator loss = 14.235340118408203\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 6, Batch: 206/468, discriminator loss real = 3.71417069463479e-14, disciminator loss fake = 1.244051077264885e-06, generator loss = 14.134264945983887\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 6, Batch: 207/468, discriminator loss real = 6.899653832076252e-15, disciminator loss fake = 1.8005700894718757e-06, generator loss = 14.158719062805176\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 6, Batch: 208/468, discriminator loss real = 7.058172405913221e-14, disciminator loss fake = 1.2104719644412398e-06, generator loss = 14.151169776916504\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 6, Batch: 209/468, discriminator loss real = 2.1324064611522378e-14, disciminator loss fake = 1.204274667543359e-06, generator loss = 14.162031173706055\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 6, Batch: 210/468, discriminator loss real = 7.032499176095122e-14, disciminator loss fake = 9.985623137254152e-07, generator loss = 14.207633972167969\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 6, Batch: 211/468, discriminator loss real = 1.2036746111551005e-13, disciminator loss fake = 1.226479639626632e-06, generator loss = 14.454303741455078\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 6, Batch: 212/468, discriminator loss real = 3.459642782758371e-13, disciminator loss fake = 1.340678181804833e-06, generator loss = 14.37216854095459\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 6, Batch: 213/468, discriminator loss real = 1.993921995287022e-14, disciminator loss fake = 1.101372845369042e-06, generator loss = 14.235010147094727\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 6, Batch: 214/468, discriminator loss real = 1.3947476947241437e-18, disciminator loss fake = 8.878381549948244e-07, generator loss = 14.473060607910156\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 6, Batch: 215/468, discriminator loss real = 1.0370974912188302e-12, disciminator loss fake = 1.1714603260770673e-06, generator loss = 14.081275939941406\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 6, Batch: 216/468, discriminator loss real = 9.410113586312834e-16, disciminator loss fake = 6.478167620116437e-07, generator loss = 14.493152618408203\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 6, Batch: 217/468, discriminator loss real = 2.003832429847696e-12, disciminator loss fake = 1.0710646165534854e-06, generator loss = 14.418892860412598\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 6, Batch: 218/468, discriminator loss real = 9.048138215235479e-13, disciminator loss fake = 8.434926712652668e-07, generator loss = 14.423734664916992\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 6, Batch: 219/468, discriminator loss real = 9.761027266140792e-15, disciminator loss fake = 1.0897011861743522e-06, generator loss = 14.562080383300781\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 6, Batch: 220/468, discriminator loss real = 1.810138350322177e-08, disciminator loss fake = 9.001703915600956e-07, generator loss = 14.66794490814209\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 6, Batch: 221/468, discriminator loss real = 2.310800536041587e-15, disciminator loss fake = 8.753158340368827e-07, generator loss = 14.414530754089355\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 6, Batch: 222/468, discriminator loss real = 7.369663039547003e-12, disciminator loss fake = 7.080813020365895e-07, generator loss = 14.673583984375\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 6, Batch: 223/468, discriminator loss real = 1.7251335383545834e-14, disciminator loss fake = 4.876710590906441e-07, generator loss = 14.74468994140625\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 6, Batch: 224/468, discriminator loss real = 3.849813195555378e-14, disciminator loss fake = 7.669087835893151e-07, generator loss = 14.679682731628418\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 6, Batch: 225/468, discriminator loss real = 1.005829940821032e-13, disciminator loss fake = 9.24290475268208e-07, generator loss = 14.684270858764648\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 6, Batch: 226/468, discriminator loss real = 1.8433676487366116e-14, disciminator loss fake = 1.0662037084330223e-06, generator loss = 14.73122787475586\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 6, Batch: 227/468, discriminator loss real = 2.287183300826029e-13, disciminator loss fake = 8.563344522372063e-07, generator loss = 14.745697975158691\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 6, Batch: 228/468, discriminator loss real = 2.472922582853754e-13, disciminator loss fake = 7.402816777357657e-07, generator loss = 14.549741744995117\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 6, Batch: 229/468, discriminator loss real = 4.706544876054153e-11, disciminator loss fake = 5.71285568184976e-07, generator loss = 14.901976585388184\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 6, Batch: 230/468, discriminator loss real = 2.110212354314026e-17, disciminator loss fake = 6.706377462251112e-07, generator loss = 14.69760799407959\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 6, Batch: 231/468, discriminator loss real = 2.2219893432802104e-14, disciminator loss fake = 7.787767231093312e-07, generator loss = 14.884057998657227\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 6, Batch: 232/468, discriminator loss real = 2.3642602158262423e-14, disciminator loss fake = 6.660796429969196e-07, generator loss = 14.784845352172852\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 6, Batch: 233/468, discriminator loss real = 1.5358475938514332e-13, disciminator loss fake = 6.706404178657976e-07, generator loss = 14.760744094848633\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 6, Batch: 234/468, discriminator loss real = 1.4573059555975099e-13, disciminator loss fake = 5.125424991092586e-07, generator loss = 14.832998275756836\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 6, Batch: 235/468, discriminator loss real = 7.177058860413643e-12, disciminator loss fake = 7.744707772872061e-07, generator loss = 14.701045989990234\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 6, Batch: 236/468, discriminator loss real = 1.0688648188761363e-08, disciminator loss fake = 6.395715672624647e-07, generator loss = 14.887776374816895\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 6, Batch: 237/468, discriminator loss real = 2.146476779548963e-15, disciminator loss fake = 5.951482080490678e-07, generator loss = 14.899401664733887\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 6, Batch: 238/468, discriminator loss real = 3.371210255398438e-11, disciminator loss fake = 5.817918236061814e-07, generator loss = 14.999443054199219\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 6, Batch: 239/468, discriminator loss real = 1.42290815089742e-13, disciminator loss fake = 4.6448201374005293e-07, generator loss = 14.98735237121582\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 6, Batch: 240/468, discriminator loss real = 1.3957913736492925e-14, disciminator loss fake = 5.086993724034983e-07, generator loss = 14.904874801635742\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 6, Batch: 241/468, discriminator loss real = 1.9778668245849958e-14, disciminator loss fake = 3.741857881323085e-07, generator loss = 14.82443618774414\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 6, Batch: 242/468, discriminator loss real = 3.8359255008502124e-12, disciminator loss fake = 6.26962673777598e-07, generator loss = 14.99934196472168\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 6, Batch: 243/468, discriminator loss real = 5.08827147083224e-10, disciminator loss fake = 6.652273896179395e-07, generator loss = 14.917367935180664\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 6, Batch: 244/468, discriminator loss real = 5.552246488092771e-13, disciminator loss fake = 5.824190907333104e-07, generator loss = 14.898590087890625\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 6, Batch: 245/468, discriminator loss real = 1.5862909130779507e-13, disciminator loss fake = 5.01860711210611e-07, generator loss = 14.901241302490234\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 6, Batch: 246/468, discriminator loss real = 6.466757684897573e-11, disciminator loss fake = 5.100564521853812e-07, generator loss = 14.860288619995117\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 6, Batch: 247/468, discriminator loss real = 3.507190371454527e-11, disciminator loss fake = 5.249915489002888e-07, generator loss = 15.040307998657227\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 6, Batch: 248/468, discriminator loss real = 1.3143145451977034e-06, disciminator loss fake = 4.329951366344176e-07, generator loss = 15.005521774291992\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 6, Batch: 249/468, discriminator loss real = 1.0759551236083631e-11, disciminator loss fake = 4.6635491912638827e-07, generator loss = 15.005071640014648\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 6, Batch: 250/468, discriminator loss real = 3.5957434946221056e-11, disciminator loss fake = 4.2771563357746345e-07, generator loss = 15.132424354553223\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 6, Batch: 251/468, discriminator loss real = 8.477904142600856e-12, disciminator loss fake = 5.827787958878616e-07, generator loss = 15.121464729309082\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 6, Batch: 252/468, discriminator loss real = 1.5625932839324896e-11, disciminator loss fake = 4.2966553337464575e-07, generator loss = 14.99980354309082\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 6, Batch: 253/468, discriminator loss real = 2.1149412082754893e-11, disciminator loss fake = 4.295615383398399e-07, generator loss = 14.977558135986328\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 6, Batch: 254/468, discriminator loss real = 1.0260421852426038e-11, disciminator loss fake = 5.150513970875181e-07, generator loss = 15.013912200927734\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 6, Batch: 255/468, discriminator loss real = 5.012567763613236e-15, disciminator loss fake = 4.214859927742509e-07, generator loss = 15.07271957397461\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 6, Batch: 256/468, discriminator loss real = 1.5688958378973217e-13, disciminator loss fake = 4.330042315814353e-07, generator loss = 14.95820140838623\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 6, Batch: 257/468, discriminator loss real = 2.023593898242519e-15, disciminator loss fake = 5.201364956519683e-07, generator loss = 15.130126953125\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 6, Batch: 258/468, discriminator loss real = 1.4020789737556605e-11, disciminator loss fake = 4.276095637578692e-07, generator loss = 15.262945175170898\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 6, Batch: 259/468, discriminator loss real = 1.4033059111441537e-13, disciminator loss fake = 4.6561100930375687e-07, generator loss = 15.163095474243164\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 6, Batch: 260/468, discriminator loss real = 1.7659537027148176e-11, disciminator loss fake = 4.099140937796619e-07, generator loss = 15.301065444946289\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 6, Batch: 261/468, discriminator loss real = 4.911759434414966e-17, disciminator loss fake = 3.306186044937931e-07, generator loss = 15.224000930786133\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 6, Batch: 262/468, discriminator loss real = 3.230899815875464e-15, disciminator loss fake = 5.439425194708747e-07, generator loss = 15.274826049804688\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 6, Batch: 263/468, discriminator loss real = 1.7727671137697867e-14, disciminator loss fake = 4.795723498318694e-07, generator loss = 15.171802520751953\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 6, Batch: 264/468, discriminator loss real = 2.13552279700914e-13, disciminator loss fake = 4.914601845484867e-07, generator loss = 15.16822338104248\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 6, Batch: 265/468, discriminator loss real = 7.044277270870647e-13, disciminator loss fake = 4.86888666273444e-07, generator loss = 15.188255310058594\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 6, Batch: 266/468, discriminator loss real = 3.6326231058576505e-14, disciminator loss fake = 2.7785173983829736e-07, generator loss = 15.240321159362793\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 6, Batch: 267/468, discriminator loss real = 5.2788159260463985e-11, disciminator loss fake = 5.55009933123074e-07, generator loss = 15.101764678955078\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 6, Batch: 268/468, discriminator loss real = 6.022924026183318e-07, disciminator loss fake = 4.140929945606331e-07, generator loss = 15.214664459228516\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 6, Batch: 269/468, discriminator loss real = 9.531611611102164e-14, disciminator loss fake = 4.573722378609091e-07, generator loss = 15.205022811889648\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 6, Batch: 270/468, discriminator loss real = 3.020491431942457e-16, disciminator loss fake = 3.9399276374751935e-07, generator loss = 15.258180618286133\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 6, Batch: 271/468, discriminator loss real = 9.812597782932198e-12, disciminator loss fake = 3.490620485990803e-07, generator loss = 15.196410179138184\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 6, Batch: 272/468, discriminator loss real = 7.230894748187756e-16, disciminator loss fake = 4.207485915230791e-07, generator loss = 15.020641326904297\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 6, Batch: 273/468, discriminator loss real = 3.4643024126451705e-14, disciminator loss fake = 3.480120653875929e-07, generator loss = 15.192560195922852\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 6, Batch: 274/468, discriminator loss real = 2.7556724263577692e-11, disciminator loss fake = 3.350415056502243e-07, generator loss = 15.316414833068848\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 6, Batch: 275/468, discriminator loss real = 1.1528270742536262e-12, disciminator loss fake = 3.7075611203363223e-07, generator loss = 15.332155227661133\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 6, Batch: 276/468, discriminator loss real = 8.710495436048404e-09, disciminator loss fake = 3.8489332609970006e-07, generator loss = 15.183393478393555\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 6, Batch: 277/468, discriminator loss real = 8.075745475989715e-13, disciminator loss fake = 3.749510142370127e-07, generator loss = 15.18231201171875\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 6, Batch: 278/468, discriminator loss real = 1.154104936618161e-10, disciminator loss fake = 3.447520384725067e-07, generator loss = 15.343724250793457\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 6, Batch: 279/468, discriminator loss real = 8.835052481281913e-12, disciminator loss fake = 3.554448539944133e-07, generator loss = 15.321617126464844\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 6, Batch: 280/468, discriminator loss real = 3.3291649551193828e-15, disciminator loss fake = 5.303258490130247e-07, generator loss = 15.262359619140625\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 6, Batch: 281/468, discriminator loss real = 2.7000920943542894e-10, disciminator loss fake = 3.5701836509360874e-07, generator loss = 15.332152366638184\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 6, Batch: 282/468, discriminator loss real = 2.6513287978428195e-16, disciminator loss fake = 3.869445208692923e-07, generator loss = 15.255996704101562\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 6, Batch: 283/468, discriminator loss real = 2.9690611080823714e-10, disciminator loss fake = 3.771972387767164e-07, generator loss = 15.424939155578613\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 6, Batch: 284/468, discriminator loss real = 2.5636244124457083e-15, disciminator loss fake = 3.4890675237875257e-07, generator loss = 15.177206039428711\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 6, Batch: 285/468, discriminator loss real = 9.359262768005722e-14, disciminator loss fake = 3.565330644050846e-07, generator loss = 15.238231658935547\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 6, Batch: 286/468, discriminator loss real = 1.0158283719405303e-12, disciminator loss fake = 3.5256340424894006e-07, generator loss = 15.422012329101562\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 6, Batch: 287/468, discriminator loss real = 6.824075193812007e-10, disciminator loss fake = 3.772901777665538e-07, generator loss = 15.417675018310547\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 6, Batch: 288/468, discriminator loss real = 2.2975874675035257e-12, disciminator loss fake = 4.143550427215814e-07, generator loss = 15.408266067504883\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 6, Batch: 289/468, discriminator loss real = 1.4769790208576938e-12, disciminator loss fake = 3.347320216562366e-07, generator loss = 15.308019638061523\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 6, Batch: 290/468, discriminator loss real = 1.185383215196456e-11, disciminator loss fake = 3.708362044108071e-07, generator loss = 15.256455421447754\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 6, Batch: 291/468, discriminator loss real = 1.7245009240052234e-11, disciminator loss fake = 3.259206664552039e-07, generator loss = 15.50657844543457\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 6, Batch: 292/468, discriminator loss real = 1.1636563357342311e-07, disciminator loss fake = 2.663899181243323e-07, generator loss = 15.336433410644531\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 6, Batch: 293/468, discriminator loss real = 4.624454031515457e-13, disciminator loss fake = 2.757247443696542e-07, generator loss = 15.526667594909668\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 6, Batch: 294/468, discriminator loss real = 7.756603248153943e-14, disciminator loss fake = 3.3162663726216124e-07, generator loss = 15.4784574508667\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 6, Batch: 295/468, discriminator loss real = 9.729713779452198e-13, disciminator loss fake = 3.1497381769440835e-07, generator loss = 15.322835922241211\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 6, Batch: 296/468, discriminator loss real = 2.2136312964951554e-13, disciminator loss fake = 2.649343855409825e-07, generator loss = 15.311819076538086\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 6, Batch: 297/468, discriminator loss real = 4.057363033873815e-14, disciminator loss fake = 2.6156993726544897e-07, generator loss = 15.489277839660645\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 6, Batch: 298/468, discriminator loss real = 7.435754789675286e-10, disciminator loss fake = 3.283198282133526e-07, generator loss = 15.499631881713867\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 6, Batch: 299/468, discriminator loss real = 7.042289521712666e-15, disciminator loss fake = 3.1448632853425806e-07, generator loss = 15.601631164550781\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 6, Batch: 300/468, discriminator loss real = 1.0441799334903745e-12, disciminator loss fake = 3.692917118769401e-07, generator loss = 15.51835823059082\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 6, Batch: 301/468, discriminator loss real = 1.3332098690007135e-14, disciminator loss fake = 2.526614082398737e-07, generator loss = 15.338306427001953\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 6, Batch: 302/468, discriminator loss real = 1.4177489748596478e-13, disciminator loss fake = 2.792837108245294e-07, generator loss = 15.513513565063477\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 6, Batch: 303/468, discriminator loss real = 3.870515358412631e-14, disciminator loss fake = 2.6931903107652033e-07, generator loss = 15.342489242553711\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 6, Batch: 304/468, discriminator loss real = 1.5115368809034968e-12, disciminator loss fake = 2.84822959883968e-07, generator loss = 15.485025405883789\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 6, Batch: 305/468, discriminator loss real = 9.203652284739405e-10, disciminator loss fake = 3.348998802721326e-07, generator loss = 15.61195182800293\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 6, Batch: 306/468, discriminator loss real = 4.7507248921449877e-14, disciminator loss fake = 2.611658374007675e-07, generator loss = 15.48042106628418\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 6, Batch: 307/468, discriminator loss real = 2.3999322494583364e-12, disciminator loss fake = 3.3881704553095915e-07, generator loss = 15.396929740905762\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 6, Batch: 308/468, discriminator loss real = 1.0094542931583794e-13, disciminator loss fake = 2.7990415674139513e-07, generator loss = 15.542118072509766\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 6, Batch: 309/468, discriminator loss real = 6.835775689392016e-15, disciminator loss fake = 3.042871128400293e-07, generator loss = 15.399097442626953\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 6, Batch: 310/468, discriminator loss real = 2.2486898387796828e-07, disciminator loss fake = 2.5749613996595144e-07, generator loss = 15.651156425476074\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 6, Batch: 311/468, discriminator loss real = 2.008330134140035e-12, disciminator loss fake = 3.4084115441146423e-07, generator loss = 15.508794784545898\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 6, Batch: 312/468, discriminator loss real = 1.0189787381931215e-12, disciminator loss fake = 2.3432559714819945e-07, generator loss = 15.608450889587402\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 6, Batch: 313/468, discriminator loss real = 2.432457846257563e-10, disciminator loss fake = 3.029831532330718e-07, generator loss = 15.32131576538086\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 6, Batch: 314/468, discriminator loss real = 6.130975879365948e-16, disciminator loss fake = 2.965798557852395e-07, generator loss = 15.670438766479492\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 6, Batch: 315/468, discriminator loss real = 3.409090718053953e-12, disciminator loss fake = 2.098995537380688e-07, generator loss = 15.543280601501465\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 6, Batch: 316/468, discriminator loss real = 9.293157606296565e-13, disciminator loss fake = 3.538675059644447e-07, generator loss = 15.633398056030273\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 6, Batch: 317/468, discriminator loss real = 2.395407141956088e-14, disciminator loss fake = 2.442872641950089e-07, generator loss = 15.532224655151367\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 6, Batch: 318/468, discriminator loss real = 4.100939694166167e-13, disciminator loss fake = 2.7344032105247607e-07, generator loss = 15.679817199707031\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 6, Batch: 319/468, discriminator loss real = 7.618435802214663e-07, disciminator loss fake = 3.575175355763349e-07, generator loss = 15.543938636779785\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 6, Batch: 320/468, discriminator loss real = 3.2905007386375973e-13, disciminator loss fake = 4.114461944482173e-07, generator loss = 15.563411712646484\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 6, Batch: 321/468, discriminator loss real = 1.051325435670776e-13, disciminator loss fake = 2.6373390937806107e-07, generator loss = 15.403270721435547\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 6, Batch: 322/468, discriminator loss real = 1.702782879975384e-14, disciminator loss fake = 3.706372808665037e-07, generator loss = 15.487885475158691\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 6, Batch: 323/468, discriminator loss real = 1.1356776352395691e-15, disciminator loss fake = 2.7937113600273733e-07, generator loss = 15.66948413848877\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 6, Batch: 324/468, discriminator loss real = 6.851780809391528e-10, disciminator loss fake = 2.3285170414055756e-07, generator loss = 15.582303047180176\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 6, Batch: 325/468, discriminator loss real = 2.731674331180045e-10, disciminator loss fake = 2.631928737173439e-07, generator loss = 15.461132049560547\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 6, Batch: 326/468, discriminator loss real = 7.091573855921851e-11, disciminator loss fake = 2.623200714424456e-07, generator loss = 15.600421905517578\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 6, Batch: 327/468, discriminator loss real = 7.309844359860724e-15, disciminator loss fake = 2.807294663398352e-07, generator loss = 15.451078414916992\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 6, Batch: 328/468, discriminator loss real = 2.9717164059389622e-12, disciminator loss fake = 2.423916782845481e-07, generator loss = 15.562139511108398\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 6, Batch: 329/468, discriminator loss real = 1.5871446518156418e-11, disciminator loss fake = 2.9656524702659226e-07, generator loss = 15.647600173950195\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 6, Batch: 330/468, discriminator loss real = 1.2749493127905964e-10, disciminator loss fake = 2.2987489955994533e-07, generator loss = 15.507314682006836\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 6, Batch: 331/468, discriminator loss real = 4.670375197690646e-11, disciminator loss fake = 3.0670597084281326e-07, generator loss = 15.744058609008789\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 6, Batch: 332/468, discriminator loss real = 1.5811042796201602e-12, disciminator loss fake = 2.2561275159205252e-07, generator loss = 15.571599006652832\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 6, Batch: 333/468, discriminator loss real = 3.928611654198909e-15, disciminator loss fake = 2.1398093963398424e-07, generator loss = 15.679893493652344\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 6, Batch: 334/468, discriminator loss real = 6.184157901750493e-15, disciminator loss fake = 2.2885591022259177e-07, generator loss = 15.706596374511719\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 6, Batch: 335/468, discriminator loss real = 2.410239163200961e-13, disciminator loss fake = 2.433031909276906e-07, generator loss = 15.523638725280762\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 6, Batch: 336/468, discriminator loss real = 1.7638730103256006e-12, disciminator loss fake = 2.5999992203651345e-07, generator loss = 15.645872116088867\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 6, Batch: 337/468, discriminator loss real = 1.3380637743642954e-11, disciminator loss fake = 1.9570457254758367e-07, generator loss = 15.415044784545898\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 6, Batch: 338/468, discriminator loss real = 4.485162019562949e-09, disciminator loss fake = 2.946718211660482e-07, generator loss = 15.749491691589355\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 6, Batch: 339/468, discriminator loss real = 5.250668436929118e-06, disciminator loss fake = 2.3549202410322323e-07, generator loss = 15.589094161987305\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 6, Batch: 340/468, discriminator loss real = 1.972828705953944e-10, disciminator loss fake = 2.477641487530491e-07, generator loss = 15.632783889770508\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 6, Batch: 341/468, discriminator loss real = 1.815661370438513e-14, disciminator loss fake = 2.9943640811325167e-07, generator loss = 15.560420036315918\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 6, Batch: 342/468, discriminator loss real = 4.3971302154943714e-09, disciminator loss fake = 2.984048705911846e-07, generator loss = 15.591596603393555\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 6, Batch: 343/468, discriminator loss real = 2.146229027832902e-11, disciminator loss fake = 2.5891790755849797e-07, generator loss = 15.7445068359375\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 6, Batch: 344/468, discriminator loss real = 5.681110857727676e-16, disciminator loss fake = 2.3630470025182149e-07, generator loss = 15.563101768493652\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 6, Batch: 345/468, discriminator loss real = 3.485031816082007e-13, disciminator loss fake = 2.2147116851556348e-07, generator loss = 15.511457443237305\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 6, Batch: 346/468, discriminator loss real = 6.978793931633476e-11, disciminator loss fake = 3.5640945839077176e-07, generator loss = 15.552774429321289\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 6, Batch: 347/468, discriminator loss real = 3.9282054171974057e-13, disciminator loss fake = 3.2775199088064255e-07, generator loss = 15.55441951751709\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 6, Batch: 348/468, discriminator loss real = 1.2117292724767026e-09, disciminator loss fake = 2.1977734832034912e-07, generator loss = 15.502023696899414\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 6, Batch: 349/468, discriminator loss real = 4.7505129170677396e-12, disciminator loss fake = 2.8197561618981126e-07, generator loss = 15.587881088256836\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 6, Batch: 350/468, discriminator loss real = 1.6049519569252824e-12, disciminator loss fake = 2.508322722860612e-07, generator loss = 15.57861328125\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 6, Batch: 351/468, discriminator loss real = 8.207320240094518e-12, disciminator loss fake = 2.9904487064413843e-07, generator loss = 15.58557415008545\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 6, Batch: 352/468, discriminator loss real = 1.1271951931958804e-13, disciminator loss fake = 2.431150960546802e-07, generator loss = 15.640501022338867\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 6, Batch: 353/468, discriminator loss real = 4.592327020503002e-14, disciminator loss fake = 2.6412567422084976e-07, generator loss = 15.524980545043945\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 6, Batch: 354/468, discriminator loss real = 7.543983883764871e-13, disciminator loss fake = 3.7955203424644424e-07, generator loss = 15.580246925354004\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 6, Batch: 355/468, discriminator loss real = 2.641121522872769e-11, disciminator loss fake = 2.898902380366053e-07, generator loss = 15.598766326904297\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 6, Batch: 356/468, discriminator loss real = 1.9113096622723824e-17, disciminator loss fake = 2.4412270249740686e-07, generator loss = 15.63215446472168\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 6, Batch: 357/468, discriminator loss real = 4.865530645048466e-09, disciminator loss fake = 2.604514008908154e-07, generator loss = 15.679155349731445\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 6, Batch: 358/468, discriminator loss real = 2.661267295422931e-08, disciminator loss fake = 2.4607840032331296e-07, generator loss = 15.527222633361816\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 6, Batch: 359/468, discriminator loss real = 5.961665080871092e-13, disciminator loss fake = 2.5032801431734697e-07, generator loss = 15.501846313476562\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 6, Batch: 360/468, discriminator loss real = 5.812472432957017e-16, disciminator loss fake = 2.424773981601902e-07, generator loss = 15.756814002990723\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 6, Batch: 361/468, discriminator loss real = 7.7361832495626e-09, disciminator loss fake = 2.2871989813211258e-07, generator loss = 15.535404205322266\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 6, Batch: 362/468, discriminator loss real = 1.4153624761092942e-07, disciminator loss fake = 2.2111480291187036e-07, generator loss = 15.588801383972168\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 6, Batch: 363/468, discriminator loss real = 6.290824805521567e-11, disciminator loss fake = 2.063160877696646e-07, generator loss = 15.786109924316406\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 6, Batch: 364/468, discriminator loss real = 2.3921245539959557e-10, disciminator loss fake = 2.2613252781411575e-07, generator loss = 15.648908615112305\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 6, Batch: 365/468, discriminator loss real = 3.298479545055244e-11, disciminator loss fake = 2.504785356904904e-07, generator loss = 15.775489807128906\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 6, Batch: 366/468, discriminator loss real = 5.891005998986953e-13, disciminator loss fake = 2.2026621593340678e-07, generator loss = 15.595781326293945\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 6, Batch: 367/468, discriminator loss real = 6.291352161458263e-11, disciminator loss fake = 2.981289242143248e-07, generator loss = 15.500144958496094\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 6, Batch: 368/468, discriminator loss real = 3.228645432604149e-12, disciminator loss fake = 2.8475562885432737e-07, generator loss = 15.6459321975708\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 6, Batch: 369/468, discriminator loss real = 5.579020580626093e-06, disciminator loss fake = 2.6550918619250297e-07, generator loss = 15.744725227355957\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 6, Batch: 370/468, discriminator loss real = 3.50931308701173e-17, disciminator loss fake = 2.0883591389520006e-07, generator loss = 15.793075561523438\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 6, Batch: 371/468, discriminator loss real = 4.430961240281528e-12, disciminator loss fake = 2.7816525971502415e-07, generator loss = 15.534082412719727\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 6, Batch: 372/468, discriminator loss real = 4.230933381421664e-09, disciminator loss fake = 2.0724309024444665e-07, generator loss = 15.615074157714844\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 6, Batch: 373/468, discriminator loss real = 7.387395382918438e-12, disciminator loss fake = 3.3212666039617034e-07, generator loss = 15.50601863861084\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 6, Batch: 374/468, discriminator loss real = 3.783068476537199e-12, disciminator loss fake = 2.8396419793352834e-07, generator loss = 15.417784690856934\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 6, Batch: 375/468, discriminator loss real = 2.427374967695073e-10, disciminator loss fake = 2.490099859642214e-07, generator loss = 15.437347412109375\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 6, Batch: 376/468, discriminator loss real = 4.625855254403177e-10, disciminator loss fake = 2.178456668389117e-07, generator loss = 15.543657302856445\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 6, Batch: 377/468, discriminator loss real = 4.959973200929259e-14, disciminator loss fake = 2.3360718159892713e-07, generator loss = 15.450395584106445\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 6, Batch: 378/468, discriminator loss real = 5.619309462190358e-10, disciminator loss fake = 2.5955355908990896e-07, generator loss = 15.685504913330078\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 6, Batch: 379/468, discriminator loss real = 3.140831837978599e-15, disciminator loss fake = 2.784391313070955e-07, generator loss = 15.54791259765625\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 6, Batch: 380/468, discriminator loss real = 8.093703387623136e-14, disciminator loss fake = 2.67700954736938e-07, generator loss = 15.534795761108398\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 6, Batch: 381/468, discriminator loss real = 7.648106120313782e-15, disciminator loss fake = 2.514188395252859e-07, generator loss = 15.540131568908691\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 6, Batch: 382/468, discriminator loss real = 3.602987908024602e-09, disciminator loss fake = 2.642757408466423e-07, generator loss = 15.652481079101562\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 6, Batch: 383/468, discriminator loss real = 3.162437488529041e-14, disciminator loss fake = 1.9326296296640066e-07, generator loss = 15.5426664352417\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 6, Batch: 384/468, discriminator loss real = 6.021053237427205e-15, disciminator loss fake = 2.9223400588307413e-07, generator loss = 15.647912979125977\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 6, Batch: 385/468, discriminator loss real = 1.3230159155719345e-11, disciminator loss fake = 2.3310542474064277e-07, generator loss = 15.560368537902832\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 6, Batch: 386/468, discriminator loss real = 1.920436804915028e-14, disciminator loss fake = 2.6378145889793814e-07, generator loss = 15.414795875549316\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 6, Batch: 387/468, discriminator loss real = 6.927452101540554e-12, disciminator loss fake = 2.6791252594193793e-07, generator loss = 15.570871353149414\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 6, Batch: 388/468, discriminator loss real = 6.992785517301314e-11, disciminator loss fake = 2.7698393978425884e-07, generator loss = 15.647064208984375\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 6, Batch: 389/468, discriminator loss real = 1.9240214754745466e-08, disciminator loss fake = 2.37068363162507e-07, generator loss = 15.549757957458496\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 6, Batch: 390/468, discriminator loss real = 1.647293998985333e-07, disciminator loss fake = 2.3362075296518015e-07, generator loss = 15.500797271728516\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 6, Batch: 391/468, discriminator loss real = 2.298678224016957e-15, disciminator loss fake = 3.207257179838052e-07, generator loss = 15.646620750427246\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 6, Batch: 392/468, discriminator loss real = 1.3812938502151524e-17, disciminator loss fake = 3.2705696639823145e-07, generator loss = 15.446073532104492\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 6, Batch: 393/468, discriminator loss real = 6.029710584998238e-12, disciminator loss fake = 2.530142637624522e-07, generator loss = 15.721023559570312\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 6, Batch: 394/468, discriminator loss real = 1.1067575892212411e-12, disciminator loss fake = 2.429077028409665e-07, generator loss = 15.52861213684082\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 6, Batch: 395/468, discriminator loss real = 2.024114383047948e-12, disciminator loss fake = 2.542565482599457e-07, generator loss = 15.603013038635254\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 6, Batch: 396/468, discriminator loss real = 1.2046575958990502e-09, disciminator loss fake = 1.9984264554295805e-07, generator loss = 15.539085388183594\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 6, Batch: 397/468, discriminator loss real = 4.4037961211690346e-14, disciminator loss fake = 2.255194431199925e-07, generator loss = 15.578641891479492\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 6, Batch: 398/468, discriminator loss real = 1.2276772480557252e-11, disciminator loss fake = 2.399034997324634e-07, generator loss = 15.591728210449219\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 6, Batch: 399/468, discriminator loss real = 2.232463752705957e-15, disciminator loss fake = 2.2578075231649564e-07, generator loss = 15.743881225585938\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 6, Batch: 400/468, discriminator loss real = 7.557996108406909e-16, disciminator loss fake = 2.917344090747065e-07, generator loss = 15.62519645690918\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 6, Batch: 401/468, discriminator loss real = 1.1371267425938636e-12, disciminator loss fake = 2.1478388134710258e-07, generator loss = 15.694141387939453\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 6, Batch: 402/468, discriminator loss real = 6.390343549461663e-12, disciminator loss fake = 2.1232418134786712e-07, generator loss = 15.666994094848633\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 6, Batch: 403/468, discriminator loss real = 3.968251750574116e-17, disciminator loss fake = 2.6174387812716304e-07, generator loss = 15.72872543334961\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 6, Batch: 404/468, discriminator loss real = 2.1042836798133152e-13, disciminator loss fake = 2.6960145760313026e-07, generator loss = 15.654317855834961\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 6, Batch: 405/468, discriminator loss real = 1.7477070138327555e-11, disciminator loss fake = 2.243101704380024e-07, generator loss = 15.80250072479248\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 6, Batch: 406/468, discriminator loss real = 1.2480637666262826e-15, disciminator loss fake = 2.9072114671180316e-07, generator loss = 15.679081916809082\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 6, Batch: 407/468, discriminator loss real = 8.683696123279461e-11, disciminator loss fake = 2.508434704395768e-07, generator loss = 15.694124221801758\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 6, Batch: 408/468, discriminator loss real = 2.781173034926976e-11, disciminator loss fake = 2.0662550070937868e-07, generator loss = 15.810931205749512\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 6, Batch: 409/468, discriminator loss real = 8.483860823875391e-15, disciminator loss fake = 1.8792420064528415e-07, generator loss = 15.703157424926758\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 6, Batch: 410/468, discriminator loss real = 5.84246798720166e-17, disciminator loss fake = 2.363398721172416e-07, generator loss = 15.811980247497559\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 6, Batch: 411/468, discriminator loss real = 2.3623240516523758e-11, disciminator loss fake = 2.6876946890297404e-07, generator loss = 15.703022003173828\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 6, Batch: 412/468, discriminator loss real = 4.8137236384471205e-12, disciminator loss fake = 2.3117252112569986e-07, generator loss = 15.712004661560059\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 6, Batch: 413/468, discriminator loss real = 2.7436276381766038e-14, disciminator loss fake = 2.098193476740562e-07, generator loss = 15.783343315124512\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 6, Batch: 414/468, discriminator loss real = 1.8277253321929976e-10, disciminator loss fake = 2.5853995566649246e-07, generator loss = 15.832597732543945\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 6, Batch: 415/468, discriminator loss real = 1.37675000523238e-13, disciminator loss fake = 2.51339145052043e-07, generator loss = 15.669645309448242\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 6, Batch: 416/468, discriminator loss real = 1.6585875468183575e-13, disciminator loss fake = 1.9890944713552017e-07, generator loss = 15.72289752960205\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 6, Batch: 417/468, discriminator loss real = 2.208958385131743e-13, disciminator loss fake = 2.1333956112812302e-07, generator loss = 15.879779815673828\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 6, Batch: 418/468, discriminator loss real = 7.797853527335974e-07, disciminator loss fake = 2.767035596207279e-07, generator loss = 15.777393341064453\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 6, Batch: 419/468, discriminator loss real = 2.7352827034615723e-12, disciminator loss fake = 2.1950822315375262e-07, generator loss = 15.761467933654785\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 6, Batch: 420/468, discriminator loss real = 1.2831046175641042e-13, disciminator loss fake = 1.905446822547674e-07, generator loss = 15.69289779663086\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 6, Batch: 421/468, discriminator loss real = 1.2691513421800305e-13, disciminator loss fake = 1.8574240812085918e-07, generator loss = 15.804940223693848\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 6, Batch: 422/468, discriminator loss real = 4.677412428731598e-13, disciminator loss fake = 2.0401650147050532e-07, generator loss = 15.669843673706055\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 6, Batch: 423/468, discriminator loss real = 2.7521628639254336e-12, disciminator loss fake = 1.9878027046615898e-07, generator loss = 15.88491439819336\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 6, Batch: 424/468, discriminator loss real = 2.4748402979724027e-11, disciminator loss fake = 1.911137985644018e-07, generator loss = 15.897687911987305\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 6, Batch: 425/468, discriminator loss real = 8.226122040488892e-12, disciminator loss fake = 2.101162550616209e-07, generator loss = 15.803905487060547\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 6, Batch: 426/468, discriminator loss real = 4.5211432424715e-17, disciminator loss fake = 2.1095516444802342e-07, generator loss = 15.819704055786133\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 6, Batch: 427/468, discriminator loss real = 1.3733792748882312e-11, disciminator loss fake = 2.410324952961673e-07, generator loss = 15.712394714355469\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 6, Batch: 428/468, discriminator loss real = 4.538330110071551e-15, disciminator loss fake = 1.7920268646776094e-07, generator loss = 15.8289794921875\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 6, Batch: 429/468, discriminator loss real = 4.805271291985491e-09, disciminator loss fake = 1.996808833837349e-07, generator loss = 15.717020034790039\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 6, Batch: 430/468, discriminator loss real = 1.2441000378331235e-13, disciminator loss fake = 2.6496971372580447e-07, generator loss = 15.872223854064941\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 6, Batch: 431/468, discriminator loss real = 1.8654935374229353e-08, disciminator loss fake = 2.3359531553523993e-07, generator loss = 15.894586563110352\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 6, Batch: 432/468, discriminator loss real = 2.489709480246738e-11, disciminator loss fake = 2.2787193643125647e-07, generator loss = 15.732431411743164\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 6, Batch: 433/468, discriminator loss real = 3.1603983752931386e-13, disciminator loss fake = 2.0215075835494645e-07, generator loss = 15.71778678894043\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 6, Batch: 434/468, discriminator loss real = 2.8171328381176863e-07, disciminator loss fake = 1.9409034734962916e-07, generator loss = 15.77079963684082\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 6, Batch: 435/468, discriminator loss real = 1.2492238354866458e-09, disciminator loss fake = 2.3527030634795665e-07, generator loss = 15.763175010681152\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 6, Batch: 436/468, discriminator loss real = 1.6065875080897287e-16, disciminator loss fake = 2.333594295578223e-07, generator loss = 15.798559188842773\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 6, Batch: 437/468, discriminator loss real = 7.26724583288707e-12, disciminator loss fake = 1.7296987664394692e-07, generator loss = 15.772602081298828\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 6, Batch: 438/468, discriminator loss real = 6.772847473829335e-12, disciminator loss fake = 1.9314995824970538e-07, generator loss = 15.745502471923828\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 6, Batch: 439/468, discriminator loss real = 2.5652206053772275e-11, disciminator loss fake = 2.650186559094436e-07, generator loss = 15.837635040283203\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 6, Batch: 440/468, discriminator loss real = 1.3093368056438237e-10, disciminator loss fake = 1.8255855138704646e-07, generator loss = 15.864013671875\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 6, Batch: 441/468, discriminator loss real = 1.1084425478175008e-12, disciminator loss fake = 2.2180449832376326e-07, generator loss = 15.893632888793945\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 6, Batch: 442/468, discriminator loss real = 4.1707019782233345e-12, disciminator loss fake = 2.0470025674512726e-07, generator loss = 15.904068946838379\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 6, Batch: 443/468, discriminator loss real = 9.769589922204586e-15, disciminator loss fake = 1.592239868841716e-07, generator loss = 15.781807899475098\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 6, Batch: 444/468, discriminator loss real = 1.6728276749922166e-11, disciminator loss fake = 2.1949657025288616e-07, generator loss = 15.840133666992188\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 6, Batch: 445/468, discriminator loss real = 2.422617106923042e-10, disciminator loss fake = 1.996676957105592e-07, generator loss = 15.981372833251953\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 6, Batch: 446/468, discriminator loss real = 6.509920158492832e-09, disciminator loss fake = 1.837562564332984e-07, generator loss = 15.858158111572266\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 6, Batch: 447/468, discriminator loss real = 1.2389190151215757e-12, disciminator loss fake = 2.0052110016877123e-07, generator loss = 15.931175231933594\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 6, Batch: 448/468, discriminator loss real = 6.406458480032184e-14, disciminator loss fake = 2.0594779925886542e-07, generator loss = 15.821769714355469\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 6, Batch: 449/468, discriminator loss real = 1.6763204322908787e-12, disciminator loss fake = 1.9050993671498873e-07, generator loss = 15.781427383422852\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 6, Batch: 450/468, discriminator loss real = 2.4603127356053432e-14, disciminator loss fake = 2.2803968136031472e-07, generator loss = 15.78548526763916\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 6, Batch: 451/468, discriminator loss real = 1.3790284192349844e-10, disciminator loss fake = 2.095697766435478e-07, generator loss = 15.88675308227539\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 6, Batch: 452/468, discriminator loss real = 3.4613590747974154e-13, disciminator loss fake = 2.5292422378697665e-07, generator loss = 16.080244064331055\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 6, Batch: 453/468, discriminator loss real = 6.131059608572784e-14, disciminator loss fake = 2.1732313371103373e-07, generator loss = 15.897879600524902\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 6, Batch: 454/468, discriminator loss real = 5.516166950297885e-13, disciminator loss fake = 1.9844509324684623e-07, generator loss = 15.920114517211914\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 6, Batch: 455/468, discriminator loss real = 9.311788319588121e-12, disciminator loss fake = 1.7005463348596095e-07, generator loss = 15.937606811523438\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 6, Batch: 456/468, discriminator loss real = 2.4101748374860676e-10, disciminator loss fake = 2.355316297553145e-07, generator loss = 16.02460479736328\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 6, Batch: 457/468, discriminator loss real = 1.4296204844943539e-11, disciminator loss fake = 2.069918707547913e-07, generator loss = 15.85489273071289\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 6, Batch: 458/468, discriminator loss real = 1.284751516428945e-16, disciminator loss fake = 2.242563255094865e-07, generator loss = 15.906481742858887\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 6, Batch: 459/468, discriminator loss real = 1.1192016280761607e-12, disciminator loss fake = 2.229363929018291e-07, generator loss = 15.878551483154297\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 6, Batch: 460/468, discriminator loss real = 9.936073400954471e-15, disciminator loss fake = 1.409041203714878e-07, generator loss = 15.940118789672852\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 6, Batch: 461/468, discriminator loss real = 2.5607047038356257e-10, disciminator loss fake = 1.773111648617487e-07, generator loss = 15.931468963623047\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 6, Batch: 462/468, discriminator loss real = 1.2620919663097058e-13, disciminator loss fake = 2.0047917814736138e-07, generator loss = 15.986127853393555\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 6, Batch: 463/468, discriminator loss real = 5.249172208010577e-10, disciminator loss fake = 1.4793837976867508e-07, generator loss = 15.973249435424805\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 6, Batch: 464/468, discriminator loss real = 4.128137380001416e-14, disciminator loss fake = 1.9691415786837752e-07, generator loss = 15.953231811523438\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 6, Batch: 465/468, discriminator loss real = 1.0246022696946966e-08, disciminator loss fake = 1.6379222245177516e-07, generator loss = 15.985432624816895\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 6, Batch: 466/468, discriminator loss real = 4.235287467957427e-12, disciminator loss fake = 1.6717685014100425e-07, generator loss = 16.06888198852539\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 6, Batch: 467/468, discriminator loss real = 7.995146211747794e-12, disciminator loss fake = 1.8469734186510323e-07, generator loss = 15.889681816101074\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 6, Batch: 468/468, discriminator loss real = 1.0695638168536914e-12, disciminator loss fake = 2.2914409214536136e-07, generator loss = 15.900956153869629\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 7, Batch: 1/468, discriminator loss real = 6.9282826986605e-15, disciminator loss fake = 1.7224752468791849e-07, generator loss = 15.934450149536133\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 7, Batch: 2/468, discriminator loss real = 1.998666777396009e-15, disciminator loss fake = 1.726768061871553e-07, generator loss = 15.995397567749023\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 7, Batch: 3/468, discriminator loss real = 1.1939923875992076e-12, disciminator loss fake = 1.983539164029935e-07, generator loss = 15.800741195678711\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 7, Batch: 4/468, discriminator loss real = 2.094870026688074e-15, disciminator loss fake = 1.7985209410653624e-07, generator loss = 15.999984741210938\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 7, Batch: 5/468, discriminator loss real = 5.210680384349839e-14, disciminator loss fake = 1.6198590913063526e-07, generator loss = 15.97446060180664\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 7, Batch: 6/468, discriminator loss real = 5.940604453670562e-13, disciminator loss fake = 1.427435165624047e-07, generator loss = 15.967723846435547\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 7, Batch: 7/468, discriminator loss real = 5.196189312162147e-11, disciminator loss fake = 1.2488074219163536e-07, generator loss = 15.965066909790039\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 7, Batch: 8/468, discriminator loss real = 4.0238976040107843e-10, disciminator loss fake = 1.6877787345492834e-07, generator loss = 15.969730377197266\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 7, Batch: 9/468, discriminator loss real = 5.166634264516801e-13, disciminator loss fake = 1.816761425743607e-07, generator loss = 15.99772834777832\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 7, Batch: 10/468, discriminator loss real = 3.5878616050366574e-11, disciminator loss fake = 1.6795289070614672e-07, generator loss = 16.146480560302734\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 7, Batch: 11/468, discriminator loss real = 4.8341186739339626e-14, disciminator loss fake = 1.695463254236529e-07, generator loss = 15.996316909790039\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 7, Batch: 12/468, discriminator loss real = 9.033342129871613e-11, disciminator loss fake = 1.3580334723428678e-07, generator loss = 15.96029281616211\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 7, Batch: 13/468, discriminator loss real = 1.552172140817376e-10, disciminator loss fake = 2.2060707749460562e-07, generator loss = 16.144180297851562\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 7, Batch: 14/468, discriminator loss real = 3.0961339093519896e-15, disciminator loss fake = 1.210763258541192e-07, generator loss = 16.05841064453125\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 7, Batch: 15/468, discriminator loss real = 2.5941659302468334e-13, disciminator loss fake = 2.4175969315365364e-07, generator loss = 16.140865325927734\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 7, Batch: 16/468, discriminator loss real = 3.2957736457891974e-15, disciminator loss fake = 1.5528189578617457e-07, generator loss = 16.03977394104004\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 7, Batch: 17/468, discriminator loss real = 1.3740754367663754e-10, disciminator loss fake = 1.5035628564419312e-07, generator loss = 16.019201278686523\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 7, Batch: 18/468, discriminator loss real = 2.999617766089209e-14, disciminator loss fake = 1.2653366354697937e-07, generator loss = 15.930828094482422\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 7, Batch: 19/468, discriminator loss real = 4.859222833136778e-13, disciminator loss fake = 1.7512188321688882e-07, generator loss = 16.09052085876465\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 7, Batch: 20/468, discriminator loss real = 3.332767395392011e-09, disciminator loss fake = 1.9133167938889528e-07, generator loss = 15.979272842407227\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 7, Batch: 21/468, discriminator loss real = 2.233667695250574e-10, disciminator loss fake = 1.3722194580623182e-07, generator loss = 16.11138916015625\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 7, Batch: 22/468, discriminator loss real = 3.408839097599609e-16, disciminator loss fake = 1.4996311392678763e-07, generator loss = 16.085433959960938\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 7, Batch: 23/468, discriminator loss real = 5.532931623974946e-08, disciminator loss fake = 1.9002405338142125e-07, generator loss = 16.107929229736328\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 7, Batch: 24/468, discriminator loss real = 7.552397596199967e-11, disciminator loss fake = 1.648916736485262e-07, generator loss = 16.050689697265625\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 7, Batch: 25/468, discriminator loss real = 6.451304876593789e-13, disciminator loss fake = 1.4786699864544062e-07, generator loss = 15.965710639953613\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 7, Batch: 26/468, discriminator loss real = 9.960734494163237e-12, disciminator loss fake = 1.2475095445552142e-07, generator loss = 16.132701873779297\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 7, Batch: 27/468, discriminator loss real = 9.577836570726084e-14, disciminator loss fake = 1.3472075011122797e-07, generator loss = 16.069429397583008\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 7, Batch: 28/468, discriminator loss real = 3.5041136387924804e-14, disciminator loss fake = 1.6787701895282225e-07, generator loss = 16.178668975830078\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 7, Batch: 29/468, discriminator loss real = 2.509485241830589e-08, disciminator loss fake = 1.4569445738743525e-07, generator loss = 16.102951049804688\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 7, Batch: 30/468, discriminator loss real = 5.753418630405349e-09, disciminator loss fake = 1.3655287034453067e-07, generator loss = 15.938657760620117\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 7, Batch: 31/468, discriminator loss real = 5.181873873780728e-16, disciminator loss fake = 1.426088118705593e-07, generator loss = 16.083984375\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 7, Batch: 32/468, discriminator loss real = 2.0746442758179384e-12, disciminator loss fake = 1.6558649917897128e-07, generator loss = 16.203060150146484\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 7, Batch: 33/468, discriminator loss real = 3.722929950433773e-12, disciminator loss fake = 1.4218126409559773e-07, generator loss = 15.962661743164062\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 7, Batch: 34/468, discriminator loss real = 3.248723512427887e-11, disciminator loss fake = 1.4568780670742854e-07, generator loss = 16.158308029174805\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 7, Batch: 35/468, discriminator loss real = 8.646069157933894e-14, disciminator loss fake = 1.232306772180891e-07, generator loss = 16.134628295898438\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 7, Batch: 36/468, discriminator loss real = 2.247531154242477e-11, disciminator loss fake = 1.4204425724528846e-07, generator loss = 16.16783905029297\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 7, Batch: 37/468, discriminator loss real = 1.9616487989537745e-08, disciminator loss fake = 1.266506330921402e-07, generator loss = 16.20842742919922\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 7, Batch: 38/468, discriminator loss real = 1.401044970143761e-12, disciminator loss fake = 1.4322499453101045e-07, generator loss = 16.020736694335938\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 7, Batch: 39/468, discriminator loss real = 6.740096036850218e-09, disciminator loss fake = 1.6094968202651216e-07, generator loss = 16.09293556213379\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 7, Batch: 40/468, discriminator loss real = 4.365131520134291e-12, disciminator loss fake = 1.839001129155804e-07, generator loss = 16.236560821533203\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 7, Batch: 41/468, discriminator loss real = 4.3373679963850016e-16, disciminator loss fake = 1.4066803544210416e-07, generator loss = 16.134260177612305\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 7, Batch: 42/468, discriminator loss real = 2.571707957699232e-09, disciminator loss fake = 1.119201797905589e-07, generator loss = 16.160259246826172\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 7, Batch: 43/468, discriminator loss real = 6.892642381330083e-13, disciminator loss fake = 1.5130530073292903e-07, generator loss = 16.052330017089844\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 7, Batch: 44/468, discriminator loss real = 1.1869251415053128e-10, disciminator loss fake = 1.6907749511574366e-07, generator loss = 16.123823165893555\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 7, Batch: 45/468, discriminator loss real = 8.183079214241218e-11, disciminator loss fake = 1.293965112836304e-07, generator loss = 16.149703979492188\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 7, Batch: 46/468, discriminator loss real = 2.02544578331576e-12, disciminator loss fake = 1.35286342128893e-07, generator loss = 16.15060806274414\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 7, Batch: 47/468, discriminator loss real = 5.178665656024872e-12, disciminator loss fake = 1.883063021068665e-07, generator loss = 16.20756721496582\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 7, Batch: 48/468, discriminator loss real = 7.160296119045062e-14, disciminator loss fake = 1.7386000195074303e-07, generator loss = 16.14303207397461\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 7, Batch: 49/468, discriminator loss real = 3.4525082445724387e-12, disciminator loss fake = 1.396964535160805e-07, generator loss = 16.043251037597656\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 7, Batch: 50/468, discriminator loss real = 1.4679049087362728e-09, disciminator loss fake = 1.153906268314131e-07, generator loss = 15.98511028289795\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 7, Batch: 51/468, discriminator loss real = 6.256544327759572e-12, disciminator loss fake = 1.5220457783016172e-07, generator loss = 16.11997413635254\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 7, Batch: 52/468, discriminator loss real = 6.693444687400074e-10, disciminator loss fake = 1.2070543675690715e-07, generator loss = 16.252788543701172\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 7, Batch: 53/468, discriminator loss real = 4.701575934129565e-12, disciminator loss fake = 1.1973605751336436e-07, generator loss = 16.032804489135742\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 7, Batch: 54/468, discriminator loss real = 5.977039176097154e-12, disciminator loss fake = 1.307494557067912e-07, generator loss = 16.283212661743164\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 7, Batch: 55/468, discriminator loss real = 1.0621164321308885e-13, disciminator loss fake = 1.237729350123118e-07, generator loss = 16.091583251953125\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 7, Batch: 56/468, discriminator loss real = 1.876348252119464e-12, disciminator loss fake = 1.352557603695459e-07, generator loss = 16.152114868164062\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 7, Batch: 57/468, discriminator loss real = 2.8377468560755736e-13, disciminator loss fake = 1.455949529827194e-07, generator loss = 16.20548439025879\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 7, Batch: 58/468, discriminator loss real = 2.998682899213456e-11, disciminator loss fake = 1.486620249124826e-07, generator loss = 16.155223846435547\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 7, Batch: 59/468, discriminator loss real = 4.046889979700784e-14, disciminator loss fake = 1.531687132683146e-07, generator loss = 16.11949920654297\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 7, Batch: 60/468, discriminator loss real = 8.678989601648701e-14, disciminator loss fake = 1.3105807283864124e-07, generator loss = 16.231639862060547\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 7, Batch: 61/468, discriminator loss real = 6.1112755481151915e-12, disciminator loss fake = 1.4184962537910906e-07, generator loss = 16.182323455810547\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 7, Batch: 62/468, discriminator loss real = 5.2164900003759396e-12, disciminator loss fake = 1.7607037250400026e-07, generator loss = 16.13262176513672\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 7, Batch: 63/468, discriminator loss real = 1.2482909671207576e-12, disciminator loss fake = 1.5904268479971506e-07, generator loss = 16.303974151611328\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 7, Batch: 64/468, discriminator loss real = 2.191834491682698e-09, disciminator loss fake = 1.175655768292927e-07, generator loss = 16.037349700927734\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 7, Batch: 65/468, discriminator loss real = 1.0106082637406644e-09, disciminator loss fake = 1.2239488000886922e-07, generator loss = 16.263582229614258\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 7, Batch: 66/468, discriminator loss real = 1.2562264561921666e-09, disciminator loss fake = 1.5059619329349516e-07, generator loss = 16.168922424316406\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 7, Batch: 67/468, discriminator loss real = 8.851907650885699e-14, disciminator loss fake = 1.4464868058894353e-07, generator loss = 16.178955078125\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 7, Batch: 68/468, discriminator loss real = 7.455360417907286e-08, disciminator loss fake = 1.6175332007151155e-07, generator loss = 16.029804229736328\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 7, Batch: 69/468, discriminator loss real = 2.7382930056774057e-06, disciminator loss fake = 1.4608968967877445e-07, generator loss = 16.290685653686523\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 7, Batch: 70/468, discriminator loss real = 1.8879386232129036e-07, disciminator loss fake = 1.3352200767258182e-07, generator loss = 16.277713775634766\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 7, Batch: 71/468, discriminator loss real = 1.9464081735254268e-10, disciminator loss fake = 1.5139178799472575e-07, generator loss = 16.147205352783203\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 7, Batch: 72/468, discriminator loss real = 2.43271153221869e-10, disciminator loss fake = 1.3700518763926084e-07, generator loss = 16.254148483276367\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 7, Batch: 73/468, discriminator loss real = 1.7467224333600484e-09, disciminator loss fake = 1.3585399472049176e-07, generator loss = 16.186962127685547\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 7, Batch: 74/468, discriminator loss real = 1.9478485664692347e-12, disciminator loss fake = 1.2699122464709944e-07, generator loss = 16.185319900512695\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 7, Batch: 75/468, discriminator loss real = 7.56477491759e-10, disciminator loss fake = 1.523359003385849e-07, generator loss = 16.167774200439453\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 7, Batch: 76/468, discriminator loss real = 2.3872107846045765e-08, disciminator loss fake = 1.5330485325648624e-07, generator loss = 16.081932067871094\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 7, Batch: 77/468, discriminator loss real = 8.863339207541843e-14, disciminator loss fake = 1.1643710706721322e-07, generator loss = 16.116363525390625\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 7, Batch: 78/468, discriminator loss real = 6.687432183537234e-14, disciminator loss fake = 1.1858606541181871e-07, generator loss = 16.269805908203125\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 7, Batch: 79/468, discriminator loss real = 4.08267949341453e-14, disciminator loss fake = 1.175043564671796e-07, generator loss = 16.046222686767578\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 7, Batch: 80/468, discriminator loss real = 2.060654771818271e-11, disciminator loss fake = 1.5716904044893454e-07, generator loss = 16.26599884033203\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 7, Batch: 81/468, discriminator loss real = 1.3144173249823865e-10, disciminator loss fake = 1.4231400768949243e-07, generator loss = 16.052627563476562\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 7, Batch: 82/468, discriminator loss real = 1.829309100032095e-11, disciminator loss fake = 1.4346971966006095e-07, generator loss = 16.23781967163086\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 7, Batch: 83/468, discriminator loss real = 4.520181173806037e-10, disciminator loss fake = 1.4014736393619387e-07, generator loss = 16.172510147094727\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 7, Batch: 84/468, discriminator loss real = 3.822147459642267e-12, disciminator loss fake = 1.1565667534796376e-07, generator loss = 16.27086639404297\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 7, Batch: 85/468, discriminator loss real = 2.037504550928687e-14, disciminator loss fake = 1.4204019294083992e-07, generator loss = 16.24384880065918\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 7, Batch: 86/468, discriminator loss real = 3.613110921563134e-10, disciminator loss fake = 1.4410358062377782e-07, generator loss = 16.34026527404785\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 7, Batch: 87/468, discriminator loss real = 2.8253299005909227e-11, disciminator loss fake = 1.3790777586564218e-07, generator loss = 16.17533302307129\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 7, Batch: 88/468, discriminator loss real = 4.0979037089134324e-17, disciminator loss fake = 1.4395469349892664e-07, generator loss = 16.00407600402832\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 7, Batch: 89/468, discriminator loss real = 8.559739722580062e-11, disciminator loss fake = 1.3601749060399015e-07, generator loss = 16.183687210083008\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 7, Batch: 90/468, discriminator loss real = 2.970184980534722e-15, disciminator loss fake = 1.0544804496248616e-07, generator loss = 16.199275970458984\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 7, Batch: 91/468, discriminator loss real = 6.067979259751787e-17, disciminator loss fake = 1.134809650693569e-07, generator loss = 16.293292999267578\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 7, Batch: 92/468, discriminator loss real = 2.867345683804645e-12, disciminator loss fake = 1.4389470948117378e-07, generator loss = 16.211763381958008\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 7, Batch: 93/468, discriminator loss real = 3.0914413390314976e-11, disciminator loss fake = 1.7108627048401104e-07, generator loss = 16.124080657958984\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 7, Batch: 94/468, discriminator loss real = 6.557275833429799e-10, disciminator loss fake = 1.6539695479877992e-07, generator loss = 16.171222686767578\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 7, Batch: 95/468, discriminator loss real = 2.0057571159526333e-09, disciminator loss fake = 1.1213965933620784e-07, generator loss = 16.238969802856445\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 7, Batch: 96/468, discriminator loss real = 7.236899745915668e-14, disciminator loss fake = 1.7034636812240933e-07, generator loss = 16.299047470092773\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 7, Batch: 97/468, discriminator loss real = 4.1760732784161536e-13, disciminator loss fake = 1.8394263179288828e-07, generator loss = 16.341476440429688\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 7, Batch: 98/468, discriminator loss real = 5.361714761412117e-13, disciminator loss fake = 1.351600360521843e-07, generator loss = 16.350309371948242\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 7, Batch: 99/468, discriminator loss real = 3.2783078495413065e-05, disciminator loss fake = 1.5645227335880918e-07, generator loss = 15.989189147949219\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 7, Batch: 100/468, discriminator loss real = 1.3868672920150371e-12, disciminator loss fake = 1.827005746690702e-07, generator loss = 15.89718246459961\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 7, Batch: 101/468, discriminator loss real = 1.1389240484049878e-07, disciminator loss fake = 1.9448373222985538e-07, generator loss = 15.606433868408203\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 7, Batch: 102/468, discriminator loss real = 2.428244508679428e-13, disciminator loss fake = 3.225842419851688e-07, generator loss = 15.516620635986328\n",
      "2/2 [==============================] - 0s 36ms/step\n",
      "Epoch: 7, Batch: 103/468, discriminator loss real = 1.8985512946788135e-15, disciminator loss fake = 2.7787004341917054e-07, generator loss = 15.328620910644531\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 7, Batch: 104/468, discriminator loss real = 7.387851012105161e-15, disciminator loss fake = 3.2276145134346734e-07, generator loss = 15.24074649810791\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 7, Batch: 105/468, discriminator loss real = 1.0253697124238339e-16, disciminator loss fake = 3.095362046678929e-07, generator loss = 15.101764678955078\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 7, Batch: 106/468, discriminator loss real = 4.915680085204599e-10, disciminator loss fake = 6.43681801193452e-07, generator loss = 15.28414249420166\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 7, Batch: 107/468, discriminator loss real = 2.5230215052601812e-12, disciminator loss fake = 4.632726984254987e-07, generator loss = 15.105379104614258\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 7, Batch: 108/468, discriminator loss real = 2.0233803516412213e-18, disciminator loss fake = 8.579896189075953e-07, generator loss = 15.108335494995117\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 7, Batch: 109/468, discriminator loss real = 1.01200614555097e-09, disciminator loss fake = 5.164988579053897e-07, generator loss = 14.976861953735352\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 7, Batch: 110/468, discriminator loss real = 1.7600139824280187e-13, disciminator loss fake = 6.754416403964569e-07, generator loss = 15.104371070861816\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 7, Batch: 111/468, discriminator loss real = 2.3306070615070063e-12, disciminator loss fake = 1.1612889920797898e-06, generator loss = 15.257670402526855\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 7, Batch: 112/468, discriminator loss real = 1.1092077777108411e-11, disciminator loss fake = 5.947830459263059e-07, generator loss = 15.044626235961914\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 7, Batch: 113/468, discriminator loss real = 4.3508158355627457e-17, disciminator loss fake = 5.332248065315071e-07, generator loss = 15.161876678466797\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 7, Batch: 114/468, discriminator loss real = 1.1226609919479102e-12, disciminator loss fake = 6.299054007286031e-07, generator loss = 14.860352516174316\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 7, Batch: 115/468, discriminator loss real = 2.9182335801319903e-12, disciminator loss fake = 8.391693882003892e-07, generator loss = 15.061727523803711\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 7, Batch: 116/468, discriminator loss real = 7.082619513188522e-16, disciminator loss fake = 5.429111524790642e-07, generator loss = 15.006689071655273\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 7, Batch: 117/468, discriminator loss real = 2.3240387479056546e-12, disciminator loss fake = 1.3462160950439284e-06, generator loss = 15.024669647216797\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 7, Batch: 118/468, discriminator loss real = 2.134240527362774e-11, disciminator loss fake = 7.311534773180028e-07, generator loss = 15.281105041503906\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 7, Batch: 119/468, discriminator loss real = 3.7829153004542704e-11, disciminator loss fake = 8.06930643193482e-07, generator loss = 15.181281089782715\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 7, Batch: 120/468, discriminator loss real = 1.1229066653839319e-14, disciminator loss fake = 4.835413278669876e-07, generator loss = 15.285085678100586\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 7, Batch: 121/468, discriminator loss real = 6.493917816680073e-12, disciminator loss fake = 4.595500513460138e-07, generator loss = 15.167139053344727\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 7, Batch: 122/468, discriminator loss real = 6.5466590482010645e-12, disciminator loss fake = 5.614743940896005e-07, generator loss = 15.300737380981445\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 7, Batch: 123/468, discriminator loss real = 1.7427222198559663e-15, disciminator loss fake = 4.005738105661294e-07, generator loss = 15.375039100646973\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 7, Batch: 124/468, discriminator loss real = 4.934071272215401e-14, disciminator loss fake = 4.262938659849169e-07, generator loss = 15.268180847167969\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 7, Batch: 125/468, discriminator loss real = 3.172578505786748e-14, disciminator loss fake = 6.61012279579154e-07, generator loss = 15.142717361450195\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 7, Batch: 126/468, discriminator loss real = 4.831640296187878e-12, disciminator loss fake = 3.4076734323207347e-07, generator loss = 15.386731147766113\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 7, Batch: 127/468, discriminator loss real = 4.988010330296555e-13, disciminator loss fake = 3.387712865787762e-07, generator loss = 15.319784164428711\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 7, Batch: 128/468, discriminator loss real = 1.5346856340543898e-14, disciminator loss fake = 3.051097507977829e-07, generator loss = 15.295023918151855\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 7, Batch: 129/468, discriminator loss real = 9.867424655141122e-10, disciminator loss fake = 4.3757535195254604e-07, generator loss = 15.248714447021484\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 7, Batch: 130/468, discriminator loss real = 8.39401085531849e-13, disciminator loss fake = 3.0577342613469227e-07, generator loss = 15.315555572509766\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 7, Batch: 131/468, discriminator loss real = 8.664736239432074e-15, disciminator loss fake = 4.40348884467312e-07, generator loss = 15.525921821594238\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 7, Batch: 132/468, discriminator loss real = 1.6487448342358824e-12, disciminator loss fake = 4.828110604648828e-07, generator loss = 15.446414947509766\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 7, Batch: 133/468, discriminator loss real = 6.173019418494099e-15, disciminator loss fake = 5.305950026013306e-07, generator loss = 15.478011131286621\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 7, Batch: 134/468, discriminator loss real = 4.105113471375432e-11, disciminator loss fake = 5.908116236241767e-07, generator loss = 15.619648933410645\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 7, Batch: 135/468, discriminator loss real = 2.1273541506161564e-07, disciminator loss fake = 3.1489099683312816e-07, generator loss = 15.511082649230957\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 7, Batch: 136/468, discriminator loss real = 8.915013299522039e-16, disciminator loss fake = 4.2191689431092527e-07, generator loss = 15.59399127960205\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 7, Batch: 137/468, discriminator loss real = 5.413502423569881e-14, disciminator loss fake = 4.417829586600419e-07, generator loss = 15.544909477233887\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 7, Batch: 138/468, discriminator loss real = 1.4684556738989163e-12, disciminator loss fake = 5.565822789321828e-07, generator loss = 15.429366111755371\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 7, Batch: 139/468, discriminator loss real = 5.842711720932233e-15, disciminator loss fake = 3.1371772024613165e-07, generator loss = 15.52630615234375\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 7, Batch: 140/468, discriminator loss real = 8.041342860142485e-15, disciminator loss fake = 2.3316813724250096e-07, generator loss = 15.613944053649902\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 7, Batch: 141/468, discriminator loss real = 1.6255255766035588e-16, disciminator loss fake = 3.5999170222567045e-07, generator loss = 15.576348304748535\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 7, Batch: 142/468, discriminator loss real = 1.1367622988756043e-11, disciminator loss fake = 2.714305082918145e-07, generator loss = 15.562782287597656\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 7, Batch: 143/468, discriminator loss real = 1.2750252242899052e-12, disciminator loss fake = 2.430654717500147e-07, generator loss = 15.710866928100586\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 7, Batch: 144/468, discriminator loss real = 7.912445004754076e-12, disciminator loss fake = 3.2823237461343524e-07, generator loss = 15.446746826171875\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 7, Batch: 145/468, discriminator loss real = 2.6671069866535113e-12, disciminator loss fake = 2.757183779067418e-07, generator loss = 15.725339889526367\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 7, Batch: 146/468, discriminator loss real = 1.1176789745451221e-12, disciminator loss fake = 3.3766684737202013e-07, generator loss = 15.662883758544922\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 7, Batch: 147/468, discriminator loss real = 3.36413979254446e-15, disciminator loss fake = 2.7994502715955605e-07, generator loss = 15.670259475708008\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 7, Batch: 148/468, discriminator loss real = 1.1745096912998531e-14, disciminator loss fake = 4.3904663016292034e-07, generator loss = 15.94281005859375\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 7, Batch: 149/468, discriminator loss real = 1.0423857440663357e-15, disciminator loss fake = 2.445304971843143e-07, generator loss = 15.624273300170898\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 7, Batch: 150/468, discriminator loss real = 5.7167600392578864e-15, disciminator loss fake = 1.915216358838734e-07, generator loss = 15.59197998046875\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 7, Batch: 151/468, discriminator loss real = 1.1033883682997305e-19, disciminator loss fake = 3.1450997539650416e-07, generator loss = 15.613794326782227\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 7, Batch: 152/468, discriminator loss real = 6.444217603984725e-08, disciminator loss fake = 3.0668829253954755e-07, generator loss = 15.695222854614258\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 7, Batch: 153/468, discriminator loss real = 1.2506136236563712e-17, disciminator loss fake = 2.3660308556827658e-07, generator loss = 15.781452178955078\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 7, Batch: 154/468, discriminator loss real = 1.3632986815728491e-15, disciminator loss fake = 2.1144325046407175e-07, generator loss = 15.759132385253906\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 7, Batch: 155/468, discriminator loss real = 1.991858555264875e-13, disciminator loss fake = 2.550438580328773e-07, generator loss = 15.725683212280273\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 7, Batch: 156/468, discriminator loss real = 1.4891673540183645e-15, disciminator loss fake = 2.3302550289372448e-07, generator loss = 15.774480819702148\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 7, Batch: 157/468, discriminator loss real = 2.241665706886691e-15, disciminator loss fake = 2.2797182452904963e-07, generator loss = 15.802362442016602\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 7, Batch: 158/468, discriminator loss real = 6.601291643306903e-14, disciminator loss fake = 1.5943564335429983e-07, generator loss = 15.845213890075684\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 7, Batch: 159/468, discriminator loss real = 2.7394414319446836e-14, disciminator loss fake = 2.432068981761404e-07, generator loss = 15.820528030395508\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 7, Batch: 160/468, discriminator loss real = 3.491393285592892e-11, disciminator loss fake = 3.0420329721891903e-07, generator loss = 15.865436553955078\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 7, Batch: 161/468, discriminator loss real = 7.807366313847719e-16, disciminator loss fake = 2.4447791702186805e-07, generator loss = 15.774599075317383\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 7, Batch: 162/468, discriminator loss real = 1.133316186791963e-16, disciminator loss fake = 2.5610199827497127e-07, generator loss = 15.739171981811523\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 7, Batch: 163/468, discriminator loss real = 1.0492867332458533e-15, disciminator loss fake = 2.7177898687114066e-07, generator loss = 15.878162384033203\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 7, Batch: 164/468, discriminator loss real = 7.40091234824325e-12, disciminator loss fake = 2.535296630412631e-07, generator loss = 15.797977447509766\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 7, Batch: 165/468, discriminator loss real = 6.851998911430778e-16, disciminator loss fake = 3.544778053310438e-07, generator loss = 15.999626159667969\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 7, Batch: 166/468, discriminator loss real = 4.811473380438017e-17, disciminator loss fake = 1.866404062411675e-07, generator loss = 15.799888610839844\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 7, Batch: 167/468, discriminator loss real = 9.607983679493781e-12, disciminator loss fake = 2.1856838827716274e-07, generator loss = 15.75638484954834\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 7, Batch: 168/468, discriminator loss real = 1.9947636495750614e-16, disciminator loss fake = 2.7384984946365876e-07, generator loss = 15.847219467163086\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 7, Batch: 169/468, discriminator loss real = 1.8964638887064567e-11, disciminator loss fake = 2.019729095081857e-07, generator loss = 15.951659202575684\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 7, Batch: 170/468, discriminator loss real = 3.5165740784287203e-17, disciminator loss fake = 1.8879937613291986e-07, generator loss = 15.874833106994629\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 7, Batch: 171/468, discriminator loss real = 6.7361248042463896e-15, disciminator loss fake = 2.5410645321244374e-07, generator loss = 15.991453170776367\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 7, Batch: 172/468, discriminator loss real = 1.172788643977185e-09, disciminator loss fake = 1.702931484715009e-07, generator loss = 15.845924377441406\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 7, Batch: 173/468, discriminator loss real = 2.2809712452165343e-11, disciminator loss fake = 2.0013405332974799e-07, generator loss = 15.895427703857422\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 7, Batch: 174/468, discriminator loss real = 1.5651911021332798e-15, disciminator loss fake = 2.545455686231435e-07, generator loss = 15.804925918579102\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 7, Batch: 175/468, discriminator loss real = 2.123167774925605e-08, disciminator loss fake = 1.914716278861306e-07, generator loss = 15.90764045715332\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 7, Batch: 176/468, discriminator loss real = 6.880756950539482e-14, disciminator loss fake = 2.415260667021357e-07, generator loss = 16.034530639648438\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 7, Batch: 177/468, discriminator loss real = 1.2073405189288403e-14, disciminator loss fake = 2.0778733755832945e-07, generator loss = 16.036108016967773\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 7, Batch: 178/468, discriminator loss real = 4.100762630398873e-15, disciminator loss fake = 3.0991037647254416e-07, generator loss = 15.944146156311035\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 7, Batch: 179/468, discriminator loss real = 4.84502937769804e-10, disciminator loss fake = 3.106803205810138e-07, generator loss = 16.025131225585938\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 7, Batch: 180/468, discriminator loss real = 4.170886455222983e-13, disciminator loss fake = 2.4796520392555976e-07, generator loss = 15.805303573608398\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 7, Batch: 181/468, discriminator loss real = 2.1431147134709505e-10, disciminator loss fake = 2.0169562731098267e-07, generator loss = 15.950945854187012\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 7, Batch: 182/468, discriminator loss real = 1.0550820633836722e-11, disciminator loss fake = 2.066782371912268e-07, generator loss = 15.864269256591797\n",
      "2/2 [==============================] - 0s 39ms/step\n",
      "Epoch: 7, Batch: 183/468, discriminator loss real = 1.0323690791125273e-09, disciminator loss fake = 2.0751716078848403e-07, generator loss = 16.148143768310547\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 7, Batch: 184/468, discriminator loss real = 5.340450737884028e-12, disciminator loss fake = 1.9693140984600177e-07, generator loss = 15.957071304321289\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 7, Batch: 185/468, discriminator loss real = 3.5464488113643713e-15, disciminator loss fake = 1.956249491286144e-07, generator loss = 15.93213939666748\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 7, Batch: 186/468, discriminator loss real = 4.5791521685600856e-09, disciminator loss fake = 1.9215970326058596e-07, generator loss = 15.974821090698242\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 7, Batch: 187/468, discriminator loss real = 2.3169136151735686e-14, disciminator loss fake = 2.792546069940727e-07, generator loss = 16.036901473999023\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 7, Batch: 188/468, discriminator loss real = 4.344067762299987e-14, disciminator loss fake = 1.7075751657102956e-07, generator loss = 15.897493362426758\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 7, Batch: 189/468, discriminator loss real = 5.04781318966252e-08, disciminator loss fake = 1.972490935031601e-07, generator loss = 15.951685905456543\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 7, Batch: 190/468, discriminator loss real = 6.956056824297674e-14, disciminator loss fake = 2.0412601031694066e-07, generator loss = 15.924837112426758\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 7, Batch: 191/468, discriminator loss real = 6.451495793584935e-16, disciminator loss fake = 2.1293882923600904e-07, generator loss = 16.165912628173828\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 7, Batch: 192/468, discriminator loss real = 8.8736560688394e-15, disciminator loss fake = 1.4565247852260654e-07, generator loss = 16.08793830871582\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 7, Batch: 193/468, discriminator loss real = 6.795983220619917e-10, disciminator loss fake = 2.1094385260767012e-07, generator loss = 16.060617446899414\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 7, Batch: 194/468, discriminator loss real = 2.677168930986795e-09, disciminator loss fake = 2.0711932791073195e-07, generator loss = 16.037158966064453\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 7, Batch: 195/468, discriminator loss real = 5.402728178033334e-12, disciminator loss fake = 1.4623185506934533e-07, generator loss = 16.134166717529297\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 7, Batch: 196/468, discriminator loss real = 1.9256124232924776e-06, disciminator loss fake = 1.640467957031433e-07, generator loss = 16.09302520751953\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 7, Batch: 197/468, discriminator loss real = 3.4857833058303935e-16, disciminator loss fake = 2.0241044751401205e-07, generator loss = 15.947165489196777\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 7, Batch: 198/468, discriminator loss real = 1.8212931163219537e-12, disciminator loss fake = 1.8154585745833174e-07, generator loss = 16.215816497802734\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 7, Batch: 199/468, discriminator loss real = 4.710928536155734e-08, disciminator loss fake = 2.0866332306468394e-07, generator loss = 16.12908935546875\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 7, Batch: 200/468, discriminator loss real = 1.4982103285852283e-13, disciminator loss fake = 2.469452624609403e-07, generator loss = 15.876965522766113\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 7, Batch: 201/468, discriminator loss real = 4.610761100178051e-13, disciminator loss fake = 1.9186629174328118e-07, generator loss = 16.22860336303711\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 7, Batch: 202/468, discriminator loss real = 1.4775016279888753e-11, disciminator loss fake = 1.580674506840296e-07, generator loss = 16.145103454589844\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 7, Batch: 203/468, discriminator loss real = 8.215310891420899e-14, disciminator loss fake = 1.278142747196398e-07, generator loss = 16.03900909423828\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 7, Batch: 204/468, discriminator loss real = 4.1488934141541145e-13, disciminator loss fake = 2.3470485643883876e-07, generator loss = 15.994335174560547\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 7, Batch: 205/468, discriminator loss real = 1.0993429257200038e-11, disciminator loss fake = 1.7598723900391633e-07, generator loss = 15.998579025268555\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 7, Batch: 206/468, discriminator loss real = 1.4761334515833724e-12, disciminator loss fake = 1.3570021906161855e-07, generator loss = 16.049320220947266\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 7, Batch: 207/468, discriminator loss real = 5.117410960725531e-16, disciminator loss fake = 1.5039685763440502e-07, generator loss = 15.98762321472168\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 7, Batch: 208/468, discriminator loss real = 1.3459715830776986e-07, disciminator loss fake = 1.8279288838130014e-07, generator loss = 16.192672729492188\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 7, Batch: 209/468, discriminator loss real = 1.0883226072708148e-17, disciminator loss fake = 1.4542740700562717e-07, generator loss = 16.013668060302734\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 7, Batch: 210/468, discriminator loss real = 1.2364650969765023e-10, disciminator loss fake = 1.230930735118818e-07, generator loss = 16.051136016845703\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 7, Batch: 211/468, discriminator loss real = 5.226876223507482e-11, disciminator loss fake = 1.4336353615362896e-07, generator loss = 16.030864715576172\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 7, Batch: 212/468, discriminator loss real = 5.205066846286632e-12, disciminator loss fake = 1.388115578038196e-07, generator loss = 16.035985946655273\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 7, Batch: 213/468, discriminator loss real = 1.7721773869325956e-17, disciminator loss fake = 1.7904829974213499e-07, generator loss = 15.9866361618042\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 7, Batch: 214/468, discriminator loss real = 6.466108204428167e-10, disciminator loss fake = 1.6408461078754044e-07, generator loss = 16.03676986694336\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 7, Batch: 215/468, discriminator loss real = 6.320561885290663e-14, disciminator loss fake = 1.764997676900748e-07, generator loss = 16.23522186279297\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 7, Batch: 216/468, discriminator loss real = 1.3939838083842915e-07, disciminator loss fake = 1.7464738277794822e-07, generator loss = 16.07141876220703\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 7, Batch: 217/468, discriminator loss real = 8.890810830608498e-12, disciminator loss fake = 1.8298263171345752e-07, generator loss = 16.09004783630371\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 7, Batch: 218/468, discriminator loss real = 7.20421777788971e-10, disciminator loss fake = 1.452180384831081e-07, generator loss = 16.260377883911133\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 7, Batch: 219/468, discriminator loss real = 4.825389046669848e-11, disciminator loss fake = 1.2249260805674567e-07, generator loss = 16.232128143310547\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 7, Batch: 220/468, discriminator loss real = 2.362961204482872e-08, disciminator loss fake = 2.3294641948723438e-07, generator loss = 16.109033584594727\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 7, Batch: 221/468, discriminator loss real = 1.3246826968682512e-09, disciminator loss fake = 1.4999139352767088e-07, generator loss = 16.231237411499023\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 7, Batch: 222/468, discriminator loss real = 6.687722020615183e-07, disciminator loss fake = 1.5159480426518712e-07, generator loss = 16.05904769897461\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 7, Batch: 223/468, discriminator loss real = 5.548476345040854e-09, disciminator loss fake = 2.2288477907750348e-07, generator loss = 16.11671257019043\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 7, Batch: 224/468, discriminator loss real = 8.525397727186801e-13, disciminator loss fake = 1.6187738083317527e-07, generator loss = 16.230560302734375\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 7, Batch: 225/468, discriminator loss real = 7.274350566355281e-11, disciminator loss fake = 1.6202375263674185e-07, generator loss = 16.221349716186523\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 7, Batch: 226/468, discriminator loss real = 2.4072054571888657e-08, disciminator loss fake = 1.6613060438430693e-07, generator loss = 16.193429946899414\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 7, Batch: 227/468, discriminator loss real = 1.389773712778819e-12, disciminator loss fake = 1.994095129020934e-07, generator loss = 16.232666015625\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 7, Batch: 228/468, discriminator loss real = 9.219809635262026e-15, disciminator loss fake = 1.7819928643802996e-07, generator loss = 16.15056610107422\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 7, Batch: 229/468, discriminator loss real = 1.8261241585722232e-13, disciminator loss fake = 1.399281757130666e-07, generator loss = 16.25469207763672\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 7, Batch: 230/468, discriminator loss real = 7.177209382369654e-10, disciminator loss fake = 1.5251362128765322e-07, generator loss = 16.26935577392578\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 7, Batch: 231/468, discriminator loss real = 1.2687678165035354e-11, disciminator loss fake = 1.3208203597514512e-07, generator loss = 16.21664810180664\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 7, Batch: 232/468, discriminator loss real = 1.230928969864209e-10, disciminator loss fake = 1.8594531070448284e-07, generator loss = 16.183551788330078\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 7, Batch: 233/468, discriminator loss real = 2.6264415447195544e-13, disciminator loss fake = 1.9190684952263837e-07, generator loss = 16.120765686035156\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 7, Batch: 234/468, discriminator loss real = 8.029382754927254e-15, disciminator loss fake = 2.480737748555839e-07, generator loss = 16.10150146484375\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 7, Batch: 235/468, discriminator loss real = 1.3287766720271321e-11, disciminator loss fake = 1.4426740335693466e-07, generator loss = 16.141910552978516\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 7, Batch: 236/468, discriminator loss real = 1.2872707344513401e-09, disciminator loss fake = 1.5054899904498598e-07, generator loss = 16.34575080871582\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 7, Batch: 237/468, discriminator loss real = 3.3349766599287314e-15, disciminator loss fake = 1.3522156905310112e-07, generator loss = 16.2066650390625\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 7, Batch: 238/468, discriminator loss real = 5.457728019520047e-12, disciminator loss fake = 1.5993867918950855e-07, generator loss = 16.286418914794922\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 7, Batch: 239/468, discriminator loss real = 5.7532298898348676e-15, disciminator loss fake = 1.678835985785554e-07, generator loss = 16.270036697387695\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 7, Batch: 240/468, discriminator loss real = 6.45288197875793e-11, disciminator loss fake = 1.522308252788207e-07, generator loss = 16.35296058654785\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 7, Batch: 241/468, discriminator loss real = 2.4455514924335425e-14, disciminator loss fake = 1.2433743279416376e-07, generator loss = 16.317476272583008\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 7, Batch: 242/468, discriminator loss real = 2.1731880958895255e-16, disciminator loss fake = 1.727310063870391e-07, generator loss = 16.214445114135742\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 7, Batch: 243/468, discriminator loss real = 1.0975874431551347e-08, disciminator loss fake = 1.7147283415397396e-07, generator loss = 16.339008331298828\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 7, Batch: 244/468, discriminator loss real = 7.129619160675671e-13, disciminator loss fake = 1.9117814531455224e-07, generator loss = 16.12604522705078\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 7, Batch: 245/468, discriminator loss real = 4.430155461226937e-12, disciminator loss fake = 1.5000567543665966e-07, generator loss = 16.475109100341797\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 7, Batch: 246/468, discriminator loss real = 5.1360903377539735e-12, disciminator loss fake = 1.3355860062347347e-07, generator loss = 16.175273895263672\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 7, Batch: 247/468, discriminator loss real = 1.252140210093733e-13, disciminator loss fake = 2.0681908097230917e-07, generator loss = 16.2813720703125\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 7, Batch: 248/468, discriminator loss real = 1.7368632573844245e-12, disciminator loss fake = 1.347688254327295e-07, generator loss = 16.255842208862305\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 7, Batch: 249/468, discriminator loss real = 4.7403975855786484e-08, disciminator loss fake = 1.5486806148601318e-07, generator loss = 16.312599182128906\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 7, Batch: 250/468, discriminator loss real = 1.3275386123723365e-08, disciminator loss fake = 1.3694285883047996e-07, generator loss = 16.098594665527344\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 7, Batch: 251/468, discriminator loss real = 3.1501140584921927e-10, disciminator loss fake = 1.5716673829047068e-07, generator loss = 16.228178024291992\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 7, Batch: 252/468, discriminator loss real = 9.06436037340086e-12, disciminator loss fake = 1.7432694221497513e-07, generator loss = 16.25491714477539\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 7, Batch: 253/468, discriminator loss real = 3.0793870058054562e-12, disciminator loss fake = 1.7893667347834707e-07, generator loss = 16.14876365661621\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 7, Batch: 254/468, discriminator loss real = 1.3403542165058013e-11, disciminator loss fake = 1.6325911644798907e-07, generator loss = 16.36180305480957\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 7, Batch: 255/468, discriminator loss real = 3.7390863381848646e-14, disciminator loss fake = 1.0058997190753871e-07, generator loss = 16.26911735534668\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 7, Batch: 256/468, discriminator loss real = 7.08297136498004e-08, disciminator loss fake = 1.3288691036450473e-07, generator loss = 16.390640258789062\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 7, Batch: 257/468, discriminator loss real = 2.04118582388009e-13, disciminator loss fake = 1.2087778600289312e-07, generator loss = 16.314937591552734\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 7, Batch: 258/468, discriminator loss real = 1.3257658046470638e-14, disciminator loss fake = 1.600539860646677e-07, generator loss = 16.280345916748047\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 7, Batch: 259/468, discriminator loss real = 1.1159760724029077e-14, disciminator loss fake = 1.478771736174167e-07, generator loss = 16.2149715423584\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 7, Batch: 260/468, discriminator loss real = 5.867402397274901e-11, disciminator loss fake = 1.8746223418020236e-07, generator loss = 16.26485824584961\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 7, Batch: 261/468, discriminator loss real = 2.442172805061887e-16, disciminator loss fake = 1.5905980887964688e-07, generator loss = 16.394746780395508\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 7, Batch: 262/468, discriminator loss real = 1.4880227583967398e-13, disciminator loss fake = 1.2724673581487878e-07, generator loss = 16.376874923706055\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 7, Batch: 263/468, discriminator loss real = 4.0315611959940156e-11, disciminator loss fake = 1.524672370578628e-07, generator loss = 16.299047470092773\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 7, Batch: 264/468, discriminator loss real = 3.854942463021871e-07, disciminator loss fake = 1.4654401070401946e-07, generator loss = 16.308591842651367\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 7, Batch: 265/468, discriminator loss real = 1.6297176824199566e-13, disciminator loss fake = 1.451759601422964e-07, generator loss = 16.3065242767334\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 7, Batch: 266/468, discriminator loss real = 1.245161001861561e-06, disciminator loss fake = 1.3921589925303124e-07, generator loss = 16.316822052001953\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 7, Batch: 267/468, discriminator loss real = 9.578959228194375e-15, disciminator loss fake = 1.3455010616780783e-07, generator loss = 16.433143615722656\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 7, Batch: 268/468, discriminator loss real = 3.5806115559512686e-14, disciminator loss fake = 1.0961849028490178e-07, generator loss = 16.341094970703125\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 7, Batch: 269/468, discriminator loss real = 2.4766573340773146e-12, disciminator loss fake = 1.2439915053619188e-07, generator loss = 16.38442611694336\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 7, Batch: 270/468, discriminator loss real = 1.4495282144727506e-12, disciminator loss fake = 1.448234456802311e-07, generator loss = 16.39719009399414\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 7, Batch: 271/468, discriminator loss real = 3.649625046620031e-10, disciminator loss fake = 1.5491241356357932e-07, generator loss = 16.40184783935547\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 7, Batch: 272/468, discriminator loss real = 3.0427663427062823e-12, disciminator loss fake = 1.5001022291016852e-07, generator loss = 16.35553741455078\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 7, Batch: 273/468, discriminator loss real = 1.0352559738288636e-12, disciminator loss fake = 1.1408678091129332e-07, generator loss = 16.39307975769043\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 7, Batch: 274/468, discriminator loss real = 7.787815547999344e-08, disciminator loss fake = 1.3249180597085797e-07, generator loss = 16.41455841064453\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 7, Batch: 275/468, discriminator loss real = 5.253113499747997e-10, disciminator loss fake = 1.7133635310528916e-07, generator loss = 16.315229415893555\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 7, Batch: 276/468, discriminator loss real = 4.394539399044106e-09, disciminator loss fake = 1.2651642578020983e-07, generator loss = 16.43732452392578\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 7, Batch: 277/468, discriminator loss real = 2.3580696856956296e-12, disciminator loss fake = 1.6215284404097474e-07, generator loss = 16.457658767700195\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 7, Batch: 278/468, discriminator loss real = 7.904184170246312e-14, disciminator loss fake = 1.2665663007283e-07, generator loss = 16.26345443725586\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 7, Batch: 279/468, discriminator loss real = 7.177753129274794e-14, disciminator loss fake = 8.030848874795993e-08, generator loss = 16.463214874267578\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 7, Batch: 280/468, discriminator loss real = 5.2849818271694105e-11, disciminator loss fake = 1.1626293172639635e-07, generator loss = 16.243877410888672\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 7, Batch: 281/468, discriminator loss real = 1.0521938138483011e-12, disciminator loss fake = 1.7142110664281063e-07, generator loss = 16.38306999206543\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 7, Batch: 282/468, discriminator loss real = 2.5787122545813113e-13, disciminator loss fake = 1.3109317364978779e-07, generator loss = 16.388154983520508\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 7, Batch: 283/468, discriminator loss real = 7.971807103324124e-10, disciminator loss fake = 2.0640712250497018e-07, generator loss = 16.367769241333008\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 7, Batch: 284/468, discriminator loss real = 1.687731443315854e-13, disciminator loss fake = 1.5401360542455222e-07, generator loss = 16.26450538635254\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 7, Batch: 285/468, discriminator loss real = 1.0003030305114069e-12, disciminator loss fake = 8.265098472293175e-08, generator loss = 16.360576629638672\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 7, Batch: 286/468, discriminator loss real = 4.0678635530901606e-16, disciminator loss fake = 1.823605941808637e-07, generator loss = 16.205703735351562\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 7, Batch: 287/468, discriminator loss real = 6.5776453633315836e-15, disciminator loss fake = 1.588034024280205e-07, generator loss = 16.409744262695312\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 7, Batch: 288/468, discriminator loss real = 1.3120198287183693e-12, disciminator loss fake = 1.1249572651195194e-07, generator loss = 16.446468353271484\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 7, Batch: 289/468, discriminator loss real = 4.047930419386654e-17, disciminator loss fake = 1.5599188429860078e-07, generator loss = 16.40898895263672\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "Epoch: 7, Batch: 290/468, discriminator loss real = 1.8051411873522966e-13, disciminator loss fake = 1.0135758543583506e-07, generator loss = 16.452287673950195\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 7, Batch: 291/468, discriminator loss real = 2.3777035895733434e-10, disciminator loss fake = 8.018705699441853e-08, generator loss = 16.501239776611328\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 7, Batch: 292/468, discriminator loss real = 2.493245787604792e-08, disciminator loss fake = 1.1155234602711062e-07, generator loss = 16.522729873657227\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 7, Batch: 293/468, discriminator loss real = 3.857120733918862e-10, disciminator loss fake = 1.023653837251004e-07, generator loss = 16.397998809814453\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 7, Batch: 294/468, discriminator loss real = 3.248778633266336e-12, disciminator loss fake = 1.0268984595995789e-07, generator loss = 16.435840606689453\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 7, Batch: 295/468, discriminator loss real = 5.746961382804043e-18, disciminator loss fake = 1.512468514874854e-07, generator loss = 16.519329071044922\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 7, Batch: 296/468, discriminator loss real = 6.294713639221072e-09, disciminator loss fake = 1.4703608997024276e-07, generator loss = 16.371212005615234\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 7, Batch: 297/468, discriminator loss real = 3.992448732725862e-11, disciminator loss fake = 1.2810707517019182e-07, generator loss = 16.421531677246094\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 7, Batch: 298/468, discriminator loss real = 5.0241536625472705e-11, disciminator loss fake = 1.270647516093959e-07, generator loss = 16.495452880859375\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 7, Batch: 299/468, discriminator loss real = 2.344929805886409e-10, disciminator loss fake = 9.581369653233196e-08, generator loss = 16.43153953552246\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 7, Batch: 300/468, discriminator loss real = 1.5779283261962984e-13, disciminator loss fake = 1.6680121461831732e-07, generator loss = 16.544963836669922\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 7, Batch: 301/468, discriminator loss real = 6.458567708422791e-11, disciminator loss fake = 1.970250025351561e-07, generator loss = 16.475385665893555\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 7, Batch: 302/468, discriminator loss real = 1.2041980260169005e-11, disciminator loss fake = 9.364545405787794e-08, generator loss = 16.389545440673828\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 7, Batch: 303/468, discriminator loss real = 8.521636521430231e-12, disciminator loss fake = 1.295469331807908e-07, generator loss = 16.423152923583984\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 7, Batch: 304/468, discriminator loss real = 4.5099685162634795e-13, disciminator loss fake = 1.4150035099191882e-07, generator loss = 16.437652587890625\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 7, Batch: 305/468, discriminator loss real = 8.510737245466219e-18, disciminator loss fake = 1.0558341045907582e-07, generator loss = 16.4681453704834\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 7, Batch: 306/468, discriminator loss real = 1.1319346068100478e-12, disciminator loss fake = 1.283266470863964e-07, generator loss = 16.493619918823242\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 7, Batch: 307/468, discriminator loss real = 3.4583429453505232e-09, disciminator loss fake = 1.243051173105414e-07, generator loss = 16.4835262298584\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 7, Batch: 308/468, discriminator loss real = 2.7789145984336017e-11, disciminator loss fake = 1.058148981769591e-07, generator loss = 16.467195510864258\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 7, Batch: 309/468, discriminator loss real = 2.4933826114903468e-09, disciminator loss fake = 1.0724875210144091e-07, generator loss = 16.573904037475586\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 7, Batch: 310/468, discriminator loss real = 2.664256585260729e-15, disciminator loss fake = 1.231316701932883e-07, generator loss = 16.486125946044922\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 7, Batch: 311/468, discriminator loss real = 9.607666884292598e-10, disciminator loss fake = 1.1908879571365105e-07, generator loss = 16.612762451171875\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 7, Batch: 312/468, discriminator loss real = 3.758959810085116e-11, disciminator loss fake = 1.0807148953517753e-07, generator loss = 16.426315307617188\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 7, Batch: 313/468, discriminator loss real = 3.941045840366586e-12, disciminator loss fake = 1.254826855756619e-07, generator loss = 16.552457809448242\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 7, Batch: 314/468, discriminator loss real = 3.893902127821702e-12, disciminator loss fake = 1.1048563663962341e-07, generator loss = 16.420541763305664\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 7, Batch: 315/468, discriminator loss real = 7.209148100532914e-13, disciminator loss fake = 1.1067213989690572e-07, generator loss = 16.54671287536621\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 7, Batch: 316/468, discriminator loss real = 1.3802510931000783e-15, disciminator loss fake = 1.3005978871660773e-07, generator loss = 16.570362091064453\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 7, Batch: 317/468, discriminator loss real = 5.055781639694279e-13, disciminator loss fake = 1.0695185181930356e-07, generator loss = 16.645130157470703\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 7, Batch: 318/468, discriminator loss real = 7.508020635123313e-16, disciminator loss fake = 1.3619933270092588e-07, generator loss = 16.52757453918457\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 7, Batch: 319/468, discriminator loss real = 2.870778916985728e-05, disciminator loss fake = 1.1775496489008219e-07, generator loss = 16.273197174072266\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 7, Batch: 320/468, discriminator loss real = 1.4275742859972546e-13, disciminator loss fake = 2.286728886247147e-07, generator loss = 16.20604705810547\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 7, Batch: 321/468, discriminator loss real = 1.9324207964593713e-14, disciminator loss fake = 2.1432992980408017e-07, generator loss = 16.03863525390625\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 7, Batch: 322/468, discriminator loss real = 4.1154077771173405e-16, disciminator loss fake = 2.0217808582856378e-07, generator loss = 15.794465065002441\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 7, Batch: 323/468, discriminator loss real = 1.680988383429352e-14, disciminator loss fake = 1.6990638584957196e-07, generator loss = 15.8553466796875\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 7, Batch: 324/468, discriminator loss real = 1.7992461687210692e-11, disciminator loss fake = 3.3334930549244746e-07, generator loss = 15.708975791931152\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 7, Batch: 325/468, discriminator loss real = 1.8023095914144323e-17, disciminator loss fake = 2.863894223992247e-07, generator loss = 15.628711700439453\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 7, Batch: 326/468, discriminator loss real = 5.948517503226447e-13, disciminator loss fake = 2.683389652702317e-07, generator loss = 15.497773170471191\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 7, Batch: 327/468, discriminator loss real = 7.926970711780168e-12, disciminator loss fake = 3.4176605367974844e-07, generator loss = 15.655670166015625\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 7, Batch: 328/468, discriminator loss real = 3.4892129739975616e-14, disciminator loss fake = 3.340323360134789e-07, generator loss = 15.352293014526367\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 7, Batch: 329/468, discriminator loss real = 5.248544366454706e-15, disciminator loss fake = 2.830581422585965e-07, generator loss = 15.401954650878906\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 7, Batch: 330/468, discriminator loss real = 5.3364854446210155e-14, disciminator loss fake = 3.67236367537771e-07, generator loss = 15.376968383789062\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 7, Batch: 331/468, discriminator loss real = 1.0116118880076908e-11, disciminator loss fake = 3.8190972873053397e-07, generator loss = 15.359037399291992\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 7, Batch: 332/468, discriminator loss real = 2.3165911411382467e-09, disciminator loss fake = 4.71845510219282e-07, generator loss = 15.524657249450684\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 7, Batch: 333/468, discriminator loss real = 4.523528253363995e-12, disciminator loss fake = 3.8791469592069916e-07, generator loss = 15.43790054321289\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 7, Batch: 334/468, discriminator loss real = 2.1240471881345258e-10, disciminator loss fake = 3.431834727507521e-07, generator loss = 15.646085739135742\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 7, Batch: 335/468, discriminator loss real = 1.5637889746143718e-13, disciminator loss fake = 3.4032825624308316e-07, generator loss = 15.579911231994629\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 7, Batch: 336/468, discriminator loss real = 5.4004157916398565e-12, disciminator loss fake = 3.424788133088441e-07, generator loss = 15.506025314331055\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 7, Batch: 337/468, discriminator loss real = 4.407529164774174e-15, disciminator loss fake = 2.861685288735316e-07, generator loss = 15.431732177734375\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 7, Batch: 338/468, discriminator loss real = 1.0027674524071273e-10, disciminator loss fake = 4.09370500165096e-07, generator loss = 15.5370512008667\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 7, Batch: 339/468, discriminator loss real = 2.699756329604952e-08, disciminator loss fake = 5.021095716983837e-07, generator loss = 15.338981628417969\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 7, Batch: 340/468, discriminator loss real = 1.8296271615814153e-12, disciminator loss fake = 3.0495266400976107e-07, generator loss = 15.577839851379395\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 7, Batch: 341/468, discriminator loss real = 2.187752149579447e-12, disciminator loss fake = 2.632693281157117e-07, generator loss = 15.550008773803711\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 7, Batch: 342/468, discriminator loss real = 6.305493253862303e-16, disciminator loss fake = 3.6393009850144153e-07, generator loss = 15.646062850952148\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 7, Batch: 343/468, discriminator loss real = 7.193747423454204e-18, disciminator loss fake = 2.9950217594887363e-07, generator loss = 15.357625007629395\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 7, Batch: 344/468, discriminator loss real = 2.8247434413209685e-16, disciminator loss fake = 4.1871564349094115e-07, generator loss = 15.555728912353516\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 7, Batch: 345/468, discriminator loss real = 9.028428231832531e-17, disciminator loss fake = 3.827669559086644e-07, generator loss = 15.5264892578125\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 7, Batch: 346/468, discriminator loss real = 8.018663066877707e-09, disciminator loss fake = 3.5975835999124683e-07, generator loss = 15.468205451965332\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 7, Batch: 347/468, discriminator loss real = 4.191114955087727e-10, disciminator loss fake = 3.6823288951381983e-07, generator loss = 15.615457534790039\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 7, Batch: 348/468, discriminator loss real = 8.735233369971951e-11, disciminator loss fake = 3.443022080773517e-07, generator loss = 15.834026336669922\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 7, Batch: 349/468, discriminator loss real = 1.3750331848565346e-16, disciminator loss fake = 3.283038267909433e-07, generator loss = 15.777469635009766\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 7, Batch: 350/468, discriminator loss real = 2.213263794459408e-09, disciminator loss fake = 3.0603189316025237e-07, generator loss = 15.64334487915039\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 7, Batch: 351/468, discriminator loss real = 2.882715699720033e-16, disciminator loss fake = 2.9580326099676313e-07, generator loss = 15.732614517211914\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 7, Batch: 352/468, discriminator loss real = 1.0013343487713655e-09, disciminator loss fake = 3.536139843163255e-07, generator loss = 15.80948257446289\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 7, Batch: 353/468, discriminator loss real = 3.7695489633372825e-13, disciminator loss fake = 3.2481000289408257e-07, generator loss = 15.82526969909668\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 7, Batch: 354/468, discriminator loss real = 2.0846936669806425e-18, disciminator loss fake = 2.689434097646881e-07, generator loss = 15.87138557434082\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 7, Batch: 355/468, discriminator loss real = 7.228579540496938e-11, disciminator loss fake = 2.7355343945600907e-07, generator loss = 15.717426300048828\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 7, Batch: 356/468, discriminator loss real = 6.329904378432616e-10, disciminator loss fake = 1.8053077610602486e-07, generator loss = 15.7609281539917\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 7, Batch: 357/468, discriminator loss real = 3.251178493091089e-11, disciminator loss fake = 3.407355677609303e-07, generator loss = 15.849393844604492\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 7, Batch: 358/468, discriminator loss real = 1.7257719259111052e-15, disciminator loss fake = 1.736257217999082e-07, generator loss = 15.701347351074219\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 7, Batch: 359/468, discriminator loss real = 1.1986977382916209e-11, disciminator loss fake = 2.3521981518115354e-07, generator loss = 15.738030433654785\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 7, Batch: 360/468, discriminator loss real = 1.936528271073712e-08, disciminator loss fake = 3.1283002499549184e-07, generator loss = 15.869298934936523\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 7, Batch: 361/468, discriminator loss real = 2.456721654722164e-16, disciminator loss fake = 2.4192161163227865e-07, generator loss = 15.86500358581543\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 7, Batch: 362/468, discriminator loss real = 6.740479285838319e-10, disciminator loss fake = 2.569962589404895e-07, generator loss = 15.890214920043945\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 7, Batch: 363/468, discriminator loss real = 6.72022784642401e-11, disciminator loss fake = 2.3805591808923054e-07, generator loss = 15.91020679473877\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 7, Batch: 364/468, discriminator loss real = 4.164564540117856e-15, disciminator loss fake = 2.964965801766084e-07, generator loss = 16.025638580322266\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 7, Batch: 365/468, discriminator loss real = 2.591342591895529e-11, disciminator loss fake = 1.7741088242928527e-07, generator loss = 15.899026870727539\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 7, Batch: 366/468, discriminator loss real = 5.491611905614115e-15, disciminator loss fake = 2.3862662601459306e-07, generator loss = 15.956283569335938\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 7, Batch: 367/468, discriminator loss real = 1.3112066770890052e-12, disciminator loss fake = 2.3842434870857687e-07, generator loss = 15.883598327636719\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 7, Batch: 368/468, discriminator loss real = 7.552952404135671e-13, disciminator loss fake = 1.8371758869761834e-07, generator loss = 15.84387493133545\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 7, Batch: 369/468, discriminator loss real = 3.7632310462276664e-13, disciminator loss fake = 2.309094213615026e-07, generator loss = 16.10539436340332\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 7, Batch: 370/468, discriminator loss real = 5.3629052492788244e-15, disciminator loss fake = 1.8604836782287748e-07, generator loss = 15.858924865722656\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 7, Batch: 371/468, discriminator loss real = 6.246837899390179e-13, disciminator loss fake = 2.393571207903733e-07, generator loss = 16.037675857543945\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 7, Batch: 372/468, discriminator loss real = 3.194096022559028e-15, disciminator loss fake = 1.3742550208917237e-07, generator loss = 16.10337257385254\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 7, Batch: 373/468, discriminator loss real = 9.148250597812088e-15, disciminator loss fake = 2.2862781179355807e-07, generator loss = 15.995402336120605\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 7, Batch: 374/468, discriminator loss real = 3.110767789870514e-20, disciminator loss fake = 1.8867481799134111e-07, generator loss = 15.946623802185059\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 7, Batch: 375/468, discriminator loss real = 1.210576886130632e-12, disciminator loss fake = 1.4627939037836768e-07, generator loss = 16.124738693237305\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 7, Batch: 376/468, discriminator loss real = 7.829792370017685e-10, disciminator loss fake = 2.0040332060489163e-07, generator loss = 15.926322937011719\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 7, Batch: 377/468, discriminator loss real = 3.962981286583173e-17, disciminator loss fake = 2.1186718868193566e-07, generator loss = 16.094594955444336\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 7, Batch: 378/468, discriminator loss real = 4.248762730529876e-10, disciminator loss fake = 1.773210840383399e-07, generator loss = 15.969449996948242\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 7, Batch: 379/468, discriminator loss real = 7.805594278570416e-13, disciminator loss fake = 2.0099727748856822e-07, generator loss = 16.137516021728516\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 7, Batch: 380/468, discriminator loss real = 3.873914183992607e-16, disciminator loss fake = 1.968769396398784e-07, generator loss = 16.05367660522461\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 7, Batch: 381/468, discriminator loss real = 2.5630388478248278e-08, disciminator loss fake = 1.2479236488616152e-07, generator loss = 16.053958892822266\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 7, Batch: 382/468, discriminator loss real = 4.0431267817227223e-14, disciminator loss fake = 1.4640129109011468e-07, generator loss = 16.135658264160156\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 7, Batch: 383/468, discriminator loss real = 3.1211138118436565e-09, disciminator loss fake = 1.6031341942834842e-07, generator loss = 16.070764541625977\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 7, Batch: 384/468, discriminator loss real = 7.274010631027131e-14, disciminator loss fake = 1.5061985436659597e-07, generator loss = 16.153249740600586\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 7, Batch: 385/468, discriminator loss real = 3.616555663765801e-16, disciminator loss fake = 1.938984723892645e-07, generator loss = 16.091428756713867\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 7, Batch: 386/468, discriminator loss real = 5.344157530244066e-14, disciminator loss fake = 2.5020375460371724e-07, generator loss = 15.945735931396484\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 7, Batch: 387/468, discriminator loss real = 6.089568038464711e-15, disciminator loss fake = 2.0030230984957598e-07, generator loss = 16.328990936279297\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 7, Batch: 388/468, discriminator loss real = 2.0162827841802705e-13, disciminator loss fake = 1.8193172479641362e-07, generator loss = 16.039531707763672\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 7, Batch: 389/468, discriminator loss real = 1.4818563585407285e-14, disciminator loss fake = 1.2784511227437179e-07, generator loss = 16.269126892089844\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 7, Batch: 390/468, discriminator loss real = 2.8983862724653805e-18, disciminator loss fake = 1.8615777719332982e-07, generator loss = 16.1709041595459\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 7, Batch: 391/468, discriminator loss real = 3.362066536283237e-08, disciminator loss fake = 2.3234281343320617e-07, generator loss = 16.05694007873535\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 7, Batch: 392/468, discriminator loss real = 7.560254912343176e-14, disciminator loss fake = 1.5223491800497868e-07, generator loss = 16.18058204650879\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 7, Batch: 393/468, discriminator loss real = 2.818124143535972e-15, disciminator loss fake = 1.6480039732869045e-07, generator loss = 15.987829208374023\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 7, Batch: 394/468, discriminator loss real = 2.1983867702049693e-14, disciminator loss fake = 1.691503541678685e-07, generator loss = 16.05974578857422\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 7, Batch: 395/468, discriminator loss real = 1.1113429080605451e-15, disciminator loss fake = 1.5604635450472415e-07, generator loss = 16.23366928100586\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 7, Batch: 396/468, discriminator loss real = 4.674178145230856e-12, disciminator loss fake = 1.5278146747732535e-07, generator loss = 16.318328857421875\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 7, Batch: 397/468, discriminator loss real = 4.154239729992071e-10, disciminator loss fake = 2.2550759126716002e-07, generator loss = 16.176057815551758\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 7, Batch: 398/468, discriminator loss real = 3.354758961945925e-13, disciminator loss fake = 1.7327155887869594e-07, generator loss = 16.09177017211914\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 7, Batch: 399/468, discriminator loss real = 1.1523019951414915e-13, disciminator loss fake = 1.7906396010403114e-07, generator loss = 16.286367416381836\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 7, Batch: 400/468, discriminator loss real = 5.418927084832603e-09, disciminator loss fake = 1.2611170063792088e-07, generator loss = 16.161579132080078\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 7, Batch: 401/468, discriminator loss real = 1.94461677663349e-12, disciminator loss fake = 1.887877374429081e-07, generator loss = 16.16004180908203\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 7, Batch: 402/468, discriminator loss real = 1.9922592464638456e-09, disciminator loss fake = 1.7606387814339541e-07, generator loss = 16.14488410949707\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 7, Batch: 403/468, discriminator loss real = 1.337304087454562e-15, disciminator loss fake = 1.4878807519380643e-07, generator loss = 16.128948211669922\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 7, Batch: 404/468, discriminator loss real = 1.884167301346995e-11, disciminator loss fake = 1.1172754454946698e-07, generator loss = 16.211334228515625\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 7, Batch: 405/468, discriminator loss real = 5.692358476944159e-13, disciminator loss fake = 1.2316638731135754e-07, generator loss = 16.30284881591797\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 7, Batch: 406/468, discriminator loss real = 2.987044747833345e-15, disciminator loss fake = 1.558301789827965e-07, generator loss = 16.283283233642578\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 7, Batch: 407/468, discriminator loss real = 7.724487716131989e-11, disciminator loss fake = 1.5838671174606134e-07, generator loss = 16.287872314453125\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 7, Batch: 408/468, discriminator loss real = 1.9758805702707605e-10, disciminator loss fake = 1.6185875040264364e-07, generator loss = 16.24128532409668\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 7, Batch: 409/468, discriminator loss real = 5.965194158942533e-13, disciminator loss fake = 1.4916574286871764e-07, generator loss = 16.40584373474121\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 7, Batch: 410/468, discriminator loss real = 1.9790475036529642e-08, disciminator loss fake = 1.585800930570258e-07, generator loss = 16.252832412719727\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 7, Batch: 411/468, discriminator loss real = 8.298957766654513e-13, disciminator loss fake = 1.1973996549841104e-07, generator loss = 16.43674659729004\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 7, Batch: 412/468, discriminator loss real = 5.285320588848709e-14, disciminator loss fake = 1.722164029160922e-07, generator loss = 16.295272827148438\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 7, Batch: 413/468, discriminator loss real = 2.537148304782022e-07, disciminator loss fake = 1.110552076966087e-07, generator loss = 16.242517471313477\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 7, Batch: 414/468, discriminator loss real = 3.935935507636684e-13, disciminator loss fake = 1.173154728917325e-07, generator loss = 16.314712524414062\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 7, Batch: 415/468, discriminator loss real = 9.80090388323163e-15, disciminator loss fake = 1.4597726760712249e-07, generator loss = 16.232187271118164\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 7, Batch: 416/468, discriminator loss real = 8.879739825384814e-12, disciminator loss fake = 1.182835092095047e-07, generator loss = 16.691242218017578\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 7, Batch: 417/468, discriminator loss real = 1.2969904013629407e-13, disciminator loss fake = 1.382524601467594e-07, generator loss = 16.431581497192383\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 7, Batch: 418/468, discriminator loss real = 3.888639410476458e-12, disciminator loss fake = 1.4752872345979995e-07, generator loss = 16.379436492919922\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 7, Batch: 419/468, discriminator loss real = 7.319162250496447e-06, disciminator loss fake = 1.3566526035901916e-07, generator loss = 16.33160400390625\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 7, Batch: 420/468, discriminator loss real = 7.873297240879626e-16, disciminator loss fake = 1.75917747924359e-07, generator loss = 16.15018081665039\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 7, Batch: 421/468, discriminator loss real = 2.198859566648892e-10, disciminator loss fake = 1.863269574187143e-07, generator loss = 15.993542671203613\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 7, Batch: 422/468, discriminator loss real = 6.6082152770652325e-12, disciminator loss fake = 2.0829259028687375e-07, generator loss = 16.2025089263916\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 7, Batch: 423/468, discriminator loss real = 2.384975084177704e-14, disciminator loss fake = 2.278273711908696e-07, generator loss = 15.893970489501953\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 7, Batch: 424/468, discriminator loss real = 1.5709664268775438e-14, disciminator loss fake = 2.0264192812646797e-07, generator loss = 15.885211944580078\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 7, Batch: 425/468, discriminator loss real = 5.25041948564169e-16, disciminator loss fake = 1.4722800756317156e-07, generator loss = 15.860038757324219\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 7, Batch: 426/468, discriminator loss real = 6.20889461806079e-13, disciminator loss fake = 2.0317386884016742e-07, generator loss = 16.02927589416504\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 7, Batch: 427/468, discriminator loss real = 6.293805808552794e-14, disciminator loss fake = 1.8283513725236844e-07, generator loss = 15.940713882446289\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 7, Batch: 428/468, discriminator loss real = 1.0757846436587615e-12, disciminator loss fake = 2.0224324259743298e-07, generator loss = 15.957239151000977\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 7, Batch: 429/468, discriminator loss real = 3.060272440189374e-14, disciminator loss fake = 2.24359737899249e-07, generator loss = 15.888471603393555\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 7, Batch: 430/468, discriminator loss real = 2.7843077507212072e-14, disciminator loss fake = 1.5126765617878846e-07, generator loss = 15.880325317382812\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 7, Batch: 431/468, discriminator loss real = 8.20319756567045e-10, disciminator loss fake = 2.6296726218788535e-07, generator loss = 16.00946807861328\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 7, Batch: 432/468, discriminator loss real = 3.043606961073027e-16, disciminator loss fake = 2.529054654587526e-07, generator loss = 15.88787841796875\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 7, Batch: 433/468, discriminator loss real = 1.51235940437644e-10, disciminator loss fake = 1.9820868146780413e-07, generator loss = 16.06611442565918\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 7, Batch: 434/468, discriminator loss real = 7.769862871316851e-16, disciminator loss fake = 1.7149207565125835e-07, generator loss = 15.963134765625\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 7, Batch: 435/468, discriminator loss real = 3.263382619689281e-10, disciminator loss fake = 2.107287428998461e-07, generator loss = 15.814201354980469\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 7, Batch: 436/468, discriminator loss real = 4.597543266232629e-12, disciminator loss fake = 1.4816392024386005e-07, generator loss = 16.03156089782715\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 7, Batch: 437/468, discriminator loss real = 1.7624431585712961e-15, disciminator loss fake = 2.1451512566272868e-07, generator loss = 15.907181739807129\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 7, Batch: 438/468, discriminator loss real = 3.8240672564290867e-13, disciminator loss fake = 2.01636581209641e-07, generator loss = 16.04153060913086\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 7, Batch: 439/468, discriminator loss real = 5.071310345538269e-15, disciminator loss fake = 2.281408058024681e-07, generator loss = 15.997686386108398\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 7, Batch: 440/468, discriminator loss real = 4.1944928433346185e-12, disciminator loss fake = 1.7500316573659802e-07, generator loss = 16.249725341796875\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 7, Batch: 441/468, discriminator loss real = 2.3302121343604654e-10, disciminator loss fake = 2.149598259393315e-07, generator loss = 15.975777626037598\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 7, Batch: 442/468, discriminator loss real = 6.073635518133447e-13, disciminator loss fake = 2.5004155190799793e-07, generator loss = 15.878473281860352\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 7, Batch: 443/468, discriminator loss real = 2.1727008213401344e-12, disciminator loss fake = 1.636340982713591e-07, generator loss = 16.075510025024414\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 7, Batch: 444/468, discriminator loss real = 1.4256597204859167e-12, disciminator loss fake = 1.6209929754040786e-07, generator loss = 16.09812355041504\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 7, Batch: 445/468, discriminator loss real = 7.561341418445278e-13, disciminator loss fake = 1.885859148842428e-07, generator loss = 16.067968368530273\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 7, Batch: 446/468, discriminator loss real = 1.1062936387828438e-14, disciminator loss fake = 1.5283669085874863e-07, generator loss = 16.024269104003906\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 7, Batch: 447/468, discriminator loss real = 4.0054970465794185e-16, disciminator loss fake = 1.949447039351071e-07, generator loss = 16.086158752441406\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 7, Batch: 448/468, discriminator loss real = 1.6973239220369196e-12, disciminator loss fake = 1.5683619380979508e-07, generator loss = 16.276565551757812\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 7, Batch: 449/468, discriminator loss real = 1.5705159612036668e-12, disciminator loss fake = 1.7983519740027987e-07, generator loss = 16.042945861816406\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 7, Batch: 450/468, discriminator loss real = 1.8024495229695958e-09, disciminator loss fake = 1.5049371882014384e-07, generator loss = 16.19115447998047\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 7, Batch: 451/468, discriminator loss real = 2.1653400709354184e-16, disciminator loss fake = 1.5996609192825417e-07, generator loss = 15.955215454101562\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 7, Batch: 452/468, discriminator loss real = 2.5297671943369515e-12, disciminator loss fake = 1.5478008208447136e-07, generator loss = 16.272775650024414\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 7, Batch: 453/468, discriminator loss real = 5.756486842756203e-09, disciminator loss fake = 2.0228675623457093e-07, generator loss = 16.25025177001953\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 7, Batch: 454/468, discriminator loss real = 2.7747127262500726e-08, disciminator loss fake = 1.4662887792837864e-07, generator loss = 16.017776489257812\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 7, Batch: 455/468, discriminator loss real = 4.527378916208136e-09, disciminator loss fake = 1.780689160568727e-07, generator loss = 16.103925704956055\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 7, Batch: 456/468, discriminator loss real = 1.9411812957059738e-07, disciminator loss fake = 1.3205320215092797e-07, generator loss = 16.162872314453125\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 7, Batch: 457/468, discriminator loss real = 1.7610140776169736e-11, disciminator loss fake = 1.8210948837804608e-07, generator loss = 16.163829803466797\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 7, Batch: 458/468, discriminator loss real = 4.286577169609895e-12, disciminator loss fake = 1.1373511199508357e-07, generator loss = 16.324064254760742\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 7, Batch: 459/468, discriminator loss real = 2.4726304581309047e-14, disciminator loss fake = 1.829059499414143e-07, generator loss = 16.350664138793945\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 7, Batch: 460/468, discriminator loss real = 8.781302074378772e-12, disciminator loss fake = 1.8177618699155573e-07, generator loss = 16.328210830688477\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 7, Batch: 461/468, discriminator loss real = 4.357609325461587e-12, disciminator loss fake = 1.5508045692058658e-07, generator loss = 16.133481979370117\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 7, Batch: 462/468, discriminator loss real = 4.459102968053415e-14, disciminator loss fake = 1.538301717118884e-07, generator loss = 16.288177490234375\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 7, Batch: 463/468, discriminator loss real = 9.45187231061247e-16, disciminator loss fake = 1.5463572822227434e-07, generator loss = 16.25408172607422\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 7, Batch: 464/468, discriminator loss real = 1.2873939247981525e-08, disciminator loss fake = 1.367247079997469e-07, generator loss = 16.31931495666504\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 7, Batch: 465/468, discriminator loss real = 1.7250160151801298e-17, disciminator loss fake = 1.2157833850778843e-07, generator loss = 16.251201629638672\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 7, Batch: 466/468, discriminator loss real = 8.479745090784682e-14, disciminator loss fake = 1.7512269323560758e-07, generator loss = 16.256507873535156\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 7, Batch: 467/468, discriminator loss real = 6.108502917899494e-13, disciminator loss fake = 1.420536506202552e-07, generator loss = 16.21155548095703\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 7, Batch: 468/468, discriminator loss real = 3.541066094861489e-13, disciminator loss fake = 1.4793072011798358e-07, generator loss = 16.334217071533203\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 8, Batch: 1/468, discriminator loss real = 4.667057306955813e-16, disciminator loss fake = 1.8609125618240796e-07, generator loss = 16.249324798583984\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 8, Batch: 2/468, discriminator loss real = 7.553832559459295e-11, disciminator loss fake = 1.218631382471358e-07, generator loss = 16.325756072998047\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 8, Batch: 3/468, discriminator loss real = 4.3592026147641627e-13, disciminator loss fake = 1.2810673410967865e-07, generator loss = 16.264751434326172\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 8, Batch: 4/468, discriminator loss real = 6.729159330448597e-13, disciminator loss fake = 1.669151572514238e-07, generator loss = 16.230533599853516\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 8, Batch: 5/468, discriminator loss real = 8.032051586337463e-12, disciminator loss fake = 1.4184794849825266e-07, generator loss = 16.32027816772461\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 8, Batch: 6/468, discriminator loss real = 1.550179429266052e-11, disciminator loss fake = 1.0849073817098542e-07, generator loss = 16.263769149780273\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 8, Batch: 7/468, discriminator loss real = 1.6636015075276525e-14, disciminator loss fake = 2.0383276932989247e-07, generator loss = 16.282033920288086\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 8, Batch: 8/468, discriminator loss real = 2.3748317548588638e-11, disciminator loss fake = 1.507713136561506e-07, generator loss = 16.5144100189209\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 8, Batch: 9/468, discriminator loss real = 7.546152885880183e-20, disciminator loss fake = 1.5829297694835986e-07, generator loss = 16.434423446655273\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 8, Batch: 10/468, discriminator loss real = 4.160654893531346e-12, disciminator loss fake = 1.3467203530126426e-07, generator loss = 16.16362762451172\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 8, Batch: 11/468, discriminator loss real = 6.764647050558402e-16, disciminator loss fake = 1.3995807535138738e-07, generator loss = 16.348716735839844\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 8, Batch: 12/468, discriminator loss real = 6.085446005566457e-17, disciminator loss fake = 1.427889628757839e-07, generator loss = 16.285078048706055\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 8, Batch: 13/468, discriminator loss real = 3.449856096323159e-14, disciminator loss fake = 1.0410477813138641e-07, generator loss = 16.362571716308594\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 8, Batch: 14/468, discriminator loss real = 3.8052198119702834e-16, disciminator loss fake = 1.2345671507318912e-07, generator loss = 16.22060775756836\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 8, Batch: 15/468, discriminator loss real = 1.7355375540484573e-16, disciminator loss fake = 1.0755379520333008e-07, generator loss = 16.410507202148438\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 16/468, discriminator loss real = 7.101703123138514e-13, disciminator loss fake = 1.5242260076320235e-07, generator loss = 16.48625946044922\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 17/468, discriminator loss real = 2.714912967154799e-15, disciminator loss fake = 1.2087267009519564e-07, generator loss = 16.2265567779541\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 8, Batch: 18/468, discriminator loss real = 1.129395275217826e-11, disciminator loss fake = 1.2810454563805251e-07, generator loss = 16.43528938293457\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 8, Batch: 19/468, discriminator loss real = 1.0830778685969224e-17, disciminator loss fake = 1.6051694728957955e-07, generator loss = 16.3409481048584\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 8, Batch: 20/468, discriminator loss real = 2.739826594766459e-12, disciminator loss fake = 1.253854833294099e-07, generator loss = 16.45684051513672\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 21/468, discriminator loss real = 3.1776648369910565e-13, disciminator loss fake = 1.217484424387294e-07, generator loss = 16.44672203063965\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 22/468, discriminator loss real = 2.0722020020041976e-12, disciminator loss fake = 1.1591354365236839e-07, generator loss = 16.49123764038086\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 8, Batch: 23/468, discriminator loss real = 2.9194946643832027e-16, disciminator loss fake = 1.099425617212546e-07, generator loss = 16.38814926147461\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 8, Batch: 24/468, discriminator loss real = 1.180203851314232e-10, disciminator loss fake = 1.1700877422526901e-07, generator loss = 16.315393447875977\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 8, Batch: 25/468, discriminator loss real = 4.51604621753976e-11, disciminator loss fake = 1.6650126610784355e-07, generator loss = 16.42510986328125\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 8, Batch: 26/468, discriminator loss real = 1.238767768918514e-12, disciminator loss fake = 1.2082590217232791e-07, generator loss = 16.384714126586914\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 8, Batch: 27/468, discriminator loss real = 7.345468871556345e-15, disciminator loss fake = 1.3627092698698107e-07, generator loss = 16.503246307373047\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 8, Batch: 28/468, discriminator loss real = 8.570553121367563e-12, disciminator loss fake = 1.4590369801226188e-07, generator loss = 16.217273712158203\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 8, Batch: 29/468, discriminator loss real = 2.2595101499864973e-16, disciminator loss fake = 1.1702822177994676e-07, generator loss = 16.366477966308594\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 8, Batch: 30/468, discriminator loss real = 5.78358860803263e-10, disciminator loss fake = 9.66268274282811e-08, generator loss = 16.41464614868164\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 8, Batch: 31/468, discriminator loss real = 4.878394129631536e-12, disciminator loss fake = 1.1398026344977552e-07, generator loss = 16.262779235839844\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 8, Batch: 32/468, discriminator loss real = 1.691757151034423e-11, disciminator loss fake = 9.950810664349774e-08, generator loss = 16.490737915039062\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 8, Batch: 33/468, discriminator loss real = 8.675595201815874e-15, disciminator loss fake = 1.0644760095601669e-07, generator loss = 16.395835876464844\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 8, Batch: 34/468, discriminator loss real = 7.240741887364413e-14, disciminator loss fake = 1.2077789790509996e-07, generator loss = 16.416704177856445\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 8, Batch: 35/468, discriminator loss real = 2.4569013273509355e-13, disciminator loss fake = 1.1102775943072629e-07, generator loss = 16.384441375732422\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 8, Batch: 36/468, discriminator loss real = 3.779469480978161e-15, disciminator loss fake = 1.414731229942845e-07, generator loss = 16.510459899902344\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 8, Batch: 37/468, discriminator loss real = 4.556392981792631e-16, disciminator loss fake = 1.3493567507794069e-07, generator loss = 16.45125389099121\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 8, Batch: 38/468, discriminator loss real = 1.4265502841503963e-12, disciminator loss fake = 1.3915325780544663e-07, generator loss = 16.634265899658203\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 39/468, discriminator loss real = 3.2649810589521766e-13, disciminator loss fake = 1.2588097320076486e-07, generator loss = 16.51123809814453\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 8, Batch: 40/468, discriminator loss real = 2.4090382466646076e-12, disciminator loss fake = 1.0367311631398479e-07, generator loss = 16.514814376831055\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 8, Batch: 41/468, discriminator loss real = 3.2242465838330184e-15, disciminator loss fake = 1.0826680352238327e-07, generator loss = 16.640933990478516\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 8, Batch: 42/468, discriminator loss real = 4.1644650137465534e-16, disciminator loss fake = 1.0483525869631194e-07, generator loss = 16.57550048828125\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 8, Batch: 43/468, discriminator loss real = 6.659933021735398e-13, disciminator loss fake = 1.2857944398092513e-07, generator loss = 16.52970314025879\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 8, Batch: 44/468, discriminator loss real = 5.187697382780243e-09, disciminator loss fake = 1.35031314130174e-07, generator loss = 16.505935668945312\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 8, Batch: 45/468, discriminator loss real = 1.976115937551981e-10, disciminator loss fake = 9.565320624460583e-08, generator loss = 16.36724090576172\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 46/468, discriminator loss real = 6.9156432730215715e-15, disciminator loss fake = 1.1290639179151185e-07, generator loss = 16.472593307495117\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 8, Batch: 47/468, discriminator loss real = 3.883488091516304e-15, disciminator loss fake = 9.752116625350027e-08, generator loss = 16.475948333740234\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 8, Batch: 48/468, discriminator loss real = 1.734823764677762e-12, disciminator loss fake = 8.240408533310983e-08, generator loss = 16.610191345214844\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 8, Batch: 49/468, discriminator loss real = 1.4328330188995153e-12, disciminator loss fake = 9.608388040760474e-08, generator loss = 16.543968200683594\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 8, Batch: 50/468, discriminator loss real = 3.6118218083818333e-16, disciminator loss fake = 1.0468810529573602e-07, generator loss = 16.603342056274414\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 51/468, discriminator loss real = 5.00579631079745e-08, disciminator loss fake = 1.007008805231635e-07, generator loss = 16.573719024658203\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 8, Batch: 52/468, discriminator loss real = 1.663449326200217e-12, disciminator loss fake = 1.2006256611130084e-07, generator loss = 16.832656860351562\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 8, Batch: 53/468, discriminator loss real = 3.274837320673676e-15, disciminator loss fake = 1.187697407090127e-07, generator loss = 16.49673080444336\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 8, Batch: 54/468, discriminator loss real = 3.3760369716820393e-13, disciminator loss fake = 1.1274399724925388e-07, generator loss = 16.61435317993164\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 55/468, discriminator loss real = 1.5981661794731844e-14, disciminator loss fake = 1.0267892491810926e-07, generator loss = 16.58765411376953\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 8, Batch: 56/468, discriminator loss real = 7.632674238805992e-16, disciminator loss fake = 1.204548709665687e-07, generator loss = 16.614547729492188\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 57/468, discriminator loss real = 1.994602183072458e-12, disciminator loss fake = 1.3239832696854137e-07, generator loss = 16.450576782226562\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 8, Batch: 58/468, discriminator loss real = 4.529191691832191e-12, disciminator loss fake = 1.1157431600850032e-07, generator loss = 16.58163070678711\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 8, Batch: 59/468, discriminator loss real = 5.901008848230305e-13, disciminator loss fake = 9.631479258587206e-08, generator loss = 16.641910552978516\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 8, Batch: 60/468, discriminator loss real = 1.3821414499015638e-11, disciminator loss fake = 8.462721723390132e-08, generator loss = 16.591060638427734\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 8, Batch: 61/468, discriminator loss real = 9.749256957292118e-12, disciminator loss fake = 9.265285427773051e-08, generator loss = 16.696609497070312\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 8, Batch: 62/468, discriminator loss real = 1.4235447130979406e-13, disciminator loss fake = 8.619227997996859e-08, generator loss = 16.68581199645996\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 8, Batch: 63/468, discriminator loss real = 2.6523547897935873e-13, disciminator loss fake = 1.0436870212515714e-07, generator loss = 16.70858383178711\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 8, Batch: 64/468, discriminator loss real = 8.835795593450935e-13, disciminator loss fake = 8.30344788482762e-08, generator loss = 16.64159393310547\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 8, Batch: 65/468, discriminator loss real = 7.447221150869154e-08, disciminator loss fake = 8.924985195335466e-08, generator loss = 16.586151123046875\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 8, Batch: 66/468, discriminator loss real = 2.0906461783119779e-13, disciminator loss fake = 6.82393377360313e-08, generator loss = 16.796791076660156\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 8, Batch: 67/468, discriminator loss real = 1.9981384602463237e-11, disciminator loss fake = 9.93319488884481e-08, generator loss = 16.70443344116211\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 8, Batch: 68/468, discriminator loss real = 1.5859828641356932e-12, disciminator loss fake = 1.2794549775207997e-07, generator loss = 16.717212677001953\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 8, Batch: 69/468, discriminator loss real = 1.0236172091968986e-14, disciminator loss fake = 8.840932963494197e-08, generator loss = 16.56338882446289\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 8, Batch: 70/468, discriminator loss real = 2.6078779028848934e-14, disciminator loss fake = 1.0760810198462423e-07, generator loss = 16.744258880615234\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 8, Batch: 71/468, discriminator loss real = 1.9882734347831388e-11, disciminator loss fake = 8.726858169438856e-08, generator loss = 16.69651222229004\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 8, Batch: 72/468, discriminator loss real = 5.217651311006932e-10, disciminator loss fake = 9.975930481687101e-08, generator loss = 16.754812240600586\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 8, Batch: 73/468, discriminator loss real = 2.906728802533284e-18, disciminator loss fake = 1.0908395609021682e-07, generator loss = 16.705352783203125\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 8, Batch: 74/468, discriminator loss real = 1.7927197226708103e-10, disciminator loss fake = 9.747088824951788e-08, generator loss = 16.67462158203125\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 8, Batch: 75/468, discriminator loss real = 1.1381913207070271e-12, disciminator loss fake = 7.896946385699266e-08, generator loss = 16.71261215209961\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 8, Batch: 76/468, discriminator loss real = 1.101194195508512e-13, disciminator loss fake = 9.421680147170264e-08, generator loss = 16.785099029541016\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 8, Batch: 77/468, discriminator loss real = 1.4213594019753424e-14, disciminator loss fake = 8.793308836629876e-08, generator loss = 16.680538177490234\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 8, Batch: 78/468, discriminator loss real = 2.1847848530320846e-10, disciminator loss fake = 9.828979585790876e-08, generator loss = 16.669509887695312\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 8, Batch: 79/468, discriminator loss real = 2.7886601448173787e-12, disciminator loss fake = 9.467889583447686e-08, generator loss = 16.74380874633789\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 80/468, discriminator loss real = 2.1369765109521181e-16, disciminator loss fake = 1.0805663919200015e-07, generator loss = 16.726871490478516\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 8, Batch: 81/468, discriminator loss real = 2.5710170103998564e-11, disciminator loss fake = 9.068860151728586e-08, generator loss = 16.667491912841797\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 82/468, discriminator loss real = 1.3160425440389423e-13, disciminator loss fake = 9.68383204735801e-08, generator loss = 16.698375701904297\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 8, Batch: 83/468, discriminator loss real = 1.6912236888710908e-10, disciminator loss fake = 9.230231512447062e-08, generator loss = 16.869901657104492\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 8, Batch: 84/468, discriminator loss real = 1.1529619778030036e-15, disciminator loss fake = 7.495177101191075e-08, generator loss = 16.729717254638672\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 8, Batch: 85/468, discriminator loss real = 2.639848246683424e-13, disciminator loss fake = 8.841614373977791e-08, generator loss = 16.7320613861084\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 8, Batch: 86/468, discriminator loss real = 8.151458837351439e-15, disciminator loss fake = 1.0600983557651489e-07, generator loss = 16.74238395690918\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 8, Batch: 87/468, discriminator loss real = 8.120301577419636e-14, disciminator loss fake = 7.474640284499401e-08, generator loss = 16.707414627075195\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 8, Batch: 88/468, discriminator loss real = 7.25614839325317e-08, disciminator loss fake = 7.444293004255087e-08, generator loss = 16.902280807495117\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 8, Batch: 89/468, discriminator loss real = 1.1316847547959696e-07, disciminator loss fake = 1.0017721052690831e-07, generator loss = 16.648094177246094\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 8, Batch: 90/468, discriminator loss real = 2.2250927025923607e-14, disciminator loss fake = 1.1305984770615396e-07, generator loss = 16.66680335998535\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 8, Batch: 91/468, discriminator loss real = 6.242325178897751e-14, disciminator loss fake = 5.942976599726535e-08, generator loss = 16.833843231201172\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 8, Batch: 92/468, discriminator loss real = 2.6702769566366337e-14, disciminator loss fake = 1.0438911601795553e-07, generator loss = 16.853605270385742\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 8, Batch: 93/468, discriminator loss real = 1.1372077324267593e-06, disciminator loss fake = 1.1440458536071674e-07, generator loss = 16.81710433959961\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 8, Batch: 94/468, discriminator loss real = 7.473118478207308e-12, disciminator loss fake = 8.151380370691186e-08, generator loss = 16.82395362854004\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 8, Batch: 95/468, discriminator loss real = 2.197722391442461e-13, disciminator loss fake = 7.955653558155973e-08, generator loss = 16.58660888671875\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 8, Batch: 96/468, discriminator loss real = 1.7577715812847755e-14, disciminator loss fake = 1.0088571400501678e-07, generator loss = 16.702392578125\n",
      "2/2 [==============================] - 0s 39ms/step\n",
      "Epoch: 8, Batch: 97/468, discriminator loss real = 9.651462788695664e-12, disciminator loss fake = 1.1249070297481012e-07, generator loss = 16.60511589050293\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 8, Batch: 98/468, discriminator loss real = 1.850674995196311e-12, disciminator loss fake = 8.375032223284506e-08, generator loss = 16.6926212310791\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 8, Batch: 99/468, discriminator loss real = 9.697570003963651e-12, disciminator loss fake = 1.1760786122749778e-07, generator loss = 16.576866149902344\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 8, Batch: 100/468, discriminator loss real = 2.958572582344339e-14, disciminator loss fake = 8.027294029488985e-08, generator loss = 16.898998260498047\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 8, Batch: 101/468, discriminator loss real = 5.825374037315978e-12, disciminator loss fake = 6.972317834197383e-08, generator loss = 16.749099731445312\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 8, Batch: 102/468, discriminator loss real = 3.180036312402934e-12, disciminator loss fake = 1.105971989545651e-07, generator loss = 16.8244571685791\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 8, Batch: 103/468, discriminator loss real = 1.8602344358207852e-16, disciminator loss fake = 8.683505825501925e-08, generator loss = 16.701190948486328\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 8, Batch: 104/468, discriminator loss real = 4.808686782098448e-09, disciminator loss fake = 7.741019203422184e-08, generator loss = 16.725662231445312\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 8, Batch: 105/468, discriminator loss real = 8.724687096915706e-13, disciminator loss fake = 8.72790479888863e-08, generator loss = 16.61530876159668\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 8, Batch: 106/468, discriminator loss real = 3.6370170763966314e-11, disciminator loss fake = 7.633343557245098e-08, generator loss = 16.828025817871094\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 8, Batch: 107/468, discriminator loss real = 1.8253683287117184e-11, disciminator loss fake = 9.328365990768361e-08, generator loss = 16.644088745117188\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 8, Batch: 108/468, discriminator loss real = 1.049889667391335e-12, disciminator loss fake = 8.42285032831569e-08, generator loss = 16.72705078125\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 8, Batch: 109/468, discriminator loss real = 1.8042753163922953e-13, disciminator loss fake = 1.0258685989583682e-07, generator loss = 16.759319305419922\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 8, Batch: 110/468, discriminator loss real = 1.28191633198306e-13, disciminator loss fake = 1.1389990106636105e-07, generator loss = 16.80731964111328\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 8, Batch: 111/468, discriminator loss real = 9.161556590697728e-06, disciminator loss fake = 1.0498106206568991e-07, generator loss = 16.458534240722656\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 8, Batch: 112/468, discriminator loss real = 1.7023846525174302e-12, disciminator loss fake = 1.1732528548691334e-07, generator loss = 16.595184326171875\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 8, Batch: 113/468, discriminator loss real = 1.5678708602685082e-14, disciminator loss fake = 9.229418651557353e-08, generator loss = 16.34217071533203\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 8, Batch: 114/468, discriminator loss real = 2.6555539451439403e-12, disciminator loss fake = 1.0704133046601783e-07, generator loss = 16.50762939453125\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 8, Batch: 115/468, discriminator loss real = 2.8049307451146494e-17, disciminator loss fake = 1.38578513997345e-07, generator loss = 16.394329071044922\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 8, Batch: 116/468, discriminator loss real = 1.7047784895991153e-13, disciminator loss fake = 9.853162197259735e-08, generator loss = 16.278358459472656\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 8, Batch: 117/468, discriminator loss real = 9.940672959264651e-14, disciminator loss fake = 1.5358828875378094e-07, generator loss = 16.323762893676758\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 8, Batch: 118/468, discriminator loss real = 1.6978080183069344e-13, disciminator loss fake = 1.490459453634685e-07, generator loss = 16.263660430908203\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 8, Batch: 119/468, discriminator loss real = 3.146434501832829e-12, disciminator loss fake = 1.1968782587246096e-07, generator loss = 16.33440399169922\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 8, Batch: 120/468, discriminator loss real = 2.324936243525144e-09, disciminator loss fake = 1.309291377538102e-07, generator loss = 16.30868148803711\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 8, Batch: 121/468, discriminator loss real = 1.564318843486065e-16, disciminator loss fake = 1.2808112614948186e-07, generator loss = 16.389236450195312\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 8, Batch: 122/468, discriminator loss real = 3.8753986727601414e-14, disciminator loss fake = 1.3494585004991677e-07, generator loss = 16.40754508972168\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 8, Batch: 123/468, discriminator loss real = 7.917322837104352e-15, disciminator loss fake = 1.9413849372540426e-07, generator loss = 16.24565887451172\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 8, Batch: 124/468, discriminator loss real = 1.8273765984286924e-15, disciminator loss fake = 1.1973509117524372e-07, generator loss = 16.278738021850586\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 8, Batch: 125/468, discriminator loss real = 1.668348659222829e-08, disciminator loss fake = 1.2969348972546868e-07, generator loss = 16.476490020751953\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 8, Batch: 126/468, discriminator loss real = 2.205479722461323e-12, disciminator loss fake = 1.4686499127947172e-07, generator loss = 16.250835418701172\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 8, Batch: 127/468, discriminator loss real = 2.1532331039714192e-12, disciminator loss fake = 1.3473268722918874e-07, generator loss = 16.336944580078125\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 8, Batch: 128/468, discriminator loss real = 4.4348482134901057e-13, disciminator loss fake = 1.2455309672532167e-07, generator loss = 16.111358642578125\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 8, Batch: 129/468, discriminator loss real = 1.0325837407343386e-10, disciminator loss fake = 1.434768819308374e-07, generator loss = 16.368362426757812\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 8, Batch: 130/468, discriminator loss real = 5.239053080252631e-10, disciminator loss fake = 1.1291042767425097e-07, generator loss = 16.29778289794922\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 8, Batch: 131/468, discriminator loss real = 6.198514580810861e-16, disciminator loss fake = 1.2887025491181703e-07, generator loss = 16.320476531982422\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 8, Batch: 132/468, discriminator loss real = 2.4144253529811976e-07, disciminator loss fake = 1.2667105409036594e-07, generator loss = 16.330554962158203\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 8, Batch: 133/468, discriminator loss real = 1.119945976235659e-11, disciminator loss fake = 1.544513565931993e-07, generator loss = 16.254592895507812\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 8, Batch: 134/468, discriminator loss real = 8.676495286130681e-12, disciminator loss fake = 1.9550677166080277e-07, generator loss = 16.220401763916016\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 8, Batch: 135/468, discriminator loss real = 2.1606665295912514e-13, disciminator loss fake = 1.5736077330075204e-07, generator loss = 16.42430305480957\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 8, Batch: 136/468, discriminator loss real = 1.4602907641783625e-13, disciminator loss fake = 1.2014210426514182e-07, generator loss = 16.306747436523438\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 8, Batch: 137/468, discriminator loss real = 1.4346566545769325e-15, disciminator loss fake = 1.6553124737583857e-07, generator loss = 16.48491668701172\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 8, Batch: 138/468, discriminator loss real = 4.871314115972858e-11, disciminator loss fake = 1.1481726147621885e-07, generator loss = 16.424213409423828\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 139/468, discriminator loss real = 3.6833208705289167e-10, disciminator loss fake = 1.203856072606868e-07, generator loss = 16.35451316833496\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 140/468, discriminator loss real = 3.893036067126321e-12, disciminator loss fake = 1.6282339743156626e-07, generator loss = 16.5050106048584\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 8, Batch: 141/468, discriminator loss real = 7.017549681174283e-18, disciminator loss fake = 1.622619976160422e-07, generator loss = 16.256072998046875\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 8, Batch: 142/468, discriminator loss real = 2.8343851710133094e-08, disciminator loss fake = 1.3297068335305084e-07, generator loss = 16.338823318481445\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 143/468, discriminator loss real = 2.109754259043816e-14, disciminator loss fake = 1.2518920300408354e-07, generator loss = 16.561609268188477\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 8, Batch: 144/468, discriminator loss real = 8.046873063716209e-12, disciminator loss fake = 1.3151137068234675e-07, generator loss = 16.38271713256836\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 8, Batch: 145/468, discriminator loss real = 1.38364485342303e-13, disciminator loss fake = 9.18884524025998e-08, generator loss = 16.653640747070312\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 8, Batch: 146/468, discriminator loss real = 1.7680397076946797e-11, disciminator loss fake = 1.2361620349565783e-07, generator loss = 16.509075164794922\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 147/468, discriminator loss real = 2.470613158500612e-10, disciminator loss fake = 1.1639849617495202e-07, generator loss = 16.43549346923828\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 8, Batch: 148/468, discriminator loss real = 1.5144797308602742e-13, disciminator loss fake = 1.2887298339592235e-07, generator loss = 16.72797393798828\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 8, Batch: 149/468, discriminator loss real = 1.5801598853178167e-13, disciminator loss fake = 1.1326925175580982e-07, generator loss = 16.384191513061523\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 8, Batch: 150/468, discriminator loss real = 9.90872640015128e-13, disciminator loss fake = 1.5967702893249225e-07, generator loss = 16.479061126708984\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 8, Batch: 151/468, discriminator loss real = 8.339631704585357e-21, disciminator loss fake = 1.397370112954377e-07, generator loss = 16.51695442199707\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 8, Batch: 152/468, discriminator loss real = 1.9689777586151536e-11, disciminator loss fake = 1.2122754355914367e-07, generator loss = 16.430557250976562\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 8, Batch: 153/468, discriminator loss real = 1.9997478065830743e-12, disciminator loss fake = 1.0136650985259621e-07, generator loss = 16.294734954833984\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 8, Batch: 154/468, discriminator loss real = 6.002604012803059e-15, disciminator loss fake = 1.0645276660170566e-07, generator loss = 16.49557876586914\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 8, Batch: 155/468, discriminator loss real = 8.52312334207947e-14, disciminator loss fake = 1.3294172163114126e-07, generator loss = 16.30826759338379\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 8, Batch: 156/468, discriminator loss real = 1.220875478621583e-13, disciminator loss fake = 1.1433118629611272e-07, generator loss = 16.3359375\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 8, Batch: 157/468, discriminator loss real = 3.603318815201262e-15, disciminator loss fake = 1.0571899622391356e-07, generator loss = 16.375455856323242\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 8, Batch: 158/468, discriminator loss real = 3.497101425716659e-13, disciminator loss fake = 1.0681455364647263e-07, generator loss = 16.51373863220215\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 8, Batch: 159/468, discriminator loss real = 1.3302527968050981e-08, disciminator loss fake = 9.944101009295991e-08, generator loss = 16.50527000427246\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 8, Batch: 160/468, discriminator loss real = 1.6999427039643411e-12, disciminator loss fake = 9.067933604001155e-08, generator loss = 16.392662048339844\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 8, Batch: 161/468, discriminator loss real = 1.4852195981490083e-16, disciminator loss fake = 1.0451726240034986e-07, generator loss = 16.34666633605957\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 8, Batch: 162/468, discriminator loss real = 1.4322701645141933e-05, disciminator loss fake = 1.2187905440441682e-07, generator loss = 16.189777374267578\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 8, Batch: 163/468, discriminator loss real = 1.5892166055353485e-12, disciminator loss fake = 1.2499532431320404e-07, generator loss = 16.19464111328125\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 8, Batch: 164/468, discriminator loss real = 7.821553056923045e-16, disciminator loss fake = 1.3724195468967082e-07, generator loss = 16.041080474853516\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 8, Batch: 165/468, discriminator loss real = 7.165879218132276e-13, disciminator loss fake = 2.2812858446741302e-07, generator loss = 15.80074691772461\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 8, Batch: 166/468, discriminator loss real = 5.814931869352336e-10, disciminator loss fake = 2.0744927553550951e-07, generator loss = 15.78697681427002\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 8, Batch: 167/468, discriminator loss real = 1.6954225024769232e-14, disciminator loss fake = 2.6453315626895346e-07, generator loss = 15.955421447753906\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 8, Batch: 168/468, discriminator loss real = 8.705370625750053e-12, disciminator loss fake = 4.2881515582848806e-07, generator loss = 15.489517211914062\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 8, Batch: 169/468, discriminator loss real = 3.000144377060429e-16, disciminator loss fake = 3.7774367456222535e-07, generator loss = 15.688690185546875\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 8, Batch: 170/468, discriminator loss real = 7.212840452675267e-15, disciminator loss fake = 5.113545853419055e-07, generator loss = 15.72191047668457\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 8, Batch: 171/468, discriminator loss real = 1.1496299467950166e-09, disciminator loss fake = 4.4049923531019886e-07, generator loss = 15.65351676940918\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 8, Batch: 172/468, discriminator loss real = 1.4667026274062245e-12, disciminator loss fake = 5.786265546703362e-07, generator loss = 15.58759880065918\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 8, Batch: 173/468, discriminator loss real = 1.7155751753743936e-18, disciminator loss fake = 5.440817858470837e-07, generator loss = 15.727118492126465\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 8, Batch: 174/468, discriminator loss real = 9.20489253802793e-15, disciminator loss fake = 5.121221988702018e-07, generator loss = 15.734329223632812\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 8, Batch: 175/468, discriminator loss real = 8.212489390792277e-13, disciminator loss fake = 4.760630645250785e-07, generator loss = 15.582978248596191\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 8, Batch: 176/468, discriminator loss real = 2.7313984407584257e-09, disciminator loss fake = 5.389802026911639e-07, generator loss = 15.472711563110352\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 8, Batch: 177/468, discriminator loss real = 1.2380398993191364e-17, disciminator loss fake = 4.805684739039862e-07, generator loss = 15.724311828613281\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 8, Batch: 178/468, discriminator loss real = 1.152736667039034e-16, disciminator loss fake = 3.814245133071381e-07, generator loss = 15.684711456298828\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 8, Batch: 179/468, discriminator loss real = 9.483330055482311e-15, disciminator loss fake = 3.6620383525587386e-07, generator loss = 15.75548267364502\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 8, Batch: 180/468, discriminator loss real = 4.984628752424967e-17, disciminator loss fake = 3.539763042681443e-07, generator loss = 15.680488586425781\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 8, Batch: 181/468, discriminator loss real = 6.415713416123769e-16, disciminator loss fake = 1.8514595012675272e-07, generator loss = 15.73755168914795\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 8, Batch: 182/468, discriminator loss real = 7.6442505658747e-09, disciminator loss fake = 2.714071456466627e-07, generator loss = 15.822345733642578\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 8, Batch: 183/468, discriminator loss real = 4.0091446649265936e-18, disciminator loss fake = 2.958814775411156e-07, generator loss = 15.90566635131836\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 8, Batch: 184/468, discriminator loss real = 5.247333058518155e-13, disciminator loss fake = 3.263638461703522e-07, generator loss = 15.71193790435791\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 185/468, discriminator loss real = 1.1542203824654873e-11, disciminator loss fake = 3.8559019799322414e-07, generator loss = 15.860949516296387\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 8, Batch: 186/468, discriminator loss real = 6.0747187038663955e-15, disciminator loss fake = 2.294059839869078e-07, generator loss = 16.011859893798828\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 8, Batch: 187/468, discriminator loss real = 4.5019147673882146e-18, disciminator loss fake = 2.8980878141737776e-07, generator loss = 15.71026611328125\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 8, Batch: 188/468, discriminator loss real = 1.9924578480157162e-12, disciminator loss fake = 3.766216991607507e-07, generator loss = 16.06772804260254\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 8, Batch: 189/468, discriminator loss real = 3.1158292634371476e-13, disciminator loss fake = 2.4018231670197565e-07, generator loss = 16.23044204711914\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 8, Batch: 190/468, discriminator loss real = 1.1053737092314719e-10, disciminator loss fake = 2.1652220993928495e-07, generator loss = 15.931468963623047\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 8, Batch: 191/468, discriminator loss real = 1.1045954224268937e-14, disciminator loss fake = 2.1886326351250318e-07, generator loss = 16.14603614807129\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 8, Batch: 192/468, discriminator loss real = 2.584510074403072e-16, disciminator loss fake = 2.465614556967921e-07, generator loss = 15.946325302124023\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 8, Batch: 193/468, discriminator loss real = 7.427763373986374e-14, disciminator loss fake = 2.3730166276436648e-07, generator loss = 15.944023132324219\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 8, Batch: 194/468, discriminator loss real = 2.2314151259172563e-14, disciminator loss fake = 2.62389761473969e-07, generator loss = 16.15328025817871\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 8, Batch: 195/468, discriminator loss real = 2.0014245049140324e-15, disciminator loss fake = 3.0218487268030003e-07, generator loss = 16.10968589782715\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 8, Batch: 196/468, discriminator loss real = 3.9935743600949536e-10, disciminator loss fake = 1.650301157951617e-07, generator loss = 16.213123321533203\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 8, Batch: 197/468, discriminator loss real = 1.7545673572892662e-13, disciminator loss fake = 1.6176143446955393e-07, generator loss = 16.177825927734375\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 8, Batch: 198/468, discriminator loss real = 1.220531595950492e-16, disciminator loss fake = 2.499207312212093e-07, generator loss = 16.101856231689453\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 8, Batch: 199/468, discriminator loss real = 8.060068535144791e-16, disciminator loss fake = 1.4863695696476498e-07, generator loss = 16.19980239868164\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 8, Batch: 200/468, discriminator loss real = 2.3492328349024143e-14, disciminator loss fake = 1.5495743355131708e-07, generator loss = 16.277631759643555\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 8, Batch: 201/468, discriminator loss real = 1.1107869485327271e-10, disciminator loss fake = 1.763514205777028e-07, generator loss = 16.291032791137695\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 8, Batch: 202/468, discriminator loss real = 4.042720544721219e-14, disciminator loss fake = 1.344702553751631e-07, generator loss = 16.35993003845215\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 8, Batch: 203/468, discriminator loss real = 1.2670291519526616e-14, disciminator loss fake = 1.7907296978592058e-07, generator loss = 16.15228271484375\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 8, Batch: 204/468, discriminator loss real = 1.3878370024381081e-12, disciminator loss fake = 1.9278425611446437e-07, generator loss = 16.30754852294922\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 8, Batch: 205/468, discriminator loss real = 4.392899655147886e-10, disciminator loss fake = 2.2517231457186426e-07, generator loss = 16.32867431640625\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 8, Batch: 206/468, discriminator loss real = 3.845598156321933e-13, disciminator loss fake = 1.7676157426649297e-07, generator loss = 16.304569244384766\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 8, Batch: 207/468, discriminator loss real = 3.950097193783364e-12, disciminator loss fake = 1.6269052593997912e-07, generator loss = 16.43050765991211\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 8, Batch: 208/468, discriminator loss real = 1.864981286807746e-13, disciminator loss fake = 2.3910718027764233e-07, generator loss = 16.400558471679688\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 8, Batch: 209/468, discriminator loss real = 7.304855505207986e-12, disciminator loss fake = 9.493180641584331e-08, generator loss = 16.162883758544922\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 8, Batch: 210/468, discriminator loss real = 1.6729788398801154e-13, disciminator loss fake = 1.5822647014829272e-07, generator loss = 16.349355697631836\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 8, Batch: 211/468, discriminator loss real = 3.909025880766137e-13, disciminator loss fake = 1.1334002181229152e-07, generator loss = 16.442184448242188\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 8, Batch: 212/468, discriminator loss real = 9.706449439131495e-20, disciminator loss fake = 1.6567931027111626e-07, generator loss = 16.384998321533203\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 8, Batch: 213/468, discriminator loss real = 1.0171308240103372e-10, disciminator loss fake = 1.480383389207418e-07, generator loss = 16.3211669921875\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 8, Batch: 214/468, discriminator loss real = 8.998674545198999e-19, disciminator loss fake = 1.034781291764375e-07, generator loss = 16.36880111694336\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 8, Batch: 215/468, discriminator loss real = 3.305126625944427e-14, disciminator loss fake = 2.447848714837164e-07, generator loss = 16.510169982910156\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 8, Batch: 216/468, discriminator loss real = 4.2120884651328036e-18, disciminator loss fake = 1.8699930137699994e-07, generator loss = 16.558692932128906\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 8, Batch: 217/468, discriminator loss real = 1.0776232350906412e-08, disciminator loss fake = 1.2747123889766954e-07, generator loss = 16.295597076416016\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 8, Batch: 218/468, discriminator loss real = 2.4646436713737785e-07, disciminator loss fake = 1.6715262063371483e-07, generator loss = 16.288211822509766\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 219/468, discriminator loss real = 5.7319176072212485e-09, disciminator loss fake = 2.1672630623470468e-07, generator loss = 16.55329132080078\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 8, Batch: 220/468, discriminator loss real = 4.2873227752321554e-17, disciminator loss fake = 1.3940845633442223e-07, generator loss = 16.50476837158203\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 8, Batch: 221/468, discriminator loss real = 5.6101255368687375e-14, disciminator loss fake = 9.600517358876459e-08, generator loss = 16.541301727294922\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 8, Batch: 222/468, discriminator loss real = 4.418937798601183e-18, disciminator loss fake = 1.2406505334183748e-07, generator loss = 16.510547637939453\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 8, Batch: 223/468, discriminator loss real = 6.600789359545445e-12, disciminator loss fake = 1.176958051019028e-07, generator loss = 16.586355209350586\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 8, Batch: 224/468, discriminator loss real = 2.499769705469057e-12, disciminator loss fake = 1.521535040183153e-07, generator loss = 16.4794864654541\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 8, Batch: 225/468, discriminator loss real = 1.507047091287017e-12, disciminator loss fake = 1.671010778636628e-07, generator loss = 16.483592987060547\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 8, Batch: 226/468, discriminator loss real = 1.1972878472075316e-14, disciminator loss fake = 1.323205793823945e-07, generator loss = 16.55523681640625\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 8, Batch: 227/468, discriminator loss real = 1.4517122320701592e-17, disciminator loss fake = 1.276636822922228e-07, generator loss = 16.566829681396484\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 8, Batch: 228/468, discriminator loss real = 7.016152524415287e-13, disciminator loss fake = 1.7011976183312072e-07, generator loss = 16.54145050048828\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 8, Batch: 229/468, discriminator loss real = 5.717492246301229e-17, disciminator loss fake = 1.212876838962984e-07, generator loss = 16.604297637939453\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 8, Batch: 230/468, discriminator loss real = 8.125954770177302e-12, disciminator loss fake = 1.3041191948559572e-07, generator loss = 16.7269287109375\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 8, Batch: 231/468, discriminator loss real = 8.060506133541166e-15, disciminator loss fake = 1.1907619068551867e-07, generator loss = 16.544511795043945\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 8, Batch: 232/468, discriminator loss real = 6.966889935136662e-19, disciminator loss fake = 1.7752054759512248e-07, generator loss = 16.671789169311523\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 8, Batch: 233/468, discriminator loss real = 5.594885550675149e-17, disciminator loss fake = 1.6550785630897735e-07, generator loss = 16.62777328491211\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 8, Batch: 234/468, discriminator loss real = 9.47026962058728e-13, disciminator loss fake = 1.0071650535792287e-07, generator loss = 16.538055419921875\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 8, Batch: 235/468, discriminator loss real = 2.2920835368589465e-11, disciminator loss fake = 1.1254245180225553e-07, generator loss = 16.544511795043945\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 8, Batch: 236/468, discriminator loss real = 7.335931992077938e-13, disciminator loss fake = 1.3181515612359362e-07, generator loss = 16.62240982055664\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 8, Batch: 237/468, discriminator loss real = 9.826697227615605e-18, disciminator loss fake = 9.730615602165926e-08, generator loss = 16.59527587890625\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 8, Batch: 238/468, discriminator loss real = 1.2033454961646317e-11, disciminator loss fake = 7.411821911773586e-08, generator loss = 16.544719696044922\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 8, Batch: 239/468, discriminator loss real = 1.3426893535266153e-14, disciminator loss fake = 1.11985890782762e-07, generator loss = 16.739715576171875\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 8, Batch: 240/468, discriminator loss real = 4.689609811592277e-12, disciminator loss fake = 8.79267645359505e-08, generator loss = 16.73331642150879\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 8, Batch: 241/468, discriminator loss real = 6.499670728932552e-14, disciminator loss fake = 1.0295102015334123e-07, generator loss = 16.63394546508789\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 8, Batch: 242/468, discriminator loss real = 9.859048121082722e-14, disciminator loss fake = 1.0885703716212447e-07, generator loss = 16.649917602539062\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 8, Batch: 243/468, discriminator loss real = 2.561857948002455e-10, disciminator loss fake = 1.3515548857867543e-07, generator loss = 16.736719131469727\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 8, Batch: 244/468, discriminator loss real = 7.2436726755720215e-12, disciminator loss fake = 7.406579527469148e-08, generator loss = 16.560012817382812\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 8, Batch: 245/468, discriminator loss real = 2.7802521569697536e-13, disciminator loss fake = 1.1538005395550499e-07, generator loss = 16.77637481689453\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 246/468, discriminator loss real = 2.6859108470320137e-13, disciminator loss fake = 1.5003659825651994e-07, generator loss = 16.71240997314453\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 247/468, discriminator loss real = 7.957960936814772e-15, disciminator loss fake = 1.1040680192309082e-07, generator loss = 16.651519775390625\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 248/468, discriminator loss real = 1.3573883734352421e-05, disciminator loss fake = 1.0865259980619157e-07, generator loss = 16.505050659179688\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 8, Batch: 249/468, discriminator loss real = 6.367941113652464e-13, disciminator loss fake = 1.6032819871725223e-07, generator loss = 16.113201141357422\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 8, Batch: 250/468, discriminator loss real = 3.865557505165762e-14, disciminator loss fake = 1.9809337459264498e-07, generator loss = 15.94359016418457\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 8, Batch: 251/468, discriminator loss real = 1.0921844415738395e-14, disciminator loss fake = 1.9822927299628645e-07, generator loss = 16.12335968017578\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 8, Batch: 252/468, discriminator loss real = 3.2742137993924114e-12, disciminator loss fake = 1.8720712091635505e-07, generator loss = 16.041929244995117\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 8, Batch: 253/468, discriminator loss real = 9.96212898144496e-15, disciminator loss fake = 2.4281763444378157e-07, generator loss = 16.097576141357422\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 8, Batch: 254/468, discriminator loss real = 5.501063607459347e-14, disciminator loss fake = 2.922542421401886e-07, generator loss = 15.852219581604004\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 8, Batch: 255/468, discriminator loss real = 2.798151250635317e-13, disciminator loss fake = 2.408850434676424e-07, generator loss = 15.940702438354492\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 8, Batch: 256/468, discriminator loss real = 8.872823808146746e-13, disciminator loss fake = 4.867639518124633e-07, generator loss = 15.782279968261719\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 8, Batch: 257/468, discriminator loss real = 3.5277932918659216e-14, disciminator loss fake = 2.622519161832315e-07, generator loss = 15.717857360839844\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 258/468, discriminator loss real = 2.1907105018925677e-09, disciminator loss fake = 3.258730032484891e-07, generator loss = 15.651651382446289\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 8, Batch: 259/468, discriminator loss real = 4.469513995020158e-11, disciminator loss fake = 3.7688721477024956e-07, generator loss = 15.837652206420898\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 8, Batch: 260/468, discriminator loss real = 3.911485718655072e-12, disciminator loss fake = 3.2948372563623707e-07, generator loss = 15.79955005645752\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 261/468, discriminator loss real = 3.991905764277881e-12, disciminator loss fake = 3.6117086210651905e-07, generator loss = 15.781085968017578\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 8, Batch: 262/468, discriminator loss real = 8.330963414786285e-14, disciminator loss fake = 3.9885128444439033e-07, generator loss = 15.878052711486816\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 8, Batch: 263/468, discriminator loss real = 2.163585918641214e-16, disciminator loss fake = 4.368952488675859e-07, generator loss = 15.959725379943848\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 264/468, discriminator loss real = 5.143019943094581e-17, disciminator loss fake = 2.8134911644883687e-07, generator loss = 15.722493171691895\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 8, Batch: 265/468, discriminator loss real = 4.594856396408775e-13, disciminator loss fake = 3.1632168884243583e-07, generator loss = 15.848356246948242\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 8, Batch: 266/468, discriminator loss real = 2.666326492928306e-09, disciminator loss fake = 2.8654278594331117e-07, generator loss = 15.826178550720215\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 8, Batch: 267/468, discriminator loss real = 3.707755267092286e-14, disciminator loss fake = 3.323102362173813e-07, generator loss = 15.921866416931152\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 8, Batch: 268/468, discriminator loss real = 6.8105404128770974e-12, disciminator loss fake = 3.896662690294761e-07, generator loss = 15.837814331054688\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 8, Batch: 269/468, discriminator loss real = 1.0396585814476111e-09, disciminator loss fake = 2.1589100640539982e-07, generator loss = 15.924296379089355\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 8, Batch: 270/468, discriminator loss real = 8.928164874077993e-10, disciminator loss fake = 2.4820803901093313e-07, generator loss = 15.822219848632812\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 8, Batch: 271/468, discriminator loss real = 7.523561773581378e-10, disciminator loss fake = 2.500802338545327e-07, generator loss = 16.02399444580078\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 8, Batch: 272/468, discriminator loss real = 1.5792610817168262e-13, disciminator loss fake = 1.9331790213072964e-07, generator loss = 15.837215423583984\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 8, Batch: 273/468, discriminator loss real = 2.825836009634486e-09, disciminator loss fake = 3.2820753403939307e-07, generator loss = 16.160228729248047\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 8, Batch: 274/468, discriminator loss real = 1.1664925969601114e-10, disciminator loss fake = 3.365787222264771e-07, generator loss = 16.201948165893555\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 8, Batch: 275/468, discriminator loss real = 2.073172430711208e-15, disciminator loss fake = 3.5012450894100766e-07, generator loss = 15.882379531860352\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 8, Batch: 276/468, discriminator loss real = 1.9151537994366308e-11, disciminator loss fake = 1.323614355897007e-07, generator loss = 16.104957580566406\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 8, Batch: 277/468, discriminator loss real = 4.617482056739795e-16, disciminator loss fake = 2.2355089868142386e-07, generator loss = 16.15673065185547\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 8, Batch: 278/468, discriminator loss real = 3.982444235495208e-11, disciminator loss fake = 1.6925997670114157e-07, generator loss = 16.006223678588867\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 8, Batch: 279/468, discriminator loss real = 2.099176952055637e-12, disciminator loss fake = 1.3731946069128753e-07, generator loss = 16.14190673828125\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 8, Batch: 280/468, discriminator loss real = 2.994561846755839e-12, disciminator loss fake = 2.22516007397644e-07, generator loss = 16.023822784423828\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 8, Batch: 281/468, discriminator loss real = 3.392910907724288e-17, disciminator loss fake = 1.5268624053987878e-07, generator loss = 16.249774932861328\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 8, Batch: 282/468, discriminator loss real = 1.1066084680544375e-11, disciminator loss fake = 1.4745243959168874e-07, generator loss = 16.222360610961914\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 8, Batch: 283/468, discriminator loss real = 1.4512214130055212e-13, disciminator loss fake = 1.909459967919247e-07, generator loss = 16.273303985595703\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 8, Batch: 284/468, discriminator loss real = 8.948829226468683e-14, disciminator loss fake = 1.4164572803565534e-07, generator loss = 16.27202033996582\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 8, Batch: 285/468, discriminator loss real = 2.2361110088141983e-13, disciminator loss fake = 1.730849419345759e-07, generator loss = 16.22600555419922\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 8, Batch: 286/468, discriminator loss real = 2.3470102168092243e-18, disciminator loss fake = 2.2936330879019806e-07, generator loss = 16.254783630371094\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 8, Batch: 287/468, discriminator loss real = 7.110944930219416e-15, disciminator loss fake = 1.7350285475004057e-07, generator loss = 16.235370635986328\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 8, Batch: 288/468, discriminator loss real = 3.9589608446990304e-14, disciminator loss fake = 1.9352563640495646e-07, generator loss = 16.314306259155273\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 8, Batch: 289/468, discriminator loss real = 2.414838294606536e-12, disciminator loss fake = 1.3988295677336282e-07, generator loss = 16.282630920410156\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 8, Batch: 290/468, discriminator loss real = 4.513756413722283e-15, disciminator loss fake = 1.4997777952885372e-07, generator loss = 16.540555953979492\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 8, Batch: 291/468, discriminator loss real = 6.363013990760922e-15, disciminator loss fake = 1.6438394823126146e-07, generator loss = 16.468101501464844\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 8, Batch: 292/468, discriminator loss real = 5.334275805322509e-20, disciminator loss fake = 1.534908449229988e-07, generator loss = 16.34151840209961\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 8, Batch: 293/468, discriminator loss real = 7.80271819378342e-11, disciminator loss fake = 1.7823411724293692e-07, generator loss = 16.339139938354492\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 8, Batch: 294/468, discriminator loss real = 1.6976229365787012e-17, disciminator loss fake = 1.7958313947019633e-07, generator loss = 16.474376678466797\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 8, Batch: 295/468, discriminator loss real = 4.681828825365183e-19, disciminator loss fake = 1.4816787086147087e-07, generator loss = 16.468408584594727\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 296/468, discriminator loss real = 1.9496701300923046e-16, disciminator loss fake = 1.2956211037362664e-07, generator loss = 16.339950561523438\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 8, Batch: 297/468, discriminator loss real = 9.092077066816077e-15, disciminator loss fake = 1.700490628309126e-07, generator loss = 16.712528228759766\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 8, Batch: 298/468, discriminator loss real = 2.4974156857121566e-12, disciminator loss fake = 1.400914868554537e-07, generator loss = 16.458354949951172\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 8, Batch: 299/468, discriminator loss real = 8.961417491317597e-14, disciminator loss fake = 8.532726525345424e-08, generator loss = 16.467273712158203\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 8, Batch: 300/468, discriminator loss real = 1.731876523081155e-06, disciminator loss fake = 1.3127078091201838e-07, generator loss = 16.412490844726562\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 8, Batch: 301/468, discriminator loss real = 1.4828575938360304e-15, disciminator loss fake = 1.348921188082386e-07, generator loss = 16.47551727294922\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 8, Batch: 302/468, discriminator loss real = 1.7864267641239036e-16, disciminator loss fake = 1.7270463104068767e-07, generator loss = 16.42547035217285\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 8, Batch: 303/468, discriminator loss real = 3.023519878908587e-09, disciminator loss fake = 1.7762138782018155e-07, generator loss = 16.630352020263672\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 8, Batch: 304/468, discriminator loss real = 7.673177236761325e-16, disciminator loss fake = 1.5471792380594707e-07, generator loss = 16.28221893310547\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 8, Batch: 305/468, discriminator loss real = 8.623829630277375e-15, disciminator loss fake = 1.2718280117951508e-07, generator loss = 16.46442413330078\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 8, Batch: 306/468, discriminator loss real = 1.7076303330654902e-17, disciminator loss fake = 1.7251407768981153e-07, generator loss = 16.344226837158203\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 307/468, discriminator loss real = 7.086008619065429e-14, disciminator loss fake = 1.0108321646384866e-07, generator loss = 16.49330711364746\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 8, Batch: 308/468, discriminator loss real = 4.326009062083358e-08, disciminator loss fake = 1.298527081416978e-07, generator loss = 16.283893585205078\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 8, Batch: 309/468, discriminator loss real = 6.586973634609299e-19, disciminator loss fake = 1.2059589948876237e-07, generator loss = 16.46394920349121\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 8, Batch: 310/468, discriminator loss real = 1.7895638313239481e-12, disciminator loss fake = 1.820185389078688e-07, generator loss = 16.495811462402344\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 8, Batch: 311/468, discriminator loss real = 5.476326059294934e-09, disciminator loss fake = 1.1036273406261898e-07, generator loss = 16.570091247558594\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 8, Batch: 312/468, discriminator loss real = 1.245644143388347e-10, disciminator loss fake = 1.2442643537724507e-07, generator loss = 16.269617080688477\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 8, Batch: 313/468, discriminator loss real = 8.376202936279369e-17, disciminator loss fake = 1.6140126035679714e-07, generator loss = 16.66071128845215\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 314/468, discriminator loss real = 1.2395188174474381e-11, disciminator loss fake = 1.0111079973285086e-07, generator loss = 16.533693313598633\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "Epoch: 8, Batch: 315/468, discriminator loss real = 2.816807388467818e-13, disciminator loss fake = 9.664052669222656e-08, generator loss = 16.52892303466797\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 8, Batch: 316/468, discriminator loss real = 1.158835966003755e-16, disciminator loss fake = 1.4882232335367007e-07, generator loss = 16.476806640625\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 317/468, discriminator loss real = 1.323848031198338e-09, disciminator loss fake = 9.593589567202798e-08, generator loss = 16.58439826965332\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 8, Batch: 318/468, discriminator loss real = 5.646555222202151e-17, disciminator loss fake = 1.5063629632550146e-07, generator loss = 16.440956115722656\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 8, Batch: 319/468, discriminator loss real = 1.0132991112854484e-09, disciminator loss fake = 1.2611532440587325e-07, generator loss = 16.533519744873047\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 8, Batch: 320/468, discriminator loss real = 9.398524058012027e-16, disciminator loss fake = 9.817286894531208e-08, generator loss = 16.56332015991211\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 8, Batch: 321/468, discriminator loss real = 1.5316894419470373e-09, disciminator loss fake = 1.091220340754262e-07, generator loss = 16.49471664428711\n",
      "2/2 [==============================] - 0s 39ms/step\n",
      "Epoch: 8, Batch: 322/468, discriminator loss real = 3.269780973758074e-11, disciminator loss fake = 1.1774468333669574e-07, generator loss = 16.3978271484375\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 8, Batch: 323/468, discriminator loss real = 1.4429546424908624e-13, disciminator loss fake = 1.4181026131154795e-07, generator loss = 16.493257522583008\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 8, Batch: 324/468, discriminator loss real = 2.1335664138200094e-11, disciminator loss fake = 1.0665625183037264e-07, generator loss = 16.52116584777832\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 8, Batch: 325/468, discriminator loss real = 5.517311229340946e-18, disciminator loss fake = 1.6033590100050787e-07, generator loss = 16.459280014038086\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 8, Batch: 326/468, discriminator loss real = 1.6912976849578552e-16, disciminator loss fake = 1.1504538122153463e-07, generator loss = 16.388607025146484\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 8, Batch: 327/468, discriminator loss real = 3.8993158418129266e-17, disciminator loss fake = 8.627936409766335e-08, generator loss = 16.556896209716797\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 328/468, discriminator loss real = 1.1762155309523285e-14, disciminator loss fake = 1.0587791621219367e-07, generator loss = 16.69545555114746\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 8, Batch: 329/468, discriminator loss real = 9.631308828950006e-16, disciminator loss fake = 1.0214253620688396e-07, generator loss = 16.655620574951172\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 8, Batch: 330/468, discriminator loss real = 2.6074356895833262e-08, disciminator loss fake = 1.2949385563842952e-07, generator loss = 16.667505264282227\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 8, Batch: 331/468, discriminator loss real = 8.378209557331415e-15, disciminator loss fake = 1.0180993115227466e-07, generator loss = 16.566539764404297\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 8, Batch: 332/468, discriminator loss real = 5.557770498161585e-13, disciminator loss fake = 1.0826330054669597e-07, generator loss = 16.726825714111328\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 8, Batch: 333/468, discriminator loss real = 1.9681509839854922e-13, disciminator loss fake = 1.2835485563300608e-07, generator loss = 16.688961029052734\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 8, Batch: 334/468, discriminator loss real = 5.0647837025697903e-14, disciminator loss fake = 1.1440753411307014e-07, generator loss = 16.71078872680664\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 8, Batch: 335/468, discriminator loss real = 3.229279257194184e-12, disciminator loss fake = 8.247721439147426e-08, generator loss = 16.541038513183594\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 8, Batch: 336/468, discriminator loss real = 6.764903595662302e-15, disciminator loss fake = 1.2030973550736235e-07, generator loss = 16.733678817749023\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 8, Batch: 337/468, discriminator loss real = 6.1945882451341916e-12, disciminator loss fake = 8.998971168239223e-08, generator loss = 16.80853271484375\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 8, Batch: 338/468, discriminator loss real = 3.6512191382322146e-13, disciminator loss fake = 9.644375609241251e-08, generator loss = 16.62139892578125\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 8, Batch: 339/468, discriminator loss real = 3.278596144573598e-11, disciminator loss fake = 1.089838264078935e-07, generator loss = 16.745655059814453\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 8, Batch: 340/468, discriminator loss real = 1.5153455001763218e-14, disciminator loss fake = 1.0726611776590289e-07, generator loss = 16.711088180541992\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 8, Batch: 341/468, discriminator loss real = 1.4220918869513704e-17, disciminator loss fake = 7.591959416686223e-08, generator loss = 16.521669387817383\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 8, Batch: 342/468, discriminator loss real = 2.9200571471997387e-16, disciminator loss fake = 1.3254404507279105e-07, generator loss = 16.758499145507812\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 8, Batch: 343/468, discriminator loss real = 8.028061722342716e-13, disciminator loss fake = 1.1002306621321623e-07, generator loss = 16.657310485839844\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 8, Batch: 344/468, discriminator loss real = 6.678181821423565e-15, disciminator loss fake = 1.1925320109185122e-07, generator loss = 16.741832733154297\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 8, Batch: 345/468, discriminator loss real = 9.550664295879252e-13, disciminator loss fake = 1.0206264988710245e-07, generator loss = 16.918758392333984\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 8, Batch: 346/468, discriminator loss real = 5.793161987583751e-15, disciminator loss fake = 8.246146876444982e-08, generator loss = 16.79233169555664\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 8, Batch: 347/468, discriminator loss real = 9.32392617974953e-13, disciminator loss fake = 1.0576411568763433e-07, generator loss = 16.7904052734375\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 8, Batch: 348/468, discriminator loss real = 2.1404231197782314e-13, disciminator loss fake = 1.316668658546405e-07, generator loss = 16.766511917114258\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 349/468, discriminator loss real = 5.132518322735404e-16, disciminator loss fake = 9.863749994565296e-08, generator loss = 16.54425621032715\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 350/468, discriminator loss real = 3.49516117816636e-14, disciminator loss fake = 7.709093097219011e-08, generator loss = 16.646358489990234\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 8, Batch: 351/468, discriminator loss real = 1.980344360719144e-11, disciminator loss fake = 1.7648906691647426e-07, generator loss = 16.785236358642578\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 8, Batch: 352/468, discriminator loss real = 9.560372784232773e-15, disciminator loss fake = 1.0922431670223887e-07, generator loss = 16.849031448364258\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 8, Batch: 353/468, discriminator loss real = 5.385430184686921e-16, disciminator loss fake = 8.462492928629217e-08, generator loss = 16.820743560791016\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 8, Batch: 354/468, discriminator loss real = 6.935645946448687e-10, disciminator loss fake = 6.44171649355485e-08, generator loss = 16.645313262939453\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 8, Batch: 355/468, discriminator loss real = 7.307289179096213e-16, disciminator loss fake = 7.611411945163127e-08, generator loss = 16.673622131347656\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 8, Batch: 356/468, discriminator loss real = 3.168273821074763e-08, disciminator loss fake = 8.06524269592046e-08, generator loss = 16.734355926513672\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 8, Batch: 357/468, discriminator loss real = 2.9713509874795818e-08, disciminator loss fake = 8.826406627804317e-08, generator loss = 16.87879180908203\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 8, Batch: 358/468, discriminator loss real = 1.2820321160234016e-07, disciminator loss fake = 8.414598084982572e-08, generator loss = 16.898193359375\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 8, Batch: 359/468, discriminator loss real = 2.571075973040941e-15, disciminator loss fake = 6.86641996594517e-08, generator loss = 16.827470779418945\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 8, Batch: 360/468, discriminator loss real = 5.119195733982451e-09, disciminator loss fake = 1.1438772418159715e-07, generator loss = 16.777389526367188\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 8, Batch: 361/468, discriminator loss real = 2.2001787891579028e-10, disciminator loss fake = 9.062695482953131e-08, generator loss = 16.783315658569336\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 8, Batch: 362/468, discriminator loss real = 4.1599292370173013e-14, disciminator loss fake = 7.923205203042016e-08, generator loss = 17.040611267089844\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 8, Batch: 363/468, discriminator loss real = 1.0767656467250853e-14, disciminator loss fake = 7.724678141585173e-08, generator loss = 16.95650291442871\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 8, Batch: 364/468, discriminator loss real = 7.470398431796976e-12, disciminator loss fake = 8.142680485434539e-08, generator loss = 16.929794311523438\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 8, Batch: 365/468, discriminator loss real = 3.780215592996683e-06, disciminator loss fake = 8.755112901326356e-08, generator loss = 16.7292537689209\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 8, Batch: 366/468, discriminator loss real = 2.9403746104605943e-10, disciminator loss fake = 1.2222270129313983e-07, generator loss = 16.813940048217773\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 8, Batch: 367/468, discriminator loss real = 4.313786334435646e-15, disciminator loss fake = 9.74236940010087e-08, generator loss = 16.58768653869629\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 8, Batch: 368/468, discriminator loss real = 8.946794971542715e-10, disciminator loss fake = 1.2151500072832278e-07, generator loss = 16.683521270751953\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 8, Batch: 369/468, discriminator loss real = 1.108558037032914e-11, disciminator loss fake = 1.3093945483433345e-07, generator loss = 16.734886169433594\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 8, Batch: 370/468, discriminator loss real = 6.63605143058632e-11, disciminator loss fake = 1.226516417318635e-07, generator loss = 16.707889556884766\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 371/468, discriminator loss real = 1.1288308985203232e-14, disciminator loss fake = 1.22952002357124e-07, generator loss = 16.762142181396484\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 8, Batch: 372/468, discriminator loss real = 5.401098839008522e-12, disciminator loss fake = 1.1080837936106036e-07, generator loss = 16.67223358154297\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 8, Batch: 373/468, discriminator loss real = 1.8938672448321446e-14, disciminator loss fake = 1.2668182591824007e-07, generator loss = 16.661144256591797\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 8, Batch: 374/468, discriminator loss real = 9.0421455045675e-11, disciminator loss fake = 1.3556990552388015e-07, generator loss = 16.608318328857422\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 8, Batch: 375/468, discriminator loss real = 1.2616440605811536e-16, disciminator loss fake = 1.520970442925318e-07, generator loss = 16.426502227783203\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 8, Batch: 376/468, discriminator loss real = 6.199047847608162e-18, disciminator loss fake = 1.2731689480460773e-07, generator loss = 16.63465118408203\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 8, Batch: 377/468, discriminator loss real = 7.67543717472563e-09, disciminator loss fake = 1.1503882291208356e-07, generator loss = 16.693313598632812\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 8, Batch: 378/468, discriminator loss real = 1.369668538742791e-14, disciminator loss fake = 9.534515754694439e-08, generator loss = 16.77037239074707\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 8, Batch: 379/468, discriminator loss real = 4.1000121592076055e-14, disciminator loss fake = 1.2176252539575216e-07, generator loss = 16.5927791595459\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 8, Batch: 380/468, discriminator loss real = 7.668760510512809e-14, disciminator loss fake = 1.4092049127611972e-07, generator loss = 16.64659309387207\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 8, Batch: 381/468, discriminator loss real = 6.882100445082528e-11, disciminator loss fake = 1.0492321678157168e-07, generator loss = 16.62782859802246\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 8, Batch: 382/468, discriminator loss real = 4.563294098147708e-08, disciminator loss fake = 1.2917416825075634e-07, generator loss = 16.73600959777832\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 8, Batch: 383/468, discriminator loss real = 3.001348058973008e-10, disciminator loss fake = 1.0989266030492217e-07, generator loss = 16.510723114013672\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 8, Batch: 384/468, discriminator loss real = 1.7553196114848874e-16, disciminator loss fake = 1.0405432249172009e-07, generator loss = 16.672164916992188\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 8, Batch: 385/468, discriminator loss real = 1.3758146098080681e-13, disciminator loss fake = 1.3656489272761974e-07, generator loss = 16.61798095703125\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 8, Batch: 386/468, discriminator loss real = 2.5236952793121405e-15, disciminator loss fake = 1.0571128683523057e-07, generator loss = 16.662830352783203\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 8, Batch: 387/468, discriminator loss real = 1.1045506567356313e-15, disciminator loss fake = 1.1031322344479122e-07, generator loss = 16.607898712158203\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 8, Batch: 388/468, discriminator loss real = 5.121815447347959e-14, disciminator loss fake = 1.0700217956127744e-07, generator loss = 16.708982467651367\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 8, Batch: 389/468, discriminator loss real = 8.232539372161462e-15, disciminator loss fake = 1.1563933099978385e-07, generator loss = 16.7415771484375\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 8, Batch: 390/468, discriminator loss real = 5.522430860586784e-14, disciminator loss fake = 9.272175560681717e-08, generator loss = 16.819339752197266\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 8, Batch: 391/468, discriminator loss real = 3.992856562149306e-15, disciminator loss fake = 7.759377496086017e-08, generator loss = 16.88087272644043\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 8, Batch: 392/468, discriminator loss real = 7.590005013380363e-12, disciminator loss fake = 8.566283327127167e-08, generator loss = 16.819480895996094\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 8, Batch: 393/468, discriminator loss real = 3.062991574768738e-17, disciminator loss fake = 1.5332150837821246e-07, generator loss = 16.761585235595703\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 8, Batch: 394/468, discriminator loss real = 1.8353131514547982e-12, disciminator loss fake = 1.0345043222059758e-07, generator loss = 16.681873321533203\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 8, Batch: 395/468, discriminator loss real = 1.4727656621376164e-14, disciminator loss fake = 1.0901941038810037e-07, generator loss = 16.960283279418945\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 8, Batch: 396/468, discriminator loss real = 1.0881090272514202e-13, disciminator loss fake = 1.3660556419381464e-07, generator loss = 16.64031219482422\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 8, Batch: 397/468, discriminator loss real = 5.8800146284128385e-15, disciminator loss fake = 1.0248324144868093e-07, generator loss = 16.739656448364258\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 8, Batch: 398/468, discriminator loss real = 1.366727998136641e-11, disciminator loss fake = 1.0524756532959145e-07, generator loss = 16.694591522216797\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 8, Batch: 399/468, discriminator loss real = 2.564475324803861e-13, disciminator loss fake = 8.677048413119337e-08, generator loss = 16.880970001220703\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 400/468, discriminator loss real = 1.4631752406901732e-11, disciminator loss fake = 8.354468405968873e-08, generator loss = 16.702959060668945\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 8, Batch: 401/468, discriminator loss real = 2.855276265917077e-17, disciminator loss fake = 1.2583700481627602e-07, generator loss = 16.776165008544922\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 8, Batch: 402/468, discriminator loss real = 7.305580587910148e-19, disciminator loss fake = 1.2139157945512125e-07, generator loss = 16.889690399169922\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 8, Batch: 403/468, discriminator loss real = 1.41836389855321e-10, disciminator loss fake = 1.0992408761012484e-07, generator loss = 16.97750473022461\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 8, Batch: 404/468, discriminator loss real = 4.96598849010748e-14, disciminator loss fake = 1.1668998212144288e-07, generator loss = 16.794986724853516\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 8, Batch: 405/468, discriminator loss real = 4.720950193271012e-13, disciminator loss fake = 1.0307068976089795e-07, generator loss = 16.849437713623047\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 8, Batch: 406/468, discriminator loss real = 2.8223747783329145e-09, disciminator loss fake = 8.908011750463629e-08, generator loss = 16.99396514892578\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 8, Batch: 407/468, discriminator loss real = 2.5472348839580827e-13, disciminator loss fake = 8.320066058331577e-08, generator loss = 16.851871490478516\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 8, Batch: 408/468, discriminator loss real = 4.7459623037093834e-12, disciminator loss fake = 7.68283427987626e-08, generator loss = 16.9481258392334\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 8, Batch: 409/468, discriminator loss real = 1.669861398645217e-16, disciminator loss fake = 1.0612683354338515e-07, generator loss = 16.932205200195312\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 8, Batch: 410/468, discriminator loss real = 3.181920029821366e-16, disciminator loss fake = 8.301029907897828e-08, generator loss = 16.802078247070312\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 411/468, discriminator loss real = 1.979127625673094e-11, disciminator loss fake = 6.899556126427342e-08, generator loss = 16.844093322753906\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 8, Batch: 412/468, discriminator loss real = 3.1450457408644055e-18, disciminator loss fake = 9.369338727083232e-08, generator loss = 16.753435134887695\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 8, Batch: 413/468, discriminator loss real = 1.3121785880088055e-09, disciminator loss fake = 1.1916742437279026e-07, generator loss = 17.047170639038086\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 8, Batch: 414/468, discriminator loss real = 6.18329350462782e-15, disciminator loss fake = 1.1360117468939279e-07, generator loss = 16.82903289794922\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 8, Batch: 415/468, discriminator loss real = 6.784348772213741e-17, disciminator loss fake = 8.14573866136925e-08, generator loss = 16.895729064941406\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 8, Batch: 416/468, discriminator loss real = 4.905774617247022e-17, disciminator loss fake = 8.28322370693968e-08, generator loss = 16.96756935119629\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 8, Batch: 417/468, discriminator loss real = 3.398295317022515e-12, disciminator loss fake = 9.36027433340314e-08, generator loss = 16.965900421142578\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 8, Batch: 418/468, discriminator loss real = 1.7506735034202996e-16, disciminator loss fake = 7.827595283060873e-08, generator loss = 16.766578674316406\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch: 8, Batch: 419/468, discriminator loss real = 2.4229446574097757e-11, disciminator loss fake = 8.399514683787856e-08, generator loss = 16.75694465637207\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 8, Batch: 420/468, discriminator loss real = 4.61864921308397e-13, disciminator loss fake = 8.271614859722831e-08, generator loss = 16.858285903930664\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 8, Batch: 421/468, discriminator loss real = 3.655366382536748e-17, disciminator loss fake = 1.0890227031268296e-07, generator loss = 17.040491104125977\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 8, Batch: 422/468, discriminator loss real = 5.29330819176721e-08, disciminator loss fake = 7.209018804132938e-08, generator loss = 16.81763458251953\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 8, Batch: 423/468, discriminator loss real = 6.77985662403402e-13, disciminator loss fake = 9.559836655625986e-08, generator loss = 16.880577087402344\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 8, Batch: 424/468, discriminator loss real = 2.2527647607593904e-14, disciminator loss fake = 7.849138228266384e-08, generator loss = 16.82185173034668\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 8, Batch: 425/468, discriminator loss real = 5.364939178673089e-13, disciminator loss fake = 8.52254657957019e-08, generator loss = 16.875774383544922\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 8, Batch: 426/468, discriminator loss real = 2.0985032288256544e-12, disciminator loss fake = 8.596698819474113e-08, generator loss = 16.876312255859375\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 8, Batch: 427/468, discriminator loss real = 5.144578381077736e-07, disciminator loss fake = 8.150865937750496e-08, generator loss = 17.0383243560791\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 8, Batch: 428/468, discriminator loss real = 3.3090165400513974e-14, disciminator loss fake = 8.319167932313576e-08, generator loss = 16.9881591796875\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 8, Batch: 429/468, discriminator loss real = 8.497350739711251e-11, disciminator loss fake = 6.362650850633145e-08, generator loss = 17.103469848632812\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 430/468, discriminator loss real = 2.9992742095258026e-15, disciminator loss fake = 7.399191304102715e-08, generator loss = 17.00994873046875\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 8, Batch: 431/468, discriminator loss real = 3.197640107258423e-19, disciminator loss fake = 7.710734450938617e-08, generator loss = 17.112640380859375\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 8, Batch: 432/468, discriminator loss real = 2.708708196706277e-14, disciminator loss fake = 6.513467099011905e-08, generator loss = 16.86869239807129\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 8, Batch: 433/468, discriminator loss real = 3.969372747159028e-11, disciminator loss fake = 6.410964914493889e-08, generator loss = 17.04082489013672\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 8, Batch: 434/468, discriminator loss real = 2.243817789349123e-07, disciminator loss fake = 9.661589217557776e-08, generator loss = 16.937358856201172\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 8, Batch: 435/468, discriminator loss real = 9.475292051626047e-14, disciminator loss fake = 6.977435873523063e-08, generator loss = 16.941822052001953\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 8, Batch: 436/468, discriminator loss real = 9.51859793242582e-13, disciminator loss fake = 8.69851390916665e-08, generator loss = 16.9708251953125\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 8, Batch: 437/468, discriminator loss real = 2.521074711839266e-13, disciminator loss fake = 6.445293365686666e-08, generator loss = 16.85025978088379\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 8, Batch: 438/468, discriminator loss real = 4.507189288460722e-08, disciminator loss fake = 7.103950849796092e-08, generator loss = 17.133670806884766\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 8, Batch: 439/468, discriminator loss real = 3.43488248627505e-19, disciminator loss fake = 8.85463080635418e-08, generator loss = 17.01279067993164\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 8, Batch: 440/468, discriminator loss real = 3.9726200302438175e-13, disciminator loss fake = 9.903564546220878e-08, generator loss = 17.298686981201172\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 8, Batch: 441/468, discriminator loss real = 6.343966693113379e-13, disciminator loss fake = 6.752775050244963e-08, generator loss = 16.99004554748535\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 8, Batch: 442/468, discriminator loss real = 5.69523107060016e-13, disciminator loss fake = 7.902261245362752e-08, generator loss = 16.993541717529297\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 8, Batch: 443/468, discriminator loss real = 6.021150646216139e-16, disciminator loss fake = 5.552879400738675e-08, generator loss = 17.127090454101562\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 8, Batch: 444/468, discriminator loss real = 2.0116319295548045e-14, disciminator loss fake = 8.422725272794196e-08, generator loss = 17.028335571289062\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 8, Batch: 445/468, discriminator loss real = 3.0749165810562166e-15, disciminator loss fake = 7.403895807556182e-08, generator loss = 17.005348205566406\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 8, Batch: 446/468, discriminator loss real = 7.055980962272085e-14, disciminator loss fake = 9.004364187603642e-08, generator loss = 17.050457000732422\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 8, Batch: 447/468, discriminator loss real = 1.3259385993683037e-12, disciminator loss fake = 6.356400916729399e-08, generator loss = 17.200618743896484\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 8, Batch: 448/468, discriminator loss real = 1.4105294189603601e-11, disciminator loss fake = 5.10102466932949e-08, generator loss = 16.97970962524414\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 8, Batch: 449/468, discriminator loss real = 1.9693350587539972e-16, disciminator loss fake = 6.078775527385005e-08, generator loss = 17.060375213623047\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 8, Batch: 450/468, discriminator loss real = 2.7782709786698613e-16, disciminator loss fake = 6.231421423308348e-08, generator loss = 17.08658790588379\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 8, Batch: 451/468, discriminator loss real = 1.0704566144616903e-16, disciminator loss fake = 1.225106700530887e-07, generator loss = 17.14846420288086\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 8, Batch: 452/468, discriminator loss real = 6.242338868034381e-10, disciminator loss fake = 7.120496547941002e-08, generator loss = 17.006473541259766\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 8, Batch: 453/468, discriminator loss real = 3.0502715221811423e-15, disciminator loss fake = 6.784230066614327e-08, generator loss = 17.01468276977539\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 8, Batch: 454/468, discriminator loss real = 3.8732453117203136e-13, disciminator loss fake = 7.810938029706449e-08, generator loss = 17.18417739868164\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 8, Batch: 455/468, discriminator loss real = 3.245248736405415e-09, disciminator loss fake = 7.36813703383632e-08, generator loss = 16.92690658569336\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 8, Batch: 456/468, discriminator loss real = 8.457728441213508e-12, disciminator loss fake = 6.263103102810419e-08, generator loss = 17.08860969543457\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 8, Batch: 457/468, discriminator loss real = 5.289434688859895e-12, disciminator loss fake = 8.29818560532658e-08, generator loss = 17.132568359375\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 8, Batch: 458/468, discriminator loss real = 1.4382749548638718e-13, disciminator loss fake = 5.8176745199034485e-08, generator loss = 17.30130958557129\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 8, Batch: 459/468, discriminator loss real = 2.705139497821696e-12, disciminator loss fake = 5.96120059981331e-08, generator loss = 17.1821346282959\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 8, Batch: 460/468, discriminator loss real = 5.13486449812018e-15, disciminator loss fake = 7.328293349928572e-08, generator loss = 17.130084991455078\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 8, Batch: 461/468, discriminator loss real = 1.671279120040684e-16, disciminator loss fake = 8.331510059633729e-08, generator loss = 17.14862060546875\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 8, Batch: 462/468, discriminator loss real = 2.4610603485686333e-11, disciminator loss fake = 6.779130501399777e-08, generator loss = 17.086788177490234\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 8, Batch: 463/468, discriminator loss real = 3.91882122387807e-16, disciminator loss fake = 8.368269277525542e-08, generator loss = 17.17754364013672\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 8, Batch: 464/468, discriminator loss real = 6.31285301810891e-11, disciminator loss fake = 6.800776475301973e-08, generator loss = 17.134309768676758\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 8, Batch: 465/468, discriminator loss real = 1.7850381594859986e-16, disciminator loss fake = 6.62203092360869e-08, generator loss = 17.149629592895508\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 8, Batch: 466/468, discriminator loss real = 1.3194908499158942e-09, disciminator loss fake = 6.476915359598934e-08, generator loss = 17.1658935546875\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 8, Batch: 467/468, discriminator loss real = 1.3920870012285036e-10, disciminator loss fake = 5.187906992887292e-08, generator loss = 17.181005477905273\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 8, Batch: 468/468, discriminator loss real = 1.4771762643379233e-13, disciminator loss fake = 6.221686277285698e-08, generator loss = 17.104637145996094\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 9, Batch: 1/468, discriminator loss real = 1.9229024331211906e-15, disciminator loss fake = 5.501804878349503e-08, generator loss = 17.193523406982422\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 9, Batch: 2/468, discriminator loss real = 9.391002405440409e-16, disciminator loss fake = 5.6291128203156404e-08, generator loss = 17.28721046447754\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 9, Batch: 3/468, discriminator loss real = 8.836169101099356e-13, disciminator loss fake = 1.0649154091879609e-07, generator loss = 17.212665557861328\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 9, Batch: 4/468, discriminator loss real = 2.752590906943131e-13, disciminator loss fake = 7.806312396496651e-08, generator loss = 17.098190307617188\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 9, Batch: 5/468, discriminator loss real = 8.910381088091742e-16, disciminator loss fake = 6.193402413146032e-08, generator loss = 17.312725067138672\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 9, Batch: 6/468, discriminator loss real = 5.365563408073898e-14, disciminator loss fake = 6.131271845788433e-08, generator loss = 17.06766128540039\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 9, Batch: 7/468, discriminator loss real = 2.4793209263407334e-07, disciminator loss fake = 5.6535952808189904e-08, generator loss = 17.233963012695312\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 9, Batch: 8/468, discriminator loss real = 2.3831816728381305e-11, disciminator loss fake = 9.52520622377051e-08, generator loss = 17.375133514404297\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 9, Batch: 9/468, discriminator loss real = 2.7403049447649597e-12, disciminator loss fake = 4.823732524528168e-08, generator loss = 17.316280364990234\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 9, Batch: 10/468, discriminator loss real = 1.58339680478509e-16, disciminator loss fake = 7.869499540902325e-08, generator loss = 17.217002868652344\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 9, Batch: 11/468, discriminator loss real = 1.9750198698709198e-10, disciminator loss fake = 5.2369721004197345e-08, generator loss = 17.198287963867188\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 9, Batch: 12/468, discriminator loss real = 4.019628629947647e-09, disciminator loss fake = 5.014656068169643e-08, generator loss = 17.30443572998047\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 9, Batch: 13/468, discriminator loss real = 3.3936145560353737e-11, disciminator loss fake = 7.611528474171791e-08, generator loss = 17.15599822998047\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 9, Batch: 14/468, discriminator loss real = 3.234117075708032e-13, disciminator loss fake = 6.91776449457393e-08, generator loss = 17.413753509521484\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 9, Batch: 15/468, discriminator loss real = 1.0134543870776724e-08, disciminator loss fake = 6.401911178954833e-08, generator loss = 17.289688110351562\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 9, Batch: 16/468, discriminator loss real = 4.179118599030758e-14, disciminator loss fake = 4.960681820875834e-08, generator loss = 17.314895629882812\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 9, Batch: 17/468, discriminator loss real = 9.063178420238129e-17, disciminator loss fake = 5.479692433141281e-08, generator loss = 17.25666618347168\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 9, Batch: 18/468, discriminator loss real = 1.6728353186175327e-13, disciminator loss fake = 4.5087823252742965e-08, generator loss = 17.050243377685547\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 9, Batch: 19/468, discriminator loss real = 8.991674627090163e-10, disciminator loss fake = 5.533724589668054e-08, generator loss = 17.086139678955078\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 9, Batch: 20/468, discriminator loss real = 5.306903250179573e-10, disciminator loss fake = 7.475576069282397e-08, generator loss = 17.193401336669922\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 9, Batch: 21/468, discriminator loss real = 1.3447521540388874e-16, disciminator loss fake = 7.584153394191162e-08, generator loss = 17.232189178466797\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 9, Batch: 22/468, discriminator loss real = 3.382586094904938e-14, disciminator loss fake = 7.417809655407837e-08, generator loss = 17.280475616455078\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 9, Batch: 23/468, discriminator loss real = 4.947537605298757e-13, disciminator loss fake = 6.139536878890794e-08, generator loss = 17.16590118408203\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 9, Batch: 24/468, discriminator loss real = 8.020474244723185e-17, disciminator loss fake = 4.2836116875832886e-08, generator loss = 17.141965866088867\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 9, Batch: 25/468, discriminator loss real = 1.4175564358004074e-15, disciminator loss fake = 4.529738362180069e-08, generator loss = 17.37885284423828\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 9, Batch: 26/468, discriminator loss real = 1.815259921544854e-11, disciminator loss fake = 4.4159136791677156e-08, generator loss = 17.243221282958984\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 9, Batch: 27/468, discriminator loss real = 6.729693028968003e-14, disciminator loss fake = 4.980312695579414e-08, generator loss = 17.329479217529297\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 9, Batch: 28/468, discriminator loss real = 3.0764788787335067e-18, disciminator loss fake = 5.3701711522080586e-08, generator loss = 17.233905792236328\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 9, Batch: 29/468, discriminator loss real = 2.1045348843744824e-16, disciminator loss fake = 7.839078364213492e-08, generator loss = 17.217369079589844\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 9, Batch: 30/468, discriminator loss real = 5.022770275462914e-15, disciminator loss fake = 5.5820017053065385e-08, generator loss = 17.31890106201172\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 9, Batch: 31/468, discriminator loss real = 3.157495376271413e-10, disciminator loss fake = 6.38523545148928e-08, generator loss = 17.191349029541016\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 9, Batch: 32/468, discriminator loss real = 6.670002221653704e-07, disciminator loss fake = 5.5103754448282416e-08, generator loss = 17.201946258544922\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 9, Batch: 33/468, discriminator loss real = 6.475738829447419e-15, disciminator loss fake = 3.702144013573161e-08, generator loss = 17.22547149658203\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 9, Batch: 34/468, discriminator loss real = 2.038167967732818e-10, disciminator loss fake = 5.075745690419353e-08, generator loss = 17.1611328125\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 9, Batch: 35/468, discriminator loss real = 6.378985339082488e-13, disciminator loss fake = 6.471707791888548e-08, generator loss = 17.23834800720215\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 9, Batch: 36/468, discriminator loss real = 1.001361672617676e-13, disciminator loss fake = 6.10810033663256e-08, generator loss = 17.13007926940918\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 9, Batch: 37/468, discriminator loss real = 4.93688148864463e-18, disciminator loss fake = 4.939134612413909e-08, generator loss = 17.280426025390625\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 9, Batch: 38/468, discriminator loss real = 4.94199414311831e-16, disciminator loss fake = 3.8944335756241344e-08, generator loss = 17.241689682006836\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 9, Batch: 39/468, discriminator loss real = 2.435089110875647e-14, disciminator loss fake = 4.996908131715827e-08, generator loss = 17.39608383178711\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 9, Batch: 40/468, discriminator loss real = 1.738026226844741e-14, disciminator loss fake = 4.4111597929941126e-08, generator loss = 17.314716339111328\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 9, Batch: 41/468, discriminator loss real = 1.8985935139772782e-16, disciminator loss fake = 4.7370562583637366e-08, generator loss = 17.213153839111328\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 9, Batch: 42/468, discriminator loss real = 5.739488398437409e-11, disciminator loss fake = 6.628951609854994e-08, generator loss = 17.37106704711914\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 9, Batch: 43/468, discriminator loss real = 9.117695747712373e-13, disciminator loss fake = 6.146559172748312e-08, generator loss = 17.212188720703125\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 9, Batch: 44/468, discriminator loss real = 1.4812158322260148e-14, disciminator loss fake = 6.472628655274093e-08, generator loss = 17.203845977783203\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 9, Batch: 45/468, discriminator loss real = 8.235474764840172e-16, disciminator loss fake = 4.759691663025478e-08, generator loss = 17.329864501953125\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 9, Batch: 46/468, discriminator loss real = 6.755290771209843e-13, disciminator loss fake = 5.625621213312115e-08, generator loss = 17.336223602294922\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 9, Batch: 47/468, discriminator loss real = 5.180997724075912e-15, disciminator loss fake = 1.0788209436896068e-07, generator loss = 17.34445571899414\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 9, Batch: 48/468, discriminator loss real = 3.1124136512517e-07, disciminator loss fake = 6.680812703052652e-08, generator loss = 17.07779312133789\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 9, Batch: 49/468, discriminator loss real = 1.2220519735040014e-11, disciminator loss fake = 6.106417060891545e-08, generator loss = 17.168170928955078\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 9, Batch: 50/468, discriminator loss real = 3.124831258550023e-14, disciminator loss fake = 4.4123542153329254e-08, generator loss = 17.293933868408203\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 9, Batch: 51/468, discriminator loss real = 7.906246187253108e-14, disciminator loss fake = 7.88654048733406e-08, generator loss = 17.088111877441406\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 9, Batch: 52/468, discriminator loss real = 6.549200514655126e-16, disciminator loss fake = 4.6166249489942857e-08, generator loss = 17.183706283569336\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 9, Batch: 53/468, discriminator loss real = 2.938421207743236e-12, disciminator loss fake = 6.353192816277442e-08, generator loss = 17.400588989257812\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 9, Batch: 54/468, discriminator loss real = 1.8716302053349077e-16, disciminator loss fake = 5.6152043015345043e-08, generator loss = 17.205432891845703\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 9, Batch: 55/468, discriminator loss real = 1.0092617713786112e-11, disciminator loss fake = 5.729502561280242e-08, generator loss = 17.30422592163086\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 9, Batch: 56/468, discriminator loss real = 2.469360445086382e-16, disciminator loss fake = 7.319682993056631e-08, generator loss = 17.311880111694336\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 9, Batch: 57/468, discriminator loss real = 3.092130995696607e-09, disciminator loss fake = 6.745896996562806e-08, generator loss = 17.192058563232422\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 9, Batch: 58/468, discriminator loss real = 7.463029760151896e-13, disciminator loss fake = 3.480598564920001e-08, generator loss = 17.291664123535156\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 9, Batch: 59/468, discriminator loss real = 1.693628050303264e-11, disciminator loss fake = 5.2286882379348754e-08, generator loss = 17.12479019165039\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 9, Batch: 60/468, discriminator loss real = 5.476752940047902e-10, disciminator loss fake = 6.781118599974434e-08, generator loss = 17.229570388793945\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 9, Batch: 61/468, discriminator loss real = 3.030075973117774e-12, disciminator loss fake = 5.0389470374057055e-08, generator loss = 17.413328170776367\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 9, Batch: 62/468, discriminator loss real = 9.119682717600042e-15, disciminator loss fake = 5.553209092568068e-08, generator loss = 17.39004135131836\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 9, Batch: 63/468, discriminator loss real = 4.0594226114257226e-13, disciminator loss fake = 4.787479213064216e-08, generator loss = 17.195632934570312\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 9, Batch: 64/468, discriminator loss real = 2.4146880051034714e-09, disciminator loss fake = 5.911888578680191e-08, generator loss = 17.234981536865234\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 9, Batch: 65/468, discriminator loss real = 2.2324603277112942e-10, disciminator loss fake = 4.7536101277501075e-08, generator loss = 17.402477264404297\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 9, Batch: 66/468, discriminator loss real = 1.2146843253457718e-10, disciminator loss fake = 5.371133227072278e-08, generator loss = 17.330991744995117\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 9, Batch: 67/468, discriminator loss real = 5.12835399146816e-11, disciminator loss fake = 5.7683397614027854e-08, generator loss = 17.281017303466797\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 9, Batch: 68/468, discriminator loss real = 3.799217190847415e-11, disciminator loss fake = 4.7251234036593814e-08, generator loss = 17.170244216918945\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 9, Batch: 69/468, discriminator loss real = 9.79889236418785e-08, disciminator loss fake = 6.196830071303339e-08, generator loss = 17.221817016601562\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 9, Batch: 70/468, discriminator loss real = 1.697545641381193e-12, disciminator loss fake = 5.4288783246647654e-08, generator loss = 17.297513961791992\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 9, Batch: 71/468, discriminator loss real = 8.133361172057985e-12, disciminator loss fake = 5.3171692826481376e-08, generator loss = 17.2617130279541\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 9, Batch: 72/468, discriminator loss real = 1.6061624252827755e-11, disciminator loss fake = 6.609576530536287e-08, generator loss = 17.326261520385742\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 9, Batch: 73/468, discriminator loss real = 2.0308434838314793e-13, disciminator loss fake = 3.468146303475805e-08, generator loss = 17.282939910888672\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 9, Batch: 74/468, discriminator loss real = 1.1946188829825566e-11, disciminator loss fake = 3.751108579308493e-08, generator loss = 17.355979919433594\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 9, Batch: 75/468, discriminator loss real = 4.0746479107456324e-11, disciminator loss fake = 5.8852069884096636e-08, generator loss = 17.56412696838379\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 9, Batch: 76/468, discriminator loss real = 2.1777534203043514e-12, disciminator loss fake = 4.625880478670297e-08, generator loss = 17.1671142578125\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 9, Batch: 77/468, discriminator loss real = 1.0477335416359673e-13, disciminator loss fake = 3.717141794368217e-08, generator loss = 17.367393493652344\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 9, Batch: 78/468, discriminator loss real = 2.4168520785927e-16, disciminator loss fake = 6.386991913132078e-08, generator loss = 17.3494815826416\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 9, Batch: 79/468, discriminator loss real = 9.485782215864613e-16, disciminator loss fake = 4.245814722025898e-08, generator loss = 17.299745559692383\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 9, Batch: 80/468, discriminator loss real = 4.7673419845042225e-15, disciminator loss fake = 4.3098538071717485e-08, generator loss = 17.343318939208984\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 9, Batch: 81/468, discriminator loss real = 8.332280889832445e-15, disciminator loss fake = 5.564501748267503e-08, generator loss = 17.352153778076172\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 9, Batch: 82/468, discriminator loss real = 5.5169264989718414e-11, disciminator loss fake = 5.839928007844719e-08, generator loss = 17.359439849853516\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 9, Batch: 83/468, discriminator loss real = 1.5532308512283821e-12, disciminator loss fake = 3.751716093347568e-08, generator loss = 17.400882720947266\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 9, Batch: 84/468, discriminator loss real = 1.7224027715201373e-06, disciminator loss fake = 5.975481087716616e-08, generator loss = 17.21151351928711\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 9, Batch: 85/468, discriminator loss real = 1.472666016910651e-10, disciminator loss fake = 5.029206917583906e-08, generator loss = 17.268611907958984\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 9, Batch: 86/468, discriminator loss real = 7.410644668715775e-15, disciminator loss fake = 6.017603482177947e-08, generator loss = 17.254718780517578\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 9, Batch: 87/468, discriminator loss real = 4.3697112612616374e-15, disciminator loss fake = 4.572888911980044e-08, generator loss = 17.31110382080078\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 9, Batch: 88/468, discriminator loss real = 4.453224474696175e-15, disciminator loss fake = 5.919888934613482e-08, generator loss = 17.49650001525879\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 9, Batch: 89/468, discriminator loss real = 5.632127471783552e-15, disciminator loss fake = 5.4256705794841764e-08, generator loss = 17.43651580810547\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 9, Batch: 90/468, discriminator loss real = 6.238543102249361e-12, disciminator loss fake = 4.613935544739434e-08, generator loss = 17.359012603759766\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 9, Batch: 91/468, discriminator loss real = 8.084691249798936e-11, disciminator loss fake = 4.912839557391635e-08, generator loss = 17.421585083007812\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 9, Batch: 92/468, discriminator loss real = 1.023797366328516e-10, disciminator loss fake = 4.834899058892006e-08, generator loss = 17.268709182739258\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 9, Batch: 93/468, discriminator loss real = 8.082625948972459e-17, disciminator loss fake = 6.702798316382541e-08, generator loss = 17.16634750366211\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 9, Batch: 94/468, discriminator loss real = 1.800606419521955e-08, disciminator loss fake = 5.093461297178692e-08, generator loss = 17.261674880981445\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 9, Batch: 95/468, discriminator loss real = 7.781263827721929e-11, disciminator loss fake = 6.28434264626776e-08, generator loss = 17.42047882080078\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 9, Batch: 96/468, discriminator loss real = 9.291747926631899e-11, disciminator loss fake = 6.712111400020149e-08, generator loss = 17.271404266357422\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 9, Batch: 97/468, discriminator loss real = 3.16810076436691e-12, disciminator loss fake = 5.787978096805091e-08, generator loss = 17.275903701782227\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 9, Batch: 98/468, discriminator loss real = 1.6070630937115027e-11, disciminator loss fake = 4.619933235971985e-08, generator loss = 17.291229248046875\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 9, Batch: 99/468, discriminator loss real = 7.486612406777053e-16, disciminator loss fake = 6.239287131393212e-08, generator loss = 17.299158096313477\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 9, Batch: 100/468, discriminator loss real = 4.901293892365386e-15, disciminator loss fake = 7.258719847413886e-08, generator loss = 17.27642059326172\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 9, Batch: 101/468, discriminator loss real = 1.2299586262670692e-12, disciminator loss fake = 4.289999466777772e-08, generator loss = 17.332157135009766\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 9, Batch: 102/468, discriminator loss real = 3.838640153354736e-14, disciminator loss fake = 8.098575676740438e-08, generator loss = 17.204307556152344\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 9, Batch: 103/468, discriminator loss real = 2.132228414826725e-15, disciminator loss fake = 4.583093726751031e-08, generator loss = 17.35538101196289\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 9, Batch: 104/468, discriminator loss real = 3.081569133200901e-08, disciminator loss fake = 7.143053437630442e-08, generator loss = 17.329681396484375\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 9, Batch: 105/468, discriminator loss real = 2.169091288691232e-15, disciminator loss fake = 8.353624991741526e-08, generator loss = 17.334331512451172\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 9, Batch: 106/468, discriminator loss real = 7.1512270931328725e-12, disciminator loss fake = 6.702858001972345e-08, generator loss = 17.394329071044922\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 9, Batch: 107/468, discriminator loss real = 4.410162773166304e-12, disciminator loss fake = 5.552648474349553e-08, generator loss = 17.27326774597168\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 9, Batch: 108/468, discriminator loss real = 3.809823414862787e-14, disciminator loss fake = 6.208871639046265e-08, generator loss = 17.36516571044922\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 9, Batch: 109/468, discriminator loss real = 3.543696933117069e-11, disciminator loss fake = 5.4831005513733544e-08, generator loss = 17.42906951904297\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 9, Batch: 110/468, discriminator loss real = 9.213682039543869e-10, disciminator loss fake = 5.1039567239286043e-08, generator loss = 17.302608489990234\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 9, Batch: 111/468, discriminator loss real = 1.9657218967806742e-14, disciminator loss fake = 5.717210171951592e-08, generator loss = 17.430150985717773\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 9, Batch: 112/468, discriminator loss real = 1.881303374532111e-15, disciminator loss fake = 3.8327144125105406e-08, generator loss = 17.202861785888672\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 9, Batch: 113/468, discriminator loss real = 1.6291811649749022e-11, disciminator loss fake = 5.8764193511251506e-08, generator loss = 17.42232322692871\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 9, Batch: 114/468, discriminator loss real = 1.0020786886545048e-17, disciminator loss fake = 5.96195803836963e-08, generator loss = 17.347869873046875\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 9, Batch: 115/468, discriminator loss real = 1.561285822848646e-13, disciminator loss fake = 5.081181342347918e-08, generator loss = 17.452320098876953\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 9, Batch: 116/468, discriminator loss real = 4.788094609349308e-17, disciminator loss fake = 6.42783533066904e-08, generator loss = 17.561376571655273\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 9, Batch: 117/468, discriminator loss real = 1.6722551137541577e-15, disciminator loss fake = 7.202380203352732e-08, generator loss = 17.21975326538086\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 9, Batch: 118/468, discriminator loss real = 1.6074543509603245e-06, disciminator loss fake = 6.214983727659273e-08, generator loss = 17.070537567138672\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 9, Batch: 119/468, discriminator loss real = 5.94085830865076e-18, disciminator loss fake = 4.1656953442270606e-08, generator loss = 17.190187454223633\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 9, Batch: 120/468, discriminator loss real = 2.2182380037634106e-14, disciminator loss fake = 4.7538140535152706e-08, generator loss = 17.21023941040039\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 9, Batch: 121/468, discriminator loss real = 2.09946162288855e-14, disciminator loss fake = 6.450974865401804e-08, generator loss = 17.20269775390625\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 9, Batch: 122/468, discriminator loss real = 9.386830505594967e-13, disciminator loss fake = 6.045630129847268e-08, generator loss = 17.35718536376953\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 9, Batch: 123/468, discriminator loss real = 5.1562508624284893e-17, disciminator loss fake = 5.723329721263326e-08, generator loss = 17.17774200439453\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 9, Batch: 124/468, discriminator loss real = 1.6861831375614145e-11, disciminator loss fake = 5.267210667625477e-08, generator loss = 17.181949615478516\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 9, Batch: 125/468, discriminator loss real = 3.7344920314789573e-16, disciminator loss fake = 4.908832096361948e-08, generator loss = 17.302230834960938\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 9, Batch: 126/468, discriminator loss real = 2.8326939572616934e-15, disciminator loss fake = 7.248664957160145e-08, generator loss = 17.208850860595703\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 9, Batch: 127/468, discriminator loss real = 2.2140693445305004e-10, disciminator loss fake = 6.367815785779385e-08, generator loss = 17.169347763061523\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 9, Batch: 128/468, discriminator loss real = 1.891396110911825e-12, disciminator loss fake = 7.846702487768198e-08, generator loss = 17.194154739379883\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 9, Batch: 129/468, discriminator loss real = 6.148341113575845e-14, disciminator loss fake = 7.774949750682936e-08, generator loss = 17.210201263427734\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 9, Batch: 130/468, discriminator loss real = 2.984461094056312e-13, disciminator loss fake = 6.162699861533838e-08, generator loss = 17.3704833984375\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 9, Batch: 131/468, discriminator loss real = 1.0505833399412912e-12, disciminator loss fake = 6.92135913027414e-08, generator loss = 17.213937759399414\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 9, Batch: 132/468, discriminator loss real = 2.282490640936885e-09, disciminator loss fake = 7.166543980474671e-08, generator loss = 17.11923599243164\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 9, Batch: 133/468, discriminator loss real = 6.946439696917843e-15, disciminator loss fake = 4.8738719726770796e-08, generator loss = 17.195781707763672\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 9, Batch: 134/468, discriminator loss real = 4.305987543271598e-16, disciminator loss fake = 7.240771537908586e-08, generator loss = 17.27802276611328\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 9, Batch: 135/468, discriminator loss real = 2.683499852450949e-13, disciminator loss fake = 4.9408988900268014e-08, generator loss = 17.099111557006836\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 9, Batch: 136/468, discriminator loss real = 9.542460571720923e-11, disciminator loss fake = 6.432250643229054e-08, generator loss = 17.39340591430664\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 9, Batch: 137/468, discriminator loss real = 3.263449894434084e-13, disciminator loss fake = 7.463633266979741e-08, generator loss = 17.30902862548828\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 9, Batch: 138/468, discriminator loss real = 1.9111117202652572e-11, disciminator loss fake = 3.6404326664296605e-08, generator loss = 17.26630973815918\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 9, Batch: 139/468, discriminator loss real = 2.1855380005764147e-10, disciminator loss fake = 5.513895828812565e-08, generator loss = 17.311031341552734\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 9, Batch: 140/468, discriminator loss real = 6.630879179070348e-10, disciminator loss fake = 5.9374656302679796e-08, generator loss = 17.270633697509766\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 9, Batch: 141/468, discriminator loss real = 1.1714904046833396e-10, disciminator loss fake = 4.9332214757669135e-08, generator loss = 17.22885513305664\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 9, Batch: 142/468, discriminator loss real = 1.7902424076510215e-07, disciminator loss fake = 4.715264267929342e-08, generator loss = 17.458965301513672\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 9, Batch: 143/468, discriminator loss real = 9.254083764681487e-17, disciminator loss fake = 6.224675530575041e-08, generator loss = 17.215505599975586\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 9, Batch: 144/468, discriminator loss real = 7.143498682783445e-18, disciminator loss fake = 4.244775198003481e-08, generator loss = 17.281036376953125\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 9, Batch: 145/468, discriminator loss real = 8.015423546077385e-16, disciminator loss fake = 4.340386183798728e-08, generator loss = 17.295259475708008\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 9, Batch: 146/468, discriminator loss real = 2.7153970464841547e-14, disciminator loss fake = 3.968639816775976e-08, generator loss = 17.422218322753906\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 9, Batch: 147/468, discriminator loss real = 1.389975137213676e-14, disciminator loss fake = 5.240362810354782e-08, generator loss = 17.36818504333496\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 9, Batch: 148/468, discriminator loss real = 4.548456663394651e-12, disciminator loss fake = 8.21506347392642e-08, generator loss = 17.135581970214844\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 9, Batch: 149/468, discriminator loss real = 1.5467434191090979e-13, disciminator loss fake = 6.544195940705322e-08, generator loss = 17.264965057373047\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 9, Batch: 150/468, discriminator loss real = 1.6414657176902492e-12, disciminator loss fake = 4.7613823994652194e-08, generator loss = 17.40859603881836\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 9, Batch: 151/468, discriminator loss real = 2.19721619032498e-06, disciminator loss fake = 5.427848748240649e-08, generator loss = 17.31158447265625\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 9, Batch: 152/468, discriminator loss real = 9.625140311511626e-15, disciminator loss fake = 6.260506779653952e-08, generator loss = 17.221010208129883\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 9, Batch: 153/468, discriminator loss real = 3.073697709115447e-13, disciminator loss fake = 6.318025214113732e-08, generator loss = 17.156749725341797\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 9, Batch: 154/468, discriminator loss real = 1.9382380855859083e-07, disciminator loss fake = 6.343971392652747e-08, generator loss = 17.050756454467773\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 9, Batch: 155/468, discriminator loss real = 1.1001813431563384e-15, disciminator loss fake = 5.864679764044922e-08, generator loss = 17.233272552490234\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 9, Batch: 156/468, discriminator loss real = 1.019286391401586e-11, disciminator loss fake = 5.587936513506975e-08, generator loss = 16.868371963500977\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 9, Batch: 157/468, discriminator loss real = 7.391179682181281e-13, disciminator loss fake = 9.396477906875589e-08, generator loss = 17.08310317993164\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 9, Batch: 158/468, discriminator loss real = 9.372898982016979e-15, disciminator loss fake = 7.350391229010711e-08, generator loss = 17.084869384765625\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 9, Batch: 159/468, discriminator loss real = 2.731787844822975e-07, disciminator loss fake = 6.784132011716792e-08, generator loss = 17.23641014099121\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 9, Batch: 160/468, discriminator loss real = 2.03542960264258e-09, disciminator loss fake = 7.083292530296603e-08, generator loss = 17.033863067626953\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 9, Batch: 161/468, discriminator loss real = 1.5410445272298623e-12, disciminator loss fake = 7.403846780107415e-08, generator loss = 17.054546356201172\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 9, Batch: 162/468, discriminator loss real = 9.755592702751208e-15, disciminator loss fake = 7.100648957703015e-08, generator loss = 17.144519805908203\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 9, Batch: 163/468, discriminator loss real = 5.351079024329408e-10, disciminator loss fake = 1.0587157106556333e-07, generator loss = 16.994693756103516\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 9, Batch: 164/468, discriminator loss real = 2.2660014056125055e-12, disciminator loss fake = 8.37918605611776e-08, generator loss = 17.03478240966797\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 9, Batch: 165/468, discriminator loss real = 7.584116711381594e-13, disciminator loss fake = 9.859072491735787e-08, generator loss = 16.935144424438477\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 9, Batch: 166/468, discriminator loss real = 4.2141326434933814e-16, disciminator loss fake = 7.191106021764426e-08, generator loss = 16.99786376953125\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 9, Batch: 167/468, discriminator loss real = 4.142334912582424e-12, disciminator loss fake = 6.942988051150678e-08, generator loss = 17.0070743560791\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 9, Batch: 168/468, discriminator loss real = 2.2357462547972773e-09, disciminator loss fake = 6.601480606605037e-08, generator loss = 17.046369552612305\n",
      "2/2 [==============================] - 0s 130ms/step\n",
      "Epoch: 9, Batch: 169/468, discriminator loss real = 6.451052799588686e-12, disciminator loss fake = 7.428300108358599e-08, generator loss = 16.91407585144043\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 9, Batch: 170/468, discriminator loss real = 3.029628956562058e-13, disciminator loss fake = 8.446341581702654e-08, generator loss = 17.367183685302734\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 9, Batch: 171/468, discriminator loss real = 5.51629148108179e-16, disciminator loss fake = 6.474128610989283e-08, generator loss = 17.081478118896484\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 9, Batch: 172/468, discriminator loss real = 1.3798649180739309e-13, disciminator loss fake = 7.83647777780061e-08, generator loss = 17.117250442504883\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 9, Batch: 173/468, discriminator loss real = 1.5336804177042357e-15, disciminator loss fake = 6.525685591896035e-08, generator loss = 17.036354064941406\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 9, Batch: 174/468, discriminator loss real = 8.713106625091172e-11, disciminator loss fake = 5.977697270509452e-08, generator loss = 17.117822647094727\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 9, Batch: 175/468, discriminator loss real = 2.033261720544243e-15, disciminator loss fake = 6.918246242548776e-08, generator loss = 16.947895050048828\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 9, Batch: 176/468, discriminator loss real = 1.1799749003414683e-13, disciminator loss fake = 8.575023002777016e-08, generator loss = 17.189640045166016\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 9, Batch: 177/468, discriminator loss real = 1.2769000079515536e-07, disciminator loss fake = 4.8926921181191574e-08, generator loss = 17.20130157470703\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 9, Batch: 178/468, discriminator loss real = 4.407759747471207e-12, disciminator loss fake = 8.003440399306783e-08, generator loss = 17.059410095214844\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 9, Batch: 179/468, discriminator loss real = 1.1525496845159276e-15, disciminator loss fake = 8.232139947494943e-08, generator loss = 17.122560501098633\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 9, Batch: 180/468, discriminator loss real = 7.25022852084839e-13, disciminator loss fake = 6.325865342660109e-08, generator loss = 17.261764526367188\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 9, Batch: 181/468, discriminator loss real = 1.6380400508220205e-11, disciminator loss fake = 6.837905175416381e-08, generator loss = 17.272144317626953\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 9, Batch: 182/468, discriminator loss real = 1.879054377373901e-11, disciminator loss fake = 5.876377073832373e-08, generator loss = 17.18030548095703\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 9, Batch: 183/468, discriminator loss real = 4.706593459153502e-14, disciminator loss fake = 9.485228247285704e-08, generator loss = 17.058719635009766\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 9, Batch: 184/468, discriminator loss real = 2.71479062383348e-16, disciminator loss fake = 7.135730584195699e-08, generator loss = 17.172630310058594\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 9, Batch: 185/468, discriminator loss real = 2.167179213863335e-10, disciminator loss fake = 8.175797461262846e-08, generator loss = 17.245193481445312\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 9, Batch: 186/468, discriminator loss real = 2.766783980742704e-12, disciminator loss fake = 5.8017285198275204e-08, generator loss = 17.135013580322266\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 9, Batch: 187/468, discriminator loss real = 6.519315642883328e-11, disciminator loss fake = 6.413365838398022e-08, generator loss = 17.2469482421875\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 9, Batch: 188/468, discriminator loss real = 2.086009490143148e-11, disciminator loss fake = 4.912175910476435e-08, generator loss = 17.30794906616211\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 9, Batch: 189/468, discriminator loss real = 2.7436428129412604e-11, disciminator loss fake = 8.178677290970882e-08, generator loss = 17.216297149658203\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 9, Batch: 190/468, discriminator loss real = 2.5706416568972365e-14, disciminator loss fake = 6.801027296887696e-08, generator loss = 17.33077621459961\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 9, Batch: 191/468, discriminator loss real = 8.580954957010389e-13, disciminator loss fake = 6.392729545723341e-08, generator loss = 17.198076248168945\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 9, Batch: 192/468, discriminator loss real = 6.172312823609499e-14, disciminator loss fake = 4.8213262715535166e-08, generator loss = 17.298206329345703\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 9, Batch: 193/468, discriminator loss real = 1.2934706474301838e-12, disciminator loss fake = 7.027352921795682e-08, generator loss = 17.20698356628418\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 9, Batch: 194/468, discriminator loss real = 2.5667003245022357e-11, disciminator loss fake = 6.030823840319499e-08, generator loss = 17.435537338256836\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 9, Batch: 195/468, discriminator loss real = 8.6312006168635e-16, disciminator loss fake = 5.4722423925568364e-08, generator loss = 17.203001022338867\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 9, Batch: 196/468, discriminator loss real = 8.6661072469605e-14, disciminator loss fake = 5.614551668031709e-08, generator loss = 17.206371307373047\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 9, Batch: 197/468, discriminator loss real = 1.0808918999649988e-13, disciminator loss fake = 5.143404280261166e-08, generator loss = 17.1950740814209\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 9, Batch: 198/468, discriminator loss real = 7.477481411832798e-10, disciminator loss fake = 5.867563146466637e-08, generator loss = 17.243078231811523\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 9, Batch: 199/468, discriminator loss real = 3.055656313914745e-13, disciminator loss fake = 5.0804693785266863e-08, generator loss = 17.177392959594727\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 9, Batch: 200/468, discriminator loss real = 7.946777730218763e-14, disciminator loss fake = 5.3321983273235674e-08, generator loss = 17.062301635742188\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 9, Batch: 201/468, discriminator loss real = 1.1272605629635848e-16, disciminator loss fake = 5.072731568134259e-08, generator loss = 17.330074310302734\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 9, Batch: 202/468, discriminator loss real = 1.3367152979122665e-13, disciminator loss fake = 5.731639873829408e-08, generator loss = 17.277172088623047\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 9, Batch: 203/468, discriminator loss real = 2.151369915548429e-10, disciminator loss fake = 7.503795984575845e-08, generator loss = 17.23471450805664\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 9, Batch: 204/468, discriminator loss real = 3.6854975282274004e-16, disciminator loss fake = 4.5019667993528856e-08, generator loss = 17.505924224853516\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 9, Batch: 205/468, discriminator loss real = 3.593698255643929e-11, disciminator loss fake = 5.7046804613491986e-08, generator loss = 17.323223114013672\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 9, Batch: 206/468, discriminator loss real = 1.2953129373141983e-14, disciminator loss fake = 5.97717644268414e-08, generator loss = 17.22536849975586\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 9, Batch: 207/468, discriminator loss real = 4.9744368346704704e-11, disciminator loss fake = 7.606715968222488e-08, generator loss = 17.45876693725586\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 9, Batch: 208/468, discriminator loss real = 1.9593942354040328e-12, disciminator loss fake = 4.668086717174447e-08, generator loss = 17.44597625732422\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 9, Batch: 209/468, discriminator loss real = 8.331732526123403e-10, disciminator loss fake = 5.97103948507538e-08, generator loss = 17.501129150390625\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 9, Batch: 210/468, discriminator loss real = 1.7232139326583962e-11, disciminator loss fake = 5.828835725196768e-08, generator loss = 17.267019271850586\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 9, Batch: 211/468, discriminator loss real = 1.1970788418277966e-15, disciminator loss fake = 5.173869155328248e-08, generator loss = 17.324172973632812\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 9, Batch: 212/468, discriminator loss real = 7.075121196374601e-13, disciminator loss fake = 4.7245372059023794e-08, generator loss = 17.34265899658203\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 9, Batch: 213/468, discriminator loss real = 1.989850011448039e-15, disciminator loss fake = 3.668269243917166e-08, generator loss = 17.52025032043457\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 9, Batch: 214/468, discriminator loss real = 4.169969827216846e-07, disciminator loss fake = 3.5901315698083636e-08, generator loss = 17.44352149963379\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 9, Batch: 215/468, discriminator loss real = 5.650191296416697e-15, disciminator loss fake = 5.973225114530578e-08, generator loss = 17.396879196166992\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 9, Batch: 216/468, discriminator loss real = 2.4796373288005213e-11, disciminator loss fake = 4.434065203895443e-08, generator loss = 17.389232635498047\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 9, Batch: 217/468, discriminator loss real = 5.395799985543682e-16, disciminator loss fake = 4.362490813036857e-08, generator loss = 17.372243881225586\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 9, Batch: 218/468, discriminator loss real = 7.884274490091021e-18, disciminator loss fake = 4.361099925631606e-08, generator loss = 17.24851417541504\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 9, Batch: 219/468, discriminator loss real = 3.905788048541581e-08, disciminator loss fake = 4.555112553816798e-08, generator loss = 17.50829315185547\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 9, Batch: 220/468, discriminator loss real = 6.072095083686779e-12, disciminator loss fake = 5.196678642960251e-08, generator loss = 17.48659896850586\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 9, Batch: 221/468, discriminator loss real = 1.0845269566812173e-16, disciminator loss fake = 6.870604352116061e-08, generator loss = 17.366668701171875\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 9, Batch: 222/468, discriminator loss real = 2.4175708310258948e-11, disciminator loss fake = 5.117745516258765e-08, generator loss = 17.287918090820312\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 9, Batch: 223/468, discriminator loss real = 2.880699639717932e-06, disciminator loss fake = 6.593412393840481e-08, generator loss = 17.26123809814453\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 9, Batch: 224/468, discriminator loss real = 1.7232494882639615e-17, disciminator loss fake = 6.330212443117489e-08, generator loss = 17.41802978515625\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 9, Batch: 225/468, discriminator loss real = 1.3483437977246382e-10, disciminator loss fake = 7.012250335947101e-08, generator loss = 17.235952377319336\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 9, Batch: 226/468, discriminator loss real = 2.6348684345478546e-10, disciminator loss fake = 5.570327488158e-08, generator loss = 17.266948699951172\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 9, Batch: 227/468, discriminator loss real = 7.791328346384851e-12, disciminator loss fake = 7.153243331003978e-08, generator loss = 17.19354248046875\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 9, Batch: 228/468, discriminator loss real = 2.8554833787075703e-15, disciminator loss fake = 4.575819190222319e-08, generator loss = 16.9929141998291\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 9, Batch: 229/468, discriminator loss real = 3.0124806178437997e-17, disciminator loss fake = 5.492429266951149e-08, generator loss = 17.04555892944336\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 9, Batch: 230/468, discriminator loss real = 1.9035729210362812e-13, disciminator loss fake = 6.302143162884022e-08, generator loss = 16.962112426757812\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 9, Batch: 231/468, discriminator loss real = 4.2005184417508406e-16, disciminator loss fake = 6.297786114828341e-08, generator loss = 17.02971649169922\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 9, Batch: 232/468, discriminator loss real = 2.322412404836378e-16, disciminator loss fake = 5.8310497763613967e-08, generator loss = 17.156770706176758\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 9, Batch: 233/468, discriminator loss real = 1.499987154363244e-17, disciminator loss fake = 7.137464308470953e-08, generator loss = 17.16271209716797\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 9, Batch: 234/468, discriminator loss real = 3.418838101509891e-09, disciminator loss fake = 8.479085522594687e-08, generator loss = 16.921817779541016\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 9, Batch: 235/468, discriminator loss real = 3.540710216086283e-18, disciminator loss fake = 9.774647224958244e-08, generator loss = 17.232372283935547\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 9, Batch: 236/468, discriminator loss real = 8.269538831484624e-09, disciminator loss fake = 9.047880666912533e-08, generator loss = 17.095401763916016\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 9, Batch: 237/468, discriminator loss real = 1.1047971168535027e-16, disciminator loss fake = 8.286345121177874e-08, generator loss = 17.0936222076416\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 9, Batch: 238/468, discriminator loss real = 1.1669098575872033e-14, disciminator loss fake = 7.157702697213608e-08, generator loss = 17.191177368164062\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 9, Batch: 239/468, discriminator loss real = 2.6657849105243825e-12, disciminator loss fake = 7.705038029826028e-08, generator loss = 17.188507080078125\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 9, Batch: 240/468, discriminator loss real = 1.701503267301967e-15, disciminator loss fake = 7.931487999712772e-08, generator loss = 17.227584838867188\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 9, Batch: 241/468, discriminator loss real = 8.720857995539184e-16, disciminator loss fake = 6.613694836232753e-08, generator loss = 17.0251522064209\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 9, Batch: 242/468, discriminator loss real = 3.468633158476564e-10, disciminator loss fake = 7.082272190928052e-08, generator loss = 17.257022857666016\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 9, Batch: 243/468, discriminator loss real = 3.808035667124312e-16, disciminator loss fake = 7.233499843550817e-08, generator loss = 17.196880340576172\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 9, Batch: 244/468, discriminator loss real = 1.941426797102963e-09, disciminator loss fake = 5.263422053758404e-08, generator loss = 17.121360778808594\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 9, Batch: 245/468, discriminator loss real = 2.6479152550653846e-16, disciminator loss fake = 5.992498586238071e-08, generator loss = 17.276168823242188\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 9, Batch: 246/468, discriminator loss real = 1.9544157645281948e-16, disciminator loss fake = 6.216973247319402e-08, generator loss = 17.165908813476562\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 9, Batch: 247/468, discriminator loss real = 1.4743553087220633e-17, disciminator loss fake = 6.935911045502507e-08, generator loss = 17.138961791992188\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 9, Batch: 248/468, discriminator loss real = 4.5579592877764696e-10, disciminator loss fake = 6.761060689086662e-08, generator loss = 17.14209747314453\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 9, Batch: 249/468, discriminator loss real = 2.776934932002817e-12, disciminator loss fake = 5.420503512709729e-08, generator loss = 17.279895782470703\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 9, Batch: 250/468, discriminator loss real = 8.13997709399317e-16, disciminator loss fake = 5.601204122740455e-08, generator loss = 17.15386390686035\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 9, Batch: 251/468, discriminator loss real = 1.2010311907333093e-13, disciminator loss fake = 1.0578145293038688e-07, generator loss = 17.09232521057129\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 9, Batch: 252/468, discriminator loss real = 2.2470153721639713e-13, disciminator loss fake = 4.895948535477146e-08, generator loss = 17.18598175048828\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 9, Batch: 253/468, discriminator loss real = 4.471722742527967e-14, disciminator loss fake = 4.8930171914207676e-08, generator loss = 17.263408660888672\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 9, Batch: 254/468, discriminator loss real = 5.905957553521343e-14, disciminator loss fake = 8.887595015494298e-08, generator loss = 17.09864044189453\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 9, Batch: 255/468, discriminator loss real = 9.538505020660293e-19, disciminator loss fake = 5.3607799088695174e-08, generator loss = 17.118600845336914\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 9, Batch: 256/468, discriminator loss real = 6.619304667139037e-16, disciminator loss fake = 7.220958764264651e-08, generator loss = 17.181228637695312\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 9, Batch: 257/468, discriminator loss real = 3.939315193490778e-11, disciminator loss fake = 5.2344514500646255e-08, generator loss = 17.21402359008789\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 9, Batch: 258/468, discriminator loss real = 7.964597201728493e-17, disciminator loss fake = 4.5189594288785884e-08, generator loss = 17.279293060302734\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 9, Batch: 259/468, discriminator loss real = 3.109243331550493e-12, disciminator loss fake = 5.883683940055562e-08, generator loss = 17.348073959350586\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 9, Batch: 260/468, discriminator loss real = 4.6587671220787996e-11, disciminator loss fake = 5.443579098596274e-08, generator loss = 17.074554443359375\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 9, Batch: 261/468, discriminator loss real = 5.3522977716546905e-11, disciminator loss fake = 5.412468695453754e-08, generator loss = 17.10289764404297\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 9, Batch: 262/468, discriminator loss real = 8.168691417731466e-12, disciminator loss fake = 5.461590291133689e-08, generator loss = 17.26577377319336\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 9, Batch: 263/468, discriminator loss real = 1.7734742840946893e-10, disciminator loss fake = 5.6527895253566385e-08, generator loss = 17.166641235351562\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 9, Batch: 264/468, discriminator loss real = 3.662413339315879e-15, disciminator loss fake = 6.394017759703274e-08, generator loss = 17.3485107421875\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 9, Batch: 265/468, discriminator loss real = 8.066010424682968e-13, disciminator loss fake = 5.2461658128777344e-08, generator loss = 17.315534591674805\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 9, Batch: 266/468, discriminator loss real = 3.678735538414912e-08, disciminator loss fake = 6.402508745395608e-08, generator loss = 17.254344940185547\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 9, Batch: 267/468, discriminator loss real = 7.759789447288334e-14, disciminator loss fake = 5.238445055510965e-08, generator loss = 17.238964080810547\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 9, Batch: 268/468, discriminator loss real = 1.8725712441162307e-13, disciminator loss fake = 6.215445580437517e-08, generator loss = 17.230056762695312\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 9, Batch: 269/468, discriminator loss real = 1.6128133984577575e-12, disciminator loss fake = 6.02746368372209e-08, generator loss = 17.32428741455078\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 9, Batch: 270/468, discriminator loss real = 1.4212244714428834e-08, disciminator loss fake = 4.154598443051327e-08, generator loss = 17.248863220214844\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 9, Batch: 271/468, discriminator loss real = 2.4559534093915314e-12, disciminator loss fake = 6.280056652485655e-08, generator loss = 17.201398849487305\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 9, Batch: 272/468, discriminator loss real = 7.861280257401987e-14, disciminator loss fake = 4.2284597157049575e-08, generator loss = 17.176923751831055\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 9, Batch: 273/468, discriminator loss real = 3.9389552817375995e-14, disciminator loss fake = 6.022865761678986e-08, generator loss = 17.159526824951172\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 9, Batch: 274/468, discriminator loss real = 2.1305197799655236e-14, disciminator loss fake = 4.515456453191291e-08, generator loss = 17.386442184448242\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 9, Batch: 275/468, discriminator loss real = 1.1111617181924771e-09, disciminator loss fake = 5.8905914812612536e-08, generator loss = 17.38067626953125\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 9, Batch: 276/468, discriminator loss real = 4.703826304158776e-12, disciminator loss fake = 4.781332307857156e-08, generator loss = 17.36223602294922\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 9, Batch: 277/468, discriminator loss real = 5.4739442145734785e-12, disciminator loss fake = 4.7599456820535124e-08, generator loss = 17.48705291748047\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 9, Batch: 278/468, discriminator loss real = 1.070022366610017e-13, disciminator loss fake = 5.8166143901416945e-08, generator loss = 17.411026000976562\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 9, Batch: 279/468, discriminator loss real = 4.6201764636322196e-11, disciminator loss fake = 7.517947864243979e-08, generator loss = 17.247344970703125\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 9, Batch: 280/468, discriminator loss real = 1.966899706681743e-16, disciminator loss fake = 4.927765218099012e-08, generator loss = 17.23052978515625\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 9, Batch: 281/468, discriminator loss real = 3.5043400473111497e-12, disciminator loss fake = 5.096929811543305e-08, generator loss = 17.44591522216797\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 9, Batch: 282/468, discriminator loss real = 3.4233249491844335e-15, disciminator loss fake = 3.8355018716629274e-08, generator loss = 17.331932067871094\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 9, Batch: 283/468, discriminator loss real = 6.150514176602026e-15, disciminator loss fake = 4.246921747608212e-08, generator loss = 17.298381805419922\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "Epoch: 9, Batch: 284/468, discriminator loss real = 1.2447036457086114e-11, disciminator loss fake = 6.075634928492946e-08, generator loss = 17.24631118774414\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 9, Batch: 285/468, discriminator loss real = 3.396689786399785e-15, disciminator loss fake = 5.674660386034702e-08, generator loss = 17.485511779785156\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 9, Batch: 286/468, discriminator loss real = 2.3360023496728916e-14, disciminator loss fake = 4.17430428001353e-08, generator loss = 17.301918029785156\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 9, Batch: 287/468, discriminator loss real = 3.0656376566184917e-06, disciminator loss fake = 5.6430511818916784e-08, generator loss = 17.42884063720703\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 9, Batch: 288/468, discriminator loss real = 4.140500876187447e-12, disciminator loss fake = 7.118863720734225e-08, generator loss = 17.43893814086914\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 9, Batch: 289/468, discriminator loss real = 1.454513728427545e-13, disciminator loss fake = 6.411908515246978e-08, generator loss = 17.087953567504883\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 9, Batch: 290/468, discriminator loss real = 5.076141736766113e-14, disciminator loss fake = 7.269206747650969e-08, generator loss = 17.164020538330078\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 9, Batch: 291/468, discriminator loss real = 8.039444341670333e-16, disciminator loss fake = 6.769337801415531e-08, generator loss = 17.05587387084961\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 9, Batch: 292/468, discriminator loss real = 4.890373943609383e-15, disciminator loss fake = 8.540175144844397e-08, generator loss = 17.00796127319336\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 9, Batch: 293/468, discriminator loss real = 1.7116236301906512e-17, disciminator loss fake = 7.125053969048167e-08, generator loss = 17.09125518798828\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 9, Batch: 294/468, discriminator loss real = 2.046922614978001e-17, disciminator loss fake = 8.43375005388225e-08, generator loss = 17.19936180114746\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 9, Batch: 295/468, discriminator loss real = 1.9948009910564224e-09, disciminator loss fake = 7.238918442453723e-08, generator loss = 17.08367347717285\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 9, Batch: 296/468, discriminator loss real = 3.452009931701437e-14, disciminator loss fake = 7.852546701769825e-08, generator loss = 17.24694061279297\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 9, Batch: 297/468, discriminator loss real = 9.247936158368993e-17, disciminator loss fake = 6.412584951931422e-08, generator loss = 16.918827056884766\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 9, Batch: 298/468, discriminator loss real = 1.9980116397629553e-14, disciminator loss fake = 1.5889190763118677e-07, generator loss = 17.153291702270508\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 9, Batch: 299/468, discriminator loss real = 1.1944013833531386e-10, disciminator loss fake = 5.042185335923932e-08, generator loss = 17.057891845703125\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 9, Batch: 300/468, discriminator loss real = 2.7524837064533264e-14, disciminator loss fake = 1.1912443653727678e-07, generator loss = 17.017366409301758\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 9, Batch: 301/468, discriminator loss real = 1.8953914382690814e-15, disciminator loss fake = 9.53542382831074e-08, generator loss = 16.967565536499023\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 9, Batch: 302/468, discriminator loss real = 1.2533874745788943e-15, disciminator loss fake = 9.502963393970276e-08, generator loss = 16.992767333984375\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 9, Batch: 303/468, discriminator loss real = 2.998963163145703e-17, disciminator loss fake = 1.0740667732989095e-07, generator loss = 16.996082305908203\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 9, Batch: 304/468, discriminator loss real = 2.9432877034045457e-13, disciminator loss fake = 8.258779615744061e-08, generator loss = 17.1709041595459\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 9, Batch: 305/468, discriminator loss real = 1.0888690529743325e-13, disciminator loss fake = 6.142099806538681e-08, generator loss = 16.98698616027832\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 9, Batch: 306/468, discriminator loss real = 3.8391710431658284e-18, disciminator loss fake = 5.959345728001608e-08, generator loss = 17.17656707763672\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 9, Batch: 307/468, discriminator loss real = 1.8501406589305787e-19, disciminator loss fake = 8.91665905555783e-08, generator loss = 17.22352409362793\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 9, Batch: 308/468, discriminator loss real = 3.7330789257513085e-18, disciminator loss fake = 7.163280457689325e-08, generator loss = 17.153255462646484\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 9, Batch: 309/468, discriminator loss real = 3.7207285863427586e-11, disciminator loss fake = 8.672226670114469e-08, generator loss = 17.184968948364258\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 9, Batch: 310/468, discriminator loss real = 2.5158721677145945e-13, disciminator loss fake = 6.732440738232981e-08, generator loss = 17.158546447753906\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 9, Batch: 311/468, discriminator loss real = 1.20948585348446e-12, disciminator loss fake = 1.0696096808260336e-07, generator loss = 17.11461067199707\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 9, Batch: 312/468, discriminator loss real = 1.1751974397013762e-15, disciminator loss fake = 7.83152742656057e-08, generator loss = 17.0897159576416\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 9, Batch: 313/468, discriminator loss real = 8.172701153119155e-16, disciminator loss fake = 7.863589246426272e-08, generator loss = 17.112083435058594\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 9, Batch: 314/468, discriminator loss real = 5.037506637041889e-16, disciminator loss fake = 6.329556612172382e-08, generator loss = 17.21326446533203\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 9, Batch: 315/468, discriminator loss real = 2.812089414289867e-18, disciminator loss fake = 4.949379572849466e-08, generator loss = 17.189231872558594\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 9, Batch: 316/468, discriminator loss real = 2.788356692617047e-17, disciminator loss fake = 4.801893283001846e-08, generator loss = 17.333599090576172\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 9, Batch: 317/468, discriminator loss real = 6.598492368822817e-13, disciminator loss fake = 6.168337307599359e-08, generator loss = 17.28887176513672\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 9, Batch: 318/468, discriminator loss real = 1.4026573115466615e-16, disciminator loss fake = 7.222769227155368e-08, generator loss = 17.18301773071289\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 9, Batch: 319/468, discriminator loss real = 3.5817241100105646e-12, disciminator loss fake = 6.21466256234271e-08, generator loss = 17.218793869018555\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 9, Batch: 320/468, discriminator loss real = 2.5107067575143305e-13, disciminator loss fake = 6.450746781183625e-08, generator loss = 17.343711853027344\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 9, Batch: 321/468, discriminator loss real = 9.23827681020839e-12, disciminator loss fake = 6.923492890109628e-08, generator loss = 17.129243850708008\n",
      "2/2 [==============================] - 0s 130ms/step\n",
      "Epoch: 9, Batch: 322/468, discriminator loss real = 2.102030380003019e-17, disciminator loss fake = 6.570821398099724e-08, generator loss = 17.245769500732422\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 9, Batch: 323/468, discriminator loss real = 4.105090833234071e-12, disciminator loss fake = 6.323497814264556e-08, generator loss = 17.27578353881836\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 9, Batch: 324/468, discriminator loss real = 3.99592789038116e-17, disciminator loss fake = 5.810530012695381e-08, generator loss = 17.219528198242188\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 9, Batch: 325/468, discriminator loss real = 4.392834620364772e-12, disciminator loss fake = 5.439568084852908e-08, generator loss = 17.11196517944336\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 9, Batch: 326/468, discriminator loss real = 3.6771259648293864e-11, disciminator loss fake = 5.823824977824188e-08, generator loss = 17.287752151489258\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 9, Batch: 327/468, discriminator loss real = 1.1914498250845118e-13, disciminator loss fake = 5.7203433101449264e-08, generator loss = 17.33047866821289\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 9, Batch: 328/468, discriminator loss real = 2.105984874337108e-12, disciminator loss fake = 8.294026798694176e-08, generator loss = 17.422866821289062\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 9, Batch: 329/468, discriminator loss real = 4.992139679416141e-08, disciminator loss fake = 5.253941282035157e-08, generator loss = 17.321395874023438\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 9, Batch: 330/468, discriminator loss real = 2.362803170926199e-16, disciminator loss fake = 4.558603805548955e-08, generator loss = 17.254024505615234\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 9, Batch: 331/468, discriminator loss real = 3.3583005820680967e-10, disciminator loss fake = 5.968193761418661e-08, generator loss = 17.515722274780273\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 9, Batch: 332/468, discriminator loss real = 4.475862768523603e-13, disciminator loss fake = 6.84788830085381e-08, generator loss = 17.241769790649414\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 9, Batch: 333/468, discriminator loss real = 3.622644718925816e-14, disciminator loss fake = 4.341490722481467e-08, generator loss = 17.373184204101562\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 9, Batch: 334/468, discriminator loss real = 4.495786989217043e-12, disciminator loss fake = 6.841047195393912e-08, generator loss = 17.431703567504883\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 9, Batch: 335/468, discriminator loss real = 3.0939560809184474e-12, disciminator loss fake = 6.095734761402127e-08, generator loss = 17.252473831176758\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 9, Batch: 336/468, discriminator loss real = 1.0520002837605125e-13, disciminator loss fake = 4.9936758728108543e-08, generator loss = 17.33143424987793\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 9, Batch: 337/468, discriminator loss real = 6.649326373525926e-15, disciminator loss fake = 4.972739375830315e-08, generator loss = 17.34828758239746\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 9, Batch: 338/468, discriminator loss real = 2.116171423003862e-15, disciminator loss fake = 5.596035634880536e-08, generator loss = 17.58969497680664\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 9, Batch: 339/468, discriminator loss real = 5.718356696363461e-15, disciminator loss fake = 4.745058390653867e-08, generator loss = 17.3233642578125\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 9, Batch: 340/468, discriminator loss real = 2.9857761228713198e-12, disciminator loss fake = 5.4981406094611884e-08, generator loss = 17.366987228393555\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 9, Batch: 341/468, discriminator loss real = 5.1863310670282985e-15, disciminator loss fake = 4.068611758611951e-08, generator loss = 17.445140838623047\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 9, Batch: 342/468, discriminator loss real = 7.970456759875955e-12, disciminator loss fake = 5.49637064750641e-08, generator loss = 17.314449310302734\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 9, Batch: 343/468, discriminator loss real = 1.0361715166273066e-17, disciminator loss fake = 3.7595782487187535e-08, generator loss = 17.250194549560547\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 9, Batch: 344/468, discriminator loss real = 1.3960971051094062e-12, disciminator loss fake = 3.976867901656078e-08, generator loss = 17.41775131225586\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 9, Batch: 345/468, discriminator loss real = 3.49570429569214e-14, disciminator loss fake = 7.390478629076824e-08, generator loss = 17.193758010864258\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 9, Batch: 346/468, discriminator loss real = 3.4369088165595507e-15, disciminator loss fake = 4.424025590310521e-08, generator loss = 17.33228874206543\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 9, Batch: 347/468, discriminator loss real = 9.483448640094927e-15, disciminator loss fake = 4.828978106274917e-08, generator loss = 17.57239532470703\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 9, Batch: 348/468, discriminator loss real = 1.233920192585114e-13, disciminator loss fake = 4.103729622784158e-08, generator loss = 17.544891357421875\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 9, Batch: 349/468, discriminator loss real = 1.1212379469503699e-15, disciminator loss fake = 4.57979076884385e-08, generator loss = 17.473268508911133\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 9, Batch: 350/468, discriminator loss real = 1.459340460974179e-13, disciminator loss fake = 5.164020677739245e-08, generator loss = 17.579029083251953\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 9, Batch: 351/468, discriminator loss real = 2.0451884977235046e-11, disciminator loss fake = 4.48115038409469e-08, generator loss = 17.41628646850586\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 9, Batch: 352/468, discriminator loss real = 8.549315769212917e-13, disciminator loss fake = 4.556655852638869e-08, generator loss = 17.385513305664062\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 9, Batch: 353/468, discriminator loss real = 2.8625563291279077e-12, disciminator loss fake = 5.292765337117089e-08, generator loss = 17.558853149414062\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 9, Batch: 354/468, discriminator loss real = 5.141562411150593e-15, disciminator loss fake = 4.535161579610758e-08, generator loss = 17.534870147705078\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 9, Batch: 355/468, discriminator loss real = 1.0451989263930099e-19, disciminator loss fake = 6.472481572927791e-08, generator loss = 17.409954071044922\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 9, Batch: 356/468, discriminator loss real = 2.891890337088218e-15, disciminator loss fake = 3.7881331849121125e-08, generator loss = 17.33623695373535\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 9, Batch: 357/468, discriminator loss real = 9.724664988748112e-15, disciminator loss fake = 4.0417873492515355e-08, generator loss = 17.45343780517578\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 9, Batch: 358/468, discriminator loss real = 9.104331871734317e-13, disciminator loss fake = 4.369500672396498e-08, generator loss = 17.36028480529785\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 9, Batch: 359/468, discriminator loss real = 9.143275311568374e-17, disciminator loss fake = 3.72162922701591e-08, generator loss = 17.597867965698242\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 9, Batch: 360/468, discriminator loss real = 4.817951051137859e-13, disciminator loss fake = 5.940133362969391e-08, generator loss = 17.49177360534668\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 9, Batch: 361/468, discriminator loss real = 3.6278768617697965e-12, disciminator loss fake = 6.154617437914567e-08, generator loss = 17.49929428100586\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 9, Batch: 362/468, discriminator loss real = 3.711821648655356e-12, disciminator loss fake = 5.965453198086834e-08, generator loss = 17.610502243041992\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 9, Batch: 363/468, discriminator loss real = 6.249336578821943e-14, disciminator loss fake = 4.44795347220861e-08, generator loss = 17.573637008666992\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 9, Batch: 364/468, discriminator loss real = 2.3574195438628986e-13, disciminator loss fake = 5.79680659029691e-08, generator loss = 17.632308959960938\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 9, Batch: 365/468, discriminator loss real = 3.079198840350017e-10, disciminator loss fake = 4.5382762436929625e-08, generator loss = 17.55621910095215\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 9, Batch: 366/468, discriminator loss real = 2.706296693905444e-14, disciminator loss fake = 4.804443065609121e-08, generator loss = 17.576536178588867\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 9, Batch: 367/468, discriminator loss real = 2.516223557638697e-12, disciminator loss fake = 4.710570067345543e-08, generator loss = 17.564359664916992\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 9, Batch: 368/468, discriminator loss real = 7.272306400737255e-15, disciminator loss fake = 4.607936432421411e-08, generator loss = 17.594276428222656\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 9, Batch: 369/468, discriminator loss real = 8.780936915087079e-12, disciminator loss fake = 3.4209044486033235e-08, generator loss = 17.582317352294922\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 9, Batch: 370/468, discriminator loss real = 6.20144235442821e-13, disciminator loss fake = 5.584852402762408e-08, generator loss = 17.651634216308594\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 9, Batch: 371/468, discriminator loss real = 1.8957398313906165e-13, disciminator loss fake = 3.359271261160757e-08, generator loss = 17.76605796813965\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 9, Batch: 372/468, discriminator loss real = 3.405963526622799e-14, disciminator loss fake = 5.313235362791602e-08, generator loss = 17.64110565185547\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 9, Batch: 373/468, discriminator loss real = 9.585197219275088e-13, disciminator loss fake = 4.131519659722471e-08, generator loss = 17.612430572509766\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 9, Batch: 374/468, discriminator loss real = 6.225589163112721e-14, disciminator loss fake = 4.142313869692771e-08, generator loss = 17.609371185302734\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 9, Batch: 375/468, discriminator loss real = 2.6042641892813634e-13, disciminator loss fake = 3.7726607615695684e-08, generator loss = 17.580795288085938\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 9, Batch: 376/468, discriminator loss real = 7.752612571007567e-13, disciminator loss fake = 4.7850228668266936e-08, generator loss = 17.649816513061523\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 9, Batch: 377/468, discriminator loss real = 8.612822098314626e-14, disciminator loss fake = 3.65335353080809e-08, generator loss = 17.623254776000977\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 9, Batch: 378/468, discriminator loss real = 4.821166252680364e-13, disciminator loss fake = 3.099150092111813e-08, generator loss = 17.660045623779297\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 9, Batch: 379/468, discriminator loss real = 1.7100736313655808e-14, disciminator loss fake = 3.9814281649341865e-08, generator loss = 17.51404571533203\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 9, Batch: 380/468, discriminator loss real = 1.8276272422540485e-12, disciminator loss fake = 3.440795381948192e-08, generator loss = 17.64069175720215\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 9, Batch: 381/468, discriminator loss real = 6.91583409366272e-17, disciminator loss fake = 3.5283239441241676e-08, generator loss = 17.378467559814453\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 9, Batch: 382/468, discriminator loss real = 1.3012699506256484e-14, disciminator loss fake = 4.291825916880043e-08, generator loss = 17.48011016845703\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 9, Batch: 383/468, discriminator loss real = 8.068095548748565e-15, disciminator loss fake = 3.747872412418474e-08, generator loss = 17.640480041503906\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 9, Batch: 384/468, discriminator loss real = 7.794654678650037e-15, disciminator loss fake = 2.6522684493102133e-08, generator loss = 17.702987670898438\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 9, Batch: 385/468, discriminator loss real = 5.0070004566082904e-12, disciminator loss fake = 4.255022645338613e-08, generator loss = 17.63269805908203\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 9, Batch: 386/468, discriminator loss real = 6.360959502182961e-12, disciminator loss fake = 3.116883107168178e-08, generator loss = 17.637962341308594\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 9, Batch: 387/468, discriminator loss real = 3.853556796579172e-12, disciminator loss fake = 4.490867411277577e-08, generator loss = 17.770370483398438\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 9, Batch: 388/468, discriminator loss real = 4.525153919653947e-14, disciminator loss fake = 3.667349091074357e-08, generator loss = 17.669998168945312\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 9, Batch: 389/468, discriminator loss real = 5.068722871981457e-11, disciminator loss fake = 4.281829646402002e-08, generator loss = 17.65151596069336\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 9, Batch: 390/468, discriminator loss real = 4.687380274338404e-16, disciminator loss fake = 3.437326157040843e-08, generator loss = 17.765506744384766\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 9, Batch: 391/468, discriminator loss real = 3.5089110639991393e-15, disciminator loss fake = 4.14983354346532e-08, generator loss = 17.814380645751953\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 9, Batch: 392/468, discriminator loss real = 8.338345205277653e-13, disciminator loss fake = 4.3196575205683985e-08, generator loss = 17.656742095947266\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 9, Batch: 393/468, discriminator loss real = 3.384661071515827e-16, disciminator loss fake = 3.566828610246375e-08, generator loss = 17.70047950744629\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 9, Batch: 394/468, discriminator loss real = 7.066703234714022e-16, disciminator loss fake = 4.806895859132965e-08, generator loss = 17.797565460205078\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 9, Batch: 395/468, discriminator loss real = 2.526873320460459e-17, disciminator loss fake = 4.6178278978459275e-08, generator loss = 17.716394424438477\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 9, Batch: 396/468, discriminator loss real = 2.1171072355919004e-17, disciminator loss fake = 3.988775887364682e-08, generator loss = 17.691226959228516\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 9, Batch: 397/468, discriminator loss real = 1.1890710855180786e-13, disciminator loss fake = 3.0717103527422296e-08, generator loss = 17.632766723632812\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 9, Batch: 398/468, discriminator loss real = 1.2398047718740796e-16, disciminator loss fake = 2.700144463574361e-08, generator loss = 17.768024444580078\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 9, Batch: 399/468, discriminator loss real = 2.843989150083659e-13, disciminator loss fake = 3.521357427871408e-08, generator loss = 17.721813201904297\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 9, Batch: 400/468, discriminator loss real = 2.730335150135342e-14, disciminator loss fake = 2.592025616365845e-08, generator loss = 17.64620018005371\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 9, Batch: 401/468, discriminator loss real = 4.9948967081577325e-14, disciminator loss fake = 3.8663635848479316e-08, generator loss = 17.762046813964844\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 9, Batch: 402/468, discriminator loss real = 2.4833935363850757e-13, disciminator loss fake = 3.9771308024683094e-08, generator loss = 17.631210327148438\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 9, Batch: 403/468, discriminator loss real = 3.161032991435463e-17, disciminator loss fake = 4.010182408364926e-08, generator loss = 17.663772583007812\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 9, Batch: 404/468, discriminator loss real = 3.862345773070208e-12, disciminator loss fake = 3.263941295017503e-08, generator loss = 17.636531829833984\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 9, Batch: 405/468, discriminator loss real = 4.073220927214294e-12, disciminator loss fake = 3.762099964887966e-08, generator loss = 17.85247802734375\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 9, Batch: 406/468, discriminator loss real = 2.254249810686252e-16, disciminator loss fake = 3.6192965069403726e-08, generator loss = 17.780872344970703\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 9, Batch: 407/468, discriminator loss real = 3.457411630212667e-14, disciminator loss fake = 2.6652283935391097e-08, generator loss = 17.764720916748047\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 9, Batch: 408/468, discriminator loss real = 2.2331443361167658e-08, disciminator loss fake = 3.358458044999679e-08, generator loss = 17.745784759521484\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 9, Batch: 409/468, discriminator loss real = 2.8850909918623708e-15, disciminator loss fake = 4.8423110854400875e-08, generator loss = 17.689157485961914\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 9, Batch: 410/468, discriminator loss real = 2.598439663569567e-17, disciminator loss fake = 3.6869209907308687e-08, generator loss = 17.790000915527344\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 9, Batch: 411/468, discriminator loss real = 1.015340172642919e-14, disciminator loss fake = 3.569243034462488e-08, generator loss = 17.76797103881836\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 9, Batch: 412/468, discriminator loss real = 3.869377707133026e-09, disciminator loss fake = 3.476740317864824e-08, generator loss = 17.678539276123047\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 9, Batch: 413/468, discriminator loss real = 6.556233334009676e-10, disciminator loss fake = 4.4637065599317793e-08, generator loss = 17.874454498291016\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 9, Batch: 414/468, discriminator loss real = 6.625561196594592e-17, disciminator loss fake = 2.368620499737517e-08, generator loss = 17.70766258239746\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 9, Batch: 415/468, discriminator loss real = 1.6765824727327819e-16, disciminator loss fake = 3.514773183610487e-08, generator loss = 17.984111785888672\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 9, Batch: 416/468, discriminator loss real = 7.394809048953677e-13, disciminator loss fake = 3.396936776312032e-08, generator loss = 17.783931732177734\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 9, Batch: 417/468, discriminator loss real = 1.6851953166252542e-09, disciminator loss fake = 3.1471870443056105e-08, generator loss = 17.96059799194336\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 9, Batch: 418/468, discriminator loss real = 2.937215832425448e-14, disciminator loss fake = 2.953579425479802e-08, generator loss = 17.866601943969727\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 9, Batch: 419/468, discriminator loss real = 3.583022211719154e-14, disciminator loss fake = 4.0547476487518e-08, generator loss = 17.871437072753906\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 9, Batch: 420/468, discriminator loss real = 3.23737157957929e-13, disciminator loss fake = 4.080357030034065e-08, generator loss = 17.846309661865234\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 9, Batch: 421/468, discriminator loss real = 3.4463911535350768e-18, disciminator loss fake = 2.4586320535036066e-08, generator loss = 17.813037872314453\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 9, Batch: 422/468, discriminator loss real = 1.0415394099212629e-14, disciminator loss fake = 2.7836454918883646e-08, generator loss = 17.791072845458984\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 9, Batch: 423/468, discriminator loss real = 1.5294463286998072e-13, disciminator loss fake = 3.200047515861115e-08, generator loss = 17.91248893737793\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 9, Batch: 424/468, discriminator loss real = 1.2767858770246221e-08, disciminator loss fake = 2.342968130619738e-08, generator loss = 17.76723289489746\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 9, Batch: 425/468, discriminator loss real = 2.2149014245171456e-16, disciminator loss fake = 2.556525657837483e-08, generator loss = 17.826351165771484\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 9, Batch: 426/468, discriminator loss real = 8.862532832176057e-14, disciminator loss fake = 3.4001573112618644e-08, generator loss = 17.82364845275879\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 9, Batch: 427/468, discriminator loss real = 9.038532422511736e-11, disciminator loss fake = 3.978686180516888e-08, generator loss = 17.92942237854004\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 9, Batch: 428/468, discriminator loss real = 3.104247880969524e-08, disciminator loss fake = 2.7283983072834417e-08, generator loss = 17.860443115234375\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 9, Batch: 429/468, discriminator loss real = 3.231787464052539e-14, disciminator loss fake = 2.2149151845951565e-08, generator loss = 17.858362197875977\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 9, Batch: 430/468, discriminator loss real = 5.471314560978179e-16, disciminator loss fake = 3.347892985061662e-08, generator loss = 17.80808448791504\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 9, Batch: 431/468, discriminator loss real = 2.2272652997504206e-15, disciminator loss fake = 2.281436728424069e-08, generator loss = 18.00843048095703\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 9, Batch: 432/468, discriminator loss real = 9.235360821360436e-14, disciminator loss fake = 3.5146793919693664e-08, generator loss = 17.813739776611328\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 9, Batch: 433/468, discriminator loss real = 3.176789498127164e-09, disciminator loss fake = 2.8597533230367844e-08, generator loss = 17.961868286132812\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 9, Batch: 434/468, discriminator loss real = 3.8583723022123095e-11, disciminator loss fake = 2.884903338440381e-08, generator loss = 17.887042999267578\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 9, Batch: 435/468, discriminator loss real = 5.669586675138838e-11, disciminator loss fake = 2.56920476005007e-08, generator loss = 17.88248634338379\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 9, Batch: 436/468, discriminator loss real = 8.4870355033617e-15, disciminator loss fake = 2.3760655665228114e-08, generator loss = 17.759777069091797\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "Epoch: 9, Batch: 437/468, discriminator loss real = 8.182204333391757e-16, disciminator loss fake = 3.065924403244935e-08, generator loss = 17.98065185546875\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 9, Batch: 438/468, discriminator loss real = 2.35482831151268e-11, disciminator loss fake = 3.964662198541191e-08, generator loss = 17.924957275390625\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 9, Batch: 439/468, discriminator loss real = 1.4771698404400513e-12, disciminator loss fake = 2.4060339498532812e-08, generator loss = 17.84701156616211\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 9, Batch: 440/468, discriminator loss real = 1.2558537301188334e-17, disciminator loss fake = 2.982021385378175e-08, generator loss = 17.849285125732422\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 9, Batch: 441/468, discriminator loss real = 4.7618120384285145e-12, disciminator loss fake = 2.645880314844362e-08, generator loss = 17.848752975463867\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 9, Batch: 442/468, discriminator loss real = 2.5044447852368146e-12, disciminator loss fake = 2.7166437988057623e-08, generator loss = 17.918453216552734\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 9, Batch: 443/468, discriminator loss real = 1.6549541481691334e-17, disciminator loss fake = 3.555770433649741e-08, generator loss = 17.905372619628906\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 9, Batch: 444/468, discriminator loss real = 2.939908092237582e-17, disciminator loss fake = 2.1246290060616957e-08, generator loss = 17.888816833496094\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 9, Batch: 445/468, discriminator loss real = 1.0367124910273806e-12, disciminator loss fake = 3.5080358173900095e-08, generator loss = 17.754941940307617\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 9, Batch: 446/468, discriminator loss real = 6.909455273825405e-15, disciminator loss fake = 3.423880556852055e-08, generator loss = 17.95937728881836\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 9, Batch: 447/468, discriminator loss real = 2.7697827365003036e-10, disciminator loss fake = 3.368776901879755e-08, generator loss = 17.946964263916016\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 9, Batch: 448/468, discriminator loss real = 1.66653107685485e-15, disciminator loss fake = 4.298439648664498e-08, generator loss = 17.97435760498047\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 9, Batch: 449/468, discriminator loss real = 1.976861591090895e-10, disciminator loss fake = 2.498583384635822e-08, generator loss = 18.056705474853516\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 9, Batch: 450/468, discriminator loss real = 1.2687697030153156e-13, disciminator loss fake = 2.493908723977256e-08, generator loss = 17.990955352783203\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 9, Batch: 451/468, discriminator loss real = 7.321435124829634e-11, disciminator loss fake = 2.3850686758919437e-08, generator loss = 18.015350341796875\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 9, Batch: 452/468, discriminator loss real = 3.462610072580292e-16, disciminator loss fake = 3.0814192086836556e-08, generator loss = 17.9361572265625\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 9, Batch: 453/468, discriminator loss real = 2.0512317296610348e-17, disciminator loss fake = 3.077617094504603e-08, generator loss = 17.90532684326172\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 9, Batch: 454/468, discriminator loss real = 3.555389218711652e-13, disciminator loss fake = 3.4810263116469287e-08, generator loss = 17.970151901245117\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 9, Batch: 455/468, discriminator loss real = 2.3535763351526396e-16, disciminator loss fake = 2.9084134212098434e-08, generator loss = 17.872705459594727\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 9, Batch: 456/468, discriminator loss real = 6.765687315946067e-11, disciminator loss fake = 2.4146512345168958e-08, generator loss = 18.095226287841797\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 9, Batch: 457/468, discriminator loss real = 1.035931865463191e-12, disciminator loss fake = 2.6086228288590974e-08, generator loss = 18.076683044433594\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 9, Batch: 458/468, discriminator loss real = 4.9189380121731664e-15, disciminator loss fake = 3.3714179892285756e-08, generator loss = 17.881053924560547\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 9, Batch: 459/468, discriminator loss real = 2.696424639125894e-09, disciminator loss fake = 2.951890820668268e-08, generator loss = 17.865047454833984\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 9, Batch: 460/468, discriminator loss real = 8.44562522724074e-16, disciminator loss fake = 2.4581405355661445e-08, generator loss = 18.079334259033203\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 9, Batch: 461/468, discriminator loss real = 3.152113792403518e-18, disciminator loss fake = 2.7496817267547158e-08, generator loss = 17.899642944335938\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 9, Batch: 462/468, discriminator loss real = 1.0218610846379761e-08, disciminator loss fake = 1.8380958977104456e-08, generator loss = 17.902721405029297\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 9, Batch: 463/468, discriminator loss real = 9.050686669499598e-17, disciminator loss fake = 2.323378645030516e-08, generator loss = 17.89405059814453\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 9, Batch: 464/468, discriminator loss real = 1.1379149358892171e-11, disciminator loss fake = 2.9161025594248713e-08, generator loss = 17.867656707763672\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 9, Batch: 465/468, discriminator loss real = 2.306666210577686e-14, disciminator loss fake = 3.508593948708949e-08, generator loss = 17.94519805908203\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 9, Batch: 466/468, discriminator loss real = 2.6684555606837357e-11, disciminator loss fake = 2.2364126550655783e-08, generator loss = 18.18602180480957\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 9, Batch: 467/468, discriminator loss real = 1.1155864426681816e-10, disciminator loss fake = 3.6099166322856036e-08, generator loss = 18.046836853027344\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 9, Batch: 468/468, discriminator loss real = 1.090662492774213e-14, disciminator loss fake = 2.8670680052300668e-08, generator loss = 18.25173568725586\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 10, Batch: 1/468, discriminator loss real = 5.184719904483502e-16, disciminator loss fake = 2.8245613847843742e-08, generator loss = 17.87726593017578\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 10, Batch: 2/468, discriminator loss real = 6.1873207227755404e-15, disciminator loss fake = 2.023318401711549e-08, generator loss = 17.89097785949707\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 10, Batch: 3/468, discriminator loss real = 4.6674183615258436e-12, disciminator loss fake = 2.3521248948554785e-08, generator loss = 17.973220825195312\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 10, Batch: 4/468, discriminator loss real = 1.466392805793415e-11, disciminator loss fake = 2.2143495925774914e-08, generator loss = 17.934728622436523\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 10, Batch: 5/468, discriminator loss real = 1.823672289569256e-12, disciminator loss fake = 2.774169161057216e-08, generator loss = 18.07976531982422\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 10, Batch: 6/468, discriminator loss real = 3.2123810551403046e-17, disciminator loss fake = 3.237160228763969e-08, generator loss = 18.015962600708008\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 10, Batch: 7/468, discriminator loss real = 1.3583916592363661e-18, disciminator loss fake = 1.7884588032757165e-08, generator loss = 17.98905372619629\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 10, Batch: 8/468, discriminator loss real = 9.176252660015368e-15, disciminator loss fake = 2.4884025506821672e-08, generator loss = 18.145790100097656\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 10, Batch: 9/468, discriminator loss real = 1.1925276775539176e-18, disciminator loss fake = 2.2439241575966662e-08, generator loss = 18.086883544921875\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 10, Batch: 10/468, discriminator loss real = 6.650028140322726e-15, disciminator loss fake = 2.2424220702532693e-08, generator loss = 18.029212951660156\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 10, Batch: 11/468, discriminator loss real = 1.5272714191418013e-13, disciminator loss fake = 2.649268893151202e-08, generator loss = 18.045333862304688\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 10, Batch: 12/468, discriminator loss real = 2.818745201693673e-07, disciminator loss fake = 3.029877149174354e-08, generator loss = 17.93378448486328\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 10, Batch: 13/468, discriminator loss real = 4.166398197042072e-14, disciminator loss fake = 2.5313903861956533e-08, generator loss = 18.06341552734375\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 10, Batch: 14/468, discriminator loss real = 5.461299273055997e-13, disciminator loss fake = 2.7207745390001037e-08, generator loss = 18.16985321044922\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 10, Batch: 15/468, discriminator loss real = 1.8036953264299882e-08, disciminator loss fake = 2.1157887886147364e-08, generator loss = 17.948673248291016\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 10, Batch: 16/468, discriminator loss real = 1.697251677240272e-18, disciminator loss fake = 2.6076186543377844e-08, generator loss = 18.01813316345215\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 10, Batch: 17/468, discriminator loss real = 2.434287309487776e-14, disciminator loss fake = 3.061618514266229e-08, generator loss = 18.047164916992188\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 10, Batch: 18/468, discriminator loss real = 1.0670209561833982e-13, disciminator loss fake = 2.523702669066097e-08, generator loss = 18.002832412719727\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 10, Batch: 19/468, discriminator loss real = 7.305311357164374e-16, disciminator loss fake = 1.848902186907253e-08, generator loss = 18.033052444458008\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 10, Batch: 20/468, discriminator loss real = 8.897437365866512e-14, disciminator loss fake = 2.401452547928784e-08, generator loss = 17.905521392822266\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 10, Batch: 21/468, discriminator loss real = 1.1045693973395893e-15, disciminator loss fake = 2.4031063361462657e-08, generator loss = 17.975910186767578\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 10, Batch: 22/468, discriminator loss real = 2.180884846053209e-18, disciminator loss fake = 2.5026654526527636e-08, generator loss = 17.92528533935547\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 10, Batch: 23/468, discriminator loss real = 5.3274735734021306e-08, disciminator loss fake = 2.7025739868236087e-08, generator loss = 17.77295684814453\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 10, Batch: 24/468, discriminator loss real = 2.322413908319859e-13, disciminator loss fake = 2.081405980902673e-08, generator loss = 18.087677001953125\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 10, Batch: 25/468, discriminator loss real = 9.123078811498764e-13, disciminator loss fake = 2.1566030738995323e-08, generator loss = 17.942852020263672\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 10, Batch: 26/468, discriminator loss real = 5.840349905084086e-13, disciminator loss fake = 2.2412404376837003e-08, generator loss = 18.07770538330078\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 10, Batch: 27/468, discriminator loss real = 4.932168451432517e-09, disciminator loss fake = 2.7276467307046914e-08, generator loss = 17.948833465576172\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 10, Batch: 28/468, discriminator loss real = 1.629031340093126e-15, disciminator loss fake = 3.398241688046255e-08, generator loss = 18.14104461669922\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 10, Batch: 29/468, discriminator loss real = 1.1121715770556762e-09, disciminator loss fake = 3.032263862223772e-08, generator loss = 17.7679500579834\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 10, Batch: 30/468, discriminator loss real = 4.523941429047644e-17, disciminator loss fake = 2.262417986287346e-08, generator loss = 18.009572982788086\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 10, Batch: 31/468, discriminator loss real = 1.0323596903553944e-14, disciminator loss fake = 2.395997356074986e-08, generator loss = 18.0636043548584\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 10, Batch: 32/468, discriminator loss real = 1.5617475690955562e-16, disciminator loss fake = 2.7467748964227212e-08, generator loss = 18.222061157226562\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 10, Batch: 33/468, discriminator loss real = 2.8013269507963273e-16, disciminator loss fake = 2.213861804989392e-08, generator loss = 18.081117630004883\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 10, Batch: 34/468, discriminator loss real = 5.292761229291898e-10, disciminator loss fake = 2.8190633827307465e-08, generator loss = 18.126216888427734\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 10, Batch: 35/468, discriminator loss real = 7.752286226153648e-13, disciminator loss fake = 2.5364512268311046e-08, generator loss = 17.95392608642578\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 10, Batch: 36/468, discriminator loss real = 4.1122925377445885e-12, disciminator loss fake = 2.0619545182398724e-08, generator loss = 18.164718627929688\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 10, Batch: 37/468, discriminator loss real = 1.7220788326149233e-13, disciminator loss fake = 2.8599984602806217e-08, generator loss = 18.168991088867188\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 10, Batch: 38/468, discriminator loss real = 1.4034470903606373e-15, disciminator loss fake = 2.3292361817084384e-08, generator loss = 18.120880126953125\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 10, Batch: 39/468, discriminator loss real = 3.0318249809309035e-18, disciminator loss fake = 3.084780075823801e-08, generator loss = 17.966140747070312\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 10, Batch: 40/468, discriminator loss real = 3.5874330849700042e-12, disciminator loss fake = 1.8305206239688232e-08, generator loss = 17.970548629760742\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 10, Batch: 41/468, discriminator loss real = 5.260010413233671e-17, disciminator loss fake = 2.442263635771269e-08, generator loss = 18.160091400146484\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 10, Batch: 42/468, discriminator loss real = 8.084927448663223e-14, disciminator loss fake = 2.6684372045338023e-08, generator loss = 18.110862731933594\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 10, Batch: 43/468, discriminator loss real = 8.652035658014354e-14, disciminator loss fake = 2.1409903183666756e-08, generator loss = 18.202272415161133\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 10, Batch: 44/468, discriminator loss real = 9.569681676323098e-15, disciminator loss fake = 2.8931420814615194e-08, generator loss = 17.998994827270508\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 10, Batch: 45/468, discriminator loss real = 1.5445808694558583e-12, disciminator loss fake = 2.0990253091213162e-08, generator loss = 17.958702087402344\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 10, Batch: 46/468, discriminator loss real = 3.650820846399757e-15, disciminator loss fake = 3.1611193662683945e-08, generator loss = 18.104551315307617\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 10, Batch: 47/468, discriminator loss real = 2.644841810839349e-13, disciminator loss fake = 1.8195500217643712e-08, generator loss = 17.95818519592285\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 10, Batch: 48/468, discriminator loss real = 3.426885164525828e-11, disciminator loss fake = 2.2977275193625246e-08, generator loss = 18.231834411621094\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 10, Batch: 49/468, discriminator loss real = 2.6673717488240323e-12, disciminator loss fake = 2.1737459832138484e-08, generator loss = 18.089153289794922\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 10, Batch: 50/468, discriminator loss real = 1.981649296533074e-17, disciminator loss fake = 2.474761373605361e-08, generator loss = 18.125499725341797\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 10, Batch: 51/468, discriminator loss real = 1.4739944925388677e-17, disciminator loss fake = 3.070924137205111e-08, generator loss = 18.227275848388672\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 10, Batch: 52/468, discriminator loss real = 1.0955777300994396e-12, disciminator loss fake = 2.6698137034486535e-08, generator loss = 18.066253662109375\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 10, Batch: 53/468, discriminator loss real = 1.6698205589516651e-13, disciminator loss fake = 2.827290224161061e-08, generator loss = 18.056472778320312\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 10, Batch: 54/468, discriminator loss real = 5.4168170328990767e-14, disciminator loss fake = 2.3203849508490748e-08, generator loss = 18.05707550048828\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 10, Batch: 55/468, discriminator loss real = 7.378626823309562e-15, disciminator loss fake = 2.2344686101405387e-08, generator loss = 18.070011138916016\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 10, Batch: 56/468, discriminator loss real = 3.5178844971610335e-13, disciminator loss fake = 2.461790948871112e-08, generator loss = 18.059940338134766\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 10, Batch: 57/468, discriminator loss real = 2.2765856989284336e-14, disciminator loss fake = 1.62755000587822e-08, generator loss = 18.02991485595703\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 10, Batch: 58/468, discriminator loss real = 7.49611657469007e-12, disciminator loss fake = 3.169432716276788e-08, generator loss = 18.04295539855957\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 10, Batch: 59/468, discriminator loss real = 4.081539098546928e-17, disciminator loss fake = 2.7605763008864415e-08, generator loss = 18.104658126831055\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 10, Batch: 60/468, discriminator loss real = 1.1002236448287572e-12, disciminator loss fake = 2.285490730002948e-08, generator loss = 18.035573959350586\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 10, Batch: 61/468, discriminator loss real = 1.6691292792359036e-10, disciminator loss fake = 2.5271654990888237e-08, generator loss = 18.347270965576172\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 10, Batch: 62/468, discriminator loss real = 9.449646398707046e-09, disciminator loss fake = 2.4242693186238284e-08, generator loss = 17.976816177368164\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 10, Batch: 63/468, discriminator loss real = 7.090145831556427e-11, disciminator loss fake = 2.8027237419792073e-08, generator loss = 18.130630493164062\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 10, Batch: 64/468, discriminator loss real = 7.169481683138267e-15, disciminator loss fake = 2.843950674957796e-08, generator loss = 18.150623321533203\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 10, Batch: 65/468, discriminator loss real = 9.40202451484018e-13, disciminator loss fake = 2.0044357285087244e-08, generator loss = 18.101913452148438\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 10, Batch: 66/468, discriminator loss real = 5.350648259015581e-15, disciminator loss fake = 2.0236985420751807e-08, generator loss = 18.059951782226562\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 10, Batch: 67/468, discriminator loss real = 2.1236320362637187e-17, disciminator loss fake = 2.685184519179984e-08, generator loss = 18.283533096313477\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 10, Batch: 68/468, discriminator loss real = 1.9810718278508166e-13, disciminator loss fake = 2.697043655075504e-08, generator loss = 18.22564697265625\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 10, Batch: 69/468, discriminator loss real = 1.859036362350519e-12, disciminator loss fake = 1.5114409279703978e-08, generator loss = 18.237564086914062\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 10, Batch: 70/468, discriminator loss real = 2.5775337268198195e-13, disciminator loss fake = 2.290202871790825e-08, generator loss = 18.15442657470703\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 10, Batch: 71/468, discriminator loss real = 4.575448526999981e-12, disciminator loss fake = 2.307846536098168e-08, generator loss = 18.218551635742188\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 10, Batch: 72/468, discriminator loss real = 1.0202151860675465e-14, disciminator loss fake = 2.4986428925899418e-08, generator loss = 18.249107360839844\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 10, Batch: 73/468, discriminator loss real = 1.022363075274535e-12, disciminator loss fake = 2.1910929959290115e-08, generator loss = 18.082475662231445\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 10, Batch: 74/468, discriminator loss real = 3.155151649929938e-14, disciminator loss fake = 1.885756795161342e-08, generator loss = 18.204185485839844\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 10, Batch: 75/468, discriminator loss real = 1.8317213215827353e-17, disciminator loss fake = 2.1916800818644333e-08, generator loss = 18.227575302124023\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 10, Batch: 76/468, discriminator loss real = 1.4714115259550908e-08, disciminator loss fake = 1.911692848466373e-08, generator loss = 18.30007553100586\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 10, Batch: 77/468, discriminator loss real = 2.941148713464514e-10, disciminator loss fake = 2.2720939796272432e-08, generator loss = 18.18037986755371\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 10, Batch: 78/468, discriminator loss real = 4.565593779773391e-13, disciminator loss fake = 2.2929732779175538e-08, generator loss = 18.172393798828125\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 10, Batch: 79/468, discriminator loss real = 1.2102448254983859e-14, disciminator loss fake = 2.039534408027066e-08, generator loss = 18.34783172607422\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 10, Batch: 80/468, discriminator loss real = 7.542996782738953e-11, disciminator loss fake = 2.4811573240413054e-08, generator loss = 18.095163345336914\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 10, Batch: 81/468, discriminator loss real = 1.9114421959294525e-13, disciminator loss fake = 2.9716989757844203e-08, generator loss = 18.0974063873291\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 10, Batch: 82/468, discriminator loss real = 1.46021195623295e-15, disciminator loss fake = 2.40199788947848e-08, generator loss = 18.126136779785156\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 10, Batch: 83/468, discriminator loss real = 6.806979025580917e-14, disciminator loss fake = 2.1139314299034595e-08, generator loss = 18.311025619506836\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 10, Batch: 84/468, discriminator loss real = 3.925769214915831e-13, disciminator loss fake = 2.6684306320134965e-08, generator loss = 18.083189010620117\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 10, Batch: 85/468, discriminator loss real = 1.6908637033921647e-13, disciminator loss fake = 1.992092535374468e-08, generator loss = 18.258350372314453\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 10, Batch: 86/468, discriminator loss real = 2.5401886540390994e-13, disciminator loss fake = 2.2196175564204168e-08, generator loss = 18.315868377685547\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 10, Batch: 87/468, discriminator loss real = 5.0769464101250704e-17, disciminator loss fake = 2.401005616547991e-08, generator loss = 18.198837280273438\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 10, Batch: 88/468, discriminator loss real = 5.814592662303113e-17, disciminator loss fake = 2.4343567162077306e-08, generator loss = 18.190439224243164\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 10, Batch: 89/468, discriminator loss real = 5.386541026045598e-14, disciminator loss fake = 2.2334234017762356e-08, generator loss = 18.230525970458984\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 10, Batch: 90/468, discriminator loss real = 7.37501507482247e-15, disciminator loss fake = 2.298229517805339e-08, generator loss = 18.16505241394043\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 10, Batch: 91/468, discriminator loss real = 7.01393153626495e-14, disciminator loss fake = 2.2864277582357317e-08, generator loss = 18.1699161529541\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 10, Batch: 92/468, discriminator loss real = 1.3053935536688765e-11, disciminator loss fake = 1.9049039678975532e-08, generator loss = 18.165260314941406\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 10, Batch: 93/468, discriminator loss real = 1.12643216474117e-15, disciminator loss fake = 2.021740108659742e-08, generator loss = 18.159008026123047\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 10, Batch: 94/468, discriminator loss real = 1.2778477278055367e-12, disciminator loss fake = 1.828477991239197e-08, generator loss = 18.255367279052734\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 10, Batch: 95/468, discriminator loss real = 1.0335028169042513e-16, disciminator loss fake = 1.8683000035935038e-08, generator loss = 18.140132904052734\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 10, Batch: 96/468, discriminator loss real = 4.811610665456101e-07, disciminator loss fake = 2.519389674660033e-08, generator loss = 18.445051193237305\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 10, Batch: 97/468, discriminator loss real = 5.361576460582995e-11, disciminator loss fake = 2.2171363411871425e-08, generator loss = 18.135040283203125\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 10, Batch: 98/468, discriminator loss real = 1.2037160956879234e-07, disciminator loss fake = 2.0043311010908837e-08, generator loss = 18.32077407836914\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 10, Batch: 99/468, discriminator loss real = 5.806360709077751e-13, disciminator loss fake = 2.8848216260257686e-08, generator loss = 18.076683044433594\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 10, Batch: 100/468, discriminator loss real = 3.45321077288574e-10, disciminator loss fake = 1.8073309959731887e-08, generator loss = 18.112890243530273\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 10, Batch: 101/468, discriminator loss real = 4.839275410516847e-14, disciminator loss fake = 3.0551881025076e-08, generator loss = 18.052249908447266\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 10, Batch: 102/468, discriminator loss real = 8.859072067311812e-16, disciminator loss fake = 2.772866025679832e-08, generator loss = 18.228824615478516\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 10, Batch: 103/468, discriminator loss real = 1.2043188559444527e-16, disciminator loss fake = 2.0234217856796022e-08, generator loss = 18.124507904052734\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 10, Batch: 104/468, discriminator loss real = 3.6714224325648526e-13, disciminator loss fake = 1.5416585341654354e-08, generator loss = 18.230087280273438\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 10, Batch: 105/468, discriminator loss real = 9.562458179348914e-15, disciminator loss fake = 2.3893580447520435e-08, generator loss = 18.076108932495117\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 10, Batch: 106/468, discriminator loss real = 2.9425541864247506e-12, disciminator loss fake = 2.27428316179612e-08, generator loss = 18.096467971801758\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 10, Batch: 107/468, discriminator loss real = 3.8163444843544725e-13, disciminator loss fake = 1.9973439790987868e-08, generator loss = 17.969409942626953\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 10, Batch: 108/468, discriminator loss real = 2.256030029457179e-09, disciminator loss fake = 2.3459143960735673e-08, generator loss = 18.01493263244629\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 10, Batch: 109/468, discriminator loss real = 6.745442399092028e-11, disciminator loss fake = 1.4825768168691411e-08, generator loss = 18.071643829345703\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 10, Batch: 110/468, discriminator loss real = 4.116110528589942e-14, disciminator loss fake = 1.9889334623712784e-08, generator loss = 18.204002380371094\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 10, Batch: 111/468, discriminator loss real = 1.0258052220157854e-11, disciminator loss fake = 1.5814533682600995e-08, generator loss = 17.987686157226562\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 10, Batch: 112/468, discriminator loss real = 9.69271107820191e-10, disciminator loss fake = 2.871613347110724e-08, generator loss = 18.195173263549805\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 10, Batch: 113/468, discriminator loss real = 4.198899283824886e-10, disciminator loss fake = 2.296915191379867e-08, generator loss = 18.107044219970703\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 10, Batch: 114/468, discriminator loss real = 4.65039284858193e-10, disciminator loss fake = 1.7567645116400854e-08, generator loss = 18.219036102294922\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 10, Batch: 115/468, discriminator loss real = 8.211181330517326e-16, disciminator loss fake = 2.0864021621491702e-08, generator loss = 18.174922943115234\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 10, Batch: 116/468, discriminator loss real = 1.96717834910487e-07, disciminator loss fake = 2.1404790828682962e-08, generator loss = 18.072154998779297\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 10, Batch: 117/468, discriminator loss real = 2.057745250236276e-14, disciminator loss fake = 2.976450375058448e-08, generator loss = 18.14765167236328\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 10, Batch: 118/468, discriminator loss real = 8.82046849838905e-14, disciminator loss fake = 2.827544243189095e-08, generator loss = 18.312946319580078\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 10, Batch: 119/468, discriminator loss real = 2.9168152810600534e-13, disciminator loss fake = 2.8137353780266494e-08, generator loss = 18.12274932861328\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 10, Batch: 120/468, discriminator loss real = 2.7136624110996044e-12, disciminator loss fake = 1.775759983502212e-08, generator loss = 18.138200759887695\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 10, Batch: 121/468, discriminator loss real = 1.5340002149934716e-14, disciminator loss fake = 2.1590404131188734e-08, generator loss = 18.15056037902832\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 10, Batch: 122/468, discriminator loss real = 1.5990049562208952e-11, disciminator loss fake = 2.7628388465927856e-08, generator loss = 18.283000946044922\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 10, Batch: 123/468, discriminator loss real = 1.0586920879893102e-12, disciminator loss fake = 1.69696363627736e-08, generator loss = 18.26132583618164\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 10, Batch: 124/468, discriminator loss real = 9.663680272664621e-11, disciminator loss fake = 1.6134563907144184e-08, generator loss = 18.171613693237305\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 10, Batch: 125/468, discriminator loss real = 3.2645709052703253e-12, disciminator loss fake = 2.101280216493251e-08, generator loss = 18.235950469970703\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 10, Batch: 126/468, discriminator loss real = 6.466951106565144e-12, disciminator loss fake = 1.78000103545628e-08, generator loss = 18.230266571044922\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 10, Batch: 127/468, discriminator loss real = 2.3975201164649906e-13, disciminator loss fake = 2.641977481232516e-08, generator loss = 18.170269012451172\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 10, Batch: 128/468, discriminator loss real = 2.477760133334613e-17, disciminator loss fake = 2.6171161238153218e-08, generator loss = 18.13397979736328\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 10, Batch: 129/468, discriminator loss real = 2.2494487175728217e-11, disciminator loss fake = 1.845771535613494e-08, generator loss = 18.16688346862793\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 10, Batch: 130/468, discriminator loss real = 6.757607677371127e-16, disciminator loss fake = 1.6862729879107974e-08, generator loss = 18.335433959960938\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 10, Batch: 131/468, discriminator loss real = 1.9027094217685322e-14, disciminator loss fake = 2.3475910992942772e-08, generator loss = 18.108062744140625\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 10, Batch: 132/468, discriminator loss real = 6.711839742844228e-13, disciminator loss fake = 3.0833355424420006e-08, generator loss = 18.14126205444336\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 10, Batch: 133/468, discriminator loss real = 3.6262678515357194e-13, disciminator loss fake = 1.67297891096041e-08, generator loss = 18.187482833862305\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 10, Batch: 134/468, discriminator loss real = 3.5308320395048554e-13, disciminator loss fake = 1.8212379160331693e-08, generator loss = 18.3240966796875\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 10, Batch: 135/468, discriminator loss real = 2.172460507822724e-17, disciminator loss fake = 1.6494572818714914e-08, generator loss = 18.144153594970703\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 10, Batch: 136/468, discriminator loss real = 7.853359629272916e-11, disciminator loss fake = 1.910686542316853e-08, generator loss = 18.184207916259766\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 10, Batch: 137/468, discriminator loss real = 1.0822789841787635e-15, disciminator loss fake = 3.1817130263789295e-08, generator loss = 18.206708908081055\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 10, Batch: 138/468, discriminator loss real = 2.7509720914556564e-14, disciminator loss fake = 2.300767931728842e-08, generator loss = 18.308734893798828\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 10, Batch: 139/468, discriminator loss real = 1.0612685436803574e-15, disciminator loss fake = 1.8502133158904144e-08, generator loss = 18.219127655029297\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 10, Batch: 140/468, discriminator loss real = 5.540715442009514e-09, disciminator loss fake = 1.6050591966632055e-08, generator loss = 18.233800888061523\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 10, Batch: 141/468, discriminator loss real = 1.906513819429148e-13, disciminator loss fake = 1.7853187372907087e-08, generator loss = 18.34123992919922\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 10, Batch: 142/468, discriminator loss real = 4.014262609385727e-14, disciminator loss fake = 1.8163705206575287e-08, generator loss = 18.3369197845459\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 10, Batch: 143/468, discriminator loss real = 3.5962871579547405e-17, disciminator loss fake = 2.3307347163381564e-08, generator loss = 18.21662712097168\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 10, Batch: 144/468, discriminator loss real = 1.834679451802123e-16, disciminator loss fake = 1.6210712772135594e-08, generator loss = 18.20021629333496\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 10, Batch: 145/468, discriminator loss real = 5.3419809943828014e-15, disciminator loss fake = 1.870244936696963e-08, generator loss = 18.20441246032715\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 10, Batch: 146/468, discriminator loss real = 1.3802314846600439e-08, disciminator loss fake = 1.6696448668085395e-08, generator loss = 18.270984649658203\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 10, Batch: 147/468, discriminator loss real = 3.879266902823662e-15, disciminator loss fake = 2.047202762867073e-08, generator loss = 18.26293182373047\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 10, Batch: 148/468, discriminator loss real = 1.904235679848278e-16, disciminator loss fake = 1.793593185084319e-08, generator loss = 18.462907791137695\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 10, Batch: 149/468, discriminator loss real = 8.796457836751223e-18, disciminator loss fake = 1.832183116334818e-08, generator loss = 18.32392692565918\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 10, Batch: 150/468, discriminator loss real = 2.5424307992238937e-08, disciminator loss fake = 1.6514762890551538e-08, generator loss = 18.293872833251953\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 10, Batch: 151/468, discriminator loss real = 3.7643374528606444e-11, disciminator loss fake = 2.50852316696637e-08, generator loss = 18.302614212036133\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 10, Batch: 152/468, discriminator loss real = 2.3867760198803545e-11, disciminator loss fake = 3.068255693960964e-08, generator loss = 18.175790786743164\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 10, Batch: 153/468, discriminator loss real = 2.7841695615649087e-09, disciminator loss fake = 1.8277942714917117e-08, generator loss = 18.311466217041016\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 10, Batch: 154/468, discriminator loss real = 1.4092652537962087e-15, disciminator loss fake = 2.0004549128316285e-08, generator loss = 18.1051025390625\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 10, Batch: 155/468, discriminator loss real = 3.813302971999999e-12, disciminator loss fake = 1.964070150961561e-08, generator loss = 17.910852432250977\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 10, Batch: 156/468, discriminator loss real = 7.140952868085748e-13, disciminator loss fake = 1.988120246210201e-08, generator loss = 18.267040252685547\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 10, Batch: 157/468, discriminator loss real = 1.510761188459192e-13, disciminator loss fake = 2.3197817000664145e-08, generator loss = 18.172977447509766\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 10, Batch: 158/468, discriminator loss real = 1.3663789544260396e-10, disciminator loss fake = 1.686297679270865e-08, generator loss = 18.191207885742188\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 10, Batch: 159/468, discriminator loss real = 5.26572705439321e-07, disciminator loss fake = 2.8931449236324625e-08, generator loss = 18.226619720458984\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 10, Batch: 160/468, discriminator loss real = 1.0175205122919806e-10, disciminator loss fake = 1.769934243611715e-08, generator loss = 18.313617706298828\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 10, Batch: 161/468, discriminator loss real = 1.147167425410837e-15, disciminator loss fake = 2.076131266903758e-08, generator loss = 18.134662628173828\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 10, Batch: 162/468, discriminator loss real = 1.3323064873560497e-11, disciminator loss fake = 2.133685228500326e-08, generator loss = 18.21567153930664\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 10, Batch: 163/468, discriminator loss real = 3.3900193490005984e-16, disciminator loss fake = 1.868047405650941e-08, generator loss = 18.213668823242188\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "Epoch: 10, Batch: 164/468, discriminator loss real = 2.518515181560571e-13, disciminator loss fake = 1.9595528755189662e-08, generator loss = 18.106098175048828\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 10, Batch: 165/468, discriminator loss real = 5.93265529086497e-16, disciminator loss fake = 1.822423989494837e-08, generator loss = 18.24087142944336\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 10, Batch: 166/468, discriminator loss real = 1.0879045196166351e-13, disciminator loss fake = 1.9636210879525606e-08, generator loss = 18.150821685791016\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 10, Batch: 167/468, discriminator loss real = 1.3008265474066065e-17, disciminator loss fake = 1.9263046269202277e-08, generator loss = 18.317447662353516\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 10, Batch: 168/468, discriminator loss real = 1.2480318428015336e-12, disciminator loss fake = 2.154604850090891e-08, generator loss = 18.23495101928711\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 10, Batch: 169/468, discriminator loss real = 3.223471836677483e-11, disciminator loss fake = 2.237198870602697e-08, generator loss = 18.105989456176758\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 10, Batch: 170/468, discriminator loss real = 1.028307560629882e-11, disciminator loss fake = 2.324314607449196e-08, generator loss = 18.204612731933594\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 10, Batch: 171/468, discriminator loss real = 7.20580279472971e-13, disciminator loss fake = 1.7809741237329035e-08, generator loss = 18.270002365112305\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 10, Batch: 172/468, discriminator loss real = 2.719814323304086e-15, disciminator loss fake = 1.9999273348503266e-08, generator loss = 18.08149528503418\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 10, Batch: 173/468, discriminator loss real = 1.3962205523687654e-11, disciminator loss fake = 2.1898101110195967e-08, generator loss = 18.24478530883789\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 10, Batch: 174/468, discriminator loss real = 3.4387239583599793e-11, disciminator loss fake = 2.1911199965529704e-08, generator loss = 18.226028442382812\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 10, Batch: 175/468, discriminator loss real = 2.7808033653542452e-12, disciminator loss fake = 2.195889692302444e-08, generator loss = 18.194950103759766\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 10, Batch: 176/468, discriminator loss real = 6.942927135988874e-14, disciminator loss fake = 1.824111350856583e-08, generator loss = 18.27504539489746\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 10, Batch: 177/468, discriminator loss real = 7.273655618343113e-16, disciminator loss fake = 2.002796151145958e-08, generator loss = 18.318538665771484\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 10, Batch: 178/468, discriminator loss real = 1.453486832269106e-16, disciminator loss fake = 2.258629727691641e-08, generator loss = 18.136688232421875\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 10, Batch: 179/468, discriminator loss real = 4.609045783920962e-11, disciminator loss fake = 2.0915994269898874e-08, generator loss = 18.24978256225586\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 10, Batch: 180/468, discriminator loss real = 7.32964172212372e-14, disciminator loss fake = 1.8549902947029295e-08, generator loss = 18.217483520507812\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 10, Batch: 181/468, discriminator loss real = 1.0768805552147098e-13, disciminator loss fake = 1.9453944233305265e-08, generator loss = 18.229469299316406\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 10, Batch: 182/468, discriminator loss real = 1.510535030662275e-17, disciminator loss fake = 2.1829276164453404e-08, generator loss = 18.40680694580078\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 10, Batch: 183/468, discriminator loss real = 6.99583056415487e-12, disciminator loss fake = 1.6752785825246974e-08, generator loss = 18.192047119140625\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 10, Batch: 184/468, discriminator loss real = 2.9352816835123696e-13, disciminator loss fake = 1.6831450011522975e-08, generator loss = 18.224393844604492\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 10, Batch: 185/468, discriminator loss real = 7.498374837711097e-11, disciminator loss fake = 1.2659581827278998e-08, generator loss = 18.412559509277344\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 10, Batch: 186/468, discriminator loss real = 3.147595099600893e-14, disciminator loss fake = 2.3110480640298192e-08, generator loss = 18.057207107543945\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 10, Batch: 187/468, discriminator loss real = 6.58117562724915e-14, disciminator loss fake = 2.090729545045633e-08, generator loss = 18.320693969726562\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 10, Batch: 188/468, discriminator loss real = 1.0163046212973217e-13, disciminator loss fake = 1.7519308670443934e-08, generator loss = 18.301143646240234\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 10, Batch: 189/468, discriminator loss real = 3.6887872856099235e-13, disciminator loss fake = 2.4728912251248403e-08, generator loss = 18.166114807128906\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 10, Batch: 190/468, discriminator loss real = 7.481839800482781e-12, disciminator loss fake = 2.3377182856165746e-08, generator loss = 18.236921310424805\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 10, Batch: 191/468, discriminator loss real = 1.7030515575027642e-18, disciminator loss fake = 2.1750043543988795e-08, generator loss = 18.267881393432617\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 10, Batch: 192/468, discriminator loss real = 4.4960690819993024e-17, disciminator loss fake = 1.587440578987298e-08, generator loss = 18.130582809448242\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 10, Batch: 193/468, discriminator loss real = 3.427431949365456e-11, disciminator loss fake = 2.1730137689246476e-08, generator loss = 18.298818588256836\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 10, Batch: 194/468, discriminator loss real = 3.637254343200058e-15, disciminator loss fake = 1.6578930228661193e-08, generator loss = 18.339384078979492\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 10, Batch: 195/468, discriminator loss real = 1.4747903419320973e-13, disciminator loss fake = 2.1446256326385083e-08, generator loss = 18.324270248413086\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 10, Batch: 196/468, discriminator loss real = 3.241198042448182e-15, disciminator loss fake = 2.4824549527124873e-08, generator loss = 18.28920555114746\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 10, Batch: 197/468, discriminator loss real = 9.549715185297458e-11, disciminator loss fake = 2.5130951541996183e-08, generator loss = 18.196609497070312\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 10, Batch: 198/468, discriminator loss real = 1.3237697715068591e-14, disciminator loss fake = 2.1851192855137924e-08, generator loss = 18.376522064208984\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 10, Batch: 199/468, discriminator loss real = 6.240414296421193e-10, disciminator loss fake = 1.4119882152385799e-08, generator loss = 18.25437355041504\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 10, Batch: 200/468, discriminator loss real = 3.260146874684011e-10, disciminator loss fake = 3.0876631029741475e-08, generator loss = 18.33616828918457\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 10, Batch: 201/468, discriminator loss real = 1.0967365660389736e-13, disciminator loss fake = 1.644574432191348e-08, generator loss = 18.232070922851562\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 10, Batch: 202/468, discriminator loss real = 1.5837437494802854e-14, disciminator loss fake = 2.0277216350450544e-08, generator loss = 18.365989685058594\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 10, Batch: 203/468, discriminator loss real = 1.6785003088500873e-14, disciminator loss fake = 1.780738401180315e-08, generator loss = 18.44132423400879\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 10, Batch: 204/468, discriminator loss real = 8.651588560143475e-13, disciminator loss fake = 2.510951091494462e-08, generator loss = 18.35003662109375\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 10, Batch: 205/468, discriminator loss real = 7.298369943337449e-14, disciminator loss fake = 2.2357211193479998e-08, generator loss = 18.259443283081055\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 10, Batch: 206/468, discriminator loss real = 6.415071851506582e-08, disciminator loss fake = 2.2141000144415557e-08, generator loss = 18.26571273803711\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 10, Batch: 207/468, discriminator loss real = 9.738030083394821e-17, disciminator loss fake = 1.7882328506857448e-08, generator loss = 18.292972564697266\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 10, Batch: 208/468, discriminator loss real = 9.266423349127417e-13, disciminator loss fake = 1.7430274112939514e-08, generator loss = 18.29422378540039\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 10, Batch: 209/468, discriminator loss real = 8.296730070003235e-15, disciminator loss fake = 2.0585002147299747e-08, generator loss = 18.335426330566406\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 10, Batch: 210/468, discriminator loss real = 4.3335210420103465e-11, disciminator loss fake = 2.1744593681205515e-08, generator loss = 18.30579376220703\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 10, Batch: 211/468, discriminator loss real = 6.642777008898637e-16, disciminator loss fake = 1.4443894080784503e-08, generator loss = 18.255149841308594\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 10, Batch: 212/468, discriminator loss real = 4.412233086146134e-18, disciminator loss fake = 1.7214651037988915e-08, generator loss = 18.1959285736084\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 10, Batch: 213/468, discriminator loss real = 5.12954099769064e-13, disciminator loss fake = 1.7178052758026752e-08, generator loss = 18.394329071044922\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 10, Batch: 214/468, discriminator loss real = 4.7960472926433795e-08, disciminator loss fake = 1.4814589555101065e-08, generator loss = 18.367599487304688\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 10, Batch: 215/468, discriminator loss real = 6.211192017053298e-16, disciminator loss fake = 1.7517557182600285e-08, generator loss = 18.30046844482422\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 10, Batch: 216/468, discriminator loss real = 2.0844567738542708e-10, disciminator loss fake = 2.37887203269338e-08, generator loss = 18.207229614257812\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 10, Batch: 217/468, discriminator loss real = 4.105847792697714e-15, disciminator loss fake = 3.284540639469924e-08, generator loss = 18.301109313964844\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 10, Batch: 218/468, discriminator loss real = 1.448836845852411e-13, disciminator loss fake = 1.3993549430324492e-08, generator loss = 18.243511199951172\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 10, Batch: 219/468, discriminator loss real = 2.251106419326465e-11, disciminator loss fake = 1.8911157084744445e-08, generator loss = 18.283790588378906\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 10, Batch: 220/468, discriminator loss real = 9.554850834148088e-12, disciminator loss fake = 1.3773171048114818e-08, generator loss = 18.36829376220703\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 10, Batch: 221/468, discriminator loss real = 4.394152142844776e-12, disciminator loss fake = 1.938734683903931e-08, generator loss = 18.307422637939453\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 10, Batch: 222/468, discriminator loss real = 7.614097615132623e-17, disciminator loss fake = 1.5469577618887342e-08, generator loss = 18.31477928161621\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 10, Batch: 223/468, discriminator loss real = 4.751685850346021e-11, disciminator loss fake = 1.9995905375935763e-08, generator loss = 18.113849639892578\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 10, Batch: 224/468, discriminator loss real = 2.2299403643066817e-11, disciminator loss fake = 2.044116698129983e-08, generator loss = 18.340564727783203\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 10, Batch: 225/468, discriminator loss real = 4.645046626425818e-17, disciminator loss fake = 1.4378128909697807e-08, generator loss = 18.275754928588867\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 10, Batch: 226/468, discriminator loss real = 4.929029406852692e-12, disciminator loss fake = 1.7884804748291572e-08, generator loss = 18.45093536376953\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 10, Batch: 227/468, discriminator loss real = 3.8108353095383344e-17, disciminator loss fake = 2.373057483850971e-08, generator loss = 18.306865692138672\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 10, Batch: 228/468, discriminator loss real = 5.109681530971952e-14, disciminator loss fake = 1.4149478033687046e-08, generator loss = 18.3768310546875\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 10, Batch: 229/468, discriminator loss real = 2.7428133007011135e-13, disciminator loss fake = 1.4646037271859313e-08, generator loss = 18.32787322998047\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 10, Batch: 230/468, discriminator loss real = 7.306829837364082e-13, disciminator loss fake = 2.2776859509576752e-08, generator loss = 18.53673553466797\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 10, Batch: 231/468, discriminator loss real = 1.0834252738662828e-14, disciminator loss fake = 2.2988768222376166e-08, generator loss = 18.258670806884766\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 10, Batch: 232/468, discriminator loss real = 6.249212844249008e-13, disciminator loss fake = 1.6705177685594208e-08, generator loss = 18.559452056884766\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 10, Batch: 233/468, discriminator loss real = 3.069814435746783e-14, disciminator loss fake = 1.8971702431258564e-08, generator loss = 18.28402328491211\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 10, Batch: 234/468, discriminator loss real = 1.4802403009925302e-12, disciminator loss fake = 1.3368055107321197e-08, generator loss = 18.374591827392578\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 10, Batch: 235/468, discriminator loss real = 1.6014757066046964e-13, disciminator loss fake = 1.5238784456528265e-08, generator loss = 18.252395629882812\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 10, Batch: 236/468, discriminator loss real = 2.1909232240935328e-12, disciminator loss fake = 1.8036860893744233e-08, generator loss = 18.409400939941406\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 10, Batch: 237/468, discriminator loss real = 9.501921738319652e-08, disciminator loss fake = 1.9235116610616387e-08, generator loss = 18.407011032104492\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 10, Batch: 238/468, discriminator loss real = 1.835460045602577e-15, disciminator loss fake = 1.5894451976805613e-08, generator loss = 18.324459075927734\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 10, Batch: 239/468, discriminator loss real = 1.1886031167553796e-13, disciminator loss fake = 2.4455436786752216e-08, generator loss = 18.26374053955078\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 10, Batch: 240/468, discriminator loss real = 1.743507005436129e-09, disciminator loss fake = 1.277073469196921e-08, generator loss = 18.374555587768555\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 10, Batch: 241/468, discriminator loss real = 2.489762821807778e-16, disciminator loss fake = 1.591290832436698e-08, generator loss = 18.330631256103516\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 10, Batch: 242/468, discriminator loss real = 2.623106809887532e-13, disciminator loss fake = 1.856907871911062e-08, generator loss = 18.34015464782715\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 10, Batch: 243/468, discriminator loss real = 9.512433048758785e-16, disciminator loss fake = 1.5225101179794365e-08, generator loss = 18.4598388671875\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 10, Batch: 244/468, discriminator loss real = 7.563026593881972e-12, disciminator loss fake = 1.8683413927078618e-08, generator loss = 18.405200958251953\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 10, Batch: 245/468, discriminator loss real = 8.675888341080906e-10, disciminator loss fake = 1.816742312144015e-08, generator loss = 18.473346710205078\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 10, Batch: 246/468, discriminator loss real = 4.1398399872006816e-14, disciminator loss fake = 1.9598715539359546e-08, generator loss = 18.361059188842773\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 10, Batch: 247/468, discriminator loss real = 8.306645757201692e-22, disciminator loss fake = 1.802238358550312e-08, generator loss = 18.355422973632812\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 10, Batch: 248/468, discriminator loss real = 3.531244578431486e-13, disciminator loss fake = 2.0508466036517348e-08, generator loss = 18.24414825439453\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 10, Batch: 249/468, discriminator loss real = 3.156352068600654e-09, disciminator loss fake = 1.8488835351604394e-08, generator loss = 18.32229232788086\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 10, Batch: 250/468, discriminator loss real = 3.967170288023819e-13, disciminator loss fake = 1.5793354180004826e-08, generator loss = 18.429962158203125\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 10, Batch: 251/468, discriminator loss real = 1.0175328047771595e-16, disciminator loss fake = 1.9844016208026005e-08, generator loss = 18.336345672607422\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 10, Batch: 252/468, discriminator loss real = 7.70111318465494e-12, disciminator loss fake = 1.92988132141636e-08, generator loss = 18.24908447265625\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 10, Batch: 253/468, discriminator loss real = 1.8561398891416697e-14, disciminator loss fake = 1.5014563814474968e-08, generator loss = 18.357635498046875\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 10, Batch: 254/468, discriminator loss real = 3.9565615171696336e-19, disciminator loss fake = 2.1247986481398584e-08, generator loss = 18.468700408935547\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 10, Batch: 255/468, discriminator loss real = 2.350963174135856e-12, disciminator loss fake = 2.582358504810145e-08, generator loss = 18.524452209472656\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 10, Batch: 256/468, discriminator loss real = 9.821722324332427e-10, disciminator loss fake = 2.0665755329218882e-08, generator loss = 18.49551010131836\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 10, Batch: 257/468, discriminator loss real = 2.009020696385009e-14, disciminator loss fake = 1.4799223180261833e-08, generator loss = 18.431060791015625\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 10, Batch: 258/468, discriminator loss real = 2.3347412870210194e-15, disciminator loss fake = 1.9998541489485433e-08, generator loss = 18.252792358398438\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 10, Batch: 259/468, discriminator loss real = 6.903004588536472e-16, disciminator loss fake = 1.5902656969046802e-08, generator loss = 18.373083114624023\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 10, Batch: 260/468, discriminator loss real = 1.1270138603825322e-13, disciminator loss fake = 1.8619772390593425e-08, generator loss = 18.323787689208984\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 10, Batch: 261/468, discriminator loss real = 4.032885658405539e-17, disciminator loss fake = 1.6940997937808788e-08, generator loss = 18.487957000732422\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 10, Batch: 262/468, discriminator loss real = 5.332963375747214e-16, disciminator loss fake = 1.9903636072626796e-08, generator loss = 18.437353134155273\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 10, Batch: 263/468, discriminator loss real = 5.036310257722221e-11, disciminator loss fake = 1.4737119080621142e-08, generator loss = 18.342517852783203\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 10, Batch: 264/468, discriminator loss real = 3.683800486875555e-11, disciminator loss fake = 1.3719013480795184e-08, generator loss = 18.443708419799805\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 10, Batch: 265/468, discriminator loss real = 1.423111743736622e-14, disciminator loss fake = 1.809859284662707e-08, generator loss = 18.492708206176758\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 10, Batch: 266/468, discriminator loss real = 6.902974285932784e-14, disciminator loss fake = 1.6383065570835242e-08, generator loss = 18.345373153686523\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 10, Batch: 267/468, discriminator loss real = 1.9762006267520782e-11, disciminator loss fake = 1.8927124756373814e-08, generator loss = 18.31673812866211\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 10, Batch: 268/468, discriminator loss real = 3.071779890997592e-14, disciminator loss fake = 2.263618270603729e-08, generator loss = 18.36118507385254\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 10, Batch: 269/468, discriminator loss real = 1.4882435284135909e-09, disciminator loss fake = 1.849548425525427e-08, generator loss = 18.519140243530273\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 10, Batch: 270/468, discriminator loss real = 6.472769131934345e-15, disciminator loss fake = 1.3108010676887716e-08, generator loss = 18.382465362548828\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 10, Batch: 271/468, discriminator loss real = 5.752078067328137e-12, disciminator loss fake = 1.5283649901220997e-08, generator loss = 18.557865142822266\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 10, Batch: 272/468, discriminator loss real = 1.8447599676139903e-13, disciminator loss fake = 1.7554910414219194e-08, generator loss = 18.55636978149414\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 10, Batch: 273/468, discriminator loss real = 1.795907850600867e-13, disciminator loss fake = 1.387286374665564e-08, generator loss = 18.264694213867188\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 10, Batch: 274/468, discriminator loss real = 4.889950222519701e-09, disciminator loss fake = 2.050401803899149e-08, generator loss = 18.52837371826172\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 10, Batch: 275/468, discriminator loss real = 6.696753818147272e-09, disciminator loss fake = 2.0584469240247927e-08, generator loss = 18.429834365844727\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 10, Batch: 276/468, discriminator loss real = 5.332889078252245e-12, disciminator loss fake = 2.238789065245328e-08, generator loss = 18.37453842163086\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 10, Batch: 277/468, discriminator loss real = 7.262737638938713e-14, disciminator loss fake = 1.7458766876643494e-08, generator loss = 18.537612915039062\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 10, Batch: 278/468, discriminator loss real = 1.1577484571034802e-07, disciminator loss fake = 1.479093825196287e-08, generator loss = 18.32744026184082\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 10, Batch: 279/468, discriminator loss real = 3.5810063248042923e-10, disciminator loss fake = 1.7894187465117284e-08, generator loss = 18.557186126708984\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 10, Batch: 280/468, discriminator loss real = 3.062005469599456e-14, disciminator loss fake = 1.9722728339388595e-08, generator loss = 18.492576599121094\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 10, Batch: 281/468, discriminator loss real = 1.670659003139008e-05, disciminator loss fake = 2.3223883260925504e-08, generator loss = 17.71839141845703\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 10, Batch: 282/468, discriminator loss real = 1.325574798717458e-17, disciminator loss fake = 6.922159201394606e-08, generator loss = 17.15658187866211\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 10, Batch: 283/468, discriminator loss real = 3.4948179048295956e-17, disciminator loss fake = 1.9636613046714047e-07, generator loss = 16.479825973510742\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 10, Batch: 284/468, discriminator loss real = 1.5387763002638156e-17, disciminator loss fake = 1.5908574368950212e-06, generator loss = 16.044891357421875\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 10, Batch: 285/468, discriminator loss real = 4.013224898734134e-17, disciminator loss fake = 4.853562131756917e-06, generator loss = 16.143840789794922\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 10, Batch: 286/468, discriminator loss real = 2.591629358601269e-21, disciminator loss fake = 5.368608526623575e-07, generator loss = 16.39101219177246\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 10, Batch: 287/468, discriminator loss real = 9.460054267718121e-14, disciminator loss fake = 1.9086462543782545e-06, generator loss = 16.44938850402832\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 10, Batch: 288/468, discriminator loss real = 3.891053257376598e-09, disciminator loss fake = 5.217108309807372e-07, generator loss = 16.91962432861328\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 10, Batch: 289/468, discriminator loss real = 2.44341959859673e-12, disciminator loss fake = 2.41477152940206e-07, generator loss = 16.827512741088867\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 10, Batch: 290/468, discriminator loss real = 8.342235384810339e-19, disciminator loss fake = 1.336277222208082e-07, generator loss = 17.10384750366211\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 10, Batch: 291/468, discriminator loss real = 4.8603865552917475e-17, disciminator loss fake = 8.857450950472412e-08, generator loss = 17.039621353149414\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 10, Batch: 292/468, discriminator loss real = 2.0344162010403621e-13, disciminator loss fake = 1.0649443282773063e-07, generator loss = 17.46175193786621\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 10, Batch: 293/468, discriminator loss real = 2.5573395397854304e-12, disciminator loss fake = 5.954148463160891e-08, generator loss = 17.660783767700195\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 10, Batch: 294/468, discriminator loss real = 4.4396943899016605e-09, disciminator loss fake = 5.1627900177209085e-08, generator loss = 17.74602508544922\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 10, Batch: 295/468, discriminator loss real = 8.136158839988639e-07, disciminator loss fake = 5.370933564563529e-08, generator loss = 17.771154403686523\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 10, Batch: 296/468, discriminator loss real = 2.8044314588969124e-17, disciminator loss fake = 5.104568501224094e-08, generator loss = 17.78481101989746\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 10, Batch: 297/468, discriminator loss real = 7.553507627879849e-17, disciminator loss fake = 5.591955698491802e-08, generator loss = 17.809032440185547\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 10, Batch: 298/468, discriminator loss real = 1.08622565164751e-07, disciminator loss fake = 4.938211262128789e-08, generator loss = 17.688114166259766\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 10, Batch: 299/468, discriminator loss real = 3.1814762639663434e-17, disciminator loss fake = 5.868812635867471e-08, generator loss = 17.795677185058594\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 10, Batch: 300/468, discriminator loss real = 2.2593516955330545e-13, disciminator loss fake = 5.403910918744259e-08, generator loss = 17.73040771484375\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 10, Batch: 301/468, discriminator loss real = 1.3304786562609174e-19, disciminator loss fake = 4.537614017863234e-08, generator loss = 17.567413330078125\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 10, Batch: 302/468, discriminator loss real = 1.0323426494369892e-20, disciminator loss fake = 3.4953202998622146e-08, generator loss = 17.88298225402832\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 10, Batch: 303/468, discriminator loss real = 1.3398182303198114e-12, disciminator loss fake = 4.295827693567844e-08, generator loss = 17.778959274291992\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 10, Batch: 304/468, discriminator loss real = 2.87824169879769e-12, disciminator loss fake = 3.2215439205174334e-08, generator loss = 17.87188720703125\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 10, Batch: 305/468, discriminator loss real = 9.571820603921505e-14, disciminator loss fake = 5.9235123472944906e-08, generator loss = 17.99738883972168\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 10, Batch: 306/468, discriminator loss real = 6.608841620660277e-13, disciminator loss fake = 3.256758063230336e-08, generator loss = 17.963777542114258\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 10, Batch: 307/468, discriminator loss real = 4.5934076854659e-12, disciminator loss fake = 4.5788386415779314e-08, generator loss = 17.885496139526367\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 10, Batch: 308/468, discriminator loss real = 2.4188384449693942e-14, disciminator loss fake = 2.6791884266685884e-08, generator loss = 18.102134704589844\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 10, Batch: 309/468, discriminator loss real = 3.2244714578456247e-17, disciminator loss fake = 2.7999174534443227e-08, generator loss = 17.87588119506836\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 10, Batch: 310/468, discriminator loss real = 6.889867842918562e-11, disciminator loss fake = 2.7933349855402412e-08, generator loss = 17.871248245239258\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 10, Batch: 311/468, discriminator loss real = 2.221818042047463e-11, disciminator loss fake = 3.004365822789623e-08, generator loss = 18.023670196533203\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 10, Batch: 312/468, discriminator loss real = 2.2281946253366325e-12, disciminator loss fake = 4.869571057497524e-08, generator loss = 17.972728729248047\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 10, Batch: 313/468, discriminator loss real = 1.478444658059954e-16, disciminator loss fake = 2.6026064858797326e-08, generator loss = 17.717281341552734\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 10, Batch: 314/468, discriminator loss real = 9.910803020006086e-15, disciminator loss fake = 2.8871975032984665e-08, generator loss = 17.935447692871094\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 10, Batch: 315/468, discriminator loss real = 3.980327081386931e-14, disciminator loss fake = 4.057995539596959e-08, generator loss = 17.933988571166992\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 10, Batch: 316/468, discriminator loss real = 3.286933851132974e-17, disciminator loss fake = 3.7607094327540835e-08, generator loss = 18.076885223388672\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 10, Batch: 317/468, discriminator loss real = 7.197001328229646e-10, disciminator loss fake = 3.104393542230355e-08, generator loss = 17.889314651489258\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 10, Batch: 318/468, discriminator loss real = 7.073581459883082e-15, disciminator loss fake = 3.6871586672759804e-08, generator loss = 18.07387924194336\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 10, Batch: 319/468, discriminator loss real = 2.713683227781316e-13, disciminator loss fake = 3.5182125657229335e-08, generator loss = 17.797088623046875\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 10, Batch: 320/468, discriminator loss real = 2.7123657053013117e-12, disciminator loss fake = 2.9180545979556882e-08, generator loss = 17.965736389160156\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 10, Batch: 321/468, discriminator loss real = 8.645906829363509e-18, disciminator loss fake = 3.9845794219672825e-08, generator loss = 17.904788970947266\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 10, Batch: 322/468, discriminator loss real = 2.7580451553784087e-18, disciminator loss fake = 3.067683351787309e-08, generator loss = 17.9241886138916\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 10, Batch: 323/468, discriminator loss real = 1.7438273860938963e-14, disciminator loss fake = 3.0491179359160014e-08, generator loss = 18.014785766601562\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 10, Batch: 324/468, discriminator loss real = 8.330992552719671e-14, disciminator loss fake = 2.6492440241554505e-08, generator loss = 17.909631729125977\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 10, Batch: 325/468, discriminator loss real = 1.3327094419354757e-12, disciminator loss fake = 2.616771510588478e-08, generator loss = 18.057844161987305\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 10, Batch: 326/468, discriminator loss real = 3.9868893209150176e-16, disciminator loss fake = 2.66687401051513e-08, generator loss = 17.85223388671875\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 10, Batch: 327/468, discriminator loss real = 1.4911794130219314e-13, disciminator loss fake = 2.875538385183063e-08, generator loss = 18.00820541381836\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 10, Batch: 328/468, discriminator loss real = 5.910878991127744e-12, disciminator loss fake = 2.6968876909450046e-08, generator loss = 17.963645935058594\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 10, Batch: 329/468, discriminator loss real = 3.083867959068351e-17, disciminator loss fake = 3.306975671080181e-08, generator loss = 17.952411651611328\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 10, Batch: 330/468, discriminator loss real = 9.90051958176836e-19, disciminator loss fake = 3.608786158793009e-08, generator loss = 18.209396362304688\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 10, Batch: 331/468, discriminator loss real = 3.047382593891801e-18, disciminator loss fake = 2.3222330725047868e-08, generator loss = 18.075359344482422\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 10, Batch: 332/468, discriminator loss real = 1.2812476786158438e-17, disciminator loss fake = 3.018924132902612e-08, generator loss = 18.089458465576172\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 10, Batch: 333/468, discriminator loss real = 4.230578846955508e-18, disciminator loss fake = 2.936332421654697e-08, generator loss = 17.898956298828125\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 10, Batch: 334/468, discriminator loss real = 1.987879653994048e-16, disciminator loss fake = 5.340575981449547e-08, generator loss = 17.953445434570312\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 10, Batch: 335/468, discriminator loss real = 2.071477212851891e-13, disciminator loss fake = 1.960539641743253e-08, generator loss = 18.226566314697266\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 10, Batch: 336/468, discriminator loss real = 1.1380520007278627e-12, disciminator loss fake = 3.437556728158597e-08, generator loss = 18.018718719482422\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 10, Batch: 337/468, discriminator loss real = 1.0670398026664746e-15, disciminator loss fake = 1.8470444729246083e-08, generator loss = 18.20536994934082\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 10, Batch: 338/468, discriminator loss real = 2.775481498004228e-14, disciminator loss fake = 4.2461152816031245e-08, generator loss = 18.023273468017578\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 10, Batch: 339/468, discriminator loss real = 1.3172238907260825e-12, disciminator loss fake = 3.608428755796922e-08, generator loss = 18.021560668945312\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 10, Batch: 340/468, discriminator loss real = 1.020566096909814e-11, disciminator loss fake = 2.4778213258969117e-08, generator loss = 18.061565399169922\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 10, Batch: 341/468, discriminator loss real = 1.6794934338049193e-15, disciminator loss fake = 2.451664471436743e-08, generator loss = 18.073335647583008\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 10, Batch: 342/468, discriminator loss real = 5.609976289663431e-15, disciminator loss fake = 2.786751274186372e-08, generator loss = 18.06414794921875\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 10, Batch: 343/468, discriminator loss real = 5.0716673699255366e-15, disciminator loss fake = 4.408990861293205e-08, generator loss = 18.103979110717773\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 10, Batch: 344/468, discriminator loss real = 2.0961974745545706e-18, disciminator loss fake = 2.6463894187145343e-08, generator loss = 18.235595703125\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 10, Batch: 345/468, discriminator loss real = 7.024493035236053e-18, disciminator loss fake = 2.7550306924695178e-08, generator loss = 18.09347915649414\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 10, Batch: 346/468, discriminator loss real = 1.1067595069038337e-15, disciminator loss fake = 2.9016096192435725e-08, generator loss = 18.131040573120117\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 10, Batch: 347/468, discriminator loss real = 8.85928130855973e-09, disciminator loss fake = 2.2355658657602362e-08, generator loss = 18.066062927246094\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 10, Batch: 348/468, discriminator loss real = 1.0334436214773368e-13, disciminator loss fake = 2.4791761532583223e-08, generator loss = 17.968284606933594\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 10, Batch: 349/468, discriminator loss real = 2.606484872499839e-14, disciminator loss fake = 1.9315031352107326e-08, generator loss = 18.102169036865234\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 10, Batch: 350/468, discriminator loss real = 6.6799081821500295e-09, disciminator loss fake = 2.257782938386299e-08, generator loss = 18.263824462890625\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 10, Batch: 351/468, discriminator loss real = 2.9010243168749346e-16, disciminator loss fake = 2.7817923964335023e-08, generator loss = 18.15239715576172\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 10, Batch: 352/468, discriminator loss real = 3.5784465397380866e-15, disciminator loss fake = 3.2197462473959604e-08, generator loss = 18.182249069213867\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 10, Batch: 353/468, discriminator loss real = 5.289256475668892e-16, disciminator loss fake = 2.4541277454659394e-08, generator loss = 18.144567489624023\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 10, Batch: 354/468, discriminator loss real = 2.7911211143423313e-14, disciminator loss fake = 2.6799613195294114e-08, generator loss = 18.098011016845703\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 10, Batch: 355/468, discriminator loss real = 3.1002636300668565e-19, disciminator loss fake = 2.656481434826219e-08, generator loss = 18.161344528198242\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 10, Batch: 356/468, discriminator loss real = 3.263014519499195e-14, disciminator loss fake = 3.087806277335403e-08, generator loss = 18.270435333251953\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 10, Batch: 357/468, discriminator loss real = 3.571932644615464e-16, disciminator loss fake = 1.712488995053718e-08, generator loss = 18.281421661376953\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 10, Batch: 358/468, discriminator loss real = 1.7896709504985897e-12, disciminator loss fake = 3.459652120341161e-08, generator loss = 18.24452781677246\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 10, Batch: 359/468, discriminator loss real = 3.3082661112117774e-15, disciminator loss fake = 2.770831564191667e-08, generator loss = 18.315387725830078\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 10, Batch: 360/468, discriminator loss real = 1.9082042261413246e-13, disciminator loss fake = 2.1254830784300793e-08, generator loss = 17.93642807006836\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 10, Batch: 361/468, discriminator loss real = 2.380349987824164e-16, disciminator loss fake = 2.2986307968153596e-08, generator loss = 18.245330810546875\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 10, Batch: 362/468, discriminator loss real = 4.2591527093377435e-14, disciminator loss fake = 1.896469647988397e-08, generator loss = 18.135297775268555\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 10, Batch: 363/468, discriminator loss real = 1.5438349026203683e-18, disciminator loss fake = 2.0737060069109248e-08, generator loss = 18.073368072509766\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 10, Batch: 364/468, discriminator loss real = 3.231356048996679e-16, disciminator loss fake = 2.3945798233171445e-08, generator loss = 18.12906265258789\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 10, Batch: 365/468, discriminator loss real = 8.903935167363136e-16, disciminator loss fake = 1.896606072193663e-08, generator loss = 18.139358520507812\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 10, Batch: 366/468, discriminator loss real = 1.776734137592939e-07, disciminator loss fake = 2.2296596569049143e-08, generator loss = 18.153474807739258\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 10, Batch: 367/468, discriminator loss real = 2.9813079088780725e-12, disciminator loss fake = 2.9337808626905826e-08, generator loss = 18.217226028442383\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 10, Batch: 368/468, discriminator loss real = 3.6395540376518536e-15, disciminator loss fake = 2.3292116679840547e-08, generator loss = 18.24138641357422\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 10, Batch: 369/468, discriminator loss real = 8.58472754688977e-12, disciminator loss fake = 2.1774864578105735e-08, generator loss = 18.16380500793457\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 10, Batch: 370/468, discriminator loss real = 5.531465063768337e-09, disciminator loss fake = 2.395748310846102e-08, generator loss = 18.258392333984375\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 10, Batch: 371/468, discriminator loss real = 4.61859749325221e-15, disciminator loss fake = 2.374727792187059e-08, generator loss = 18.176471710205078\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 10, Batch: 372/468, discriminator loss real = 7.548898974553398e-16, disciminator loss fake = 3.360100109262021e-08, generator loss = 18.26630210876465\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 10, Batch: 373/468, discriminator loss real = 8.926960559652031e-11, disciminator loss fake = 1.5466572023115077e-08, generator loss = 18.155925750732422\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 10, Batch: 374/468, discriminator loss real = 2.0675991656765114e-15, disciminator loss fake = 1.84025115146369e-08, generator loss = 18.359800338745117\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 10, Batch: 375/468, discriminator loss real = 3.279016613788599e-09, disciminator loss fake = 1.7902468840702568e-08, generator loss = 18.0343074798584\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 10, Batch: 376/468, discriminator loss real = 8.160015225371423e-14, disciminator loss fake = 2.5347652865548298e-08, generator loss = 18.196754455566406\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 10, Batch: 377/468, discriminator loss real = 3.242900392663728e-11, disciminator loss fake = 1.736139410013493e-08, generator loss = 18.343585968017578\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 10, Batch: 378/468, discriminator loss real = 2.0285609672078542e-13, disciminator loss fake = 2.9221197905826557e-08, generator loss = 18.106122970581055\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 10, Batch: 379/468, discriminator loss real = 4.486791458659621e-14, disciminator loss fake = 2.350281569363233e-08, generator loss = 18.097923278808594\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 10, Batch: 380/468, discriminator loss real = 1.544137166493032e-14, disciminator loss fake = 1.5769401784382353e-08, generator loss = 18.19110870361328\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 10, Batch: 381/468, discriminator loss real = 4.1273726468928995e-16, disciminator loss fake = 2.036765245350125e-08, generator loss = 18.3490047454834\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 10, Batch: 382/468, discriminator loss real = 1.6280466558216133e-12, disciminator loss fake = 2.5567331363163248e-08, generator loss = 18.16868782043457\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 10, Batch: 383/468, discriminator loss real = 3.2401921857411198e-12, disciminator loss fake = 1.9668558337571085e-08, generator loss = 18.17447280883789\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch: 10, Batch: 384/468, discriminator loss real = 1.159870599565238e-08, disciminator loss fake = 2.3830853734807533e-08, generator loss = 18.222820281982422\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 10, Batch: 385/468, discriminator loss real = 1.1973249058883084e-09, disciminator loss fake = 2.0411478729442933e-08, generator loss = 18.233736038208008\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 10, Batch: 386/468, discriminator loss real = 2.396868189086807e-15, disciminator loss fake = 2.6373632167064898e-08, generator loss = 18.355159759521484\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 10, Batch: 387/468, discriminator loss real = 3.8265319190176894e-13, disciminator loss fake = 2.303756652111133e-08, generator loss = 18.232685089111328\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 10, Batch: 388/468, discriminator loss real = 2.458737857834425e-16, disciminator loss fake = 1.4336273501669439e-08, generator loss = 18.223575592041016\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 10, Batch: 389/468, discriminator loss real = 2.5329306917078813e-19, disciminator loss fake = 2.4608237225720586e-08, generator loss = 18.153223037719727\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 10, Batch: 390/468, discriminator loss real = 7.0441183268321605e-12, disciminator loss fake = 1.9614482482666062e-08, generator loss = 18.335176467895508\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 10, Batch: 391/468, discriminator loss real = 3.927260319010683e-17, disciminator loss fake = 2.6439549216661362e-08, generator loss = 18.565074920654297\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 10, Batch: 392/468, discriminator loss real = 1.7509855787523065e-09, disciminator loss fake = 2.6347183990083067e-08, generator loss = 18.39870834350586\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 10, Batch: 393/468, discriminator loss real = 1.1027383594346287e-18, disciminator loss fake = 2.292386369617816e-08, generator loss = 18.17738151550293\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 10, Batch: 394/468, discriminator loss real = 2.771143229505941e-17, disciminator loss fake = 2.5269489611901008e-08, generator loss = 18.480878829956055\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 10, Batch: 395/468, discriminator loss real = 1.3555596803469655e-13, disciminator loss fake = 2.1862739174594026e-08, generator loss = 18.154529571533203\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 10, Batch: 396/468, discriminator loss real = 3.58822884714531e-18, disciminator loss fake = 2.3007228122651213e-08, generator loss = 18.215120315551758\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 10, Batch: 397/468, discriminator loss real = 6.47094822170402e-10, disciminator loss fake = 1.830577645023368e-08, generator loss = 18.34054946899414\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 10, Batch: 398/468, discriminator loss real = 1.797910236488176e-12, disciminator loss fake = 3.020584671276083e-08, generator loss = 18.304969787597656\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 10, Batch: 399/468, discriminator loss real = 3.0060213351704515e-14, disciminator loss fake = 2.6577168910080218e-08, generator loss = 18.378047943115234\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 10, Batch: 400/468, discriminator loss real = 3.4939514033594443e-15, disciminator loss fake = 1.591036102865928e-08, generator loss = 18.406696319580078\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 10, Batch: 401/468, discriminator loss real = 4.3054140808074237e-10, disciminator loss fake = 2.475320570738404e-08, generator loss = 18.312068939208984\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 10, Batch: 402/468, discriminator loss real = 7.239824899091011e-19, disciminator loss fake = 1.53522332624334e-08, generator loss = 18.172761917114258\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 10, Batch: 403/468, discriminator loss real = 1.2743832952886308e-13, disciminator loss fake = 1.648086822569894e-08, generator loss = 18.39914321899414\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 10, Batch: 404/468, discriminator loss real = 6.252309867754713e-13, disciminator loss fake = 3.499075162949339e-08, generator loss = 18.316150665283203\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 10, Batch: 405/468, discriminator loss real = 4.4281370396295075e-17, disciminator loss fake = 1.8785524247277863e-08, generator loss = 18.395959854125977\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 10, Batch: 406/468, discriminator loss real = 7.748609393010142e-11, disciminator loss fake = 1.4776111001424397e-08, generator loss = 18.388568878173828\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 10, Batch: 407/468, discriminator loss real = 1.9599269132619722e-18, disciminator loss fake = 3.1589188154157455e-08, generator loss = 18.497329711914062\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 10, Batch: 408/468, discriminator loss real = 4.373733227805085e-14, disciminator loss fake = 1.646751357498033e-08, generator loss = 18.365585327148438\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 10, Batch: 409/468, discriminator loss real = 1.880586519960938e-17, disciminator loss fake = 2.4302522660946124e-08, generator loss = 18.37232208251953\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 10, Batch: 410/468, discriminator loss real = 1.7785493130334507e-12, disciminator loss fake = 2.0173942516521493e-08, generator loss = 18.516313552856445\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 10, Batch: 411/468, discriminator loss real = 2.1078434137011826e-11, disciminator loss fake = 2.0489839158699397e-08, generator loss = 18.425376892089844\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 10, Batch: 412/468, discriminator loss real = 6.076364224185115e-17, disciminator loss fake = 2.0443730264219084e-08, generator loss = 18.22541046142578\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 10, Batch: 413/468, discriminator loss real = 9.531293296120586e-15, disciminator loss fake = 1.536331240004074e-08, generator loss = 18.334850311279297\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 10, Batch: 414/468, discriminator loss real = 1.8788890443488526e-09, disciminator loss fake = 2.6821940224408536e-08, generator loss = 18.432899475097656\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 10, Batch: 415/468, discriminator loss real = 4.199278660801768e-14, disciminator loss fake = 2.9584420246919763e-08, generator loss = 18.37105941772461\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 10, Batch: 416/468, discriminator loss real = 1.1124492438341349e-08, disciminator loss fake = 2.031676693547979e-08, generator loss = 18.456785202026367\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 10, Batch: 417/468, discriminator loss real = 1.4575642776071263e-11, disciminator loss fake = 1.5183925228257067e-08, generator loss = 18.483154296875\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 10, Batch: 418/468, discriminator loss real = 1.5240948370077344e-17, disciminator loss fake = 2.036507318337044e-08, generator loss = 18.386323928833008\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 10, Batch: 419/468, discriminator loss real = 1.3701258010090367e-11, disciminator loss fake = 1.9444755139375047e-08, generator loss = 18.396377563476562\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 10, Batch: 420/468, discriminator loss real = 1.8632730774958972e-11, disciminator loss fake = 2.2152534029373783e-08, generator loss = 18.267711639404297\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 10, Batch: 421/468, discriminator loss real = 1.5043141428708329e-12, disciminator loss fake = 2.526385856072011e-08, generator loss = 18.37265396118164\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 10, Batch: 422/468, discriminator loss real = 7.410565759126408e-13, disciminator loss fake = 1.6773046951357173e-08, generator loss = 18.53692626953125\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 10, Batch: 423/468, discriminator loss real = 2.2395805912914235e-13, disciminator loss fake = 2.0963643265758947e-08, generator loss = 18.499286651611328\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 10, Batch: 424/468, discriminator loss real = 5.009376247144814e-10, disciminator loss fake = 2.0290308100356924e-08, generator loss = 18.445117950439453\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 10, Batch: 425/468, discriminator loss real = 2.950762885631095e-16, disciminator loss fake = 2.1078953693631775e-08, generator loss = 18.495817184448242\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 10, Batch: 426/468, discriminator loss real = 2.831540086629296e-15, disciminator loss fake = 1.262767668208653e-08, generator loss = 18.436283111572266\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 10, Batch: 427/468, discriminator loss real = 4.448635673704425e-14, disciminator loss fake = 2.054841274912178e-08, generator loss = 18.38671112060547\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 10, Batch: 428/468, discriminator loss real = 1.1787990830854078e-13, disciminator loss fake = 1.8621461705947695e-08, generator loss = 18.40424919128418\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 10, Batch: 429/468, discriminator loss real = 1.974656642506796e-17, disciminator loss fake = 1.4717684848619683e-08, generator loss = 18.474037170410156\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 10, Batch: 430/468, discriminator loss real = 1.3259774781805827e-14, disciminator loss fake = 1.5962481114684124e-08, generator loss = 18.456729888916016\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 10, Batch: 431/468, discriminator loss real = 2.1064827659955654e-10, disciminator loss fake = 1.5730535096736276e-08, generator loss = 18.147518157958984\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 10, Batch: 432/468, discriminator loss real = 2.988929242997429e-11, disciminator loss fake = 1.770165170000837e-08, generator loss = 18.446701049804688\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 10, Batch: 433/468, discriminator loss real = 9.635303648087494e-16, disciminator loss fake = 1.6034471528314498e-08, generator loss = 18.553974151611328\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 10, Batch: 434/468, discriminator loss real = 1.1741345192316905e-15, disciminator loss fake = 1.6120404566777324e-08, generator loss = 18.53085708618164\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 10, Batch: 435/468, discriminator loss real = 9.54771302980311e-16, disciminator loss fake = 1.8826753489520343e-08, generator loss = 18.687040328979492\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 10, Batch: 436/468, discriminator loss real = 2.4108205157939797e-15, disciminator loss fake = 1.384531866932548e-08, generator loss = 18.48500633239746\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 10, Batch: 437/468, discriminator loss real = 5.4321503739629406e-08, disciminator loss fake = 1.5751675519481978e-08, generator loss = 18.536785125732422\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 10, Batch: 438/468, discriminator loss real = 4.0112940746794834e-11, disciminator loss fake = 1.838461471947994e-08, generator loss = 18.35272216796875\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 10, Batch: 439/468, discriminator loss real = 3.826379317561912e-12, disciminator loss fake = 1.5680930331996024e-08, generator loss = 18.575448989868164\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Epoch: 10, Batch: 440/468, discriminator loss real = 3.344528121079326e-17, disciminator loss fake = 1.685399908524232e-08, generator loss = 18.57396697998047\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 10, Batch: 441/468, discriminator loss real = 1.7612485905468822e-12, disciminator loss fake = 1.500570689927372e-08, generator loss = 18.50502586364746\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 10, Batch: 442/468, discriminator loss real = 2.3099310567212305e-15, disciminator loss fake = 1.719660325250061e-08, generator loss = 18.331274032592773\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 10, Batch: 443/468, discriminator loss real = 9.572737771196792e-15, disciminator loss fake = 1.8676903579262216e-08, generator loss = 18.540416717529297\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 10, Batch: 444/468, discriminator loss real = 2.1123405216823266e-13, disciminator loss fake = 1.6511325640067298e-08, generator loss = 18.581981658935547\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 10, Batch: 445/468, discriminator loss real = 9.224669723577348e-20, disciminator loss fake = 2.0961950397690998e-08, generator loss = 18.507810592651367\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 10, Batch: 446/468, discriminator loss real = 2.811308348996464e-18, disciminator loss fake = 1.5680184262123475e-08, generator loss = 18.53166961669922\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 10, Batch: 447/468, discriminator loss real = 1.4763552158569837e-08, disciminator loss fake = 1.4668998460365401e-08, generator loss = 18.54410171508789\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 10, Batch: 448/468, discriminator loss real = 5.9763568334599e-14, disciminator loss fake = 1.9817219865103652e-08, generator loss = 18.472721099853516\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 10, Batch: 449/468, discriminator loss real = 4.241186568609834e-11, disciminator loss fake = 1.7280489927884446e-08, generator loss = 18.691312789916992\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 10, Batch: 450/468, discriminator loss real = 6.9550391989148426e-15, disciminator loss fake = 1.615518918640646e-08, generator loss = 18.436073303222656\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 10, Batch: 451/468, discriminator loss real = 4.9022101305514087e-17, disciminator loss fake = 1.4810823678601537e-08, generator loss = 18.584781646728516\n",
      "2/2 [==============================] - 0s 152ms/step\n",
      "Epoch: 10, Batch: 452/468, discriminator loss real = 2.991199613846217e-14, disciminator loss fake = 1.4489884847534995e-08, generator loss = 18.480640411376953\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 10, Batch: 453/468, discriminator loss real = 1.9791214656683366e-16, disciminator loss fake = 1.506540847628912e-08, generator loss = 18.581724166870117\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 10, Batch: 454/468, discriminator loss real = 1.8216889585351281e-13, disciminator loss fake = 1.9476415147323678e-08, generator loss = 18.414447784423828\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 10, Batch: 455/468, discriminator loss real = 9.739267413242303e-16, disciminator loss fake = 1.9554622809891953e-08, generator loss = 18.416250228881836\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 10, Batch: 456/468, discriminator loss real = 6.158895991131581e-15, disciminator loss fake = 1.3763255424237286e-08, generator loss = 18.455707550048828\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 10, Batch: 457/468, discriminator loss real = 3.3102080148934677e-19, disciminator loss fake = 1.6088918641798955e-08, generator loss = 18.642690658569336\n",
      "2/2 [==============================] - 0s 137ms/step\n",
      "Epoch: 10, Batch: 458/468, discriminator loss real = 4.493178832470912e-13, disciminator loss fake = 1.6685723025489096e-08, generator loss = 18.40386962890625\n",
      "2/2 [==============================] - 0s 158ms/step\n",
      "Epoch: 10, Batch: 459/468, discriminator loss real = 8.281971029117097e-13, disciminator loss fake = 1.8763657294584846e-08, generator loss = 18.582956314086914\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 10, Batch: 460/468, discriminator loss real = 1.531962924572472e-12, disciminator loss fake = 2.1627101887133904e-08, generator loss = 18.653797149658203\n",
      "2/2 [==============================] - 0s 144ms/step\n",
      "Epoch: 10, Batch: 461/468, discriminator loss real = 9.475206670704964e-14, disciminator loss fake = 1.6312718287281314e-08, generator loss = 18.47183609008789\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 10, Batch: 462/468, discriminator loss real = 1.8168727016684694e-16, disciminator loss fake = 2.082573224981843e-08, generator loss = 18.516489028930664\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 10, Batch: 463/468, discriminator loss real = 2.675367739846113e-12, disciminator loss fake = 2.017969435996747e-08, generator loss = 18.408742904663086\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 10, Batch: 464/468, discriminator loss real = 6.1443634468555386e-15, disciminator loss fake = 1.6662950130807985e-08, generator loss = 18.65106964111328\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Epoch: 10, Batch: 465/468, discriminator loss real = 4.548036751893247e-13, disciminator loss fake = 1.860035681033878e-08, generator loss = 18.7310791015625\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 10, Batch: 466/468, discriminator loss real = 1.2092350731851553e-10, disciminator loss fake = 1.4293425110167846e-08, generator loss = 18.54230499267578\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 10, Batch: 467/468, discriminator loss real = 1.7402580028066938e-12, disciminator loss fake = 1.2123864578938992e-08, generator loss = 18.678627014160156\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 10, Batch: 468/468, discriminator loss real = 1.155998802677147e-14, disciminator loss fake = 2.178711078215656e-08, generator loss = 18.563690185546875\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 11, Batch: 1/468, discriminator loss real = 1.6080130645399577e-15, disciminator loss fake = 1.4628678712824694e-08, generator loss = 18.586753845214844\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 11, Batch: 2/468, discriminator loss real = 4.7315705842265743e-07, disciminator loss fake = 1.51024401873201e-08, generator loss = 18.542980194091797\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 11, Batch: 3/468, discriminator loss real = 8.634414577502738e-16, disciminator loss fake = 1.4211803289754243e-08, generator loss = 18.57498550415039\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 11, Batch: 4/468, discriminator loss real = 9.733973880838437e-15, disciminator loss fake = 1.790450454564052e-08, generator loss = 18.601871490478516\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 11, Batch: 5/468, discriminator loss real = 4.293558340622266e-15, disciminator loss fake = 1.6340138131454296e-08, generator loss = 18.43914031982422\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 11, Batch: 6/468, discriminator loss real = 1.604735360436274e-13, disciminator loss fake = 1.8657681621903066e-08, generator loss = 18.591163635253906\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 11, Batch: 7/468, discriminator loss real = 2.6336283414502004e-12, disciminator loss fake = 1.674393956818676e-08, generator loss = 18.287038803100586\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 11, Batch: 8/468, discriminator loss real = 1.0640489425646095e-16, disciminator loss fake = 1.472690591697301e-08, generator loss = 18.4927978515625\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 11, Batch: 9/468, discriminator loss real = 1.355039898578883e-16, disciminator loss fake = 1.7057290691013804e-08, generator loss = 18.472768783569336\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 11, Batch: 10/468, discriminator loss real = 5.830701508424216e-17, disciminator loss fake = 1.8630307963007908e-08, generator loss = 18.42803382873535\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 11, Batch: 11/468, discriminator loss real = 3.220865651824053e-15, disciminator loss fake = 1.7627268533715323e-08, generator loss = 18.374679565429688\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 11, Batch: 12/468, discriminator loss real = 1.8952568193227742e-13, disciminator loss fake = 1.5487866988905807e-08, generator loss = 18.555936813354492\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 11, Batch: 13/468, discriminator loss real = 2.639988650864761e-13, disciminator loss fake = 1.8973942417233047e-08, generator loss = 18.404735565185547\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 11, Batch: 14/468, discriminator loss real = 5.510358015286274e-15, disciminator loss fake = 1.707667607320218e-08, generator loss = 18.4418888092041\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 11, Batch: 15/468, discriminator loss real = 2.241139163413409e-17, disciminator loss fake = 1.545521755019763e-08, generator loss = 18.62099838256836\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 11, Batch: 16/468, discriminator loss real = 7.104900435345174e-13, disciminator loss fake = 1.554102802003854e-08, generator loss = 18.458438873291016\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 11, Batch: 17/468, discriminator loss real = 7.007637959494106e-12, disciminator loss fake = 1.4643656953694517e-08, generator loss = 18.487991333007812\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 11, Batch: 18/468, discriminator loss real = 2.3034942842059536e-08, disciminator loss fake = 1.852462716556147e-08, generator loss = 18.540346145629883\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 11, Batch: 19/468, discriminator loss real = 9.713532023170046e-08, disciminator loss fake = 1.6223269838633314e-08, generator loss = 18.54773712158203\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 11, Batch: 20/468, discriminator loss real = 1.4337789744845855e-20, disciminator loss fake = 1.1446074310583754e-08, generator loss = 18.347524642944336\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 11, Batch: 21/468, discriminator loss real = 5.430039217205716e-14, disciminator loss fake = 2.3167167739757133e-08, generator loss = 18.590896606445312\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 11, Batch: 22/468, discriminator loss real = 4.81926831774615e-10, disciminator loss fake = 1.7936622853653716e-08, generator loss = 18.366500854492188\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 11, Batch: 23/468, discriminator loss real = 6.180160965030637e-16, disciminator loss fake = 1.6698015414817746e-08, generator loss = 18.438352584838867\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 11, Batch: 24/468, discriminator loss real = 3.7274542718894466e-13, disciminator loss fake = 1.718163744612866e-08, generator loss = 18.354469299316406\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 11, Batch: 25/468, discriminator loss real = 1.387689842321984e-14, disciminator loss fake = 2.0477882500813394e-08, generator loss = 18.352005004882812\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 11, Batch: 26/468, discriminator loss real = 8.47872441608324e-15, disciminator loss fake = 1.8044975291786614e-08, generator loss = 18.41497802734375\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 11, Batch: 27/468, discriminator loss real = 5.2620390683655316e-12, disciminator loss fake = 1.6857622853194698e-08, generator loss = 18.513877868652344\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 11, Batch: 28/468, discriminator loss real = 2.986822798731385e-17, disciminator loss fake = 1.6759472032390477e-08, generator loss = 18.432527542114258\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 11, Batch: 29/468, discriminator loss real = 1.909977769137274e-16, disciminator loss fake = 1.7989341571933437e-08, generator loss = 18.586456298828125\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 11, Batch: 30/468, discriminator loss real = 6.478957908680287e-18, disciminator loss fake = 1.2398389870327264e-08, generator loss = 18.50737762451172\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 11, Batch: 31/468, discriminator loss real = 1.4230741142979403e-15, disciminator loss fake = 1.724757225929352e-08, generator loss = 18.389694213867188\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 11, Batch: 32/468, discriminator loss real = 4.3069803908231397e-13, disciminator loss fake = 1.9161490172336926e-08, generator loss = 18.508026123046875\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 11, Batch: 33/468, discriminator loss real = 1.9194620393993278e-14, disciminator loss fake = 1.702747809417815e-08, generator loss = 18.617847442626953\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 11, Batch: 34/468, discriminator loss real = 2.0943623151394898e-14, disciminator loss fake = 1.834478169371323e-08, generator loss = 18.472923278808594\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 11, Batch: 35/468, discriminator loss real = 6.01701034916996e-14, disciminator loss fake = 1.9469991840992407e-08, generator loss = 18.48934555053711\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 11, Batch: 36/468, discriminator loss real = 4.2694674530529327e-16, disciminator loss fake = 2.0707974002220908e-08, generator loss = 18.694171905517578\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 11, Batch: 37/468, discriminator loss real = 4.760879468435064e-10, disciminator loss fake = 2.12431991997164e-08, generator loss = 18.62734603881836\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 11, Batch: 38/468, discriminator loss real = 8.626569781861743e-15, disciminator loss fake = 1.7508028804513742e-08, generator loss = 18.440650939941406\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 11, Batch: 39/468, discriminator loss real = 3.5979599855018307e-10, disciminator loss fake = 1.0383566007021727e-08, generator loss = 18.51133155822754\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 11, Batch: 40/468, discriminator loss real = 1.5132034739593406e-18, disciminator loss fake = 1.2552931138998247e-08, generator loss = 18.381799697875977\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 11, Batch: 41/468, discriminator loss real = 2.8782606520394438e-08, disciminator loss fake = 1.995649512309683e-08, generator loss = 18.745716094970703\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 11, Batch: 42/468, discriminator loss real = 1.2265918315768065e-11, disciminator loss fake = 1.5613123238722437e-08, generator loss = 18.618488311767578\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 11, Batch: 43/468, discriminator loss real = 1.0629526908190537e-13, disciminator loss fake = 1.8479202168464326e-08, generator loss = 18.673694610595703\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 11, Batch: 44/468, discriminator loss real = 5.785448855935216e-18, disciminator loss fake = 1.3447827740264984e-08, generator loss = 18.37041664123535\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 11, Batch: 45/468, discriminator loss real = 3.3673216125185146e-13, disciminator loss fake = 2.2298777935247927e-08, generator loss = 18.5841007232666\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 11, Batch: 46/468, discriminator loss real = 5.536157469954173e-12, disciminator loss fake = 1.8272672264174616e-08, generator loss = 18.61037826538086\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 11, Batch: 47/468, discriminator loss real = 8.396980058905476e-18, disciminator loss fake = 1.416658612640731e-08, generator loss = 18.588085174560547\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 11, Batch: 48/468, discriminator loss real = 1.26560749185399e-14, disciminator loss fake = 1.3895092187965474e-08, generator loss = 18.58572006225586\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 11, Batch: 49/468, discriminator loss real = 1.239708845392803e-15, disciminator loss fake = 1.2452979980537293e-08, generator loss = 18.399370193481445\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 11, Batch: 50/468, discriminator loss real = 7.826342005023967e-12, disciminator loss fake = 1.5681230536301882e-08, generator loss = 18.487077713012695\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 11, Batch: 51/468, discriminator loss real = 5.147490211854233e-10, disciminator loss fake = 1.1032028623958468e-08, generator loss = 18.527002334594727\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 11, Batch: 52/468, discriminator loss real = 2.950556940157882e-14, disciminator loss fake = 1.7026550835907983e-08, generator loss = 18.549922943115234\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 11, Batch: 53/468, discriminator loss real = 4.068821031192803e-17, disciminator loss fake = 1.3202516413457488e-08, generator loss = 18.50823211669922\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 11, Batch: 54/468, discriminator loss real = 8.746306434659346e-07, disciminator loss fake = 1.1149889900252674e-08, generator loss = 18.54697036743164\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 11, Batch: 55/468, discriminator loss real = 2.0446784456534806e-13, disciminator loss fake = 1.1125845134074552e-08, generator loss = 18.41893196105957\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 11, Batch: 56/468, discriminator loss real = 3.738342101156089e-13, disciminator loss fake = 1.2666338200517657e-08, generator loss = 18.41089630126953\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 11, Batch: 57/468, discriminator loss real = 2.503432574088582e-12, disciminator loss fake = 1.54810813057793e-08, generator loss = 18.48873519897461\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 11, Batch: 58/468, discriminator loss real = 1.743120642978531e-15, disciminator loss fake = 1.4519853763772517e-08, generator loss = 18.625789642333984\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 11, Batch: 59/468, discriminator loss real = 1.876321147065152e-12, disciminator loss fake = 1.9479292845403506e-08, generator loss = 18.429515838623047\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 11, Batch: 60/468, discriminator loss real = 6.876751159057964e-20, disciminator loss fake = 2.1693178808845914e-08, generator loss = 18.475597381591797\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 11, Batch: 61/468, discriminator loss real = 1.960840344261694e-12, disciminator loss fake = 1.3970652190664623e-08, generator loss = 18.234479904174805\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 11, Batch: 62/468, discriminator loss real = 4.880519816410911e-14, disciminator loss fake = 1.857216069822698e-08, generator loss = 18.580951690673828\n",
      "2/2 [==============================] - 0s 159ms/step\n",
      "Epoch: 11, Batch: 63/468, discriminator loss real = 2.168205292228404e-15, disciminator loss fake = 1.903115531831645e-08, generator loss = 18.368072509765625\n",
      "2/2 [==============================] - 0s 144ms/step\n",
      "Epoch: 11, Batch: 64/468, discriminator loss real = 1.7085107708746019e-15, disciminator loss fake = 1.5714718415438256e-08, generator loss = 18.414031982421875\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 11, Batch: 65/468, discriminator loss real = 6.998181331305253e-13, disciminator loss fake = 2.154797051900914e-08, generator loss = 18.243070602416992\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 11, Batch: 66/468, discriminator loss real = 2.0490742358283434e-19, disciminator loss fake = 1.86536706081597e-08, generator loss = 18.2562255859375\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 11, Batch: 67/468, discriminator loss real = 7.033310284257501e-17, disciminator loss fake = 1.724114540024857e-08, generator loss = 18.25421142578125\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 11, Batch: 68/468, discriminator loss real = 1.1619801043274874e-18, disciminator loss fake = 1.7503836602372758e-08, generator loss = 18.496143341064453\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 11, Batch: 69/468, discriminator loss real = 2.0657544685248608e-12, disciminator loss fake = 1.490485601607361e-08, generator loss = 18.431386947631836\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 11, Batch: 70/468, discriminator loss real = 3.5233494182114466e-13, disciminator loss fake = 1.3034774148934503e-08, generator loss = 18.439739227294922\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 11, Batch: 71/468, discriminator loss real = 5.349235811247244e-12, disciminator loss fake = 1.9088965075297892e-08, generator loss = 18.60047149658203\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 11, Batch: 72/468, discriminator loss real = 9.375693873105563e-17, disciminator loss fake = 2.3323995179680423e-08, generator loss = 18.367477416992188\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 11, Batch: 73/468, discriminator loss real = 7.93951482336297e-09, disciminator loss fake = 1.7915123606826455e-08, generator loss = 18.541589736938477\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 11, Batch: 74/468, discriminator loss real = 3.646881963081938e-10, disciminator loss fake = 2.3478508026641975e-08, generator loss = 18.345659255981445\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 11, Batch: 75/468, discriminator loss real = 1.4987852013762003e-15, disciminator loss fake = 2.3292095363558474e-08, generator loss = 18.30068588256836\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 11, Batch: 76/468, discriminator loss real = 1.783855283269114e-14, disciminator loss fake = 1.8181175676090788e-08, generator loss = 18.346694946289062\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 11, Batch: 77/468, discriminator loss real = 1.7446681876975845e-09, disciminator loss fake = 1.7514658168238384e-08, generator loss = 18.37914276123047\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 11, Batch: 78/468, discriminator loss real = 7.048397282494179e-11, disciminator loss fake = 1.7669163909772578e-08, generator loss = 18.403060913085938\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 11, Batch: 79/468, discriminator loss real = 4.3219775665520686e-15, disciminator loss fake = 1.561080331669018e-08, generator loss = 18.42116928100586\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 11, Batch: 80/468, discriminator loss real = 2.833629611031054e-18, disciminator loss fake = 3.295636119560186e-08, generator loss = 18.478973388671875\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 11, Batch: 81/468, discriminator loss real = 5.690926100158169e-18, disciminator loss fake = 2.4376587859364918e-08, generator loss = 18.5388240814209\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 11, Batch: 82/468, discriminator loss real = 5.167983757673064e-18, disciminator loss fake = 1.4032687012388578e-08, generator loss = 18.431991577148438\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 11, Batch: 83/468, discriminator loss real = 6.794278380635726e-16, disciminator loss fake = 2.295886858405538e-08, generator loss = 18.346940994262695\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 11, Batch: 84/468, discriminator loss real = 1.6999277013167793e-14, disciminator loss fake = 1.555740780645465e-08, generator loss = 18.19715118408203\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 11, Batch: 85/468, discriminator loss real = 1.2473181341954298e-11, disciminator loss fake = 1.8718878891377244e-08, generator loss = 18.438772201538086\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 11, Batch: 86/468, discriminator loss real = 5.059336264279408e-16, disciminator loss fake = 1.7701955457027907e-08, generator loss = 18.339000701904297\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 11, Batch: 87/468, discriminator loss real = 2.3245091290181874e-13, disciminator loss fake = 1.5202971326289116e-08, generator loss = 18.368621826171875\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 11, Batch: 88/468, discriminator loss real = 1.5380603149602046e-13, disciminator loss fake = 1.7200818547280505e-08, generator loss = 18.460662841796875\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "Epoch: 11, Batch: 89/468, discriminator loss real = 1.1065238503249475e-08, disciminator loss fake = 1.619694955934392e-08, generator loss = 18.551414489746094\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 11, Batch: 90/468, discriminator loss real = 2.612693915382547e-12, disciminator loss fake = 2.1769244185065872e-08, generator loss = 18.385169982910156\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 11, Batch: 91/468, discriminator loss real = 2.304879106584251e-13, disciminator loss fake = 1.7153428899518985e-08, generator loss = 18.364849090576172\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 11, Batch: 92/468, discriminator loss real = 1.5667469163689287e-16, disciminator loss fake = 1.8344497476618926e-08, generator loss = 18.527111053466797\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 11, Batch: 93/468, discriminator loss real = 8.009856223508209e-18, disciminator loss fake = 1.8447156691081545e-08, generator loss = 18.4593505859375\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 11, Batch: 94/468, discriminator loss real = 5.309816082881122e-16, disciminator loss fake = 2.2801465604516125e-08, generator loss = 18.479169845581055\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 11, Batch: 95/468, discriminator loss real = 3.658445768550678e-11, disciminator loss fake = 1.66107199106591e-08, generator loss = 18.44342041015625\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 11, Batch: 96/468, discriminator loss real = 2.084915060217231e-15, disciminator loss fake = 1.843011077085066e-08, generator loss = 18.549869537353516\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 11, Batch: 97/468, discriminator loss real = 9.127968070288262e-08, disciminator loss fake = 2.041418767362302e-08, generator loss = 18.406959533691406\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 11, Batch: 98/468, discriminator loss real = 3.2817490044911857e-12, disciminator loss fake = 1.768361279630426e-08, generator loss = 18.458847045898438\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 11, Batch: 99/468, discriminator loss real = 2.484471233344526e-13, disciminator loss fake = 1.74983831868758e-08, generator loss = 18.429658889770508\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 11, Batch: 100/468, discriminator loss real = 1.9773000801339438e-16, disciminator loss fake = 1.7604907753820953e-08, generator loss = 18.51343536376953\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 11, Batch: 101/468, discriminator loss real = 4.4019532990836314e-18, disciminator loss fake = 2.4658504571561934e-08, generator loss = 18.562929153442383\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 11, Batch: 102/468, discriminator loss real = 2.1103561183044876e-15, disciminator loss fake = 1.3961237499415802e-08, generator loss = 18.508607864379883\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 11, Batch: 103/468, discriminator loss real = 1.9906533229368364e-17, disciminator loss fake = 1.729585363818842e-08, generator loss = 18.49195098876953\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 11, Batch: 104/468, discriminator loss real = 6.219905868498177e-16, disciminator loss fake = 2.1376266090555873e-08, generator loss = 18.56768035888672\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 11, Batch: 105/468, discriminator loss real = 1.783075335331282e-14, disciminator loss fake = 1.6112883471919304e-08, generator loss = 18.56719970703125\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 11, Batch: 106/468, discriminator loss real = 4.4325373232956267e-11, disciminator loss fake = 1.6257839519084882e-08, generator loss = 18.478404998779297\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 11, Batch: 107/468, discriminator loss real = 4.899210919763475e-13, disciminator loss fake = 1.6826591675567215e-08, generator loss = 18.41181182861328\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 11, Batch: 108/468, discriminator loss real = 3.9938106388852693e-17, disciminator loss fake = 1.416054473679651e-08, generator loss = 18.517316818237305\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 11, Batch: 109/468, discriminator loss real = 8.103382602518e-14, disciminator loss fake = 1.6687259574155178e-08, generator loss = 18.64469337463379\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 11, Batch: 110/468, discriminator loss real = 4.4820124987712123e-14, disciminator loss fake = 1.7610229718911796e-08, generator loss = 18.700849533081055\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 11, Batch: 111/468, discriminator loss real = 1.6073290854350499e-15, disciminator loss fake = 1.4072202958459457e-08, generator loss = 18.581939697265625\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 11, Batch: 112/468, discriminator loss real = 3.8453078961303593e-17, disciminator loss fake = 2.156094147665044e-08, generator loss = 18.614599227905273\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 11, Batch: 113/468, discriminator loss real = 8.335886773608994e-19, disciminator loss fake = 1.651395464818961e-08, generator loss = 18.51873016357422\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 11, Batch: 114/468, discriminator loss real = 1.2035863625192711e-11, disciminator loss fake = 1.6471902952730488e-08, generator loss = 18.69622230529785\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 11, Batch: 115/468, discriminator loss real = 1.245019106697377e-15, disciminator loss fake = 1.5025435118332098e-08, generator loss = 18.740833282470703\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 11, Batch: 116/468, discriminator loss real = 2.785367030355701e-07, disciminator loss fake = 1.3531670894906256e-08, generator loss = 18.62576675415039\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 11, Batch: 117/468, discriminator loss real = 3.873576133628376e-06, disciminator loss fake = 1.7020541420720292e-08, generator loss = 18.451526641845703\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 11, Batch: 118/468, discriminator loss real = 6.685682563123407e-11, disciminator loss fake = 2.7856781770196903e-08, generator loss = 18.31321907043457\n",
      "2/2 [==============================] - 0s 159ms/step\n",
      "Epoch: 11, Batch: 119/468, discriminator loss real = 7.607571256978973e-13, disciminator loss fake = 3.713739005206662e-08, generator loss = 18.003747940063477\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 11, Batch: 120/468, discriminator loss real = 5.987333025203601e-13, disciminator loss fake = 2.775878726879455e-08, generator loss = 17.925521850585938\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 11, Batch: 121/468, discriminator loss real = 1.8660349280314945e-14, disciminator loss fake = 2.9444649385368393e-08, generator loss = 17.716861724853516\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 11, Batch: 122/468, discriminator loss real = 4.516139795029267e-13, disciminator loss fake = 3.758231059691752e-08, generator loss = 17.85858917236328\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 11, Batch: 123/468, discriminator loss real = 1.2126267188728842e-18, disciminator loss fake = 4.0500118814179586e-08, generator loss = 17.530315399169922\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 11, Batch: 124/468, discriminator loss real = 8.004516916914478e-14, disciminator loss fake = 4.901595573869599e-08, generator loss = 17.595008850097656\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 11, Batch: 125/468, discriminator loss real = 5.389031662899528e-16, disciminator loss fake = 5.466568353540424e-08, generator loss = 17.452880859375\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 11, Batch: 126/468, discriminator loss real = 2.181085978492092e-09, disciminator loss fake = 5.2561293983899304e-08, generator loss = 17.5433349609375\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 11, Batch: 127/468, discriminator loss real = 1.9942596565011156e-13, disciminator loss fake = 5.350899812128773e-08, generator loss = 17.40262794494629\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 11, Batch: 128/468, discriminator loss real = 1.684465752641584e-20, disciminator loss fake = 7.330345397349447e-08, generator loss = 17.216928482055664\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 11, Batch: 129/468, discriminator loss real = 4.003454468978762e-13, disciminator loss fake = 7.013720448867389e-08, generator loss = 17.486328125\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 11, Batch: 130/468, discriminator loss real = 8.030055299087374e-15, disciminator loss fake = 4.5809116500095115e-08, generator loss = 17.399005889892578\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 11, Batch: 131/468, discriminator loss real = 4.453583701369106e-14, disciminator loss fake = 5.071350983598677e-08, generator loss = 17.463207244873047\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 11, Batch: 132/468, discriminator loss real = 3.1450029754943876e-13, disciminator loss fake = 7.729879314410937e-08, generator loss = 17.47073745727539\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 11, Batch: 133/468, discriminator loss real = 7.610733306145248e-17, disciminator loss fake = 1.1418626399972709e-07, generator loss = 17.16596221923828\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 11, Batch: 134/468, discriminator loss real = 2.477554568612636e-20, disciminator loss fake = 7.367614784925536e-08, generator loss = 17.467397689819336\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 11, Batch: 135/468, discriminator loss real = 6.395943345262334e-13, disciminator loss fake = 3.93490431349619e-08, generator loss = 17.37809181213379\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 11, Batch: 136/468, discriminator loss real = 1.0357299906615935e-08, disciminator loss fake = 5.4197698773350567e-08, generator loss = 17.529722213745117\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 11, Batch: 137/468, discriminator loss real = 1.1780995863369063e-14, disciminator loss fake = 4.9451994499349894e-08, generator loss = 17.699068069458008\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 11, Batch: 138/468, discriminator loss real = 5.110601069939491e-14, disciminator loss fake = 4.6925642038786464e-08, generator loss = 17.628101348876953\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 11, Batch: 139/468, discriminator loss real = 3.936864804423776e-14, disciminator loss fake = 5.664928437454364e-08, generator loss = 17.48155975341797\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 11, Batch: 140/468, discriminator loss real = 1.8688277650651813e-14, disciminator loss fake = 4.982436152545233e-08, generator loss = 17.505876541137695\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 11, Batch: 141/468, discriminator loss real = 3.1077801888602626e-15, disciminator loss fake = 5.321341234321153e-08, generator loss = 17.26003646850586\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 11, Batch: 142/468, discriminator loss real = 2.82054761491235e-13, disciminator loss fake = 3.894401956472393e-08, generator loss = 17.586881637573242\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 11, Batch: 143/468, discriminator loss real = 5.168213404981026e-13, disciminator loss fake = 5.807573444371883e-08, generator loss = 17.727964401245117\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 11, Batch: 144/468, discriminator loss real = 2.521304202909354e-18, disciminator loss fake = 4.1432361541637874e-08, generator loss = 17.510225296020508\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 11, Batch: 145/468, discriminator loss real = 3.704581709924632e-16, disciminator loss fake = 3.913669388566632e-08, generator loss = 17.548458099365234\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 11, Batch: 146/468, discriminator loss real = 1.1678691791416895e-08, disciminator loss fake = 5.89698885278267e-08, generator loss = 17.69595718383789\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 11, Batch: 147/468, discriminator loss real = 4.977663081717765e-08, disciminator loss fake = 3.812338889019884e-08, generator loss = 17.648014068603516\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 11, Batch: 148/468, discriminator loss real = 4.209032075782812e-15, disciminator loss fake = 4.422084032285056e-08, generator loss = 17.808914184570312\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 11, Batch: 149/468, discriminator loss real = 1.822550999008854e-09, disciminator loss fake = 5.326594987309363e-08, generator loss = 17.741724014282227\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 11, Batch: 150/468, discriminator loss real = 9.31004320810008e-15, disciminator loss fake = 5.5244594676651104e-08, generator loss = 17.760019302368164\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 11, Batch: 151/468, discriminator loss real = 6.0640724443596685e-19, disciminator loss fake = 3.606389853416658e-08, generator loss = 17.795730590820312\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 11, Batch: 152/468, discriminator loss real = 1.6205332215024626e-11, disciminator loss fake = 4.459815272639389e-08, generator loss = 17.790897369384766\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 11, Batch: 153/468, discriminator loss real = 1.536238907191197e-16, disciminator loss fake = 3.743964782643161e-08, generator loss = 17.77863311767578\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 11, Batch: 154/468, discriminator loss real = 4.650480236903336e-15, disciminator loss fake = 5.008945080930971e-08, generator loss = 17.863985061645508\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 11, Batch: 155/468, discriminator loss real = 8.986218887063746e-13, disciminator loss fake = 4.2285044798973104e-08, generator loss = 17.79490852355957\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 11, Batch: 156/468, discriminator loss real = 1.1707586289322336e-11, disciminator loss fake = 3.819432947693713e-08, generator loss = 17.757009506225586\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 11, Batch: 157/468, discriminator loss real = 5.571161100808454e-18, disciminator loss fake = 3.4023930339799335e-08, generator loss = 17.6469783782959\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 11, Batch: 158/468, discriminator loss real = 1.7891085333006373e-18, disciminator loss fake = 3.616055010979835e-08, generator loss = 17.466331481933594\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 11, Batch: 159/468, discriminator loss real = 8.380720162987076e-15, disciminator loss fake = 3.1359732588498446e-08, generator loss = 17.90648651123047\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 11, Batch: 160/468, discriminator loss real = 1.7121441417411454e-11, disciminator loss fake = 4.864982372509985e-08, generator loss = 17.69559669494629\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 11, Batch: 161/468, discriminator loss real = 1.5965345504948003e-16, disciminator loss fake = 2.974391932752951e-08, generator loss = 17.71308135986328\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 11, Batch: 162/468, discriminator loss real = 2.8409616239372104e-12, disciminator loss fake = 2.876758742331731e-08, generator loss = 17.635540008544922\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 11, Batch: 163/468, discriminator loss real = 1.105851521465695e-11, disciminator loss fake = 3.384126046057645e-08, generator loss = 17.934738159179688\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 11, Batch: 164/468, discriminator loss real = 5.633811195338012e-10, disciminator loss fake = 4.278913579014443e-08, generator loss = 17.77509880065918\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 11, Batch: 165/468, discriminator loss real = 2.06393087774019e-15, disciminator loss fake = 2.3307112684278763e-08, generator loss = 17.937700271606445\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 11, Batch: 166/468, discriminator loss real = 2.565385841535317e-07, disciminator loss fake = 4.1943600592730945e-08, generator loss = 18.00494384765625\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 11, Batch: 167/468, discriminator loss real = 1.9080947090164093e-16, disciminator loss fake = 2.5041636320111138e-08, generator loss = 17.948637008666992\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "Epoch: 11, Batch: 168/468, discriminator loss real = 6.321097074588056e-13, disciminator loss fake = 2.8220037862070058e-08, generator loss = 17.779909133911133\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 11, Batch: 169/468, discriminator loss real = 3.165194411365764e-15, disciminator loss fake = 3.529771319676911e-08, generator loss = 17.836156845092773\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 11, Batch: 170/468, discriminator loss real = 2.430706212343718e-18, disciminator loss fake = 3.915579327440355e-08, generator loss = 17.721412658691406\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 11, Batch: 171/468, discriminator loss real = 9.481742853051138e-19, disciminator loss fake = 3.837905637738004e-08, generator loss = 17.765274047851562\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 11, Batch: 172/468, discriminator loss real = 1.3748813285779926e-12, disciminator loss fake = 3.002594439749373e-08, generator loss = 18.0626163482666\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 11, Batch: 173/468, discriminator loss real = 5.298140398624085e-12, disciminator loss fake = 4.186657776017455e-08, generator loss = 17.956024169921875\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 11, Batch: 174/468, discriminator loss real = 7.138176192440695e-15, disciminator loss fake = 3.909003254420895e-08, generator loss = 17.967248916625977\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 11, Batch: 175/468, discriminator loss real = 3.429646991344503e-17, disciminator loss fake = 2.941409604773071e-08, generator loss = 18.044353485107422\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 11, Batch: 176/468, discriminator loss real = 1.0963764843921619e-16, disciminator loss fake = 3.2823649576130265e-08, generator loss = 17.78705596923828\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 11, Batch: 177/468, discriminator loss real = 1.0353583484543302e-16, disciminator loss fake = 4.504121875470446e-08, generator loss = 17.931655883789062\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 11, Batch: 178/468, discriminator loss real = 2.435609782028324e-15, disciminator loss fake = 2.5566777139829355e-08, generator loss = 17.87124252319336\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 11, Batch: 179/468, discriminator loss real = 7.68899267172829e-12, disciminator loss fake = 2.7668635382838147e-08, generator loss = 17.925212860107422\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 11, Batch: 180/468, discriminator loss real = 4.039342365569332e-16, disciminator loss fake = 2.9156643321925912e-08, generator loss = 17.777568817138672\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 11, Batch: 181/468, discriminator loss real = 1.299770787012303e-15, disciminator loss fake = 3.3653016373591527e-08, generator loss = 17.924650192260742\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 11, Batch: 182/468, discriminator loss real = 1.206297728373329e-09, disciminator loss fake = 2.5914676626825894e-08, generator loss = 17.96188735961914\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 11, Batch: 183/468, discriminator loss real = 2.5441947471851155e-14, disciminator loss fake = 2.5403453562944378e-08, generator loss = 17.8030948638916\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 11, Batch: 184/468, discriminator loss real = 4.942387285519844e-17, disciminator loss fake = 2.612722660444433e-08, generator loss = 17.775758743286133\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 11, Batch: 185/468, discriminator loss real = 4.134422025656864e-14, disciminator loss fake = 3.226452705007432e-08, generator loss = 17.994075775146484\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 11, Batch: 186/468, discriminator loss real = 2.1249415421698004e-11, disciminator loss fake = 2.167079671266947e-08, generator loss = 17.96866226196289\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 11, Batch: 187/468, discriminator loss real = 8.659644724386129e-15, disciminator loss fake = 4.8693404863797696e-08, generator loss = 18.0662784576416\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 11, Batch: 188/468, discriminator loss real = 2.576884924993211e-16, disciminator loss fake = 3.154326577714528e-08, generator loss = 18.094711303710938\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 11, Batch: 189/468, discriminator loss real = 8.16094142413551e-17, disciminator loss fake = 3.0957515662066726e-08, generator loss = 17.92930030822754\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 11, Batch: 190/468, discriminator loss real = 1.7172317162204138e-16, disciminator loss fake = 3.2351621825910115e-08, generator loss = 18.09022331237793\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 11, Batch: 191/468, discriminator loss real = 5.128322515252678e-18, disciminator loss fake = 5.720431062172793e-08, generator loss = 18.03987693786621\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 11, Batch: 192/468, discriminator loss real = 5.124735678136913e-15, disciminator loss fake = 3.319555474945446e-08, generator loss = 18.178157806396484\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 11, Batch: 193/468, discriminator loss real = 3.3953855674192504e-16, disciminator loss fake = 2.6698662836110998e-08, generator loss = 17.98334503173828\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 11, Batch: 194/468, discriminator loss real = 6.184335270449648e-13, disciminator loss fake = 1.9609490919947348e-08, generator loss = 18.139156341552734\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 11, Batch: 195/468, discriminator loss real = 4.434571633515905e-12, disciminator loss fake = 2.5777030288054448e-08, generator loss = 18.108318328857422\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 11, Batch: 196/468, discriminator loss real = 9.5879151035875e-20, disciminator loss fake = 2.5710164663905744e-08, generator loss = 18.23377799987793\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 11, Batch: 197/468, discriminator loss real = 1.2042805641598875e-10, disciminator loss fake = 2.1761247026574893e-08, generator loss = 18.05130958557129\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 11, Batch: 198/468, discriminator loss real = 3.406807383196501e-15, disciminator loss fake = 2.8199616863844312e-08, generator loss = 18.233718872070312\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 11, Batch: 199/468, discriminator loss real = 8.229560886681561e-16, disciminator loss fake = 2.8018083852998643e-08, generator loss = 17.9788818359375\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 11, Batch: 200/468, discriminator loss real = 6.368153617278272e-13, disciminator loss fake = 2.596202364202327e-08, generator loss = 18.036903381347656\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 11, Batch: 201/468, discriminator loss real = 2.409849900739721e-14, disciminator loss fake = 3.6077192788752654e-08, generator loss = 18.121784210205078\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 11, Batch: 202/468, discriminator loss real = 6.0197259503513845e-12, disciminator loss fake = 3.428396411209178e-08, generator loss = 17.985397338867188\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 11, Batch: 203/468, discriminator loss real = 8.279316787707103e-09, disciminator loss fake = 2.6060138935690702e-08, generator loss = 18.042802810668945\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 11, Batch: 204/468, discriminator loss real = 6.603848119105381e-19, disciminator loss fake = 2.793765219166744e-08, generator loss = 18.306804656982422\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 11, Batch: 205/468, discriminator loss real = 5.017125436144174e-16, disciminator loss fake = 4.143106480114511e-08, generator loss = 17.98403549194336\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 11, Batch: 206/468, discriminator loss real = 2.241471331460021e-12, disciminator loss fake = 2.2312434566629236e-08, generator loss = 18.09438705444336\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 11, Batch: 207/468, discriminator loss real = 2.9433803484801846e-12, disciminator loss fake = 2.580557989517729e-08, generator loss = 18.22983741760254\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 11, Batch: 208/468, discriminator loss real = 3.526011427279485e-11, disciminator loss fake = 2.3840179608214385e-08, generator loss = 18.209918975830078\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 11, Batch: 209/468, discriminator loss real = 1.4845522950052495e-17, disciminator loss fake = 2.7206350949882108e-08, generator loss = 18.152511596679688\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 11, Batch: 210/468, discriminator loss real = 1.3032661701131015e-13, disciminator loss fake = 2.798726228547821e-08, generator loss = 18.221025466918945\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 11, Batch: 211/468, discriminator loss real = 1.3531160749974316e-16, disciminator loss fake = 3.172571894083376e-08, generator loss = 18.282611846923828\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 11, Batch: 212/468, discriminator loss real = 8.06205694498847e-17, disciminator loss fake = 1.9618406454924298e-08, generator loss = 18.190006256103516\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 11, Batch: 213/468, discriminator loss real = 1.3258826339824196e-19, disciminator loss fake = 1.8026078407729074e-08, generator loss = 18.256122589111328\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 11, Batch: 214/468, discriminator loss real = 1.7984370295714795e-16, disciminator loss fake = 3.014542571122547e-08, generator loss = 18.25802993774414\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 11, Batch: 215/468, discriminator loss real = 1.2645106316211407e-11, disciminator loss fake = 2.7465640428658844e-08, generator loss = 18.226356506347656\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 11, Batch: 216/468, discriminator loss real = 2.792516495819797e-10, disciminator loss fake = 2.67568900369497e-08, generator loss = 18.22840118408203\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 11, Batch: 217/468, discriminator loss real = 1.5540359323278248e-14, disciminator loss fake = 1.9121245031783474e-08, generator loss = 18.311901092529297\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 11, Batch: 218/468, discriminator loss real = 2.160608523126866e-20, disciminator loss fake = 2.721505509839517e-08, generator loss = 18.284343719482422\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 11, Batch: 219/468, discriminator loss real = 3.634658187216724e-15, disciminator loss fake = 2.7597254259603687e-08, generator loss = 18.28966522216797\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 11, Batch: 220/468, discriminator loss real = 7.17691524428337e-15, disciminator loss fake = 2.3758067513313108e-08, generator loss = 18.25799560546875\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 11, Batch: 221/468, discriminator loss real = 5.994728115171031e-17, disciminator loss fake = 1.979223007708697e-08, generator loss = 18.21184539794922\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 11, Batch: 222/468, discriminator loss real = 1.125797776768346e-18, disciminator loss fake = 2.402317278438204e-08, generator loss = 18.37621307373047\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 11, Batch: 223/468, discriminator loss real = 1.2075707213080804e-15, disciminator loss fake = 2.236309981640261e-08, generator loss = 18.44220542907715\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 11, Batch: 224/468, discriminator loss real = 1.442739638529674e-17, disciminator loss fake = 2.0466206507308016e-08, generator loss = 18.284433364868164\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 11, Batch: 225/468, discriminator loss real = 2.835172137437343e-17, disciminator loss fake = 2.441997537516727e-08, generator loss = 18.296703338623047\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 11, Batch: 226/468, discriminator loss real = 5.955662802118941e-14, disciminator loss fake = 3.134153914174931e-08, generator loss = 18.34708023071289\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 11, Batch: 227/468, discriminator loss real = 4.72825950712355e-18, disciminator loss fake = 2.047383773629008e-08, generator loss = 18.005529403686523\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 11, Batch: 228/468, discriminator loss real = 1.2493791558538094e-16, disciminator loss fake = 1.5787492202434805e-08, generator loss = 18.391605377197266\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 11, Batch: 229/468, discriminator loss real = 4.455505788533015e-13, disciminator loss fake = 1.7743097657785256e-08, generator loss = 18.149845123291016\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 11, Batch: 230/468, discriminator loss real = 5.358528206523888e-15, disciminator loss fake = 1.633950219570579e-08, generator loss = 18.362342834472656\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 11, Batch: 231/468, discriminator loss real = 1.2699331364274258e-08, disciminator loss fake = 2.3273699412129645e-08, generator loss = 18.321063995361328\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 11, Batch: 232/468, discriminator loss real = 1.3293207680453722e-13, disciminator loss fake = 2.276688526592352e-08, generator loss = 18.283546447753906\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 11, Batch: 233/468, discriminator loss real = 3.5679876479559336e-13, disciminator loss fake = 2.068806814747859e-08, generator loss = 18.378604888916016\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 11, Batch: 234/468, discriminator loss real = 1.0121436397065708e-14, disciminator loss fake = 1.9602030221221867e-08, generator loss = 18.29473114013672\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 11, Batch: 235/468, discriminator loss real = 1.2759197255723285e-17, disciminator loss fake = 1.8690553105216168e-08, generator loss = 18.441543579101562\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 11, Batch: 236/468, discriminator loss real = 2.995781495637579e-17, disciminator loss fake = 2.5074522014278955e-08, generator loss = 18.480915069580078\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 11, Batch: 237/468, discriminator loss real = 3.8472114491545917e-14, disciminator loss fake = 2.042217772668664e-08, generator loss = 18.42788314819336\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 11, Batch: 238/468, discriminator loss real = 6.921188448749671e-12, disciminator loss fake = 1.3002399157358013e-08, generator loss = 18.348283767700195\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 11, Batch: 239/468, discriminator loss real = 8.289669203354923e-15, disciminator loss fake = 2.0091745156491925e-08, generator loss = 18.39156723022461\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 11, Batch: 240/468, discriminator loss real = 6.249690739840802e-18, disciminator loss fake = 2.1915527170790483e-08, generator loss = 18.31997299194336\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 11, Batch: 241/468, discriminator loss real = 5.7669948700594645e-18, disciminator loss fake = 2.939039944749311e-08, generator loss = 18.411510467529297\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 11, Batch: 242/468, discriminator loss real = 6.912868308383072e-14, disciminator loss fake = 2.1998964427893952e-08, generator loss = 18.491044998168945\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 11, Batch: 243/468, discriminator loss real = 1.9226246219275252e-20, disciminator loss fake = 2.382136088385778e-08, generator loss = 18.476377487182617\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 11, Batch: 244/468, discriminator loss real = 3.207016663136445e-15, disciminator loss fake = 2.333514004249082e-08, generator loss = 18.459716796875\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 11, Batch: 245/468, discriminator loss real = 2.7756812283731905e-14, disciminator loss fake = 2.1620667922661596e-08, generator loss = 18.367509841918945\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 11, Batch: 246/468, discriminator loss real = 1.4445355998407594e-15, disciminator loss fake = 2.340581595206004e-08, generator loss = 18.377635955810547\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 11, Batch: 247/468, discriminator loss real = 7.537707572913624e-14, disciminator loss fake = 2.1284598972215463e-08, generator loss = 18.47321128845215\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 11, Batch: 248/468, discriminator loss real = 4.431358979848504e-13, disciminator loss fake = 1.4024496231002104e-08, generator loss = 18.457813262939453\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 11, Batch: 249/468, discriminator loss real = 6.547564268544193e-09, disciminator loss fake = 1.2859111109264632e-08, generator loss = 18.40563201904297\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 11, Batch: 250/468, discriminator loss real = 1.0375656633753157e-16, disciminator loss fake = 1.9896948089126454e-08, generator loss = 18.48924446105957\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 11, Batch: 251/468, discriminator loss real = 5.986997007233425e-15, disciminator loss fake = 1.7214825120959176e-08, generator loss = 18.516521453857422\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 11, Batch: 252/468, discriminator loss real = 6.102051779447934e-14, disciminator loss fake = 1.7669590235414034e-08, generator loss = 18.502422332763672\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 11, Batch: 253/468, discriminator loss real = 2.026253080253393e-12, disciminator loss fake = 1.7840273258684647e-08, generator loss = 18.484607696533203\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 11, Batch: 254/468, discriminator loss real = 5.438478226788002e-12, disciminator loss fake = 2.030207824077479e-08, generator loss = 18.200197219848633\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 11, Batch: 255/468, discriminator loss real = 1.4577978064541568e-15, disciminator loss fake = 2.3988453889955963e-08, generator loss = 18.567176818847656\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 11, Batch: 256/468, discriminator loss real = 2.454653147410113e-11, disciminator loss fake = 1.4229154743361505e-08, generator loss = 18.54647445678711\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 11, Batch: 257/468, discriminator loss real = 1.4809517501213065e-10, disciminator loss fake = 1.956455797369472e-08, generator loss = 18.58302879333496\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 11, Batch: 258/468, discriminator loss real = 1.3620152479867466e-17, disciminator loss fake = 2.0633727615404496e-08, generator loss = 18.490699768066406\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 11, Batch: 259/468, discriminator loss real = 6.325770129933517e-08, disciminator loss fake = 2.0897534369623827e-08, generator loss = 18.46612548828125\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 11, Batch: 260/468, discriminator loss real = 8.042885942414145e-16, disciminator loss fake = 1.2900270185411955e-08, generator loss = 18.444320678710938\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 11, Batch: 261/468, discriminator loss real = 1.0553361366760251e-14, disciminator loss fake = 1.4287199867624167e-08, generator loss = 18.494922637939453\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 11, Batch: 262/468, discriminator loss real = 1.578537376766692e-14, disciminator loss fake = 1.5190062541137195e-08, generator loss = 18.497713088989258\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 11, Batch: 263/468, discriminator loss real = 8.879372800079538e-16, disciminator loss fake = 1.5208247106102135e-08, generator loss = 18.312828063964844\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 11, Batch: 264/468, discriminator loss real = 3.369719325622966e-14, disciminator loss fake = 1.872614596720723e-08, generator loss = 18.413677215576172\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 11, Batch: 265/468, discriminator loss real = 2.8312175782142437e-20, disciminator loss fake = 1.7836899957046626e-08, generator loss = 18.33694839477539\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 11, Batch: 266/468, discriminator loss real = 4.156652913577322e-14, disciminator loss fake = 1.0168776043428807e-08, generator loss = 18.659975051879883\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 11, Batch: 267/468, discriminator loss real = 2.873157263782513e-17, disciminator loss fake = 1.7635620963574183e-08, generator loss = 18.582122802734375\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 11, Batch: 268/468, discriminator loss real = 9.087831049470169e-17, disciminator loss fake = 2.3300614770960237e-08, generator loss = 18.550718307495117\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 11, Batch: 269/468, discriminator loss real = 9.172831493941408e-14, disciminator loss fake = 1.7930698703594317e-08, generator loss = 18.555866241455078\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 11, Batch: 270/468, discriminator loss real = 1.4079128386409751e-14, disciminator loss fake = 1.704403373992136e-08, generator loss = 18.461383819580078\n",
      "2/2 [==============================] - 0s 161ms/step\n",
      "Epoch: 11, Batch: 271/468, discriminator loss real = 6.128927118424776e-15, disciminator loss fake = 1.631163470960928e-08, generator loss = 18.429058074951172\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 11, Batch: 272/468, discriminator loss real = 1.60105315671899e-08, disciminator loss fake = 1.3866531034523177e-08, generator loss = 18.677135467529297\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 11, Batch: 273/468, discriminator loss real = 8.593734761419666e-16, disciminator loss fake = 1.518595915683818e-08, generator loss = 18.318639755249023\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 11, Batch: 274/468, discriminator loss real = 3.4461922579567884e-17, disciminator loss fake = 1.4177592433384234e-08, generator loss = 18.540313720703125\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 11, Batch: 275/468, discriminator loss real = 2.3626010002553155e-12, disciminator loss fake = 1.5488192062207418e-08, generator loss = 18.553871154785156\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 11, Batch: 276/468, discriminator loss real = 2.059117633346208e-12, disciminator loss fake = 1.6583982187512447e-08, generator loss = 18.45209312438965\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 11, Batch: 277/468, discriminator loss real = 4.941331445716202e-15, disciminator loss fake = 1.3330160086866272e-08, generator loss = 18.4219913482666\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 11, Batch: 278/468, discriminator loss real = 4.668729985268403e-15, disciminator loss fake = 2.4357641237315875e-08, generator loss = 18.582290649414062\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 11, Batch: 279/468, discriminator loss real = 1.579241701602993e-13, disciminator loss fake = 1.9337695889021234e-08, generator loss = 18.491741180419922\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 11, Batch: 280/468, discriminator loss real = 2.4457591849122093e-14, disciminator loss fake = 1.3700800494120813e-08, generator loss = 18.529827117919922\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 11, Batch: 281/468, discriminator loss real = 5.38784528737778e-15, disciminator loss fake = 1.4776104784175459e-08, generator loss = 18.54654312133789\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 11, Batch: 282/468, discriminator loss real = 1.2054251694038065e-11, disciminator loss fake = 1.8829855008561935e-08, generator loss = 18.38043212890625\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 11, Batch: 283/468, discriminator loss real = 5.440152451782754e-13, disciminator loss fake = 1.675620531216282e-08, generator loss = 18.572324752807617\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 11, Batch: 284/468, discriminator loss real = 5.012436388803117e-14, disciminator loss fake = 1.3028594203490229e-08, generator loss = 18.661237716674805\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 11, Batch: 285/468, discriminator loss real = 2.309188367645166e-16, disciminator loss fake = 1.9889858648980407e-08, generator loss = 18.655427932739258\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 11, Batch: 286/468, discriminator loss real = 2.2126447063995115e-14, disciminator loss fake = 1.083947420710274e-08, generator loss = 18.418678283691406\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 11, Batch: 287/468, discriminator loss real = 1.1299172818026479e-15, disciminator loss fake = 1.3456306291459441e-08, generator loss = 18.82421875\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 11, Batch: 288/468, discriminator loss real = 2.688040793963597e-16, disciminator loss fake = 1.542447947144865e-08, generator loss = 18.589086532592773\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "Epoch: 11, Batch: 289/468, discriminator loss real = 6.567375766472483e-13, disciminator loss fake = 1.129538951261111e-08, generator loss = 18.49696159362793\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 11, Batch: 290/468, discriminator loss real = 9.833609349984423e-14, disciminator loss fake = 1.999763199478366e-08, generator loss = 18.421566009521484\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 11, Batch: 291/468, discriminator loss real = 1.3841772172895617e-09, disciminator loss fake = 1.5587103163738902e-08, generator loss = 18.757556915283203\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 11, Batch: 292/468, discriminator loss real = 2.4196136760856746e-10, disciminator loss fake = 1.3715463431651642e-08, generator loss = 18.41326141357422\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 11, Batch: 293/468, discriminator loss real = 2.1301557739938914e-10, disciminator loss fake = 1.443498831577017e-08, generator loss = 18.426929473876953\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 11, Batch: 294/468, discriminator loss real = 8.236825804752712e-11, disciminator loss fake = 1.7617427516825046e-08, generator loss = 18.66315460205078\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Epoch: 11, Batch: 295/468, discriminator loss real = 7.941518553877813e-09, disciminator loss fake = 1.1701913216199955e-08, generator loss = 18.660011291503906\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 11, Batch: 296/468, discriminator loss real = 3.6149775122125416e-13, disciminator loss fake = 1.6584525752705304e-08, generator loss = 18.67446517944336\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 11, Batch: 297/468, discriminator loss real = 6.68566384979391e-13, disciminator loss fake = 1.068865795872398e-08, generator loss = 18.807405471801758\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 11, Batch: 298/468, discriminator loss real = 1.9471922717891749e-13, disciminator loss fake = 1.0197666711064812e-08, generator loss = 18.674768447875977\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 11, Batch: 299/468, discriminator loss real = 6.0907051801963995e-15, disciminator loss fake = 1.3552672761818485e-08, generator loss = 18.50490951538086\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 11, Batch: 300/468, discriminator loss real = 1.522246849344842e-15, disciminator loss fake = 1.3039743507192725e-08, generator loss = 18.597793579101562\n",
      "2/2 [==============================] - 0s 148ms/step\n",
      "Epoch: 11, Batch: 301/468, discriminator loss real = 3.2870390685068907e-17, disciminator loss fake = 1.4417190996596219e-08, generator loss = 18.582462310791016\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 11, Batch: 302/468, discriminator loss real = 7.601117136971439e-14, disciminator loss fake = 1.5801060015974144e-08, generator loss = 18.733856201171875\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 11, Batch: 303/468, discriminator loss real = 2.536181603745853e-15, disciminator loss fake = 1.8700038850738565e-08, generator loss = 18.663776397705078\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 11, Batch: 304/468, discriminator loss real = 1.9092107741860904e-17, disciminator loss fake = 1.87454318734126e-08, generator loss = 18.612014770507812\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 11, Batch: 305/468, discriminator loss real = 3.0299048860149558e-12, disciminator loss fake = 1.3434081402863285e-08, generator loss = 18.377119064331055\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 11, Batch: 306/468, discriminator loss real = 3.3743884676897635e-15, disciminator loss fake = 1.2728147424923009e-08, generator loss = 18.63869857788086\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 11, Batch: 307/468, discriminator loss real = 4.316038515633056e-17, disciminator loss fake = 1.3255746722506956e-08, generator loss = 18.72123908996582\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 11, Batch: 308/468, discriminator loss real = 1.510044259772636e-13, disciminator loss fake = 1.5310142487123812e-08, generator loss = 18.51822280883789\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 11, Batch: 309/468, discriminator loss real = 1.3465354048794453e-12, disciminator loss fake = 1.7592100221008877e-08, generator loss = 18.693195343017578\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 11, Batch: 310/468, discriminator loss real = 2.875604485433336e-13, disciminator loss fake = 1.440128372109939e-08, generator loss = 18.653152465820312\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 11, Batch: 311/468, discriminator loss real = 4.9525003374554025e-14, disciminator loss fake = 1.7238789951079525e-08, generator loss = 18.56878662109375\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 11, Batch: 312/468, discriminator loss real = 3.4376133196698172e-18, disciminator loss fake = 1.4821369909157056e-08, generator loss = 18.817893981933594\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 11, Batch: 313/468, discriminator loss real = 8.576659348003002e-13, disciminator loss fake = 1.260543580627882e-08, generator loss = 18.633460998535156\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 11, Batch: 314/468, discriminator loss real = 2.811900899828266e-17, disciminator loss fake = 1.2849156405536633e-08, generator loss = 18.74350357055664\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 11, Batch: 315/468, discriminator loss real = 6.43409949047123e-18, disciminator loss fake = 1.2944779470558387e-08, generator loss = 18.552963256835938\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 11, Batch: 316/468, discriminator loss real = 5.621941371197227e-16, disciminator loss fake = 1.1040585334853859e-08, generator loss = 18.70037841796875\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 11, Batch: 317/468, discriminator loss real = 3.2378373121750084e-14, disciminator loss fake = 1.8902877485516e-08, generator loss = 18.72357177734375\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 11, Batch: 318/468, discriminator loss real = 1.1678788144897645e-11, disciminator loss fake = 1.690752249317029e-08, generator loss = 18.751712799072266\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 11, Batch: 319/468, discriminator loss real = 1.4841937883103241e-15, disciminator loss fake = 1.2855840836323296e-08, generator loss = 18.773191452026367\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 11, Batch: 320/468, discriminator loss real = 1.72572308916774e-17, disciminator loss fake = 1.6379022582668767e-08, generator loss = 18.6312255859375\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 11, Batch: 321/468, discriminator loss real = 1.0419179489453909e-13, disciminator loss fake = 1.3223308670262668e-08, generator loss = 18.646020889282227\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 11, Batch: 322/468, discriminator loss real = 1.0318334163723863e-20, disciminator loss fake = 7.679817670691591e-09, generator loss = 18.55103302001953\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 11, Batch: 323/468, discriminator loss real = 1.0328715523654202e-14, disciminator loss fake = 1.4126799285918423e-08, generator loss = 18.661157608032227\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 11, Batch: 324/468, discriminator loss real = 8.043649296976541e-13, disciminator loss fake = 1.7422777887077245e-08, generator loss = 18.445411682128906\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 11, Batch: 325/468, discriminator loss real = 2.9975186829206413e-12, disciminator loss fake = 1.4392570690802131e-08, generator loss = 18.911712646484375\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 11, Batch: 326/468, discriminator loss real = 3.6285546372053987e-14, disciminator loss fake = 1.426109896840444e-08, generator loss = 18.51207160949707\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch: 11, Batch: 327/468, discriminator loss real = 2.8207622002063282e-11, disciminator loss fake = 1.1714764269754596e-08, generator loss = 18.72053337097168\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 11, Batch: 328/468, discriminator loss real = 2.0548682113513683e-12, disciminator loss fake = 1.2174277586041171e-08, generator loss = 18.59223747253418\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 11, Batch: 329/468, discriminator loss real = 1.9000880242033696e-15, disciminator loss fake = 1.542133531984291e-08, generator loss = 18.735057830810547\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 11, Batch: 330/468, discriminator loss real = 1.9226443354058986e-12, disciminator loss fake = 1.4629772060459345e-08, generator loss = 18.72072982788086\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 11, Batch: 331/468, discriminator loss real = 8.899853103832081e-15, disciminator loss fake = 1.2195730647590608e-08, generator loss = 18.795061111450195\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 11, Batch: 332/468, discriminator loss real = 2.5947948650850705e-11, disciminator loss fake = 1.1399628796482375e-08, generator loss = 18.718963623046875\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 11, Batch: 333/468, discriminator loss real = 1.5158656122872538e-13, disciminator loss fake = 1.4982475704528042e-08, generator loss = 18.75925064086914\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 11, Batch: 334/468, discriminator loss real = 1.3149129832521313e-15, disciminator loss fake = 1.0320211352166098e-08, generator loss = 18.857221603393555\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 11, Batch: 335/468, discriminator loss real = 8.512947405888511e-16, disciminator loss fake = 1.4274215587306571e-08, generator loss = 18.971525192260742\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 11, Batch: 336/468, discriminator loss real = 1.3785719296914855e-17, disciminator loss fake = 1.42012108739209e-08, generator loss = 18.66635513305664\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 11, Batch: 337/468, discriminator loss real = 1.0597431959746828e-10, disciminator loss fake = 1.692360740435106e-08, generator loss = 18.849903106689453\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 11, Batch: 338/468, discriminator loss real = 6.718345942507088e-19, disciminator loss fake = 1.4960662042540207e-08, generator loss = 18.926464080810547\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 11, Batch: 339/468, discriminator loss real = 3.730782258780555e-18, disciminator loss fake = 1.2027921769686145e-08, generator loss = 18.682964324951172\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 11, Batch: 340/468, discriminator loss real = 1.595577469438852e-17, disciminator loss fake = 1.3346626914767512e-08, generator loss = 18.835369110107422\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 11, Batch: 341/468, discriminator loss real = 1.24738010515873e-15, disciminator loss fake = 1.0826336271918535e-08, generator loss = 18.79448699951172\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 11, Batch: 342/468, discriminator loss real = 1.125113546200532e-15, disciminator loss fake = 1.0536350458778543e-08, generator loss = 18.942935943603516\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 11, Batch: 343/468, discriminator loss real = 3.2068601208598807e-17, disciminator loss fake = 1.6396052515688098e-08, generator loss = 18.78903579711914\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 11, Batch: 344/468, discriminator loss real = 2.06003918486403e-16, disciminator loss fake = 1.1668664257058481e-08, generator loss = 18.76028060913086\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 11, Batch: 345/468, discriminator loss real = 3.579691265631624e-10, disciminator loss fake = 1.2476201405320353e-08, generator loss = 18.799930572509766\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 11, Batch: 346/468, discriminator loss real = 1.1252940237753012e-17, disciminator loss fake = 9.84971570971993e-09, generator loss = 18.863603591918945\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 11, Batch: 347/468, discriminator loss real = 3.9301992586398594e-16, disciminator loss fake = 1.079537170767253e-08, generator loss = 18.78705596923828\n",
      "2/2 [==============================] - 0s 152ms/step\n",
      "Epoch: 11, Batch: 348/468, discriminator loss real = 5.852458274946404e-13, disciminator loss fake = 1.0514842330167085e-08, generator loss = 18.843303680419922\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 11, Batch: 349/468, discriminator loss real = 4.0831821894361883e-19, disciminator loss fake = 1.5133613473494734e-08, generator loss = 18.991281509399414\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 11, Batch: 350/468, discriminator loss real = 4.958893538853371e-13, disciminator loss fake = 1.641179991906938e-08, generator loss = 18.750728607177734\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 11, Batch: 351/468, discriminator loss real = 5.3724203938918056e-15, disciminator loss fake = 1.0967713848231142e-08, generator loss = 18.891517639160156\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 11, Batch: 352/468, discriminator loss real = 8.121165551025836e-16, disciminator loss fake = 1.2611439004217573e-08, generator loss = 18.9053955078125\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 11, Batch: 353/468, discriminator loss real = 9.044589011661212e-15, disciminator loss fake = 1.0780548009847735e-08, generator loss = 18.80731773376465\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 11, Batch: 354/468, discriminator loss real = 3.766336404537572e-14, disciminator loss fake = 1.0742420286646848e-08, generator loss = 18.850303649902344\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 11, Batch: 355/468, discriminator loss real = 6.162775845197643e-10, disciminator loss fake = 1.1693106927168628e-08, generator loss = 18.821849822998047\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 11, Batch: 356/468, discriminator loss real = 2.7842616109175112e-18, disciminator loss fake = 1.0620037294017948e-08, generator loss = 18.67998695373535\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 11, Batch: 357/468, discriminator loss real = 6.153784519642499e-22, disciminator loss fake = 8.852516941715294e-09, generator loss = 18.847087860107422\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 11, Batch: 358/468, discriminator loss real = 6.48830096332991e-16, disciminator loss fake = 1.1464992510923366e-08, generator loss = 18.98957061767578\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 11, Batch: 359/468, discriminator loss real = 1.238837591538422e-11, disciminator loss fake = 1.656824366591536e-08, generator loss = 18.860626220703125\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 11, Batch: 360/468, discriminator loss real = 1.4593456109344982e-13, disciminator loss fake = 1.4784374613441287e-08, generator loss = 18.992942810058594\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 11, Batch: 361/468, discriminator loss real = 1.0412402312668478e-17, disciminator loss fake = 1.4607672405020367e-08, generator loss = 18.89377212524414\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 11, Batch: 362/468, discriminator loss real = 5.273493721916081e-15, disciminator loss fake = 1.0098267111402492e-08, generator loss = 19.110923767089844\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 11, Batch: 363/468, discriminator loss real = 6.242615880605248e-16, disciminator loss fake = 1.409636052329688e-08, generator loss = 18.920879364013672\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 11, Batch: 364/468, discriminator loss real = 2.877489167622295e-14, disciminator loss fake = 1.4714149010330857e-08, generator loss = 18.8685245513916\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 11, Batch: 365/468, discriminator loss real = 2.183886751994102e-14, disciminator loss fake = 1.1754549333886644e-08, generator loss = 18.959247589111328\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 11, Batch: 366/468, discriminator loss real = 3.87331009280012e-12, disciminator loss fake = 8.640495430256578e-09, generator loss = 18.807456970214844\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 11, Batch: 367/468, discriminator loss real = 5.904480328061332e-16, disciminator loss fake = 8.927798944569076e-09, generator loss = 18.706363677978516\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 11, Batch: 368/468, discriminator loss real = 1.959213014046668e-09, disciminator loss fake = 9.609072648686379e-09, generator loss = 18.92495346069336\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 11, Batch: 369/468, discriminator loss real = 1.176384834309639e-17, disciminator loss fake = 7.63678364990028e-09, generator loss = 19.003576278686523\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 11, Batch: 370/468, discriminator loss real = 4.264842653160924e-17, disciminator loss fake = 1.4755652699705024e-08, generator loss = 18.997196197509766\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 11, Batch: 371/468, discriminator loss real = 1.4187238589599607e-14, disciminator loss fake = 9.990772653623026e-09, generator loss = 18.76422882080078\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 11, Batch: 372/468, discriminator loss real = 3.082536701207953e-15, disciminator loss fake = 1.1911886588222842e-08, generator loss = 18.93012046813965\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 11, Batch: 373/468, discriminator loss real = 7.061141168301921e-12, disciminator loss fake = 9.05523833694133e-09, generator loss = 18.71919059753418\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 11, Batch: 374/468, discriminator loss real = 1.2527486264482074e-16, disciminator loss fake = 1.2408020388932073e-08, generator loss = 18.96741485595703\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 11, Batch: 375/468, discriminator loss real = 9.719877604852345e-18, disciminator loss fake = 1.0613844025897379e-08, generator loss = 18.88417625427246\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 11, Batch: 376/468, discriminator loss real = 2.773041778841856e-12, disciminator loss fake = 1.2560372297798494e-08, generator loss = 18.990245819091797\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 11, Batch: 377/468, discriminator loss real = 1.634593610640167e-13, disciminator loss fake = 1.1793256149417175e-08, generator loss = 18.88690948486328\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 11, Batch: 378/468, discriminator loss real = 1.3448307692843044e-16, disciminator loss fake = 1.3301812984423123e-08, generator loss = 18.898426055908203\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 11, Batch: 379/468, discriminator loss real = 1.4547150376659213e-12, disciminator loss fake = 1.1719873072024711e-08, generator loss = 19.011510848999023\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 11, Batch: 380/468, discriminator loss real = 8.798987520500533e-17, disciminator loss fake = 1.2159150131196839e-08, generator loss = 18.78988265991211\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 11, Batch: 381/468, discriminator loss real = 1.2986287392657836e-12, disciminator loss fake = 1.0382429138644511e-08, generator loss = 18.81381607055664\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 11, Batch: 382/468, discriminator loss real = 3.292130133566583e-16, disciminator loss fake = 9.853787119595836e-09, generator loss = 18.75113296508789\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 11, Batch: 383/468, discriminator loss real = 7.719787808134482e-13, disciminator loss fake = 9.477583162720293e-09, generator loss = 18.732149124145508\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 11, Batch: 384/468, discriminator loss real = 2.802712246711782e-17, disciminator loss fake = 1.400848415045175e-08, generator loss = 18.95056915283203\n",
      "2/2 [==============================] - 0s 55ms/step\n",
      "Epoch: 11, Batch: 385/468, discriminator loss real = 1.6958229959174176e-11, disciminator loss fake = 7.76467778962342e-09, generator loss = 18.880722045898438\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 11, Batch: 386/468, discriminator loss real = 9.881171266412289e-15, disciminator loss fake = 1.3423806066725774e-08, generator loss = 19.081668853759766\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 11, Batch: 387/468, discriminator loss real = 5.276222822367465e-18, disciminator loss fake = 9.704569592372536e-09, generator loss = 18.904481887817383\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 11, Batch: 388/468, discriminator loss real = 9.25241087461066e-17, disciminator loss fake = 1.2971742791023644e-08, generator loss = 18.936758041381836\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 11, Batch: 389/468, discriminator loss real = 2.4381935359585327e-10, disciminator loss fake = 1.1788521270261754e-08, generator loss = 18.89385986328125\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 11, Batch: 390/468, discriminator loss real = 2.688253452172917e-15, disciminator loss fake = 1.2162578499896881e-08, generator loss = 19.11450958251953\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 11, Batch: 391/468, discriminator loss real = 3.3586856067763855e-18, disciminator loss fake = 1.0718981258150961e-08, generator loss = 19.045536041259766\n",
      "2/2 [==============================] - 0s 137ms/step\n",
      "Epoch: 11, Batch: 392/468, discriminator loss real = 3.4498840907620657e-15, disciminator loss fake = 1.3251650443635299e-08, generator loss = 18.995502471923828\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 11, Batch: 393/468, discriminator loss real = 7.371542070332138e-14, disciminator loss fake = 1.0481017831409645e-08, generator loss = 19.02572250366211\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 11, Batch: 394/468, discriminator loss real = 3.6561035367818975e-14, disciminator loss fake = 1.0688165907879466e-08, generator loss = 19.02829933166504\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 11, Batch: 395/468, discriminator loss real = 1.8788181787404183e-21, disciminator loss fake = 9.518428711885463e-09, generator loss = 18.96868896484375\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 11, Batch: 396/468, discriminator loss real = 2.49972704211357e-13, disciminator loss fake = 8.685048236145576e-09, generator loss = 19.02402114868164\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 11, Batch: 397/468, discriminator loss real = 4.242578127444549e-16, disciminator loss fake = 1.0630371249931159e-08, generator loss = 19.016246795654297\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 11, Batch: 398/468, discriminator loss real = 2.443378344704067e-13, disciminator loss fake = 9.475153994742413e-09, generator loss = 18.947975158691406\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 11, Batch: 399/468, discriminator loss real = 3.165266239759691e-14, disciminator loss fake = 8.42706349146738e-09, generator loss = 19.137989044189453\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 11, Batch: 400/468, discriminator loss real = 1.2259922691306747e-14, disciminator loss fake = 1.1089946738707113e-08, generator loss = 18.858489990234375\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 11, Batch: 401/468, discriminator loss real = 2.323357728428732e-09, disciminator loss fake = 8.723011646338819e-09, generator loss = 19.149028778076172\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 11, Batch: 402/468, discriminator loss real = 3.9259356399493073e-13, disciminator loss fake = 1.1025075963289055e-08, generator loss = 18.965614318847656\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 11, Batch: 403/468, discriminator loss real = 1.9784105464992763e-09, disciminator loss fake = 1.26072698947155e-08, generator loss = 18.973108291625977\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 11, Batch: 404/468, discriminator loss real = 1.9534844575286314e-10, disciminator loss fake = 1.0022402463505387e-08, generator loss = 18.93783950805664\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 11, Batch: 405/468, discriminator loss real = 1.729427508353218e-15, disciminator loss fake = 1.0746189715860055e-08, generator loss = 18.988265991210938\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 11, Batch: 406/468, discriminator loss real = 5.735769931930479e-13, disciminator loss fake = 9.47522504901599e-09, generator loss = 18.958032608032227\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 11, Batch: 407/468, discriminator loss real = 5.103830772649779e-17, disciminator loss fake = 8.046191268817893e-09, generator loss = 18.962158203125\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Epoch: 11, Batch: 408/468, discriminator loss real = 8.639869046166582e-15, disciminator loss fake = 7.611544283747662e-09, generator loss = 19.033205032348633\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 11, Batch: 409/468, discriminator loss real = 4.4161140131011856e-14, disciminator loss fake = 9.524077526634755e-09, generator loss = 19.02838706970215\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 11, Batch: 410/468, discriminator loss real = 7.601925489097994e-08, disciminator loss fake = 1.0684882312261834e-08, generator loss = 19.05841827392578\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 11, Batch: 411/468, discriminator loss real = 5.857895350235354e-20, disciminator loss fake = 7.815761371432473e-09, generator loss = 19.028125762939453\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 11, Batch: 412/468, discriminator loss real = 1.6687255486387727e-14, disciminator loss fake = 8.814199148332591e-09, generator loss = 18.84579849243164\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 11, Batch: 413/468, discriminator loss real = 7.247437235473183e-18, disciminator loss fake = 9.145756152406648e-09, generator loss = 19.030729293823242\n",
      "2/2 [==============================] - 0s 146ms/step\n",
      "Epoch: 11, Batch: 414/468, discriminator loss real = 2.970303216077119e-18, disciminator loss fake = 8.75852101955843e-09, generator loss = 19.1041259765625\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 11, Batch: 415/468, discriminator loss real = 1.3685023437810112e-13, disciminator loss fake = 1.1247045961226831e-08, generator loss = 19.241744995117188\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 11, Batch: 416/468, discriminator loss real = 1.0210325640525042e-11, disciminator loss fake = 1.1793511056623629e-08, generator loss = 19.047847747802734\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 11, Batch: 417/468, discriminator loss real = 1.138466924899273e-11, disciminator loss fake = 1.5265001707120973e-08, generator loss = 19.132776260375977\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 11, Batch: 418/468, discriminator loss real = 1.50125141721147e-17, disciminator loss fake = 1.2386570880096315e-08, generator loss = 18.98756980895996\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 11, Batch: 419/468, discriminator loss real = 2.1390136569540003e-14, disciminator loss fake = 7.340416274814743e-09, generator loss = 19.05787467956543\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 11, Batch: 420/468, discriminator loss real = 8.195512682124956e-14, disciminator loss fake = 1.2144363736865671e-08, generator loss = 19.17137336730957\n",
      "2/2 [==============================] - 0s 168ms/step\n",
      "Epoch: 11, Batch: 421/468, discriminator loss real = 8.50956086228627e-16, disciminator loss fake = 9.228706687736121e-09, generator loss = 19.001605987548828\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 11, Batch: 422/468, discriminator loss real = 3.6701315564708194e-17, disciminator loss fake = 1.0116911752788837e-08, generator loss = 19.141279220581055\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 11, Batch: 423/468, discriminator loss real = 1.3060309534155753e-14, disciminator loss fake = 1.4084060140362453e-08, generator loss = 18.95027732849121\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 11, Batch: 424/468, discriminator loss real = 2.747866466330372e-16, disciminator loss fake = 1.3691116684810822e-08, generator loss = 19.153133392333984\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 11, Batch: 425/468, discriminator loss real = 1.1210449624047388e-17, disciminator loss fake = 1.0805425887383535e-08, generator loss = 19.1803035736084\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 11, Batch: 426/468, discriminator loss real = 3.715638907664243e-12, disciminator loss fake = 1.1362212504195668e-08, generator loss = 18.938152313232422\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 11, Batch: 427/468, discriminator loss real = 2.5913166469375415e-13, disciminator loss fake = 7.25408799695515e-09, generator loss = 19.009140014648438\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 11, Batch: 428/468, discriminator loss real = 1.7058228812230798e-14, disciminator loss fake = 1.2180770170289179e-08, generator loss = 18.977405548095703\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 11, Batch: 429/468, discriminator loss real = 9.984228199755307e-08, disciminator loss fake = 1.20433387706953e-08, generator loss = 19.068012237548828\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 11, Batch: 430/468, discriminator loss real = 2.3132478061321068e-17, disciminator loss fake = 1.487419698520398e-08, generator loss = 19.196918487548828\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 11, Batch: 431/468, discriminator loss real = 4.565192065927827e-16, disciminator loss fake = 1.0073834211254962e-08, generator loss = 18.970773696899414\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 11, Batch: 432/468, discriminator loss real = 3.5020545491315502e-12, disciminator loss fake = 1.1338081584710835e-08, generator loss = 19.066804885864258\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 11, Batch: 433/468, discriminator loss real = 8.167289141981793e-16, disciminator loss fake = 1.0170023934108485e-08, generator loss = 18.99449920654297\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 11, Batch: 434/468, discriminator loss real = 1.019227545651048e-15, disciminator loss fake = 9.643709830697844e-09, generator loss = 19.05493927001953\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 11, Batch: 435/468, discriminator loss real = 2.3709968912019044e-16, disciminator loss fake = 1.0658220972459276e-08, generator loss = 19.08367156982422\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 11, Batch: 436/468, discriminator loss real = 1.8263047324440507e-11, disciminator loss fake = 7.889585873499527e-09, generator loss = 18.99701690673828\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 11, Batch: 437/468, discriminator loss real = 2.4402726136996643e-14, disciminator loss fake = 9.655163779598297e-09, generator loss = 19.082836151123047\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 11, Batch: 438/468, discriminator loss real = 1.0603390876440244e-07, disciminator loss fake = 8.916290816785022e-09, generator loss = 18.915895462036133\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 11, Batch: 439/468, discriminator loss real = 1.917635029698514e-18, disciminator loss fake = 7.976467486514593e-09, generator loss = 19.12217903137207\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 11, Batch: 440/468, discriminator loss real = 1.5656040306950662e-15, disciminator loss fake = 9.750618978898729e-09, generator loss = 19.076745986938477\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 11, Batch: 441/468, discriminator loss real = 1.7039163482945874e-11, disciminator loss fake = 1.0797796434758311e-08, generator loss = 19.148334503173828\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 11, Batch: 442/468, discriminator loss real = 4.4657603082056546e-14, disciminator loss fake = 9.826194080631012e-09, generator loss = 19.18090057373047\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 11, Batch: 443/468, discriminator loss real = 7.357289004577042e-16, disciminator loss fake = 9.247642651644128e-09, generator loss = 19.102867126464844\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 11, Batch: 444/468, discriminator loss real = 2.1268332384691887e-15, disciminator loss fake = 8.067449819293415e-09, generator loss = 19.157329559326172\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 11, Batch: 445/468, discriminator loss real = 1.1592788361214357e-12, disciminator loss fake = 8.995439060299759e-09, generator loss = 19.007354736328125\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 11, Batch: 446/468, discriminator loss real = 2.0234116845149058e-13, disciminator loss fake = 9.545502166474762e-09, generator loss = 18.958513259887695\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 11, Batch: 447/468, discriminator loss real = 5.825227453182258e-13, disciminator loss fake = 9.879922657773932e-09, generator loss = 19.001121520996094\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 11, Batch: 448/468, discriminator loss real = 1.6355599735890305e-14, disciminator loss fake = 9.864474570520088e-09, generator loss = 19.138336181640625\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 11, Batch: 449/468, discriminator loss real = 4.585068625771391e-14, disciminator loss fake = 1.2875705834858309e-08, generator loss = 18.865808486938477\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 11, Batch: 450/468, discriminator loss real = 1.7363050453080085e-16, disciminator loss fake = 8.409637430872863e-09, generator loss = 18.922344207763672\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 11, Batch: 451/468, discriminator loss real = 4.923468924222796e-11, disciminator loss fake = 8.748250124313017e-09, generator loss = 18.980262756347656\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 11, Batch: 452/468, discriminator loss real = 5.131087366450136e-16, disciminator loss fake = 8.409058338543218e-09, generator loss = 18.917423248291016\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 11, Batch: 453/468, discriminator loss real = 1.2276826080802154e-14, disciminator loss fake = 9.22631038235977e-09, generator loss = 18.965152740478516\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 11, Batch: 454/468, discriminator loss real = 3.9506539925853075e-15, disciminator loss fake = 9.921109267452266e-09, generator loss = 19.040973663330078\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 11, Batch: 455/468, discriminator loss real = 2.4699438674891105e-11, disciminator loss fake = 9.457621352737533e-09, generator loss = 18.820816040039062\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 11, Batch: 456/468, discriminator loss real = 1.2743442608340478e-16, disciminator loss fake = 9.781938814512614e-09, generator loss = 18.928733825683594\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 11, Batch: 457/468, discriminator loss real = 3.733368018757951e-15, disciminator loss fake = 8.079356739187915e-09, generator loss = 18.926488876342773\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 11, Batch: 458/468, discriminator loss real = 6.424482854105811e-16, disciminator loss fake = 7.622792175254745e-09, generator loss = 18.972776412963867\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 11, Batch: 459/468, discriminator loss real = 3.509630406729595e-15, disciminator loss fake = 1.0415147855269424e-08, generator loss = 18.88189697265625\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 11, Batch: 460/468, discriminator loss real = 2.0134377614467033e-15, disciminator loss fake = 1.1428987534145563e-08, generator loss = 19.06856346130371\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 11, Batch: 461/468, discriminator loss real = 1.0107405364057076e-12, disciminator loss fake = 8.649990945741592e-09, generator loss = 19.000396728515625\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 11, Batch: 462/468, discriminator loss real = 3.177406700788705e-18, disciminator loss fake = 1.1131269239683661e-08, generator loss = 18.920804977416992\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 11, Batch: 463/468, discriminator loss real = 1.7912757630491385e-16, disciminator loss fake = 1.0362668945163023e-08, generator loss = 18.883167266845703\n",
      "2/2 [==============================] - 0s 147ms/step\n",
      "Epoch: 11, Batch: 464/468, discriminator loss real = 1.163255825215384e-13, disciminator loss fake = 1.2396510484791179e-08, generator loss = 19.327266693115234\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 11, Batch: 465/468, discriminator loss real = 1.0483357481801472e-14, disciminator loss fake = 1.0511195469575796e-08, generator loss = 19.22608757019043\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 11, Batch: 466/468, discriminator loss real = 6.501175334732584e-16, disciminator loss fake = 1.1850883829822578e-08, generator loss = 19.066055297851562\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 11, Batch: 467/468, discriminator loss real = 1.0696995372816431e-11, disciminator loss fake = 7.933495638212662e-09, generator loss = 18.958045959472656\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 11, Batch: 468/468, discriminator loss real = 6.15754808253044e-11, disciminator loss fake = 9.169744075165909e-09, generator loss = 19.10677146911621\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 12, Batch: 1/468, discriminator loss real = 8.315943953620514e-16, disciminator loss fake = 1.2632375145926744e-08, generator loss = 19.092063903808594\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 12, Batch: 2/468, discriminator loss real = 1.0903157852482429e-13, disciminator loss fake = 8.740325796452453e-09, generator loss = 19.066404342651367\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 12, Batch: 3/468, discriminator loss real = 5.906595199924036e-13, disciminator loss fake = 9.948172063900529e-09, generator loss = 19.175148010253906\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 12, Batch: 4/468, discriminator loss real = 2.9005952099838556e-14, disciminator loss fake = 8.313513433222397e-09, generator loss = 19.05946159362793\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 12, Batch: 5/468, discriminator loss real = 1.043200610937418e-14, disciminator loss fake = 1.314407516161964e-08, generator loss = 19.205324172973633\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 12, Batch: 6/468, discriminator loss real = 2.0076171627914086e-12, disciminator loss fake = 9.428511305031861e-09, generator loss = 19.13806915283203\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 12, Batch: 7/468, discriminator loss real = 2.198398581232386e-12, disciminator loss fake = 8.937574236256296e-09, generator loss = 19.177398681640625\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 12, Batch: 8/468, discriminator loss real = 1.067641114405049e-11, disciminator loss fake = 9.183558802305924e-09, generator loss = 19.13796615600586\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 12, Batch: 9/468, discriminator loss real = 2.574636052518251e-16, disciminator loss fake = 8.095772052740813e-09, generator loss = 19.269283294677734\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 12, Batch: 10/468, discriminator loss real = 3.669465442612818e-08, disciminator loss fake = 9.232191899855025e-09, generator loss = 19.007522583007812\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 12, Batch: 11/468, discriminator loss real = 9.656046101591542e-11, disciminator loss fake = 1.151441519908758e-08, generator loss = 19.107839584350586\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 12, Batch: 12/468, discriminator loss real = 9.56949342325057e-16, disciminator loss fake = 1.1760358908929902e-08, generator loss = 19.018085479736328\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 12, Batch: 13/468, discriminator loss real = 1.530648221018116e-12, disciminator loss fake = 1.1157492707525307e-08, generator loss = 19.27294921875\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 12, Batch: 14/468, discriminator loss real = 1.9148458818563086e-08, disciminator loss fake = 6.235096883244751e-09, generator loss = 19.171022415161133\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 12, Batch: 15/468, discriminator loss real = 1.1775635203604127e-15, disciminator loss fake = 1.0836663122404389e-08, generator loss = 19.231449127197266\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 12, Batch: 16/468, discriminator loss real = 4.878927337616915e-21, disciminator loss fake = 9.30453225578276e-09, generator loss = 19.251876831054688\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 12, Batch: 17/468, discriminator loss real = 2.757398657481417e-15, disciminator loss fake = 9.083855445624067e-09, generator loss = 19.000377655029297\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 12, Batch: 18/468, discriminator loss real = 2.1177607193931247e-13, disciminator loss fake = 8.620904878853253e-09, generator loss = 19.129764556884766\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 12, Batch: 19/468, discriminator loss real = 1.3022552871125304e-13, disciminator loss fake = 1.0828459906520038e-08, generator loss = 19.21837615966797\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 12, Batch: 20/468, discriminator loss real = 9.83545955184438e-18, disciminator loss fake = 6.947683317548581e-09, generator loss = 19.250988006591797\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 12, Batch: 21/468, discriminator loss real = 1.2541037002281041e-13, disciminator loss fake = 7.323085249311134e-09, generator loss = 19.20514678955078\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 12, Batch: 22/468, discriminator loss real = 7.303894468402294e-12, disciminator loss fake = 5.448221429560363e-09, generator loss = 19.136985778808594\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 12, Batch: 23/468, discriminator loss real = 1.7264532668591587e-22, disciminator loss fake = 7.013005287603846e-09, generator loss = 19.009775161743164\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 12, Batch: 24/468, discriminator loss real = 1.558442541682581e-10, disciminator loss fake = 7.907828170061748e-09, generator loss = 19.195758819580078\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 12, Batch: 25/468, discriminator loss real = 7.12495085153364e-09, disciminator loss fake = 7.662899648153143e-09, generator loss = 19.215877532958984\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 12, Batch: 26/468, discriminator loss real = 1.5808656467219961e-12, disciminator loss fake = 8.267024398378453e-09, generator loss = 19.02326202392578\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 12, Batch: 27/468, discriminator loss real = 4.2979783173597165e-16, disciminator loss fake = 1.062165999599074e-08, generator loss = 19.27240753173828\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 12, Batch: 28/468, discriminator loss real = 9.290324069329762e-16, disciminator loss fake = 7.475479790741701e-09, generator loss = 19.211423873901367\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 12, Batch: 29/468, discriminator loss real = 5.1800248118683e-11, disciminator loss fake = 9.46793843326077e-09, generator loss = 19.07675552368164\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 12, Batch: 30/468, discriminator loss real = 4.1012600769669275e-17, disciminator loss fake = 5.5295892309459305e-09, generator loss = 19.13684844970703\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 12, Batch: 31/468, discriminator loss real = 1.8371172232122326e-14, disciminator loss fake = 6.126984253285173e-09, generator loss = 19.196165084838867\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 12, Batch: 32/468, discriminator loss real = 2.746288710765016e-13, disciminator loss fake = 8.549466024021513e-09, generator loss = 19.152292251586914\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 12, Batch: 33/468, discriminator loss real = 1.6926972414670704e-17, disciminator loss fake = 9.301626135993502e-09, generator loss = 19.02640724182129\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 12, Batch: 34/468, discriminator loss real = 5.614693779354418e-11, disciminator loss fake = 7.371328880623196e-09, generator loss = 19.074495315551758\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 12, Batch: 35/468, discriminator loss real = 5.119103474449105e-10, disciminator loss fake = 7.250921640888919e-09, generator loss = 19.355838775634766\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 12, Batch: 36/468, discriminator loss real = 6.345958480924452e-12, disciminator loss fake = 8.196813894301158e-09, generator loss = 19.064912796020508\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 12, Batch: 37/468, discriminator loss real = 9.299050922730381e-14, disciminator loss fake = 8.223773662052736e-09, generator loss = 19.192798614501953\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 12, Batch: 38/468, discriminator loss real = 1.0880859032519601e-14, disciminator loss fake = 7.112638034101337e-09, generator loss = 19.13581657409668\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 12, Batch: 39/468, discriminator loss real = 5.497240518957959e-18, disciminator loss fake = 6.670898500260591e-09, generator loss = 19.266326904296875\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 12, Batch: 40/468, discriminator loss real = 6.378617184682293e-15, disciminator loss fake = 9.671845546677105e-09, generator loss = 19.21058464050293\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 12, Batch: 41/468, discriminator loss real = 9.034607998927241e-16, disciminator loss fake = 7.291231618467009e-09, generator loss = 19.177350997924805\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 12, Batch: 42/468, discriminator loss real = 8.779525728641602e-08, disciminator loss fake = 9.684343993399125e-09, generator loss = 19.25666618347168\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 12, Batch: 43/468, discriminator loss real = 5.156017540003388e-12, disciminator loss fake = 8.683603169856724e-09, generator loss = 19.133121490478516\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 12, Batch: 44/468, discriminator loss real = 5.714384942330173e-18, disciminator loss fake = 8.900369330433477e-09, generator loss = 19.194026947021484\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 12, Batch: 45/468, discriminator loss real = 9.313737796409413e-14, disciminator loss fake = 8.942979690118591e-09, generator loss = 19.191940307617188\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 12, Batch: 46/468, discriminator loss real = 7.618600889047755e-11, disciminator loss fake = 9.527002298170828e-09, generator loss = 19.15760040283203\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 12, Batch: 47/468, discriminator loss real = 3.728088462397715e-15, disciminator loss fake = 7.1813492930061784e-09, generator loss = 19.224124908447266\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 12, Batch: 48/468, discriminator loss real = 1.051157299630746e-15, disciminator loss fake = 7.546146818526722e-09, generator loss = 19.234516143798828\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 12, Batch: 49/468, discriminator loss real = 6.710598331356732e-13, disciminator loss fake = 1.0700451191780758e-08, generator loss = 19.16388702392578\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 12, Batch: 50/468, discriminator loss real = 6.836828021949861e-16, disciminator loss fake = 8.288170150194674e-09, generator loss = 19.234464645385742\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 12, Batch: 51/468, discriminator loss real = 2.466949442034988e-13, disciminator loss fake = 1.1191406912303137e-08, generator loss = 19.255176544189453\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 12, Batch: 52/468, discriminator loss real = 1.544344383839155e-17, disciminator loss fake = 6.883989378536626e-09, generator loss = 19.075969696044922\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 12, Batch: 53/468, discriminator loss real = 1.1675798068817417e-18, disciminator loss fake = 8.46212966365556e-09, generator loss = 19.04200553894043\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 12, Batch: 54/468, discriminator loss real = 4.5312438324348215e-15, disciminator loss fake = 8.773918480642351e-09, generator loss = 19.132917404174805\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 12, Batch: 55/468, discriminator loss real = 3.674780952082034e-14, disciminator loss fake = 7.532640289298342e-09, generator loss = 19.025863647460938\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 12, Batch: 56/468, discriminator loss real = 6.919952891953907e-14, disciminator loss fake = 1.0943119299611226e-08, generator loss = 19.06317710876465\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 12, Batch: 57/468, discriminator loss real = 2.3394247968841844e-16, disciminator loss fake = 6.355573844984974e-09, generator loss = 19.223722457885742\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 12, Batch: 58/468, discriminator loss real = 4.9140616434958234e-17, disciminator loss fake = 7.397007895093566e-09, generator loss = 19.15928077697754\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 12, Batch: 59/468, discriminator loss real = 7.951249856723368e-19, disciminator loss fake = 6.582839606750213e-09, generator loss = 19.17015838623047\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 12, Batch: 60/468, discriminator loss real = 8.426023767604818e-12, disciminator loss fake = 7.452335637481156e-09, generator loss = 19.128082275390625\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 12, Batch: 61/468, discriminator loss real = 1.24786190808704e-16, disciminator loss fake = 7.82634490548162e-09, generator loss = 19.04238510131836\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 12, Batch: 62/468, discriminator loss real = 1.6003020306479265e-12, disciminator loss fake = 6.749544034789778e-09, generator loss = 19.399198532104492\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 12, Batch: 63/468, discriminator loss real = 1.5544020199676281e-15, disciminator loss fake = 8.156748165788485e-09, generator loss = 19.469425201416016\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 12, Batch: 64/468, discriminator loss real = 1.47282935901525e-15, disciminator loss fake = 8.166085585514793e-09, generator loss = 19.20707130432129\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 12, Batch: 65/468, discriminator loss real = 1.4891613333081755e-12, disciminator loss fake = 8.769287518362034e-09, generator loss = 19.086763381958008\n",
      "2/2 [==============================] - 0s 158ms/step\n",
      "Epoch: 12, Batch: 66/468, discriminator loss real = 2.470911808494236e-10, disciminator loss fake = 9.06483421658777e-09, generator loss = 19.086536407470703\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 12, Batch: 67/468, discriminator loss real = 5.673079736014108e-14, disciminator loss fake = 8.74042171972178e-09, generator loss = 19.266883850097656\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 12, Batch: 68/468, discriminator loss real = 7.722540597450422e-13, disciminator loss fake = 8.169818599412793e-09, generator loss = 19.35761260986328\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 12, Batch: 69/468, discriminator loss real = 1.2758931931811102e-11, disciminator loss fake = 7.91901832997155e-09, generator loss = 19.313335418701172\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 12, Batch: 70/468, discriminator loss real = 8.328296340969442e-16, disciminator loss fake = 5.6827129668590715e-09, generator loss = 19.219375610351562\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 12, Batch: 71/468, discriminator loss real = 5.325086725738171e-12, disciminator loss fake = 6.761872395344426e-09, generator loss = 19.19257354736328\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 12, Batch: 72/468, discriminator loss real = 2.1259861426869975e-08, disciminator loss fake = 7.12732095564661e-09, generator loss = 19.314891815185547\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 12, Batch: 73/468, discriminator loss real = 3.321894784479135e-19, disciminator loss fake = 7.773794941101642e-09, generator loss = 19.128822326660156\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 12, Batch: 74/468, discriminator loss real = 2.728265747001246e-12, disciminator loss fake = 6.303076283131759e-09, generator loss = 19.255773544311523\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 12, Batch: 75/468, discriminator loss real = 2.257685217501638e-15, disciminator loss fake = 7.304243432315616e-09, generator loss = 19.194686889648438\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 12, Batch: 76/468, discriminator loss real = 1.2491960635611238e-18, disciminator loss fake = 9.262103972673685e-09, generator loss = 19.164390563964844\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 12, Batch: 77/468, discriminator loss real = 6.793103424342334e-19, disciminator loss fake = 8.947221630251079e-09, generator loss = 19.382247924804688\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 12, Batch: 78/468, discriminator loss real = 1.265395564210587e-14, disciminator loss fake = 5.8061857544089435e-09, generator loss = 19.2209415435791\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 12, Batch: 79/468, discriminator loss real = 1.9496742329081428e-16, disciminator loss fake = 1.026840124040973e-08, generator loss = 19.30495834350586\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 12, Batch: 80/468, discriminator loss real = 1.8201690155095207e-09, disciminator loss fake = 8.264185780149091e-09, generator loss = 19.348588943481445\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 12, Batch: 81/468, discriminator loss real = 2.820041592656828e-20, disciminator loss fake = 8.407743834482062e-09, generator loss = 19.388731002807617\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 12, Batch: 82/468, discriminator loss real = 9.467145956065792e-10, disciminator loss fake = 7.279688851724586e-09, generator loss = 19.185060501098633\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 12, Batch: 83/468, discriminator loss real = 1.1517967829499653e-10, disciminator loss fake = 9.503932751897537e-09, generator loss = 19.403274536132812\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 12, Batch: 84/468, discriminator loss real = 5.675474237068708e-20, disciminator loss fake = 8.381277893931838e-09, generator loss = 19.373336791992188\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 12, Batch: 85/468, discriminator loss real = 3.0952839033190904e-13, disciminator loss fake = 7.843893534698054e-09, generator loss = 19.182985305786133\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 12, Batch: 86/468, discriminator loss real = 5.049380662533855e-15, disciminator loss fake = 6.801812446610711e-09, generator loss = 19.313058853149414\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 12, Batch: 87/468, discriminator loss real = 2.7038077497939192e-17, disciminator loss fake = 8.43849434772892e-09, generator loss = 19.308406829833984\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 12, Batch: 88/468, discriminator loss real = 1.9694930568684398e-14, disciminator loss fake = 7.66995889023292e-09, generator loss = 19.245765686035156\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 12, Batch: 89/468, discriminator loss real = 3.120960061224209e-17, disciminator loss fake = 5.9395981466536796e-09, generator loss = 19.32653045654297\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 12, Batch: 90/468, discriminator loss real = 2.941512589060835e-10, disciminator loss fake = 8.371781490268404e-09, generator loss = 19.284744262695312\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 12, Batch: 91/468, discriminator loss real = 3.270456171503011e-12, disciminator loss fake = 9.076931206664085e-09, generator loss = 19.355754852294922\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 12, Batch: 92/468, discriminator loss real = 1.8776348748375526e-16, disciminator loss fake = 8.796495087892708e-09, generator loss = 19.025611877441406\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 12, Batch: 93/468, discriminator loss real = 1.6317310458542622e-14, disciminator loss fake = 8.183795863203613e-09, generator loss = 19.30518341064453\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 12, Batch: 94/468, discriminator loss real = 3.7750509336088086e-15, disciminator loss fake = 9.18134901439771e-09, generator loss = 19.239124298095703\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 12, Batch: 95/468, discriminator loss real = 3.1712708817999398e-18, disciminator loss fake = 4.659860053379816e-09, generator loss = 19.358362197875977\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 12, Batch: 96/468, discriminator loss real = 9.046548781203363e-17, disciminator loss fake = 8.705581144852204e-09, generator loss = 19.451656341552734\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 12, Batch: 97/468, discriminator loss real = 6.580746147663574e-13, disciminator loss fake = 8.660312467156928e-09, generator loss = 19.06460952758789\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 12, Batch: 98/468, discriminator loss real = 1.4804516987321215e-11, disciminator loss fake = 6.887007408806767e-09, generator loss = 19.275318145751953\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 12, Batch: 99/468, discriminator loss real = 2.498343265563464e-16, disciminator loss fake = 6.893249526740419e-09, generator loss = 19.507043838500977\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 12, Batch: 100/468, discriminator loss real = 3.6843283686503053e-14, disciminator loss fake = 8.212559521325602e-09, generator loss = 19.03792953491211\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 12, Batch: 101/468, discriminator loss real = 9.59218748874946e-09, disciminator loss fake = 7.407170432571775e-09, generator loss = 19.250167846679688\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 12, Batch: 102/468, discriminator loss real = 3.91698369177812e-16, disciminator loss fake = 8.142656326981523e-09, generator loss = 19.353025436401367\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 12, Batch: 103/468, discriminator loss real = 1.1695038959881696e-15, disciminator loss fake = 5.948217918216869e-09, generator loss = 19.33229637145996\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 12, Batch: 104/468, discriminator loss real = 5.95296767033572e-16, disciminator loss fake = 5.786476631186588e-09, generator loss = 19.40447235107422\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 12, Batch: 105/468, discriminator loss real = 1.1357051671190774e-17, disciminator loss fake = 7.859520145814258e-09, generator loss = 19.402618408203125\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 12, Batch: 106/468, discriminator loss real = 4.658580921197697e-13, disciminator loss fake = 8.07525246671048e-09, generator loss = 19.39834976196289\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 12, Batch: 107/468, discriminator loss real = 2.834218828324988e-15, disciminator loss fake = 9.154650371101525e-09, generator loss = 19.25507164001465\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 12, Batch: 108/468, discriminator loss real = 2.935911817262216e-17, disciminator loss fake = 9.7636743134899e-09, generator loss = 19.281173706054688\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 12, Batch: 109/468, discriminator loss real = 3.9362440390489084e-11, disciminator loss fake = 7.665262202749545e-09, generator loss = 19.315940856933594\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 12, Batch: 110/468, discriminator loss real = 1.2932275421980582e-14, disciminator loss fake = 6.4354503948038655e-09, generator loss = 19.455726623535156\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 12, Batch: 111/468, discriminator loss real = 1.657395141269058e-12, disciminator loss fake = 7.467240159542143e-09, generator loss = 19.337936401367188\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 12, Batch: 112/468, discriminator loss real = 7.102371468725721e-11, disciminator loss fake = 7.328479156853973e-09, generator loss = 19.18183135986328\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 12, Batch: 113/468, discriminator loss real = 3.7921322847264335e-14, disciminator loss fake = 8.727739420066882e-09, generator loss = 19.224674224853516\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 12, Batch: 114/468, discriminator loss real = 1.5339821857196512e-08, disciminator loss fake = 5.5649298502657984e-09, generator loss = 19.45642852783203\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 12, Batch: 115/468, discriminator loss real = 7.818855155342086e-13, disciminator loss fake = 6.000607566392091e-09, generator loss = 19.36036491394043\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 12, Batch: 116/468, discriminator loss real = 5.3155357390319055e-17, disciminator loss fake = 6.882132641550243e-09, generator loss = 19.3712158203125\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 12, Batch: 117/468, discriminator loss real = 3.9771899196239247e-07, disciminator loss fake = 6.650640926864071e-09, generator loss = 19.238758087158203\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 12, Batch: 118/468, discriminator loss real = 4.786165685999322e-09, disciminator loss fake = 1.175325703428598e-08, generator loss = 19.239559173583984\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 12, Batch: 119/468, discriminator loss real = 1.945542565010114e-15, disciminator loss fake = 8.650694383049995e-09, generator loss = 19.165164947509766\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 12, Batch: 120/468, discriminator loss real = 1.3327517258202026e-12, disciminator loss fake = 1.1851786219096994e-08, generator loss = 19.24917221069336\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 12, Batch: 121/468, discriminator loss real = 5.567662419970164e-14, disciminator loss fake = 8.647122129445961e-09, generator loss = 19.123451232910156\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 12, Batch: 122/468, discriminator loss real = 6.825049965290819e-13, disciminator loss fake = 7.319806538674811e-09, generator loss = 19.18924331665039\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 12, Batch: 123/468, discriminator loss real = 1.6297913404050499e-15, disciminator loss fake = 7.4386550252825145e-09, generator loss = 19.071474075317383\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 12, Batch: 124/468, discriminator loss real = 8.592471623537073e-15, disciminator loss fake = 7.980789362704854e-09, generator loss = 19.152368545532227\n",
      "2/2 [==============================] - 0s 153ms/step\n",
      "Epoch: 12, Batch: 125/468, discriminator loss real = 3.409893081871701e-13, disciminator loss fake = 8.659840844416067e-09, generator loss = 19.114593505859375\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 12, Batch: 126/468, discriminator loss real = 8.3579673260853315e-19, disciminator loss fake = 7.601524742995025e-09, generator loss = 19.13365364074707\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 12, Batch: 127/468, discriminator loss real = 1.121138653513128e-14, disciminator loss fake = 8.226297865121524e-09, generator loss = 19.0341796875\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 12, Batch: 128/468, discriminator loss real = 3.678297814350188e-17, disciminator loss fake = 7.332617180111356e-09, generator loss = 19.160297393798828\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 12, Batch: 129/468, discriminator loss real = 3.7129355061924784e-17, disciminator loss fake = 7.2480554891285465e-09, generator loss = 19.07149887084961\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 12, Batch: 130/468, discriminator loss real = 3.2230962283873524e-14, disciminator loss fake = 7.71983277303434e-09, generator loss = 19.193805694580078\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 12, Batch: 131/468, discriminator loss real = 3.6448108975406512e-09, disciminator loss fake = 8.28856538959144e-09, generator loss = 19.032825469970703\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 12, Batch: 132/468, discriminator loss real = 7.952224478913195e-08, disciminator loss fake = 8.492734515641587e-09, generator loss = 19.1473445892334\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 12, Batch: 133/468, discriminator loss real = 1.6427816138669948e-12, disciminator loss fake = 1.0040237086172965e-08, generator loss = 19.127859115600586\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 12, Batch: 134/468, discriminator loss real = 1.3866852273652225e-13, disciminator loss fake = 8.834235565302606e-09, generator loss = 19.033390045166016\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 12, Batch: 135/468, discriminator loss real = 5.954319746677775e-14, disciminator loss fake = 9.416615043278398e-09, generator loss = 19.25166893005371\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 12, Batch: 136/468, discriminator loss real = 6.936296159737118e-16, disciminator loss fake = 1.1422534029748022e-08, generator loss = 19.220951080322266\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 12, Batch: 137/468, discriminator loss real = 5.708906111542928e-18, disciminator loss fake = 8.60672422220432e-09, generator loss = 19.23524284362793\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 12, Batch: 138/468, discriminator loss real = 1.2661674653354198e-14, disciminator loss fake = 6.4566734181426e-09, generator loss = 19.081369400024414\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 12, Batch: 139/468, discriminator loss real = 5.242161739416051e-12, disciminator loss fake = 9.710295678644343e-09, generator loss = 19.162168502807617\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 12, Batch: 140/468, discriminator loss real = 3.848671781270241e-08, disciminator loss fake = 8.275066853968838e-09, generator loss = 19.109088897705078\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 12, Batch: 141/468, discriminator loss real = 4.620314323157176e-16, disciminator loss fake = 7.56060813955628e-09, generator loss = 19.103015899658203\n",
      "2/2 [==============================] - 0s 181ms/step\n",
      "Epoch: 12, Batch: 142/468, discriminator loss real = 1.2559829952875183e-14, disciminator loss fake = 1.0907458936060266e-08, generator loss = 19.100343704223633\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 12, Batch: 143/468, discriminator loss real = 2.980337399094424e-07, disciminator loss fake = 7.853159900150786e-09, generator loss = 19.15691375732422\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 12, Batch: 144/468, discriminator loss real = 3.787993597042854e-15, disciminator loss fake = 1.2443059027589243e-08, generator loss = 19.102989196777344\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 12, Batch: 145/468, discriminator loss real = 2.0446133596418135e-14, disciminator loss fake = 8.21256662675296e-09, generator loss = 18.9688720703125\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 12, Batch: 146/468, discriminator loss real = 1.5188916790975782e-09, disciminator loss fake = 8.588470379322644e-09, generator loss = 19.10087013244629\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 12, Batch: 147/468, discriminator loss real = 1.9429349740819916e-15, disciminator loss fake = 1.2570684049251213e-08, generator loss = 19.26163101196289\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 12, Batch: 148/468, discriminator loss real = 5.434998978648409e-11, disciminator loss fake = 1.2585931408182205e-08, generator loss = 19.138866424560547\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 12, Batch: 149/468, discriminator loss real = 8.243172854374703e-13, disciminator loss fake = 9.5680778855467e-09, generator loss = 19.101913452148438\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 12, Batch: 150/468, discriminator loss real = 4.001788948094576e-15, disciminator loss fake = 8.630290260214224e-09, generator loss = 18.960548400878906\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 12, Batch: 151/468, discriminator loss real = 2.37919855241149e-16, disciminator loss fake = 1.0512282599961509e-08, generator loss = 18.901351928710938\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 12, Batch: 152/468, discriminator loss real = 3.4879492957079483e-12, disciminator loss fake = 8.534767559353895e-09, generator loss = 19.15550994873047\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 12, Batch: 153/468, discriminator loss real = 2.7285701367611714e-13, disciminator loss fake = 1.029961804732693e-08, generator loss = 18.92572021484375\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 12, Batch: 154/468, discriminator loss real = 3.149114332104824e-19, disciminator loss fake = 1.0593776522682674e-08, generator loss = 19.144269943237305\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 12, Batch: 155/468, discriminator loss real = 6.445895656429987e-14, disciminator loss fake = 7.357735753998895e-09, generator loss = 19.056283950805664\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 12, Batch: 156/468, discriminator loss real = 1.552777817350609e-13, disciminator loss fake = 7.949411795493688e-09, generator loss = 19.044414520263672\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 12, Batch: 157/468, discriminator loss real = 2.3486254937503872e-17, disciminator loss fake = 8.950219232417567e-09, generator loss = 18.992385864257812\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 12, Batch: 158/468, discriminator loss real = 4.5083629711353105e-17, disciminator loss fake = 8.686086516718206e-09, generator loss = 19.036529541015625\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 12, Batch: 159/468, discriminator loss real = 1.587113585357642e-15, disciminator loss fake = 1.313551312165373e-08, generator loss = 18.99823760986328\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 12, Batch: 160/468, discriminator loss real = 1.860041543011448e-08, disciminator loss fake = 1.0309261888608034e-08, generator loss = 19.003887176513672\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 12, Batch: 161/468, discriminator loss real = 9.811623349876929e-17, disciminator loss fake = 1.307420305352025e-08, generator loss = 19.144058227539062\n",
      "2/2 [==============================] - 0s 158ms/step\n",
      "Epoch: 12, Batch: 162/468, discriminator loss real = 9.226610586665629e-09, disciminator loss fake = 1.275174987824812e-08, generator loss = 18.99698257446289\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 12, Batch: 163/468, discriminator loss real = 5.641338785000727e-11, disciminator loss fake = 1.207781252787754e-08, generator loss = 19.292043685913086\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 12, Batch: 164/468, discriminator loss real = 1.9455073402979695e-12, disciminator loss fake = 1.2136771587734074e-08, generator loss = 18.960887908935547\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 12, Batch: 165/468, discriminator loss real = 6.985378225019597e-15, disciminator loss fake = 1.1683876977031105e-08, generator loss = 19.001754760742188\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 12, Batch: 166/468, discriminator loss real = 2.2895601430386603e-13, disciminator loss fake = 8.928537909014267e-09, generator loss = 19.154010772705078\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 12, Batch: 167/468, discriminator loss real = 3.462361984570975e-17, disciminator loss fake = 1.0131681271730031e-08, generator loss = 19.153322219848633\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 12, Batch: 168/468, discriminator loss real = 4.698112626472413e-14, disciminator loss fake = 9.13624198517482e-09, generator loss = 19.112083435058594\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 12, Batch: 169/468, discriminator loss real = 7.402545915656533e-13, disciminator loss fake = 6.483667824852546e-09, generator loss = 19.221187591552734\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 12, Batch: 170/468, discriminator loss real = 1.0357200579925874e-16, disciminator loss fake = 1.1266740429505262e-08, generator loss = 19.214061737060547\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 12, Batch: 171/468, discriminator loss real = 3.7687083508997684e-15, disciminator loss fake = 1.0122456650663025e-08, generator loss = 19.10564422607422\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 12, Batch: 172/468, discriminator loss real = 2.7835211913185276e-10, disciminator loss fake = 9.271284184819706e-09, generator loss = 18.813365936279297\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 12, Batch: 173/468, discriminator loss real = 3.017041894093353e-10, disciminator loss fake = 1.1278334710596027e-08, generator loss = 19.114898681640625\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 12, Batch: 174/468, discriminator loss real = 3.482189376798929e-14, disciminator loss fake = 7.514548094889051e-09, generator loss = 19.156166076660156\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 12, Batch: 175/468, discriminator loss real = 2.3375800850544692e-08, disciminator loss fake = 1.0297710240081415e-08, generator loss = 19.055978775024414\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 12, Batch: 176/468, discriminator loss real = 2.7331538018215855e-17, disciminator loss fake = 7.756199238428962e-09, generator loss = 19.094898223876953\n",
      "2/2 [==============================] - 0s 161ms/step\n",
      "Epoch: 12, Batch: 177/468, discriminator loss real = 7.165427806654634e-09, disciminator loss fake = 9.108351406439397e-09, generator loss = 18.99134063720703\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 12, Batch: 178/468, discriminator loss real = 2.2872689527976553e-13, disciminator loss fake = 7.954934488907384e-09, generator loss = 19.105262756347656\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 12, Batch: 179/468, discriminator loss real = 3.7040664047256755e-13, disciminator loss fake = 1.112928948998615e-08, generator loss = 19.1461238861084\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Epoch: 12, Batch: 180/468, discriminator loss real = 6.988923328954399e-13, disciminator loss fake = 8.580271604330392e-09, generator loss = 19.055255889892578\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 12, Batch: 181/468, discriminator loss real = 8.916684279824949e-09, disciminator loss fake = 8.72789662764717e-09, generator loss = 19.124656677246094\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 12, Batch: 182/468, discriminator loss real = 2.812724921644855e-20, disciminator loss fake = 9.128848788009236e-09, generator loss = 19.017990112304688\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 12, Batch: 183/468, discriminator loss real = 3.649376739927983e-14, disciminator loss fake = 1.0467193334307012e-08, generator loss = 19.04514503479004\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 12, Batch: 184/468, discriminator loss real = 1.9580421539797804e-13, disciminator loss fake = 9.555955138296213e-09, generator loss = 19.07674789428711\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 12, Batch: 185/468, discriminator loss real = 3.073216797689314e-15, disciminator loss fake = 9.312683957318768e-09, generator loss = 19.063072204589844\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 12, Batch: 186/468, discriminator loss real = 2.2529480586891762e-14, disciminator loss fake = 9.107670173591487e-09, generator loss = 19.1239070892334\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 12, Batch: 187/468, discriminator loss real = 1.6685663977654285e-17, disciminator loss fake = 9.283107615942754e-09, generator loss = 19.093158721923828\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 12, Batch: 188/468, discriminator loss real = 2.3546474083144427e-15, disciminator loss fake = 1.0366807856598825e-08, generator loss = 19.13167953491211\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 12, Batch: 189/468, discriminator loss real = 3.8716436724728226e-17, disciminator loss fake = 7.75765940375095e-09, generator loss = 19.09459686279297\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 12, Batch: 190/468, discriminator loss real = 1.2917614894414342e-11, disciminator loss fake = 9.271348133665924e-09, generator loss = 19.194683074951172\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 12, Batch: 191/468, discriminator loss real = 5.631294042185431e-11, disciminator loss fake = 7.610755581310968e-09, generator loss = 19.171396255493164\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 12, Batch: 192/468, discriminator loss real = 5.984568851764849e-13, disciminator loss fake = 5.869187802431952e-09, generator loss = 19.222152709960938\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 12, Batch: 193/468, discriminator loss real = 1.9647200262106618e-13, disciminator loss fake = 7.990283101833029e-09, generator loss = 19.136566162109375\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 12, Batch: 194/468, discriminator loss real = 1.7775333681639867e-14, disciminator loss fake = 6.172479416477472e-09, generator loss = 18.925010681152344\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 12, Batch: 195/468, discriminator loss real = 2.286354699315707e-14, disciminator loss fake = 7.724143102905145e-09, generator loss = 18.89773178100586\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 12, Batch: 196/468, discriminator loss real = 4.7327888379651605e-20, disciminator loss fake = 9.254579325101986e-09, generator loss = 19.18916130065918\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 12, Batch: 197/468, discriminator loss real = 1.6858960245631077e-13, disciminator loss fake = 7.171102822667308e-09, generator loss = 19.19454574584961\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 12, Batch: 198/468, discriminator loss real = 1.4216747779016714e-09, disciminator loss fake = 7.910363919449992e-09, generator loss = 19.021648406982422\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 12, Batch: 199/468, discriminator loss real = 2.0470365853786365e-12, disciminator loss fake = 7.57988960486955e-09, generator loss = 19.13915252685547\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 12, Batch: 200/468, discriminator loss real = 3.1698663291198247e-18, disciminator loss fake = 1.0013991413870826e-08, generator loss = 19.216819763183594\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 12, Batch: 201/468, discriminator loss real = 2.1302229457394878e-13, disciminator loss fake = 7.467138907202298e-09, generator loss = 19.26227569580078\n",
      "2/2 [==============================] - 0s 136ms/step\n",
      "Epoch: 12, Batch: 202/468, discriminator loss real = 1.5064120977915148e-16, disciminator loss fake = 1.1488626050493167e-08, generator loss = 19.232519149780273\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 12, Batch: 203/468, discriminator loss real = 2.819896687033044e-14, disciminator loss fake = 8.172666099426351e-09, generator loss = 19.124481201171875\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 12, Batch: 204/468, discriminator loss real = 6.676915422464125e-14, disciminator loss fake = 8.052165156868796e-09, generator loss = 18.974681854248047\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 12, Batch: 205/468, discriminator loss real = 1.122956894437704e-14, disciminator loss fake = 8.849602828320258e-09, generator loss = 19.351627349853516\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 12, Batch: 206/468, discriminator loss real = 9.645458260224005e-14, disciminator loss fake = 8.068550272355424e-09, generator loss = 19.131736755371094\n",
      "2/2 [==============================] - 0s 187ms/step\n",
      "Epoch: 12, Batch: 207/468, discriminator loss real = 8.363038460228164e-19, disciminator loss fake = 9.03151242681588e-09, generator loss = 19.274126052856445\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 12, Batch: 208/468, discriminator loss real = 5.389628188190443e-10, disciminator loss fake = 6.804381502689694e-09, generator loss = 19.19611358642578\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 12, Batch: 209/468, discriminator loss real = 1.4531135587458853e-18, disciminator loss fake = 7.201200080686476e-09, generator loss = 19.17150115966797\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 12, Batch: 210/468, discriminator loss real = 9.68956817857863e-15, disciminator loss fake = 1.1626687168586614e-08, generator loss = 19.34181022644043\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 12, Batch: 211/468, discriminator loss real = 8.174884380540703e-17, disciminator loss fake = 7.286456771282701e-09, generator loss = 19.07942008972168\n",
      "2/2 [==============================] - 0s 146ms/step\n",
      "Epoch: 12, Batch: 212/468, discriminator loss real = 1.4037087176622205e-15, disciminator loss fake = 6.215176817647716e-09, generator loss = 18.976085662841797\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 12, Batch: 213/468, discriminator loss real = 1.551392231491806e-18, disciminator loss fake = 8.069642731811655e-09, generator loss = 19.187835693359375\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 12, Batch: 214/468, discriminator loss real = 1.546393508739796e-16, disciminator loss fake = 8.581151789144315e-09, generator loss = 18.95393943786621\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 12, Batch: 215/468, discriminator loss real = 2.1779833145330052e-11, disciminator loss fake = 7.415581038117125e-09, generator loss = 19.242753982543945\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 12, Batch: 216/468, discriminator loss real = 2.3409358083708795e-14, disciminator loss fake = 9.577648896197388e-09, generator loss = 19.113752365112305\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 12, Batch: 217/468, discriminator loss real = 6.800618734814634e-07, disciminator loss fake = 8.252319716461898e-09, generator loss = 19.010902404785156\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 12, Batch: 218/468, discriminator loss real = 1.8616044036162682e-12, disciminator loss fake = 9.343917639625943e-09, generator loss = 18.999393463134766\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 12, Batch: 219/468, discriminator loss real = 4.512843549374368e-13, disciminator loss fake = 8.093274495024616e-09, generator loss = 19.08325958251953\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 12, Batch: 220/468, discriminator loss real = 7.66240827162817e-16, disciminator loss fake = 9.660471533834425e-09, generator loss = 19.16219711303711\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 12, Batch: 221/468, discriminator loss real = 2.0330188921224845e-11, disciminator loss fake = 1.0624070512221806e-08, generator loss = 19.073543548583984\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 12, Batch: 222/468, discriminator loss real = 4.249925608866388e-16, disciminator loss fake = 1.1006179079231515e-08, generator loss = 18.881572723388672\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 12, Batch: 223/468, discriminator loss real = 2.2023570071890136e-18, disciminator loss fake = 9.799684619338223e-09, generator loss = 18.881614685058594\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 12, Batch: 224/468, discriminator loss real = 1.8420803619446924e-13, disciminator loss fake = 1.2954139094745187e-08, generator loss = 18.97451400756836\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 12, Batch: 225/468, discriminator loss real = 1.4935280318320624e-17, disciminator loss fake = 1.0613051770747006e-08, generator loss = 19.072681427001953\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 12, Batch: 226/468, discriminator loss real = 2.1224470477584217e-14, disciminator loss fake = 1.1370979713376528e-08, generator loss = 19.031333923339844\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 12, Batch: 227/468, discriminator loss real = 2.3943402920476203e-17, disciminator loss fake = 1.3115887043113617e-08, generator loss = 18.87645721435547\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 12, Batch: 228/468, discriminator loss real = 1.1641428793174313e-10, disciminator loss fake = 1.5541875342250933e-08, generator loss = 18.969100952148438\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 12, Batch: 229/468, discriminator loss real = 1.415720412477895e-16, disciminator loss fake = 8.131781470410715e-09, generator loss = 18.790943145751953\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 12, Batch: 230/468, discriminator loss real = 7.665756223118933e-19, disciminator loss fake = 8.641878324056051e-09, generator loss = 19.057462692260742\n",
      "2/2 [==============================] - 0s 145ms/step\n",
      "Epoch: 12, Batch: 231/468, discriminator loss real = 2.965357820405856e-11, disciminator loss fake = 1.135426952458829e-08, generator loss = 18.9693603515625\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 12, Batch: 232/468, discriminator loss real = 1.600825548508933e-11, disciminator loss fake = 1.2195069842846351e-08, generator loss = 19.002120971679688\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 12, Batch: 233/468, discriminator loss real = 4.397710027977357e-17, disciminator loss fake = 1.0784874326930094e-08, generator loss = 19.041650772094727\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 12, Batch: 234/468, discriminator loss real = 8.042341749156523e-13, disciminator loss fake = 1.2195682685955944e-08, generator loss = 18.74022674560547\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 12, Batch: 235/468, discriminator loss real = 3.157565083965891e-13, disciminator loss fake = 1.1050480530627738e-08, generator loss = 18.859222412109375\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 12, Batch: 236/468, discriminator loss real = 2.8090476643823564e-18, disciminator loss fake = 1.0429667796074682e-08, generator loss = 18.921127319335938\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 12, Batch: 237/468, discriminator loss real = 4.290340462455647e-15, disciminator loss fake = 1.1217327511303665e-08, generator loss = 19.009719848632812\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 12, Batch: 238/468, discriminator loss real = 2.8265265562127384e-12, disciminator loss fake = 1.5305936074128113e-08, generator loss = 18.83856773376465\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 12, Batch: 239/468, discriminator loss real = 3.4631992369346665e-13, disciminator loss fake = 1.5599145086753197e-08, generator loss = 19.089584350585938\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 12, Batch: 240/468, discriminator loss real = 2.293632677449059e-13, disciminator loss fake = 8.028981923757783e-09, generator loss = 18.861534118652344\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 12, Batch: 241/468, discriminator loss real = 1.0683544326983707e-11, disciminator loss fake = 1.1625061802078562e-08, generator loss = 18.913867950439453\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 12, Batch: 242/468, discriminator loss real = 1.589060808741249e-20, disciminator loss fake = 6.397534502156077e-09, generator loss = 19.02384376525879\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 12, Batch: 243/468, discriminator loss real = 2.2471902810794475e-12, disciminator loss fake = 9.613218665549539e-09, generator loss = 18.979904174804688\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 12, Batch: 244/468, discriminator loss real = 3.176444107744203e-10, disciminator loss fake = 1.842036567722971e-08, generator loss = 18.977436065673828\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 12, Batch: 245/468, discriminator loss real = 1.3592899922708498e-15, disciminator loss fake = 1.0458606425345351e-08, generator loss = 19.074800491333008\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 12, Batch: 246/468, discriminator loss real = 5.706317393567662e-15, disciminator loss fake = 1.1010835798686003e-08, generator loss = 19.065032958984375\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 12, Batch: 247/468, discriminator loss real = 2.0503843645180465e-14, disciminator loss fake = 1.097950974582318e-08, generator loss = 18.972328186035156\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 12, Batch: 248/468, discriminator loss real = 2.6998447274791777e-17, disciminator loss fake = 1.4308453089029172e-08, generator loss = 18.993497848510742\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 12, Batch: 249/468, discriminator loss real = 3.28685341476672e-14, disciminator loss fake = 1.0203200062619544e-08, generator loss = 19.093902587890625\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 12, Batch: 250/468, discriminator loss real = 2.427787273941753e-16, disciminator loss fake = 1.063886578833717e-08, generator loss = 19.107023239135742\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 12, Batch: 251/468, discriminator loss real = 1.7438115296371237e-13, disciminator loss fake = 1.354386025553822e-08, generator loss = 18.86577606201172\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 12, Batch: 252/468, discriminator loss real = 1.8243980070696726e-15, disciminator loss fake = 1.0785617732267383e-08, generator loss = 18.97161102294922\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 12, Batch: 253/468, discriminator loss real = 3.5362871485256075e-12, disciminator loss fake = 9.837641812282527e-09, generator loss = 19.07168960571289\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 12, Batch: 254/468, discriminator loss real = 1.3687333773113307e-16, disciminator loss fake = 9.057069760842751e-09, generator loss = 19.104164123535156\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 12, Batch: 255/468, discriminator loss real = 2.3325463088808007e-11, disciminator loss fake = 9.682704416036358e-09, generator loss = 18.968626022338867\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 12, Batch: 256/468, discriminator loss real = 2.3688245375658168e-14, disciminator loss fake = 7.717795291739549e-09, generator loss = 18.969484329223633\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 12, Batch: 257/468, discriminator loss real = 2.3425341666438726e-08, disciminator loss fake = 1.2400990456740146e-08, generator loss = 18.99740982055664\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 12, Batch: 258/468, discriminator loss real = 1.1080981630676303e-16, disciminator loss fake = 1.1759823337342823e-08, generator loss = 19.0935001373291\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 12, Batch: 259/468, discriminator loss real = 1.1803040766977801e-09, disciminator loss fake = 9.397776778996558e-09, generator loss = 19.222972869873047\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 12, Batch: 260/468, discriminator loss real = 1.8449092275247907e-17, disciminator loss fake = 9.85362547112345e-09, generator loss = 19.105350494384766\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 12, Batch: 261/468, discriminator loss real = 1.2311389175842444e-19, disciminator loss fake = 7.392961354213412e-09, generator loss = 19.106416702270508\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 12, Batch: 262/468, discriminator loss real = 3.6371892540120176e-17, disciminator loss fake = 9.336289075179138e-09, generator loss = 19.015230178833008\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 12, Batch: 263/468, discriminator loss real = 6.103269431661259e-19, disciminator loss fake = 8.999304412782294e-09, generator loss = 19.080406188964844\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 12, Batch: 264/468, discriminator loss real = 4.571182458293099e-18, disciminator loss fake = 7.914421118471182e-09, generator loss = 19.045228958129883\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 12, Batch: 265/468, discriminator loss real = 1.2765863019459367e-11, disciminator loss fake = 1.282407779967798e-08, generator loss = 19.210779190063477\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 12, Batch: 266/468, discriminator loss real = 7.628021277550029e-19, disciminator loss fake = 9.294279124105742e-09, generator loss = 18.910877227783203\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 12, Batch: 267/468, discriminator loss real = 9.775603009097144e-16, disciminator loss fake = 8.608232349160971e-09, generator loss = 19.102092742919922\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 12, Batch: 268/468, discriminator loss real = 4.035244631928753e-15, disciminator loss fake = 1.4873017484262618e-08, generator loss = 19.06887435913086\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "Epoch: 12, Batch: 269/468, discriminator loss real = 2.6206294911901296e-09, disciminator loss fake = 9.025207248214429e-09, generator loss = 19.310571670532227\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 12, Batch: 270/468, discriminator loss real = 5.33898866686253e-19, disciminator loss fake = 7.60915064290657e-09, generator loss = 19.211875915527344\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 12, Batch: 271/468, discriminator loss real = 1.9558100866384938e-15, disciminator loss fake = 1.2080280775705887e-08, generator loss = 19.03571319580078\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 12, Batch: 272/468, discriminator loss real = 5.5946160247913324e-14, disciminator loss fake = 8.770529191792775e-09, generator loss = 19.19751739501953\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 12, Batch: 273/468, discriminator loss real = 1.3924879044974192e-12, disciminator loss fake = 1.168261576367513e-08, generator loss = 19.141117095947266\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 12, Batch: 274/468, discriminator loss real = 2.716903579284141e-13, disciminator loss fake = 1.278631245327233e-08, generator loss = 19.18278694152832\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 12, Batch: 275/468, discriminator loss real = 3.220799627001725e-08, disciminator loss fake = 1.1358360474389428e-08, generator loss = 19.268260955810547\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 12, Batch: 276/468, discriminator loss real = 2.1782484146458493e-18, disciminator loss fake = 7.861519435437003e-09, generator loss = 19.059280395507812\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 12, Batch: 277/468, discriminator loss real = 1.532267877768126e-17, disciminator loss fake = 9.912676901535633e-09, generator loss = 19.11865997314453\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 12, Batch: 278/468, discriminator loss real = 1.5700721824313919e-16, disciminator loss fake = 1.1177340830670346e-08, generator loss = 19.00943374633789\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 12, Batch: 279/468, discriminator loss real = 1.738012552887471e-18, disciminator loss fake = 8.899656123162458e-09, generator loss = 19.017887115478516\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 12, Batch: 280/468, discriminator loss real = 5.78549062855615e-18, disciminator loss fake = 1.0737478461919636e-08, generator loss = 19.053428649902344\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 12, Batch: 281/468, discriminator loss real = 1.1751796520094839e-15, disciminator loss fake = 9.759730801306432e-09, generator loss = 19.179241180419922\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 12, Batch: 282/468, discriminator loss real = 1.7690043221028422e-17, disciminator loss fake = 8.085400793333974e-09, generator loss = 19.09364128112793\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 12, Batch: 283/468, discriminator loss real = 7.963806946458484e-16, disciminator loss fake = 1.1927525633836922e-08, generator loss = 19.32954216003418\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 12, Batch: 284/468, discriminator loss real = 3.794011117623496e-18, disciminator loss fake = 1.2343027044892096e-08, generator loss = 19.011869430541992\n",
      "2/2 [==============================] - 0s 136ms/step\n",
      "Epoch: 12, Batch: 285/468, discriminator loss real = 2.344923628898641e-16, disciminator loss fake = 1.0492867019706864e-08, generator loss = 19.20960235595703\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 12, Batch: 286/468, discriminator loss real = 1.3793565001627343e-19, disciminator loss fake = 9.700457326289325e-09, generator loss = 19.053300857543945\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 12, Batch: 287/468, discriminator loss real = 5.618673928897699e-13, disciminator loss fake = 7.823492964575962e-09, generator loss = 19.061614990234375\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 12, Batch: 288/468, discriminator loss real = 2.947135036013293e-10, disciminator loss fake = 9.897127561941943e-09, generator loss = 19.129249572753906\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 12, Batch: 289/468, discriminator loss real = 2.239177268083259e-13, disciminator loss fake = 8.4583398063387e-09, generator loss = 19.166061401367188\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 12, Batch: 290/468, discriminator loss real = 2.667778498111062e-11, disciminator loss fake = 1.3127499087772776e-08, generator loss = 19.151912689208984\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 12, Batch: 291/468, discriminator loss real = 4.966806826933734e-11, disciminator loss fake = 8.576829024775634e-09, generator loss = 19.135923385620117\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 12, Batch: 292/468, discriminator loss real = 7.62810682539616e-15, disciminator loss fake = 8.097119419403498e-09, generator loss = 19.206275939941406\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 12, Batch: 293/468, discriminator loss real = 3.072123176510455e-13, disciminator loss fake = 1.1911245323403818e-08, generator loss = 19.15886688232422\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 12, Batch: 294/468, discriminator loss real = 1.9533814737721263e-14, disciminator loss fake = 9.879697060455328e-09, generator loss = 19.383525848388672\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 12, Batch: 295/468, discriminator loss real = 8.020950033717569e-14, disciminator loss fake = 1.0308776055012459e-08, generator loss = 19.179553985595703\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 12, Batch: 296/468, discriminator loss real = 1.0186375872032853e-14, disciminator loss fake = 8.05395750091975e-09, generator loss = 19.038251876831055\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 12, Batch: 297/468, discriminator loss real = 1.4037187550026455e-14, disciminator loss fake = 9.840403158989375e-09, generator loss = 19.218687057495117\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 12, Batch: 298/468, discriminator loss real = 1.1767063018419677e-14, disciminator loss fake = 8.616838798047866e-09, generator loss = 19.117664337158203\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 12, Batch: 299/468, discriminator loss real = 8.463080063136896e-12, disciminator loss fake = 8.392611050567211e-09, generator loss = 19.303585052490234\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 12, Batch: 300/468, discriminator loss real = 7.858593013613087e-17, disciminator loss fake = 1.310509389895742e-08, generator loss = 19.276329040527344\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 12, Batch: 301/468, discriminator loss real = 2.7771413640964582e-11, disciminator loss fake = 9.15964193382024e-09, generator loss = 19.127239227294922\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 12, Batch: 302/468, discriminator loss real = 6.293335684091244e-17, disciminator loss fake = 9.22562826133344e-09, generator loss = 19.339073181152344\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 12, Batch: 303/468, discriminator loss real = 1.6303558503238946e-09, disciminator loss fake = 7.839558335831498e-09, generator loss = 19.154809951782227\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 12, Batch: 304/468, discriminator loss real = 3.65179501221613e-12, disciminator loss fake = 6.80516132334219e-09, generator loss = 19.111406326293945\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 12, Batch: 305/468, discriminator loss real = 1.3655501425804961e-12, disciminator loss fake = 7.333831320011086e-09, generator loss = 19.346294403076172\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 12, Batch: 306/468, discriminator loss real = 3.344605942231355e-16, disciminator loss fake = 8.2046875959918e-09, generator loss = 19.213809967041016\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 12, Batch: 307/468, discriminator loss real = 9.192239771620083e-16, disciminator loss fake = 1.0652045467907101e-08, generator loss = 19.116043090820312\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 12, Batch: 308/468, discriminator loss real = 3.655643852001423e-15, disciminator loss fake = 1.0618647294791117e-08, generator loss = 19.280548095703125\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 12, Batch: 309/468, discriminator loss real = 3.366927113276078e-16, disciminator loss fake = 9.356989849607089e-09, generator loss = 19.327226638793945\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 12, Batch: 310/468, discriminator loss real = 1.5752651190848593e-14, disciminator loss fake = 7.89108867138566e-09, generator loss = 19.203567504882812\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 12, Batch: 311/468, discriminator loss real = 2.2231058140198545e-12, disciminator loss fake = 7.496711695864633e-09, generator loss = 19.326522827148438\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 12, Batch: 312/468, discriminator loss real = 3.5015607492520917e-13, disciminator loss fake = 9.622979746382043e-09, generator loss = 19.276792526245117\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 12, Batch: 313/468, discriminator loss real = 1.1051862279076036e-14, disciminator loss fake = 9.16873332812429e-09, generator loss = 19.17542266845703\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 12, Batch: 314/468, discriminator loss real = 3.309689233788049e-08, disciminator loss fake = 9.871393480409552e-09, generator loss = 19.110023498535156\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 12, Batch: 315/468, discriminator loss real = 5.270004740266782e-17, disciminator loss fake = 8.301133114230197e-09, generator loss = 18.99268913269043\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 12, Batch: 316/468, discriminator loss real = 9.756690897907982e-13, disciminator loss fake = 6.510516570301661e-09, generator loss = 19.36904525756836\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 12, Batch: 317/468, discriminator loss real = 8.039814473892459e-13, disciminator loss fake = 9.079793805710779e-09, generator loss = 19.331317901611328\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 12, Batch: 318/468, discriminator loss real = 9.093993055342767e-15, disciminator loss fake = 7.160105397474581e-09, generator loss = 19.224607467651367\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 12, Batch: 319/468, discriminator loss real = 1.4463393815944414e-09, disciminator loss fake = 8.778025417655044e-09, generator loss = 19.43381690979004\n",
      "2/2 [==============================] - 0s 156ms/step\n",
      "Epoch: 12, Batch: 320/468, discriminator loss real = 3.0078046783376007e-15, disciminator loss fake = 9.878865725454489e-09, generator loss = 19.318449020385742\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 12, Batch: 321/468, discriminator loss real = 4.990118984693481e-09, disciminator loss fake = 7.984628069834798e-09, generator loss = 19.174087524414062\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 12, Batch: 322/468, discriminator loss real = 1.9756262598091823e-12, disciminator loss fake = 5.186498341913648e-09, generator loss = 19.147457122802734\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 12, Batch: 323/468, discriminator loss real = 2.6645563533378436e-10, disciminator loss fake = 7.93847654279034e-09, generator loss = 19.0450496673584\n",
      "2/2 [==============================] - 0s 157ms/step\n",
      "Epoch: 12, Batch: 324/468, discriminator loss real = 1.569122711437079e-16, disciminator loss fake = 7.408683444509734e-09, generator loss = 19.16928482055664\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 12, Batch: 325/468, discriminator loss real = 1.508863133208183e-17, disciminator loss fake = 5.620137244477519e-09, generator loss = 19.117679595947266\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 12, Batch: 326/468, discriminator loss real = 1.9538466844437608e-08, disciminator loss fake = 1.0706563635665134e-08, generator loss = 19.24386215209961\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 12, Batch: 327/468, discriminator loss real = 3.3449260776720253e-18, disciminator loss fake = 6.334455182610554e-09, generator loss = 19.00299835205078\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 12, Batch: 328/468, discriminator loss real = 5.625854599886071e-14, disciminator loss fake = 7.842588800599515e-09, generator loss = 19.383819580078125\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 12, Batch: 329/468, discriminator loss real = 1.767005440152608e-18, disciminator loss fake = 8.736165568734577e-09, generator loss = 19.244741439819336\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 12, Batch: 330/468, discriminator loss real = 9.925619489726048e-14, disciminator loss fake = 9.886234053624321e-09, generator loss = 19.22937774658203\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 12, Batch: 331/468, discriminator loss real = 1.925015702397559e-09, disciminator loss fake = 9.307972170802259e-09, generator loss = 19.205322265625\n",
      "2/2 [==============================] - 0s 159ms/step\n",
      "Epoch: 12, Batch: 332/468, discriminator loss real = 3.38902869526439e-13, disciminator loss fake = 1.0704711783660059e-08, generator loss = 19.302398681640625\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 12, Batch: 333/468, discriminator loss real = 1.6863600649230648e-07, disciminator loss fake = 8.281413776956015e-09, generator loss = 19.372493743896484\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 12, Batch: 334/468, discriminator loss real = 2.4076272942270596e-17, disciminator loss fake = 6.6896403971838936e-09, generator loss = 19.34036636352539\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 12, Batch: 335/468, discriminator loss real = 1.5389947586635909e-18, disciminator loss fake = 1.0427347874042425e-08, generator loss = 19.053295135498047\n",
      "2/2 [==============================] - 0s 144ms/step\n",
      "Epoch: 12, Batch: 336/468, discriminator loss real = 2.821741538344691e-12, disciminator loss fake = 6.889489423400619e-09, generator loss = 19.403715133666992\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 12, Batch: 337/468, discriminator loss real = 5.6623820487034654e-14, disciminator loss fake = 5.351641796380591e-09, generator loss = 19.157669067382812\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 12, Batch: 338/468, discriminator loss real = 3.7814098519106665e-09, disciminator loss fake = 8.409580587454002e-09, generator loss = 19.28528594970703\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 12, Batch: 339/468, discriminator loss real = 5.063629637119815e-13, disciminator loss fake = 6.511855499269359e-09, generator loss = 19.2409610748291\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 12, Batch: 340/468, discriminator loss real = 8.781237998030378e-14, disciminator loss fake = 1.1354211792991009e-08, generator loss = 19.158445358276367\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 12, Batch: 341/468, discriminator loss real = 2.2369591683152725e-15, disciminator loss fake = 7.78129383149917e-09, generator loss = 19.177749633789062\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 12, Batch: 342/468, discriminator loss real = 1.8305773563653815e-11, disciminator loss fake = 8.173623555762788e-09, generator loss = 19.01337432861328\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 12, Batch: 343/468, discriminator loss real = 1.969579242470823e-16, disciminator loss fake = 6.781322170468229e-09, generator loss = 19.333219528198242\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 12, Batch: 344/468, discriminator loss real = 1.887724592338903e-18, disciminator loss fake = 9.590489291610993e-09, generator loss = 19.13173484802246\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 12, Batch: 345/468, discriminator loss real = 1.857190543515488e-17, disciminator loss fake = 1.192421361650986e-08, generator loss = 19.2010440826416\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 12, Batch: 346/468, discriminator loss real = 4.968316882035528e-13, disciminator loss fake = 9.039612614003545e-09, generator loss = 19.128339767456055\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 12, Batch: 347/468, discriminator loss real = 1.4957006716064675e-13, disciminator loss fake = 8.127626571763358e-09, generator loss = 19.35938262939453\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 12, Batch: 348/468, discriminator loss real = 2.547648778137429e-13, disciminator loss fake = 7.885335051582842e-09, generator loss = 19.458206176757812\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 12, Batch: 349/468, discriminator loss real = 1.4554805360687058e-15, disciminator loss fake = 1.3645486518498728e-08, generator loss = 19.129867553710938\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 12, Batch: 350/468, discriminator loss real = 7.16913524666284e-15, disciminator loss fake = 6.883445813343769e-09, generator loss = 19.205759048461914\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 12, Batch: 351/468, discriminator loss real = 6.8795003771622305e-15, disciminator loss fake = 8.858146216539353e-09, generator loss = 19.308609008789062\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 12, Batch: 352/468, discriminator loss real = 9.29734345067601e-10, disciminator loss fake = 7.365821286242635e-09, generator loss = 19.141260147094727\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 12, Batch: 353/468, discriminator loss real = 3.903067972987895e-12, disciminator loss fake = 9.283551705152604e-09, generator loss = 19.13865089416504\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 12, Batch: 354/468, discriminator loss real = 6.001328600735434e-11, disciminator loss fake = 8.145407015547335e-09, generator loss = 19.1340274810791\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 12, Batch: 355/468, discriminator loss real = 7.886299946413544e-11, disciminator loss fake = 9.173982462584718e-09, generator loss = 18.99979591369629\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 12, Batch: 356/468, discriminator loss real = 2.2332492910612407e-14, disciminator loss fake = 6.483994230421786e-09, generator loss = 19.151430130004883\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 12, Batch: 357/468, discriminator loss real = 7.697791087766249e-17, disciminator loss fake = 7.821737035840215e-09, generator loss = 19.373207092285156\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 12, Batch: 358/468, discriminator loss real = 2.1120640501283428e-13, disciminator loss fake = 9.115012744587148e-09, generator loss = 19.153724670410156\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 12, Batch: 359/468, discriminator loss real = 9.830923789673506e-16, disciminator loss fake = 1.0864596333703957e-08, generator loss = 19.281354904174805\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 12, Batch: 360/468, discriminator loss real = 1.210636480960051e-17, disciminator loss fake = 1.0467029909477787e-08, generator loss = 19.237302780151367\n",
      "2/2 [==============================] - 0s 148ms/step\n",
      "Epoch: 12, Batch: 361/468, discriminator loss real = 4.197131686390363e-15, disciminator loss fake = 6.499759841460673e-09, generator loss = 19.290729522705078\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 12, Batch: 362/468, discriminator loss real = 9.654729025243791e-17, disciminator loss fake = 8.745698387713219e-09, generator loss = 19.153587341308594\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 12, Batch: 363/468, discriminator loss real = 2.916263921903697e-15, disciminator loss fake = 7.3910939590859925e-09, generator loss = 19.35706329345703\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 12, Batch: 364/468, discriminator loss real = 1.6908690227590735e-14, disciminator loss fake = 9.860045224741043e-09, generator loss = 19.433048248291016\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 12, Batch: 365/468, discriminator loss real = 7.71522246995537e-15, disciminator loss fake = 1.0125281946216091e-08, generator loss = 19.353557586669922\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 12, Batch: 366/468, discriminator loss real = 6.858791056876573e-17, disciminator loss fake = 7.553019543138362e-09, generator loss = 19.405929565429688\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 12, Batch: 367/468, discriminator loss real = 1.1990242647494029e-15, disciminator loss fake = 8.838997977989038e-09, generator loss = 19.42424774169922\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 12, Batch: 368/468, discriminator loss real = 1.938141869217702e-09, disciminator loss fake = 6.84366607828224e-09, generator loss = 19.541738510131836\n",
      "2/2 [==============================] - 0s 175ms/step\n",
      "Epoch: 12, Batch: 369/468, discriminator loss real = 1.6988386604685826e-16, disciminator loss fake = 7.336264040702645e-09, generator loss = 19.33041763305664\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 12, Batch: 370/468, discriminator loss real = 2.2499947936152793e-15, disciminator loss fake = 7.0514074579364205e-09, generator loss = 19.242361068725586\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 12, Batch: 371/468, discriminator loss real = 8.579901112498733e-13, disciminator loss fake = 5.339715336560857e-09, generator loss = 19.22964096069336\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 12, Batch: 372/468, discriminator loss real = 3.630829558590465e-17, disciminator loss fake = 5.17203790906251e-09, generator loss = 19.299978256225586\n",
      "2/2 [==============================] - 0s 159ms/step\n",
      "Epoch: 12, Batch: 373/468, discriminator loss real = 1.5452725321551952e-08, disciminator loss fake = 8.444526855555523e-09, generator loss = 19.425983428955078\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 12, Batch: 374/468, discriminator loss real = 3.623192220674278e-19, disciminator loss fake = 7.679298974494486e-09, generator loss = 19.35329818725586\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 12, Batch: 375/468, discriminator loss real = 7.279365234506494e-14, disciminator loss fake = 7.567932946983547e-09, generator loss = 19.30255126953125\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 12, Batch: 376/468, discriminator loss real = 1.015788761291785e-14, disciminator loss fake = 7.773932608756695e-09, generator loss = 19.45876693725586\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 12, Batch: 377/468, discriminator loss real = 1.6412317181152462e-17, disciminator loss fake = 6.582655309728125e-09, generator loss = 19.507802963256836\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 12, Batch: 378/468, discriminator loss real = 1.578329134055423e-11, disciminator loss fake = 7.489841635788252e-09, generator loss = 19.348464965820312\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 12, Batch: 379/468, discriminator loss real = 2.669908564802516e-17, disciminator loss fake = 6.980269695588959e-09, generator loss = 19.27047348022461\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 12, Batch: 380/468, discriminator loss real = 1.9868492701774487e-13, disciminator loss fake = 6.0760143583138415e-09, generator loss = 19.23153305053711\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 12, Batch: 381/468, discriminator loss real = 2.4814590486588184e-13, disciminator loss fake = 8.490660619031587e-09, generator loss = 19.335968017578125\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 12, Batch: 382/468, discriminator loss real = 2.2989422865382636e-15, disciminator loss fake = 9.184361715597333e-09, generator loss = 19.33551025390625\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 12, Batch: 383/468, discriminator loss real = 8.473721941140711e-13, disciminator loss fake = 5.2387787441432465e-09, generator loss = 19.37226676940918\n",
      "2/2 [==============================] - 0s 168ms/step\n",
      "Epoch: 12, Batch: 384/468, discriminator loss real = 3.025743544604609e-10, disciminator loss fake = 7.649747502114224e-09, generator loss = 19.280357360839844\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 12, Batch: 385/468, discriminator loss real = 1.2895675956337517e-19, disciminator loss fake = 8.644315485639709e-09, generator loss = 19.290225982666016\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 12, Batch: 386/468, discriminator loss real = 2.31904990002918e-13, disciminator loss fake = 7.415305702807018e-09, generator loss = 19.459762573242188\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 12, Batch: 387/468, discriminator loss real = 4.477408705296296e-14, disciminator loss fake = 5.223059318382184e-09, generator loss = 19.26374053955078\n",
      "2/2 [==============================] - 0s 146ms/step\n",
      "Epoch: 12, Batch: 388/468, discriminator loss real = 6.901638430271669e-15, disciminator loss fake = 7.799427770294187e-09, generator loss = 19.307880401611328\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 12, Batch: 389/468, discriminator loss real = 8.713416347876412e-18, disciminator loss fake = 6.765215054826967e-09, generator loss = 19.174110412597656\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 12, Batch: 390/468, discriminator loss real = 7.00320715047581e-13, disciminator loss fake = 6.239417871256592e-09, generator loss = 19.39258575439453\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 12, Batch: 391/468, discriminator loss real = 9.370431947736124e-13, disciminator loss fake = 6.10756334396001e-09, generator loss = 19.2542724609375\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 12, Batch: 392/468, discriminator loss real = 3.1353927429627476e-14, disciminator loss fake = 7.011405678269966e-09, generator loss = 19.37094497680664\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 12, Batch: 393/468, discriminator loss real = 6.941991926911811e-16, disciminator loss fake = 6.003911146024166e-09, generator loss = 19.37908363342285\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 12, Batch: 394/468, discriminator loss real = 1.3188125111830533e-15, disciminator loss fake = 7.562002579675209e-09, generator loss = 19.338150024414062\n",
      "2/2 [==============================] - 0s 144ms/step\n",
      "Epoch: 12, Batch: 395/468, discriminator loss real = 3.095821992857295e-12, disciminator loss fake = 7.256621969986554e-09, generator loss = 19.517902374267578\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 12, Batch: 396/468, discriminator loss real = 1.2248057242023372e-15, disciminator loss fake = 5.206382880373894e-09, generator loss = 19.473466873168945\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 12, Batch: 397/468, discriminator loss real = 1.197243937019546e-13, disciminator loss fake = 6.114764694586938e-09, generator loss = 19.449560165405273\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 12, Batch: 398/468, discriminator loss real = 9.102344800202694e-14, disciminator loss fake = 5.6760489641760614e-09, generator loss = 19.32100486755371\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 12, Batch: 399/468, discriminator loss real = 1.2646400108216362e-14, disciminator loss fake = 4.9887112218982566e-09, generator loss = 19.37968635559082\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 12, Batch: 400/468, discriminator loss real = 1.7951149398825686e-17, disciminator loss fake = 5.72053959757568e-09, generator loss = 19.509675979614258\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 12, Batch: 401/468, discriminator loss real = 2.844631404345585e-15, disciminator loss fake = 7.17082970780325e-09, generator loss = 19.638072967529297\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 12, Batch: 402/468, discriminator loss real = 6.740985672220798e-14, disciminator loss fake = 8.339871016005418e-09, generator loss = 19.381122589111328\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 12, Batch: 403/468, discriminator loss real = 5.337303377039859e-10, disciminator loss fake = 5.027770200172199e-09, generator loss = 19.454965591430664\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 12, Batch: 404/468, discriminator loss real = 9.184500382453109e-12, disciminator loss fake = 6.766373239486256e-09, generator loss = 19.44439697265625\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 12, Batch: 405/468, discriminator loss real = 1.380185384519195e-14, disciminator loss fake = 6.699656829312062e-09, generator loss = 19.5562801361084\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 12, Batch: 406/468, discriminator loss real = 1.5401320219154968e-09, disciminator loss fake = 6.797542528858003e-09, generator loss = 19.374784469604492\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 12, Batch: 407/468, discriminator loss real = 1.8835200597550755e-15, disciminator loss fake = 5.13492670606297e-09, generator loss = 19.380884170532227\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 12, Batch: 408/468, discriminator loss real = 5.304317674383139e-15, disciminator loss fake = 5.752266218905788e-09, generator loss = 19.404462814331055\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 12, Batch: 409/468, discriminator loss real = 2.2842255125961938e-15, disciminator loss fake = 5.512906131599493e-09, generator loss = 19.408910751342773\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 12, Batch: 410/468, discriminator loss real = 2.9215297715767807e-12, disciminator loss fake = 5.9865583601492744e-09, generator loss = 19.63285255432129\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 12, Batch: 411/468, discriminator loss real = 8.2530208538191975e-19, disciminator loss fake = 7.041372374061439e-09, generator loss = 19.55218505859375\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 12, Batch: 412/468, discriminator loss real = 1.9320414554009215e-17, disciminator loss fake = 3.475984389211817e-09, generator loss = 19.409076690673828\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 12, Batch: 413/468, discriminator loss real = 7.344321459550171e-16, disciminator loss fake = 6.250377104777272e-09, generator loss = 19.542232513427734\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 12, Batch: 414/468, discriminator loss real = 3.088142241924885e-10, disciminator loss fake = 5.8844666916968436e-09, generator loss = 19.26144790649414\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 12, Batch: 415/468, discriminator loss real = 5.882442648356143e-16, disciminator loss fake = 8.269764428803228e-09, generator loss = 19.408409118652344\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 12, Batch: 416/468, discriminator loss real = 9.674839274860058e-18, disciminator loss fake = 6.1619576108284946e-09, generator loss = 19.354154586791992\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 12, Batch: 417/468, discriminator loss real = 1.7969522761061493e-14, disciminator loss fake = 6.9952599268674476e-09, generator loss = 19.499534606933594\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 12, Batch: 418/468, discriminator loss real = 2.824467276816428e-14, disciminator loss fake = 5.913499911969211e-09, generator loss = 19.607431411743164\n",
      "2/2 [==============================] - 0s 148ms/step\n",
      "Epoch: 12, Batch: 419/468, discriminator loss real = 1.3402552505314969e-11, disciminator loss fake = 6.639192307034136e-09, generator loss = 19.365060806274414\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 12, Batch: 420/468, discriminator loss real = 4.989253181740061e-15, disciminator loss fake = 5.7370446171489675e-09, generator loss = 19.51793670654297\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 12, Batch: 421/468, discriminator loss real = 5.212800243542537e-12, disciminator loss fake = 5.24181853478467e-09, generator loss = 19.2645263671875\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 12, Batch: 422/468, discriminator loss real = 2.0628553233274183e-19, disciminator loss fake = 4.422293198302896e-09, generator loss = 19.437320709228516\n",
      "2/2 [==============================] - 0s 175ms/step\n",
      "Epoch: 12, Batch: 423/468, discriminator loss real = 1.0146427101287436e-11, disciminator loss fake = 5.7960147792357475e-09, generator loss = 19.505748748779297\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 12, Batch: 424/468, discriminator loss real = 6.797971278849632e-18, disciminator loss fake = 7.969668480711789e-09, generator loss = 19.369056701660156\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 12, Batch: 425/468, discriminator loss real = 8.334080934934214e-19, disciminator loss fake = 7.50285344963686e-09, generator loss = 19.458213806152344\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 12, Batch: 426/468, discriminator loss real = 3.392761353469538e-17, disciminator loss fake = 5.7376103868023165e-09, generator loss = 19.373037338256836\n",
      "2/2 [==============================] - 0s 159ms/step\n",
      "Epoch: 12, Batch: 427/468, discriminator loss real = 1.2950702306110745e-16, disciminator loss fake = 4.741286474541084e-09, generator loss = 19.439924240112305\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 12, Batch: 428/468, discriminator loss real = 1.5404752126690902e-12, disciminator loss fake = 8.182817978763524e-09, generator loss = 19.494245529174805\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 12, Batch: 429/468, discriminator loss real = 3.988815354405428e-12, disciminator loss fake = 4.671350417595477e-09, generator loss = 19.425870895385742\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 12, Batch: 430/468, discriminator loss real = 8.900505332753994e-11, disciminator loss fake = 7.652282363324048e-09, generator loss = 19.597700119018555\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 12, Batch: 431/468, discriminator loss real = 4.430731078030474e-17, disciminator loss fake = 5.974449379664293e-09, generator loss = 19.491680145263672\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 12, Batch: 432/468, discriminator loss real = 5.021124291923052e-17, disciminator loss fake = 6.202220070861131e-09, generator loss = 19.449138641357422\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 12, Batch: 433/468, discriminator loss real = 8.989708052942712e-15, disciminator loss fake = 6.500020077737645e-09, generator loss = 19.716150283813477\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 12, Batch: 434/468, discriminator loss real = 6.3420901593813726e-15, disciminator loss fake = 5.62389601554969e-09, generator loss = 19.564973831176758\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 12, Batch: 435/468, discriminator loss real = 4.2470777914534904e-17, disciminator loss fake = 5.406293634990789e-09, generator loss = 19.54779052734375\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 12, Batch: 436/468, discriminator loss real = 5.127976340166324e-18, disciminator loss fake = 6.491555737397903e-09, generator loss = 19.510528564453125\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 12, Batch: 437/468, discriminator loss real = 7.109021133107745e-17, disciminator loss fake = 5.1702686576504675e-09, generator loss = 19.481517791748047\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 12, Batch: 438/468, discriminator loss real = 9.217638186892401e-17, disciminator loss fake = 3.7208320868842293e-09, generator loss = 19.462406158447266\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 12, Batch: 439/468, discriminator loss real = 2.5414194945554136e-13, disciminator loss fake = 4.588501134605849e-09, generator loss = 19.426780700683594\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 12, Batch: 440/468, discriminator loss real = 4.698580696879066e-15, disciminator loss fake = 8.476132684620552e-09, generator loss = 19.439716339111328\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 12, Batch: 441/468, discriminator loss real = 6.53372009815946e-14, disciminator loss fake = 5.990039131376079e-09, generator loss = 19.391714096069336\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 12, Batch: 442/468, discriminator loss real = 1.012518568252761e-16, disciminator loss fake = 9.817503254794246e-09, generator loss = 19.59642791748047\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 12, Batch: 443/468, discriminator loss real = 1.7274550930326815e-12, disciminator loss fake = 6.798211771297247e-09, generator loss = 19.415456771850586\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 12, Batch: 444/468, discriminator loss real = 8.623881987501427e-17, disciminator loss fake = 3.9976084664772316e-09, generator loss = 19.565170288085938\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 12, Batch: 445/468, discriminator loss real = 1.0930529485003726e-12, disciminator loss fake = 8.730991041261404e-09, generator loss = 19.724197387695312\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 12, Batch: 446/468, discriminator loss real = 4.610886190003702e-14, disciminator loss fake = 4.376643492065568e-09, generator loss = 19.655277252197266\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 12, Batch: 447/468, discriminator loss real = 1.0137978103492637e-14, disciminator loss fake = 6.208475511471079e-09, generator loss = 19.51766014099121\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 12, Batch: 448/468, discriminator loss real = 2.684321948748236e-15, disciminator loss fake = 6.221128501238127e-09, generator loss = 19.656211853027344\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 12, Batch: 449/468, discriminator loss real = 5.900942377319769e-17, disciminator loss fake = 6.6524785680144305e-09, generator loss = 19.666704177856445\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 12, Batch: 450/468, discriminator loss real = 2.1708344824966815e-14, disciminator loss fake = 6.6369674200927875e-09, generator loss = 19.665367126464844\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 12, Batch: 451/468, discriminator loss real = 2.9561950110057467e-11, disciminator loss fake = 7.563810022759299e-09, generator loss = 19.578567504882812\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 12, Batch: 452/468, discriminator loss real = 1.5495131575543131e-15, disciminator loss fake = 6.8885985804456595e-09, generator loss = 19.82640266418457\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 12, Batch: 453/468, discriminator loss real = 4.717180639157714e-12, disciminator loss fake = 5.817146764286463e-09, generator loss = 19.493427276611328\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 12, Batch: 454/468, discriminator loss real = 3.221926725416324e-09, disciminator loss fake = 6.729402368677029e-09, generator loss = 19.54746437072754\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 12, Batch: 455/468, discriminator loss real = 5.869006258762965e-07, disciminator loss fake = 5.323850693628174e-09, generator loss = 19.63125228881836\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 12, Batch: 456/468, discriminator loss real = 1.3569224293041556e-16, disciminator loss fake = 7.993316231136305e-09, generator loss = 19.315256118774414\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 12, Batch: 457/468, discriminator loss real = 7.454232984181481e-16, disciminator loss fake = 7.115602773666296e-09, generator loss = 19.419784545898438\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 12, Batch: 458/468, discriminator loss real = 9.692483361051218e-13, disciminator loss fake = 6.272148134200961e-09, generator loss = 19.357879638671875\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 12, Batch: 459/468, discriminator loss real = 3.8150278075521626e-11, disciminator loss fake = 7.339107099824105e-09, generator loss = 19.246614456176758\n",
      "2/2 [==============================] - 0s 135ms/step\n",
      "Epoch: 12, Batch: 460/468, discriminator loss real = 4.208302045878842e-18, disciminator loss fake = 6.459656809454373e-09, generator loss = 19.218616485595703\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 12, Batch: 461/468, discriminator loss real = 1.7807241412762936e-14, disciminator loss fake = 7.17565740160353e-09, generator loss = 19.275592803955078\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 12, Batch: 462/468, discriminator loss real = 5.3312691067342044e-11, disciminator loss fake = 7.093264642321628e-09, generator loss = 19.351490020751953\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Epoch: 12, Batch: 463/468, discriminator loss real = 4.486399533126795e-12, disciminator loss fake = 8.38029379224281e-09, generator loss = 19.107189178466797\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 12, Batch: 464/468, discriminator loss real = 3.913979210179441e-11, disciminator loss fake = 6.937511010107755e-09, generator loss = 19.096759796142578\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 12, Batch: 465/468, discriminator loss real = 4.426567792870095e-11, disciminator loss fake = 6.2065748096529205e-09, generator loss = 19.277565002441406\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 12, Batch: 466/468, discriminator loss real = 9.516877642391265e-15, disciminator loss fake = 8.470840917595979e-09, generator loss = 19.05847930908203\n",
      "2/2 [==============================] - 0s 159ms/step\n",
      "Epoch: 12, Batch: 467/468, discriminator loss real = 1.4060082532953383e-16, disciminator loss fake = 1.213548195266867e-08, generator loss = 19.225065231323242\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 12, Batch: 468/468, discriminator loss real = 4.143470938189386e-18, disciminator loss fake = 8.613493918119275e-09, generator loss = 19.028968811035156\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 13, Batch: 1/468, discriminator loss real = 1.1169107732602029e-15, disciminator loss fake = 9.317401961084215e-09, generator loss = 19.14636993408203\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 13, Batch: 2/468, discriminator loss real = 5.114314527432384e-11, disciminator loss fake = 9.307162152083492e-09, generator loss = 19.134342193603516\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 13, Batch: 3/468, discriminator loss real = 1.5821116308109787e-17, disciminator loss fake = 6.628019022514309e-09, generator loss = 19.13469696044922\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 13, Batch: 4/468, discriminator loss real = 5.638869721694798e-17, disciminator loss fake = 1.0506934877696494e-08, generator loss = 19.28713035583496\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 13, Batch: 5/468, discriminator loss real = 8.825954667260945e-16, disciminator loss fake = 1.0447815057545995e-08, generator loss = 19.196561813354492\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 13, Batch: 6/468, discriminator loss real = 4.580459411285612e-14, disciminator loss fake = 9.927697774969602e-09, generator loss = 19.083887100219727\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 13, Batch: 7/468, discriminator loss real = 3.578532222414657e-18, disciminator loss fake = 9.463766659223438e-09, generator loss = 19.28321647644043\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 13, Batch: 8/468, discriminator loss real = 1.4144529731502375e-12, disciminator loss fake = 7.046805805543954e-09, generator loss = 19.099315643310547\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 13, Batch: 9/468, discriminator loss real = 8.809012287780185e-17, disciminator loss fake = 6.99362479039678e-09, generator loss = 19.100149154663086\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 13, Batch: 10/468, discriminator loss real = 7.945708367004722e-17, disciminator loss fake = 8.782314431243776e-09, generator loss = 19.302846908569336\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 13, Batch: 11/468, discriminator loss real = 5.059279817474408e-18, disciminator loss fake = 1.060492493820675e-08, generator loss = 19.0793514251709\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 13, Batch: 12/468, discriminator loss real = 1.834363773210593e-15, disciminator loss fake = 1.177268860175218e-08, generator loss = 19.230098724365234\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 13, Batch: 13/468, discriminator loss real = 2.3867037090164606e-14, disciminator loss fake = 8.985549193596398e-09, generator loss = 19.248218536376953\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 13, Batch: 14/468, discriminator loss real = 9.323472802982233e-18, disciminator loss fake = 7.29013338585105e-09, generator loss = 19.349639892578125\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 13, Batch: 15/468, discriminator loss real = 1.0613247086732613e-10, disciminator loss fake = 1.0748688161754671e-08, generator loss = 19.282730102539062\n",
      "2/2 [==============================] - 0s 158ms/step\n",
      "Epoch: 13, Batch: 16/468, discriminator loss real = 2.4307264253291662e-15, disciminator loss fake = 7.480235098000776e-09, generator loss = 19.21858787536621\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 13, Batch: 17/468, discriminator loss real = 1.0252617331507619e-11, disciminator loss fake = 8.313432608986204e-09, generator loss = 19.291332244873047\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 13, Batch: 18/468, discriminator loss real = 4.796500670196978e-15, disciminator loss fake = 8.449506871954782e-09, generator loss = 19.168251037597656\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 13, Batch: 19/468, discriminator loss real = 9.548520828184248e-13, disciminator loss fake = 7.720003303290923e-09, generator loss = 19.262670516967773\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 13, Batch: 20/468, discriminator loss real = 1.748148643167937e-20, disciminator loss fake = 7.3071615425135406e-09, generator loss = 19.344087600708008\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 13, Batch: 21/468, discriminator loss real = 3.317039254962964e-15, disciminator loss fake = 6.9818368864105196e-09, generator loss = 19.32172966003418\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 13, Batch: 22/468, discriminator loss real = 6.793793454273422e-16, disciminator loss fake = 7.078813979433107e-09, generator loss = 19.313255310058594\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 13, Batch: 23/468, discriminator loss real = 2.107325010902738e-15, disciminator loss fake = 9.460837446795267e-09, generator loss = 19.308998107910156\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 13, Batch: 24/468, discriminator loss real = 1.8507153207408637e-15, disciminator loss fake = 7.681654423663531e-09, generator loss = 19.241315841674805\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 13, Batch: 25/468, discriminator loss real = 4.798841008995352e-17, disciminator loss fake = 8.636776627213294e-09, generator loss = 19.349594116210938\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 13, Batch: 26/468, discriminator loss real = 1.9263150494563394e-17, disciminator loss fake = 7.016425662698111e-09, generator loss = 19.345699310302734\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 13, Batch: 27/468, discriminator loss real = 7.18405064983104e-15, disciminator loss fake = 7.4398993632485144e-09, generator loss = 19.32160758972168\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 13, Batch: 28/468, discriminator loss real = 5.20647205798485e-18, disciminator loss fake = 8.829850628444547e-09, generator loss = 19.405624389648438\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 13, Batch: 29/468, discriminator loss real = 3.805450198314492e-18, disciminator loss fake = 7.620943875963349e-09, generator loss = 19.284652709960938\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 13, Batch: 30/468, discriminator loss real = 4.5184966879219246e-11, disciminator loss fake = 8.383143956791628e-09, generator loss = 19.283828735351562\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 13, Batch: 31/468, discriminator loss real = 1.7877580722768828e-14, disciminator loss fake = 1.0444251685726158e-08, generator loss = 19.189712524414062\n",
      "2/2 [==============================] - 0s 152ms/step\n",
      "Epoch: 13, Batch: 32/468, discriminator loss real = 3.5425541623432255e-13, disciminator loss fake = 8.651048766239455e-09, generator loss = 19.2286376953125\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 13, Batch: 33/468, discriminator loss real = 9.040447501718063e-09, disciminator loss fake = 6.982760147877798e-09, generator loss = 19.35794448852539\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 13, Batch: 34/468, discriminator loss real = 8.621914455696408e-18, disciminator loss fake = 9.806525369526753e-09, generator loss = 19.28912353515625\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 13, Batch: 35/468, discriminator loss real = 7.306172472034377e-15, disciminator loss fake = 7.460331019615296e-09, generator loss = 19.369035720825195\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 13, Batch: 36/468, discriminator loss real = 1.3043347868793576e-13, disciminator loss fake = 7.994548134604429e-09, generator loss = 19.344158172607422\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 13, Batch: 37/468, discriminator loss real = 1.5756981223274957e-13, disciminator loss fake = 7.311579786062339e-09, generator loss = 19.273235321044922\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 13, Batch: 38/468, discriminator loss real = 2.5491775032006336e-13, disciminator loss fake = 9.340268114499395e-09, generator loss = 19.210227966308594\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 13, Batch: 39/468, discriminator loss real = 1.8702603354903147e-10, disciminator loss fake = 9.395617617258267e-09, generator loss = 19.266389846801758\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 13, Batch: 40/468, discriminator loss real = 8.802741792868912e-14, disciminator loss fake = 8.154328767773222e-09, generator loss = 19.353050231933594\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 13, Batch: 41/468, discriminator loss real = 8.793572152995116e-14, disciminator loss fake = 8.638620485612591e-09, generator loss = 19.369964599609375\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 13, Batch: 42/468, discriminator loss real = 6.33835974157837e-13, disciminator loss fake = 9.423759550486466e-09, generator loss = 19.334035873413086\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 13, Batch: 43/468, discriminator loss real = 1.8513493249018836e-16, disciminator loss fake = 1.100415136789934e-08, generator loss = 19.19894027709961\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 13, Batch: 44/468, discriminator loss real = 1.0718557118261085e-11, disciminator loss fake = 8.28720558843088e-09, generator loss = 19.29273223876953\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 13, Batch: 45/468, discriminator loss real = 1.230060319560409e-16, disciminator loss fake = 6.22778273395852e-09, generator loss = 19.43044662475586\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 13, Batch: 46/468, discriminator loss real = 3.906220761754715e-15, disciminator loss fake = 4.9749298014489796e-09, generator loss = 19.54567527770996\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 13, Batch: 47/468, discriminator loss real = 2.297789051180577e-15, disciminator loss fake = 6.8005521214331566e-09, generator loss = 19.455554962158203\n",
      "2/2 [==============================] - 0s 146ms/step\n",
      "Epoch: 13, Batch: 48/468, discriminator loss real = 4.2047117842353415e-16, disciminator loss fake = 5.921340751058324e-09, generator loss = 19.430164337158203\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 13, Batch: 49/468, discriminator loss real = 6.44247025519129e-14, disciminator loss fake = 5.863017626950295e-09, generator loss = 19.440258026123047\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 13, Batch: 50/468, discriminator loss real = 1.5363364877160612e-12, disciminator loss fake = 6.5898593248903126e-09, generator loss = 19.349008560180664\n",
      "2/2 [==============================] - 0s 157ms/step\n",
      "Epoch: 13, Batch: 51/468, discriminator loss real = 1.864383044377759e-15, disciminator loss fake = 8.696604325564294e-09, generator loss = 19.391170501708984\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 13, Batch: 52/468, discriminator loss real = 3.585300056840879e-09, disciminator loss fake = 6.110305150741624e-09, generator loss = 19.535175323486328\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 13, Batch: 53/468, discriminator loss real = 2.2215744559547334e-16, disciminator loss fake = 7.371538046641035e-09, generator loss = 19.473915100097656\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 13, Batch: 54/468, discriminator loss real = 7.924322108575531e-17, disciminator loss fake = 5.649509304817002e-09, generator loss = 19.490211486816406\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 13, Batch: 55/468, discriminator loss real = 1.1658977590943529e-15, disciminator loss fake = 5.93820370653475e-09, generator loss = 19.306732177734375\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 13, Batch: 56/468, discriminator loss real = 4.916184126457779e-11, disciminator loss fake = 5.953377346656907e-09, generator loss = 19.534975051879883\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 13, Batch: 57/468, discriminator loss real = 2.842673342104219e-17, disciminator loss fake = 5.760461885273571e-09, generator loss = 19.43189239501953\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 13, Batch: 58/468, discriminator loss real = 7.720569072944272e-09, disciminator loss fake = 5.013648607388177e-09, generator loss = 19.356250762939453\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 13, Batch: 59/468, discriminator loss real = 5.979242101439297e-10, disciminator loss fake = 9.716321969222008e-09, generator loss = 19.441743850708008\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 13, Batch: 60/468, discriminator loss real = 7.49195692151261e-08, disciminator loss fake = 5.979004402689725e-09, generator loss = 19.547391891479492\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 13, Batch: 61/468, discriminator loss real = 8.820801212930732e-14, disciminator loss fake = 5.9684643893831435e-09, generator loss = 19.642349243164062\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 13, Batch: 62/468, discriminator loss real = 4.994401064181669e-17, disciminator loss fake = 6.23000406818619e-09, generator loss = 19.326946258544922\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 13, Batch: 63/468, discriminator loss real = 1.3975255740162499e-18, disciminator loss fake = 5.71037972463273e-09, generator loss = 19.270278930664062\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 13, Batch: 64/468, discriminator loss real = 9.126641093261736e-14, disciminator loss fake = 6.091585902368024e-09, generator loss = 19.349105834960938\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 13, Batch: 65/468, discriminator loss real = 4.140886389336629e-08, disciminator loss fake = 6.110311367990562e-09, generator loss = 19.463232040405273\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 13, Batch: 66/468, discriminator loss real = 2.5051872090592176e-18, disciminator loss fake = 6.162342192084225e-09, generator loss = 19.428892135620117\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 13, Batch: 67/468, discriminator loss real = 1.0940306001749615e-16, disciminator loss fake = 6.569468080641627e-09, generator loss = 19.335960388183594\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 13, Batch: 68/468, discriminator loss real = 1.0595845495369873e-16, disciminator loss fake = 6.9061059093655786e-09, generator loss = 19.39817237854004\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 13, Batch: 69/468, discriminator loss real = 3.6818634921858835e-16, disciminator loss fake = 7.984340300026815e-09, generator loss = 19.402202606201172\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 13, Batch: 70/468, discriminator loss real = 1.1125378647539678e-18, disciminator loss fake = 5.289490179194445e-09, generator loss = 19.41640853881836\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "Epoch: 13, Batch: 71/468, discriminator loss real = 1.191061416161432e-10, disciminator loss fake = 7.908996124683654e-09, generator loss = 19.3093318939209\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 13, Batch: 72/468, discriminator loss real = 5.531916274343317e-14, disciminator loss fake = 7.499458831716765e-09, generator loss = 19.457141876220703\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 13, Batch: 73/468, discriminator loss real = 1.713969938199611e-10, disciminator loss fake = 7.559957992953059e-09, generator loss = 19.488943099975586\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "Epoch: 13, Batch: 74/468, discriminator loss real = 7.852066571814934e-14, disciminator loss fake = 6.1839848797262675e-09, generator loss = 19.342117309570312\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 13, Batch: 75/468, discriminator loss real = 1.835319819298159e-14, disciminator loss fake = 7.28954141493432e-09, generator loss = 19.3829402923584\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 13, Batch: 76/468, discriminator loss real = 5.087434067675508e-17, disciminator loss fake = 7.7373689677529e-09, generator loss = 19.355743408203125\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 13, Batch: 77/468, discriminator loss real = 3.919465053621278e-14, disciminator loss fake = 7.578929483997854e-09, generator loss = 19.5013427734375\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 13, Batch: 78/468, discriminator loss real = 7.322442652224481e-11, disciminator loss fake = 7.363105680724402e-09, generator loss = 19.36008644104004\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 13, Batch: 79/468, discriminator loss real = 6.7344007944137065e-18, disciminator loss fake = 6.3258625004891655e-09, generator loss = 19.254127502441406\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 13, Batch: 80/468, discriminator loss real = 1.990709114614792e-15, disciminator loss fake = 6.2094924757616354e-09, generator loss = 19.470624923706055\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 13, Batch: 81/468, discriminator loss real = 1.99088608639133e-19, disciminator loss fake = 5.6065880826849934e-09, generator loss = 19.52088165283203\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 13, Batch: 82/468, discriminator loss real = 5.573602560385305e-13, disciminator loss fake = 6.7338903342317735e-09, generator loss = 19.438720703125\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 13, Batch: 83/468, discriminator loss real = 3.0168291367642375e-14, disciminator loss fake = 5.229989774591104e-09, generator loss = 19.485721588134766\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 13, Batch: 84/468, discriminator loss real = 2.0340909403886165e-13, disciminator loss fake = 6.74749500717553e-09, generator loss = 19.44605255126953\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 13, Batch: 85/468, discriminator loss real = 6.748447863079519e-15, disciminator loss fake = 7.384150180200777e-09, generator loss = 19.385787963867188\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 13, Batch: 86/468, discriminator loss real = 4.647343707780971e-12, disciminator loss fake = 6.5739724774971364e-09, generator loss = 19.399192810058594\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 13, Batch: 87/468, discriminator loss real = 1.4638296008634485e-17, disciminator loss fake = 5.616568543587164e-09, generator loss = 19.55984115600586\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 13, Batch: 88/468, discriminator loss real = 1.0364876491808506e-11, disciminator loss fake = 7.193899698165751e-09, generator loss = 19.393604278564453\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 13, Batch: 89/468, discriminator loss real = 1.045510300377991e-14, disciminator loss fake = 5.445453421515367e-09, generator loss = 19.40782928466797\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 13, Batch: 90/468, discriminator loss real = 3.936553773925544e-12, disciminator loss fake = 6.83566891979126e-09, generator loss = 19.483352661132812\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 13, Batch: 91/468, discriminator loss real = 1.8475620339186705e-12, disciminator loss fake = 7.932253964781921e-09, generator loss = 19.448036193847656\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 13, Batch: 92/468, discriminator loss real = 6.194194712779864e-16, disciminator loss fake = 6.734042212741542e-09, generator loss = 19.282052993774414\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 13, Batch: 93/468, discriminator loss real = 9.263237014467754e-15, disciminator loss fake = 5.178582007658861e-09, generator loss = 19.271839141845703\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 13, Batch: 94/468, discriminator loss real = 1.6245926756912766e-15, disciminator loss fake = 7.097266774280797e-09, generator loss = 19.38732147216797\n",
      "2/2 [==============================] - 0s 160ms/step\n",
      "Epoch: 13, Batch: 95/468, discriminator loss real = 1.2811472260669532e-13, disciminator loss fake = 5.622744048139339e-09, generator loss = 19.386810302734375\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 13, Batch: 96/468, discriminator loss real = 2.1249298495575899e-16, disciminator loss fake = 4.786544938184534e-09, generator loss = 19.5234432220459\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 13, Batch: 97/468, discriminator loss real = 5.164121651393054e-17, disciminator loss fake = 8.217375224717216e-09, generator loss = 19.449169158935547\n",
      "2/2 [==============================] - 0s 162ms/step\n",
      "Epoch: 13, Batch: 98/468, discriminator loss real = 1.0301251518463062e-10, disciminator loss fake = 6.6874372706138274e-09, generator loss = 19.630352020263672\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 13, Batch: 99/468, discriminator loss real = 4.1148294786074924e-17, disciminator loss fake = 6.305092448144478e-09, generator loss = 19.525169372558594\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 13, Batch: 100/468, discriminator loss real = 3.145761913838754e-17, disciminator loss fake = 7.0126167095452274e-09, generator loss = 19.495647430419922\n",
      "2/2 [==============================] - 0s 162ms/step\n",
      "Epoch: 13, Batch: 101/468, discriminator loss real = 7.765135501028886e-17, disciminator loss fake = 6.422562925934017e-09, generator loss = 19.34524917602539\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 13, Batch: 102/468, discriminator loss real = 5.806936940297813e-17, disciminator loss fake = 6.525927354061878e-09, generator loss = 19.4628849029541\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 13, Batch: 103/468, discriminator loss real = 5.1387817612269515e-12, disciminator loss fake = 6.911357708361265e-09, generator loss = 19.52020263671875\n",
      "2/2 [==============================] - 0s 172ms/step\n",
      "Epoch: 13, Batch: 104/468, discriminator loss real = 3.4738354552959377e-19, disciminator loss fake = 5.248912415822815e-09, generator loss = 19.52320671081543\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 13, Batch: 105/468, discriminator loss real = 8.574471326374972e-15, disciminator loss fake = 5.104946687595202e-09, generator loss = 19.519004821777344\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 13, Batch: 106/468, discriminator loss real = 6.267695509733912e-14, disciminator loss fake = 5.514470657885795e-09, generator loss = 19.461772918701172\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 13, Batch: 107/468, discriminator loss real = 1.0968377203017215e-16, disciminator loss fake = 6.503391158929617e-09, generator loss = 19.555622100830078\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 13, Batch: 108/468, discriminator loss real = 6.275231392459044e-14, disciminator loss fake = 6.568941834927955e-09, generator loss = 19.718242645263672\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 13, Batch: 109/468, discriminator loss real = 7.86414153436694e-19, disciminator loss fake = 4.693972321945239e-09, generator loss = 19.480390548706055\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 13, Batch: 110/468, discriminator loss real = 1.076232922225806e-10, disciminator loss fake = 5.625627963468105e-09, generator loss = 19.5079288482666\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 13, Batch: 111/468, discriminator loss real = 1.7360726406431056e-16, disciminator loss fake = 7.0319692291320735e-09, generator loss = 19.5562744140625\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 13, Batch: 112/468, discriminator loss real = 2.3576139691586334e-17, disciminator loss fake = 5.406483261083395e-09, generator loss = 19.62869644165039\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 13, Batch: 113/468, discriminator loss real = 2.3484981862866017e-13, disciminator loss fake = 4.7392867408291295e-09, generator loss = 19.656858444213867\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 13, Batch: 114/468, discriminator loss real = 1.1702815569370438e-14, disciminator loss fake = 6.128840102093136e-09, generator loss = 19.639719009399414\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 13, Batch: 115/468, discriminator loss real = 8.257612258907865e-13, disciminator loss fake = 5.410256687099491e-09, generator loss = 19.533864974975586\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 13, Batch: 116/468, discriminator loss real = 7.101672722109598e-11, disciminator loss fake = 6.067002011889144e-09, generator loss = 19.528648376464844\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 13, Batch: 117/468, discriminator loss real = 7.287849455319372e-15, disciminator loss fake = 5.768361788227594e-09, generator loss = 19.52301788330078\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 13, Batch: 118/468, discriminator loss real = 1.0212013279442544e-07, disciminator loss fake = 6.339589742054841e-09, generator loss = 19.612939834594727\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 13, Batch: 119/468, discriminator loss real = 4.7416896797880526e-12, disciminator loss fake = 5.967744964863186e-09, generator loss = 19.443225860595703\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 13, Batch: 120/468, discriminator loss real = 1.320618744568569e-12, disciminator loss fake = 6.0559388614933596e-09, generator loss = 19.579734802246094\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 13, Batch: 121/468, discriminator loss real = 1.458096610031795e-13, disciminator loss fake = 4.8473700609008574e-09, generator loss = 19.56989097595215\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 13, Batch: 122/468, discriminator loss real = 2.9843534991667915e-17, disciminator loss fake = 5.817855974754593e-09, generator loss = 19.262128829956055\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 13, Batch: 123/468, discriminator loss real = 2.56891343609485e-20, disciminator loss fake = 7.129047574494507e-09, generator loss = 19.41730499267578\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 13, Batch: 124/468, discriminator loss real = 1.3487024791312263e-18, disciminator loss fake = 6.952298292617343e-09, generator loss = 19.670095443725586\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 13, Batch: 125/468, discriminator loss real = 9.598989355111276e-13, disciminator loss fake = 6.495340709733455e-09, generator loss = 19.620161056518555\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 13, Batch: 126/468, discriminator loss real = 7.470144551862393e-19, disciminator loss fake = 6.131604113335243e-09, generator loss = 19.58629035949707\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 13, Batch: 127/468, discriminator loss real = 3.2837179642086767e-09, disciminator loss fake = 5.908426192746674e-09, generator loss = 19.50632667541504\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 13, Batch: 128/468, discriminator loss real = 4.446160312560303e-18, disciminator loss fake = 7.40908046026334e-09, generator loss = 19.56751251220703\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 13, Batch: 129/468, discriminator loss real = 6.080371124130013e-13, disciminator loss fake = 6.703035904109811e-09, generator loss = 19.5661563873291\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 13, Batch: 130/468, discriminator loss real = 1.7991430567576572e-10, disciminator loss fake = 6.623293025143084e-09, generator loss = 19.380355834960938\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 13, Batch: 131/468, discriminator loss real = 3.8426334054812716e-13, disciminator loss fake = 5.32581712064939e-09, generator loss = 19.617164611816406\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 13, Batch: 132/468, discriminator loss real = 6.094359500559421e-13, disciminator loss fake = 5.565180316580154e-09, generator loss = 19.517351150512695\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 13, Batch: 133/468, discriminator loss real = 1.1325877649271039e-15, disciminator loss fake = 6.325277634999793e-09, generator loss = 19.486968994140625\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 13, Batch: 134/468, discriminator loss real = 7.905964771737217e-09, disciminator loss fake = 6.05543526432939e-09, generator loss = 19.613454818725586\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 13, Batch: 135/468, discriminator loss real = 5.214929152567592e-19, disciminator loss fake = 6.559424559071658e-09, generator loss = 19.587295532226562\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 13, Batch: 136/468, discriminator loss real = 2.592706849213755e-08, disciminator loss fake = 8.007935647924569e-09, generator loss = 19.62758445739746\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 13, Batch: 137/468, discriminator loss real = 4.094011100182898e-14, disciminator loss fake = 5.836841232564893e-09, generator loss = 19.52846908569336\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 13, Batch: 138/468, discriminator loss real = 5.692120962553002e-17, disciminator loss fake = 6.109128758424731e-09, generator loss = 19.586503982543945\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 13, Batch: 139/468, discriminator loss real = 6.867652080296037e-15, disciminator loss fake = 6.19943874013984e-09, generator loss = 19.434223175048828\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 13, Batch: 140/468, discriminator loss real = 1.100415656954095e-17, disciminator loss fake = 4.90026064170479e-09, generator loss = 19.531885147094727\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 13, Batch: 141/468, discriminator loss real = 1.2389820580368343e-17, disciminator loss fake = 4.983616630482857e-09, generator loss = 19.65950584411621\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 13, Batch: 142/468, discriminator loss real = 1.2244330170000511e-13, disciminator loss fake = 6.21507734166471e-09, generator loss = 19.417797088623047\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 13, Batch: 143/468, discriminator loss real = 6.644459428090121e-16, disciminator loss fake = 4.384815177616019e-09, generator loss = 19.701343536376953\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 13, Batch: 144/468, discriminator loss real = 1.8111771780157486e-14, disciminator loss fake = 4.655751784099493e-09, generator loss = 19.366716384887695\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 13, Batch: 145/468, discriminator loss real = 2.702735951709556e-11, disciminator loss fake = 5.371648015284336e-09, generator loss = 19.606765747070312\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 13, Batch: 146/468, discriminator loss real = 1.2584432024828184e-14, disciminator loss fake = 6.795715989937889e-09, generator loss = 19.713722229003906\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 13, Batch: 147/468, discriminator loss real = 4.6617397442272335e-11, disciminator loss fake = 6.33982910613895e-09, generator loss = 19.632953643798828\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 13, Batch: 148/468, discriminator loss real = 1.630978648986529e-17, disciminator loss fake = 5.55903012511294e-09, generator loss = 19.416215896606445\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 13, Batch: 149/468, discriminator loss real = 3.607924302742073e-14, disciminator loss fake = 5.273101955083348e-09, generator loss = 19.518474578857422\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 13, Batch: 150/468, discriminator loss real = 5.964614652881339e-13, disciminator loss fake = 3.954853333709707e-09, generator loss = 19.59573745727539\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 13, Batch: 151/468, discriminator loss real = 1.3068907342086858e-15, disciminator loss fake = 5.076151055050104e-09, generator loss = 19.625329971313477\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 13, Batch: 152/468, discriminator loss real = 7.598634652313317e-19, disciminator loss fake = 6.2527174549131814e-09, generator loss = 19.555683135986328\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 13, Batch: 153/468, discriminator loss real = 8.237252893672498e-12, disciminator loss fake = 6.61350352260115e-09, generator loss = 19.438865661621094\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 13, Batch: 154/468, discriminator loss real = 1.23027738170578e-12, disciminator loss fake = 5.388492319013949e-09, generator loss = 19.557621002197266\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 13, Batch: 155/468, discriminator loss real = 2.3171228323115405e-14, disciminator loss fake = 4.191881952664289e-09, generator loss = 19.548168182373047\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 13, Batch: 156/468, discriminator loss real = 7.438245766697648e-16, disciminator loss fake = 4.942161346832563e-09, generator loss = 19.646820068359375\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 13, Batch: 157/468, discriminator loss real = 2.6334328776391327e-17, disciminator loss fake = 5.77722847339146e-09, generator loss = 19.606346130371094\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 13, Batch: 158/468, discriminator loss real = 1.6645001433102403e-17, disciminator loss fake = 7.594973538971317e-09, generator loss = 19.61309242248535\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 13, Batch: 159/468, discriminator loss real = 3.135649224539176e-14, disciminator loss fake = 6.6627880990211e-09, generator loss = 19.60424041748047\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 13, Batch: 160/468, discriminator loss real = 1.4269585015149302e-15, disciminator loss fake = 4.444949741611026e-09, generator loss = 19.60768699645996\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 13, Batch: 161/468, discriminator loss real = 7.072437118371341e-14, disciminator loss fake = 4.651316665160721e-09, generator loss = 19.590335845947266\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 13, Batch: 162/468, discriminator loss real = 5.484255000950738e-15, disciminator loss fake = 6.002376373714924e-09, generator loss = 19.507591247558594\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 13, Batch: 163/468, discriminator loss real = 4.623683705871906e-13, disciminator loss fake = 7.48433759412137e-09, generator loss = 19.72397804260254\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 13, Batch: 164/468, discriminator loss real = 8.771895965775992e-16, disciminator loss fake = 5.2083786172829605e-09, generator loss = 19.766620635986328\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 13, Batch: 165/468, discriminator loss real = 1.1110093964608603e-12, disciminator loss fake = 4.345879212053205e-09, generator loss = 19.598352432250977\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 13, Batch: 166/468, discriminator loss real = 4.8025297660122396e-14, disciminator loss fake = 4.410723342118672e-09, generator loss = 19.60500717163086\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 13, Batch: 167/468, discriminator loss real = 1.300990565278326e-13, disciminator loss fake = 7.0531873674895e-09, generator loss = 19.715805053710938\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 13, Batch: 168/468, discriminator loss real = 9.901967440439918e-11, disciminator loss fake = 5.0462181100385806e-09, generator loss = 19.666011810302734\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 13, Batch: 169/468, discriminator loss real = 7.986840522278271e-09, disciminator loss fake = 4.597578318055184e-09, generator loss = 19.63412857055664\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 13, Batch: 170/468, discriminator loss real = 3.2706117909371796e-16, disciminator loss fake = 5.401719960218543e-09, generator loss = 19.59908676147461\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 13, Batch: 171/468, discriminator loss real = 2.896752390908752e-14, disciminator loss fake = 4.608772030678665e-09, generator loss = 19.602554321289062\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 13, Batch: 172/468, discriminator loss real = 1.5831325371229916e-17, disciminator loss fake = 4.178734691606678e-09, generator loss = 19.832229614257812\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 13, Batch: 173/468, discriminator loss real = 3.858734824182218e-14, disciminator loss fake = 5.521664458996156e-09, generator loss = 19.544893264770508\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 13, Batch: 174/468, discriminator loss real = 3.421726606483294e-13, disciminator loss fake = 6.876117897292033e-09, generator loss = 19.66513442993164\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 13, Batch: 175/468, discriminator loss real = 1.7268153053306978e-13, disciminator loss fake = 5.061018271135254e-09, generator loss = 19.889062881469727\n",
      "2/2 [==============================] - 0s 166ms/step\n",
      "Epoch: 13, Batch: 176/468, discriminator loss real = 1.0403317096674414e-11, disciminator loss fake = 4.395339203711046e-09, generator loss = 19.550716400146484\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 13, Batch: 177/468, discriminator loss real = 7.099123264069085e-13, disciminator loss fake = 6.00875527112521e-09, generator loss = 19.763795852661133\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 13, Batch: 178/468, discriminator loss real = 4.411500886813968e-10, disciminator loss fake = 4.319898216920137e-09, generator loss = 19.834156036376953\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 13, Batch: 179/468, discriminator loss real = 5.936421059588026e-12, disciminator loss fake = 4.994939573066404e-09, generator loss = 19.68386459350586\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 13, Batch: 180/468, discriminator loss real = 4.223352136761838e-12, disciminator loss fake = 4.2064769445460115e-09, generator loss = 19.719257354736328\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 13, Batch: 181/468, discriminator loss real = 1.5032679961946016e-14, disciminator loss fake = 5.7327707025933705e-09, generator loss = 19.697290420532227\n",
      "2/2 [==============================] - 0s 147ms/step\n",
      "Epoch: 13, Batch: 182/468, discriminator loss real = 7.726605745733521e-15, disciminator loss fake = 4.572713763195679e-09, generator loss = 19.767318725585938\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 13, Batch: 183/468, discriminator loss real = 3.30855436711164e-17, disciminator loss fake = 4.533776021276026e-09, generator loss = 19.680965423583984\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 13, Batch: 184/468, discriminator loss real = 7.093631272375073e-18, disciminator loss fake = 5.170430306122853e-09, generator loss = 19.854310989379883\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 13, Batch: 185/468, discriminator loss real = 1.2093601842882735e-15, disciminator loss fake = 5.720619089544243e-09, generator loss = 19.686500549316406\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 13, Batch: 186/468, discriminator loss real = 3.2164680685201454e-15, disciminator loss fake = 4.853645485525249e-09, generator loss = 19.836870193481445\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 13, Batch: 187/468, discriminator loss real = 6.818949972817873e-14, disciminator loss fake = 4.15684109356107e-09, generator loss = 19.666645050048828\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 13, Batch: 188/468, discriminator loss real = 4.919503321962164e-14, disciminator loss fake = 3.79845932485523e-09, generator loss = 19.659021377563477\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 13, Batch: 189/468, discriminator loss real = 4.814749487991321e-09, disciminator loss fake = 7.2725736544043684e-09, generator loss = 19.716474533081055\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 13, Batch: 190/468, discriminator loss real = 3.5619047711321628e-09, disciminator loss fake = 5.759795751458796e-09, generator loss = 19.81973648071289\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 13, Batch: 191/468, discriminator loss real = 4.137112093877127e-12, disciminator loss fake = 4.289061106277359e-09, generator loss = 19.692047119140625\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 13, Batch: 192/468, discriminator loss real = 1.5774026673595945e-19, disciminator loss fake = 5.779989820098308e-09, generator loss = 19.61665916442871\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 13, Batch: 193/468, discriminator loss real = 1.2442083712625822e-19, disciminator loss fake = 4.760594585206945e-09, generator loss = 19.678693771362305\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 13, Batch: 194/468, discriminator loss real = 5.537801662548747e-13, disciminator loss fake = 4.269116171684573e-09, generator loss = 19.754674911499023\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 13, Batch: 195/468, discriminator loss real = 4.5430723934333436e-14, disciminator loss fake = 4.1327479216590746e-09, generator loss = 19.781452178955078\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 13, Batch: 196/468, discriminator loss real = 3.255401353951177e-19, disciminator loss fake = 5.2728341692898084e-09, generator loss = 19.711320877075195\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 13, Batch: 197/468, discriminator loss real = 8.428173489791104e-15, disciminator loss fake = 4.825422283971648e-09, generator loss = 19.692459106445312\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 13, Batch: 198/468, discriminator loss real = 9.831434656419819e-17, disciminator loss fake = 4.9485993081077595e-09, generator loss = 19.82046127319336\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 13, Batch: 199/468, discriminator loss real = 1.7764927623388906e-19, disciminator loss fake = 3.984671703705089e-09, generator loss = 19.693279266357422\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 13, Batch: 200/468, discriminator loss real = 7.49379450501594e-15, disciminator loss fake = 3.749181409773428e-09, generator loss = 19.872318267822266\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 13, Batch: 201/468, discriminator loss real = 5.827414245596074e-11, disciminator loss fake = 5.48134337918782e-09, generator loss = 19.6695499420166\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 13, Batch: 202/468, discriminator loss real = 8.053519873554849e-13, disciminator loss fake = 3.552070859669243e-09, generator loss = 19.753002166748047\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 13, Batch: 203/468, discriminator loss real = 3.429019915235365e-11, disciminator loss fake = 4.275237053263936e-09, generator loss = 19.750011444091797\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 13, Batch: 204/468, discriminator loss real = 2.360256434741359e-10, disciminator loss fake = 5.175308182003846e-09, generator loss = 19.801956176757812\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 13, Batch: 205/468, discriminator loss real = 1.7918259649467305e-13, disciminator loss fake = 4.599928882242921e-09, generator loss = 19.854764938354492\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 13, Batch: 206/468, discriminator loss real = 1.2708456682830604e-11, disciminator loss fake = 4.905523098841513e-09, generator loss = 19.84002685546875\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 13, Batch: 207/468, discriminator loss real = 3.451618562775136e-17, disciminator loss fake = 5.9459779322423856e-09, generator loss = 19.762229919433594\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 13, Batch: 208/468, discriminator loss real = 1.1311404070346587e-11, disciminator loss fake = 5.250821111246751e-09, generator loss = 19.671119689941406\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 13, Batch: 209/468, discriminator loss real = 1.9893748107180365e-12, disciminator loss fake = 3.583235042015076e-09, generator loss = 19.805343627929688\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 13, Batch: 210/468, discriminator loss real = 2.9987168304046463e-10, disciminator loss fake = 4.1660865868209385e-09, generator loss = 19.67910385131836\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 13, Batch: 211/468, discriminator loss real = 3.1903242526075404e-13, disciminator loss fake = 4.824116217605479e-09, generator loss = 19.8557186126709\n",
      "2/2 [==============================] - 0s 136ms/step\n",
      "Epoch: 13, Batch: 212/468, discriminator loss real = 6.216149806772696e-17, disciminator loss fake = 5.678745473858271e-09, generator loss = 19.83761215209961\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 13, Batch: 213/468, discriminator loss real = 8.581755098213684e-13, disciminator loss fake = 4.681927290306476e-09, generator loss = 19.692371368408203\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 13, Batch: 214/468, discriminator loss real = 1.8230842589684812e-14, disciminator loss fake = 5.540412573168396e-09, generator loss = 19.715246200561523\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 13, Batch: 215/468, discriminator loss real = 7.321486113036685e-17, disciminator loss fake = 4.500662509343556e-09, generator loss = 19.727359771728516\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 13, Batch: 216/468, discriminator loss real = 7.943692281742187e-08, disciminator loss fake = 5.060513785792864e-09, generator loss = 19.645341873168945\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 13, Batch: 217/468, discriminator loss real = 1.5034004721475522e-14, disciminator loss fake = 4.103994921678122e-09, generator loss = 19.783329010009766\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 13, Batch: 218/468, discriminator loss real = 3.5928116758930377e-17, disciminator loss fake = 4.554831178893437e-09, generator loss = 19.696334838867188\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 13, Batch: 219/468, discriminator loss real = 6.021518682031721e-15, disciminator loss fake = 4.199890213385515e-09, generator loss = 19.715517044067383\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 13, Batch: 220/468, discriminator loss real = 1.6358914223246757e-11, disciminator loss fake = 4.415768195542569e-09, generator loss = 19.64163589477539\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 13, Batch: 221/468, discriminator loss real = 4.87171719591316e-15, disciminator loss fake = 8.446125576710983e-09, generator loss = 19.720230102539062\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 13, Batch: 222/468, discriminator loss real = 3.971880983832943e-12, disciminator loss fake = 4.4166812429580204e-09, generator loss = 19.718660354614258\n",
      "2/2 [==============================] - 0s 188ms/step\n",
      "Epoch: 13, Batch: 223/468, discriminator loss real = 1.145775401639737e-11, disciminator loss fake = 5.0857913436175295e-09, generator loss = 19.743099212646484\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 13, Batch: 224/468, discriminator loss real = 4.81999097752539e-13, disciminator loss fake = 4.008645415609635e-09, generator loss = 19.657148361206055\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 13, Batch: 225/468, discriminator loss real = 5.673224186895351e-17, disciminator loss fake = 4.496482297611237e-09, generator loss = 19.711166381835938\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 13, Batch: 226/468, discriminator loss real = 1.3211255700529279e-10, disciminator loss fake = 4.228825289942506e-09, generator loss = 19.71950340270996\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 13, Batch: 227/468, discriminator loss real = 1.1802202180236521e-14, disciminator loss fake = 4.802741315756975e-09, generator loss = 19.749874114990234\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 13, Batch: 228/468, discriminator loss real = 1.1001077571690457e-13, disciminator loss fake = 4.025207722690993e-09, generator loss = 19.761554718017578\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 13, Batch: 229/468, discriminator loss real = 2.5242275336403715e-16, disciminator loss fake = 6.298676247240564e-09, generator loss = 19.656692504882812\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 13, Batch: 230/468, discriminator loss real = 5.727854713970248e-13, disciminator loss fake = 4.093720917808241e-09, generator loss = 19.76884651184082\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 13, Batch: 231/468, discriminator loss real = 1.1524352999670029e-10, disciminator loss fake = 4.763934136065018e-09, generator loss = 19.763185501098633\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 13, Batch: 232/468, discriminator loss real = 7.975206606225527e-11, disciminator loss fake = 3.798580561209519e-09, generator loss = 19.66753578186035\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 13, Batch: 233/468, discriminator loss real = 1.67003067288577e-17, disciminator loss fake = 6.772988392356183e-09, generator loss = 19.730941772460938\n",
      "2/2 [==============================] - 0s 172ms/step\n",
      "Epoch: 13, Batch: 234/468, discriminator loss real = 1.865772869535931e-09, disciminator loss fake = 5.352706722305811e-09, generator loss = 19.794151306152344\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 13, Batch: 235/468, discriminator loss real = 6.700373661125154e-16, disciminator loss fake = 5.148443449343176e-09, generator loss = 19.91183090209961\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 13, Batch: 236/468, discriminator loss real = 5.669321535530436e-15, disciminator loss fake = 4.553137866736279e-09, generator loss = 19.577823638916016\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 13, Batch: 237/468, discriminator loss real = 1.6958059119404978e-15, disciminator loss fake = 5.1158126623818134e-09, generator loss = 19.502534866333008\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 13, Batch: 238/468, discriminator loss real = 3.3058446888610387e-18, disciminator loss fake = 7.67025376546826e-09, generator loss = 19.707921981811523\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 13, Batch: 239/468, discriminator loss real = 1.349082304202831e-12, disciminator loss fake = 4.1849324006193456e-09, generator loss = 19.97245979309082\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 13, Batch: 240/468, discriminator loss real = 2.8264635423824735e-11, disciminator loss fake = 6.577207223301684e-09, generator loss = 19.61892318725586\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 13, Batch: 241/468, discriminator loss real = 1.7176458410921611e-19, disciminator loss fake = 4.406989440042253e-09, generator loss = 19.811786651611328\n",
      "2/2 [==============================] - 0s 187ms/step\n",
      "Epoch: 13, Batch: 242/468, discriminator loss real = 3.239192123808186e-22, disciminator loss fake = 4.3668366700444494e-09, generator loss = 19.72509765625\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 13, Batch: 243/468, discriminator loss real = 8.848252534311707e-13, disciminator loss fake = 5.726379814774418e-09, generator loss = 19.77035903930664\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 13, Batch: 244/468, discriminator loss real = 4.561027111549265e-10, disciminator loss fake = 4.513586837617822e-09, generator loss = 19.68282127380371\n",
      "2/2 [==============================] - 0s 135ms/step\n",
      "Epoch: 13, Batch: 245/468, discriminator loss real = 1.9917440432925488e-17, disciminator loss fake = 5.2892841218010744e-09, generator loss = 19.755260467529297\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 13, Batch: 246/468, discriminator loss real = 1.418088601190179e-13, disciminator loss fake = 4.133970055164582e-09, generator loss = 19.884994506835938\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 13, Batch: 247/468, discriminator loss real = 1.0770313460528591e-11, disciminator loss fake = 3.946539095522894e-09, generator loss = 19.859844207763672\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 13, Batch: 248/468, discriminator loss real = 1.232372884296673e-11, disciminator loss fake = 4.031101674684123e-09, generator loss = 19.791454315185547\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 13, Batch: 249/468, discriminator loss real = 1.4859510852143452e-14, disciminator loss fake = 5.972727201708494e-09, generator loss = 19.80556869506836\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 13, Batch: 250/468, discriminator loss real = 1.4121401259708372e-13, disciminator loss fake = 4.3580841158075145e-09, generator loss = 19.841556549072266\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 13, Batch: 251/468, discriminator loss real = 1.6276457959207846e-10, disciminator loss fake = 5.212056564118939e-09, generator loss = 19.816410064697266\n",
      "2/2 [==============================] - 0s 152ms/step\n",
      "Epoch: 13, Batch: 252/468, discriminator loss real = 3.4682346360478565e-15, disciminator loss fake = 4.413818199822117e-09, generator loss = 19.76659393310547\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 13, Batch: 253/468, discriminator loss real = 1.2524441928007946e-08, disciminator loss fake = 5.384791723628268e-09, generator loss = 19.767423629760742\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 13, Batch: 254/468, discriminator loss real = 9.076176767618127e-13, disciminator loss fake = 3.995107800136566e-09, generator loss = 19.696977615356445\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 13, Batch: 255/468, discriminator loss real = 1.4540465728164753e-14, disciminator loss fake = 4.577130230387638e-09, generator loss = 19.674636840820312\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 13, Batch: 256/468, discriminator loss real = 1.2700674589276677e-19, disciminator loss fake = 4.171730516588923e-09, generator loss = 19.897939682006836\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 13, Batch: 257/468, discriminator loss real = 8.155427603608354e-18, disciminator loss fake = 6.066596558440551e-09, generator loss = 19.798812866210938\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 13, Batch: 258/468, discriminator loss real = 4.105482006813398e-17, disciminator loss fake = 3.9647503058404254e-09, generator loss = 19.804515838623047\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 13, Batch: 259/468, discriminator loss real = 1.1360418028516506e-07, disciminator loss fake = 4.646324214263586e-09, generator loss = 19.736221313476562\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 13, Batch: 260/468, discriminator loss real = 2.6279800276023113e-13, disciminator loss fake = 4.174763201802989e-09, generator loss = 19.961200714111328\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 13, Batch: 261/468, discriminator loss real = 3.5786227225911155e-15, disciminator loss fake = 4.787350516011202e-09, generator loss = 19.977367401123047\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 13, Batch: 262/468, discriminator loss real = 2.8529133536906587e-14, disciminator loss fake = 4.4093297901781625e-09, generator loss = 19.712512969970703\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 13, Batch: 263/468, discriminator loss real = 3.687175712254148e-16, disciminator loss fake = 5.638017164244502e-09, generator loss = 19.88179588317871\n",
      "2/2 [==============================] - 0s 191ms/step\n",
      "Epoch: 13, Batch: 264/468, discriminator loss real = 1.7173082668230219e-15, disciminator loss fake = 3.6478340348367055e-09, generator loss = 19.905658721923828\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 13, Batch: 265/468, discriminator loss real = 3.1988769814451923e-13, disciminator loss fake = 5.817939907615255e-09, generator loss = 19.704252243041992\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 13, Batch: 266/468, discriminator loss real = 7.610998284520928e-14, disciminator loss fake = 4.274647746882465e-09, generator loss = 19.703548431396484\n",
      "2/2 [==============================] - 0s 179ms/step\n",
      "Epoch: 13, Batch: 267/468, discriminator loss real = 4.655401064646014e-11, disciminator loss fake = 4.944561649011803e-09, generator loss = 19.668262481689453\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 13, Batch: 268/468, discriminator loss real = 5.009025286539361e-19, disciminator loss fake = 6.370317162662786e-09, generator loss = 19.75979995727539\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 13, Batch: 269/468, discriminator loss real = 6.517334849802108e-19, disciminator loss fake = 3.861779784841701e-09, generator loss = 19.951278686523438\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 13, Batch: 270/468, discriminator loss real = 3.0307518647521015e-12, disciminator loss fake = 4.42476766338018e-09, generator loss = 19.81941795349121\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 13, Batch: 271/468, discriminator loss real = 1.2211560709908553e-15, disciminator loss fake = 4.073329673559556e-09, generator loss = 19.764266967773438\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 13, Batch: 272/468, discriminator loss real = 5.896160466878115e-19, disciminator loss fake = 4.285783283819455e-09, generator loss = 19.91710662841797\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 13, Batch: 273/468, discriminator loss real = 5.169684667329089e-13, disciminator loss fake = 4.48065851088586e-09, generator loss = 19.84332275390625\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 13, Batch: 274/468, discriminator loss real = 1.0423818232302322e-17, disciminator loss fake = 4.582566326405413e-09, generator loss = 19.82741928100586\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 13, Batch: 275/468, discriminator loss real = 7.380822590789196e-18, disciminator loss fake = 4.058810176843508e-09, generator loss = 19.683185577392578\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 13, Batch: 276/468, discriminator loss real = 6.464042490291963e-14, disciminator loss fake = 3.331932507677493e-09, generator loss = 19.79751968383789\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 13, Batch: 277/468, discriminator loss real = 7.336979536782048e-18, disciminator loss fake = 5.609317010879522e-09, generator loss = 19.68722915649414\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 13, Batch: 278/468, discriminator loss real = 1.978062462090757e-12, disciminator loss fake = 4.849374235504911e-09, generator loss = 19.734081268310547\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 13, Batch: 279/468, discriminator loss real = 5.2686967195641516e-18, disciminator loss fake = 5.956647619598243e-09, generator loss = 19.806690216064453\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 13, Batch: 280/468, discriminator loss real = 2.692922880113334e-17, disciminator loss fake = 3.4906699752923487e-09, generator loss = 19.78230857849121\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 13, Batch: 281/468, discriminator loss real = 1.0321551149579736e-13, disciminator loss fake = 4.111637696979642e-09, generator loss = 19.813495635986328\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 13, Batch: 282/468, discriminator loss real = 3.435139170758883e-19, disciminator loss fake = 4.864762814804635e-09, generator loss = 19.94382095336914\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 13, Batch: 283/468, discriminator loss real = 1.6014918341120121e-12, disciminator loss fake = 3.2856917187018553e-09, generator loss = 19.7783260345459\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 13, Batch: 284/468, discriminator loss real = 1.456117154947642e-18, disciminator loss fake = 3.892514754966214e-09, generator loss = 19.70892906188965\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 13, Batch: 285/468, discriminator loss real = 1.5160239730249714e-10, disciminator loss fake = 3.963095629444524e-09, generator loss = 19.84403419494629\n",
      "2/2 [==============================] - 0s 159ms/step\n",
      "Epoch: 13, Batch: 286/468, discriminator loss real = 9.572559682519632e-16, disciminator loss fake = 4.401423225885992e-09, generator loss = 19.85222816467285\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 13, Batch: 287/468, discriminator loss real = 4.711174890958611e-14, disciminator loss fake = 4.227456606997748e-09, generator loss = 19.831668853759766\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 13, Batch: 288/468, discriminator loss real = 3.581226515105865e-17, disciminator loss fake = 4.556643506958835e-09, generator loss = 19.88542938232422\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 13, Batch: 289/468, discriminator loss real = 1.1913150587544719e-12, disciminator loss fake = 3.2007569927827717e-09, generator loss = 19.681835174560547\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 13, Batch: 290/468, discriminator loss real = 2.549569700631036e-16, disciminator loss fake = 4.909959994137125e-09, generator loss = 19.77304458618164\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 13, Batch: 291/468, discriminator loss real = 1.2596620968530203e-10, disciminator loss fake = 4.835980504935833e-09, generator loss = 19.94301986694336\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 13, Batch: 292/468, discriminator loss real = 3.340589794804255e-13, disciminator loss fake = 5.347926101961775e-09, generator loss = 19.855281829833984\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 13, Batch: 293/468, discriminator loss real = 6.84087863938275e-14, disciminator loss fake = 4.923045970883777e-09, generator loss = 19.91149139404297\n",
      "2/2 [==============================] - 0s 159ms/step\n",
      "Epoch: 13, Batch: 294/468, discriminator loss real = 2.2331683147114832e-14, disciminator loss fake = 3.521741565037928e-09, generator loss = 19.870277404785156\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 13, Batch: 295/468, discriminator loss real = 4.659722043984238e-14, disciminator loss fake = 4.566189204524562e-09, generator loss = 19.850746154785156\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 13, Batch: 296/468, discriminator loss real = 4.495978402324651e-19, disciminator loss fake = 4.077102211397232e-09, generator loss = 19.85207748413086\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 13, Batch: 297/468, discriminator loss real = 7.350464671879251e-15, disciminator loss fake = 2.9737243778527045e-09, generator loss = 19.79701042175293\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 13, Batch: 298/468, discriminator loss real = 1.1230054929530528e-15, disciminator loss fake = 4.34361524526139e-09, generator loss = 19.746986389160156\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 13, Batch: 299/468, discriminator loss real = 6.324261072062458e-18, disciminator loss fake = 4.3120218506942365e-09, generator loss = 19.88799285888672\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 13, Batch: 300/468, discriminator loss real = 9.987008880204661e-15, disciminator loss fake = 4.382640472755384e-09, generator loss = 19.882022857666016\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 13, Batch: 301/468, discriminator loss real = 1.6372567843996838e-17, disciminator loss fake = 5.198474983814094e-09, generator loss = 19.901569366455078\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 13, Batch: 302/468, discriminator loss real = 4.6878445542726174e-14, disciminator loss fake = 3.841513773750194e-09, generator loss = 19.95778465270996\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch: 13, Batch: 303/468, discriminator loss real = 1.4552018622290591e-15, disciminator loss fake = 5.124516810894875e-09, generator loss = 19.893890380859375\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 13, Batch: 304/468, discriminator loss real = 8.75237986345011e-18, disciminator loss fake = 4.9070121299621405e-09, generator loss = 19.86196517944336\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 13, Batch: 305/468, discriminator loss real = 9.850291833287186e-15, disciminator loss fake = 3.2957618856244153e-09, generator loss = 19.86207389831543\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 13, Batch: 306/468, discriminator loss real = 3.641257845252436e-19, disciminator loss fake = 3.2026381546756966e-09, generator loss = 19.807979583740234\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 13, Batch: 307/468, discriminator loss real = 1.1846667744008776e-11, disciminator loss fake = 4.915060802801463e-09, generator loss = 19.75444793701172\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 13, Batch: 308/468, discriminator loss real = 6.431435245479733e-12, disciminator loss fake = 3.78806408463106e-09, generator loss = 19.781455993652344\n",
      "2/2 [==============================] - 0s 174ms/step\n",
      "Epoch: 13, Batch: 309/468, discriminator loss real = 9.97361546454814e-19, disciminator loss fake = 4.142275411567198e-09, generator loss = 19.845319747924805\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 13, Batch: 310/468, discriminator loss real = 2.2441224226121825e-11, disciminator loss fake = 3.995543451651429e-09, generator loss = 19.897106170654297\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 13, Batch: 311/468, discriminator loss real = 9.7266255374944e-19, disciminator loss fake = 2.4936177567269624e-09, generator loss = 20.004850387573242\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 13, Batch: 312/468, discriminator loss real = 5.751864495884951e-19, disciminator loss fake = 4.863857760994961e-09, generator loss = 20.033647537231445\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 13, Batch: 313/468, discriminator loss real = 2.8783002863725857e-14, disciminator loss fake = 4.74710448727933e-09, generator loss = 19.94333839416504\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 13, Batch: 314/468, discriminator loss real = 8.117170997856693e-12, disciminator loss fake = 3.490094435676383e-09, generator loss = 19.951805114746094\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 13, Batch: 315/468, discriminator loss real = 1.0771779400121613e-15, disciminator loss fake = 4.429304034658799e-09, generator loss = 19.906856536865234\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 13, Batch: 316/468, discriminator loss real = 1.1075179454987611e-16, disciminator loss fake = 4.157199029464209e-09, generator loss = 19.878116607666016\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 13, Batch: 317/468, discriminator loss real = 1.6971908253782253e-11, disciminator loss fake = 3.798166225976729e-09, generator loss = 19.950904846191406\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 13, Batch: 318/468, discriminator loss real = 1.8054534375779724e-14, disciminator loss fake = 5.761312316110434e-09, generator loss = 19.998981475830078\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 13, Batch: 319/468, discriminator loss real = 2.502231382095488e-07, disciminator loss fake = 3.119913216664827e-09, generator loss = 19.983957290649414\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 13, Batch: 320/468, discriminator loss real = 1.8794159561963397e-09, disciminator loss fake = 4.135463083088098e-09, generator loss = 19.716257095336914\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 13, Batch: 321/468, discriminator loss real = 1.0670822949213066e-12, disciminator loss fake = 5.3620148321442684e-09, generator loss = 19.76880645751953\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 13, Batch: 322/468, discriminator loss real = 1.2396897744459956e-13, disciminator loss fake = 3.701353223917181e-09, generator loss = 19.872814178466797\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 13, Batch: 323/468, discriminator loss real = 1.1487807372034808e-09, disciminator loss fake = 4.1967265218545435e-09, generator loss = 19.93816375732422\n",
      "2/2 [==============================] - 0s 130ms/step\n",
      "Epoch: 13, Batch: 324/468, discriminator loss real = 1.8133130457076332e-16, disciminator loss fake = 4.6806425402223795e-09, generator loss = 19.818225860595703\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 13, Batch: 325/468, discriminator loss real = 2.0173818941326277e-13, disciminator loss fake = 5.840743888541056e-09, generator loss = 19.626373291015625\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 13, Batch: 326/468, discriminator loss real = 5.258930198071738e-18, disciminator loss fake = 3.754078825579654e-09, generator loss = 19.733646392822266\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 13, Batch: 327/468, discriminator loss real = 2.7640497719414944e-14, disciminator loss fake = 5.2404818262630215e-09, generator loss = 19.621498107910156\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 13, Batch: 328/468, discriminator loss real = 5.868306600202711e-14, disciminator loss fake = 5.461211038948477e-09, generator loss = 19.80254554748535\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 13, Batch: 329/468, discriminator loss real = 1.9772326679580454e-13, disciminator loss fake = 6.372533611909148e-09, generator loss = 19.779396057128906\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 13, Batch: 330/468, discriminator loss real = 2.3108541989669273e-12, disciminator loss fake = 3.859728536781404e-09, generator loss = 19.48810577392578\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 13, Batch: 331/468, discriminator loss real = 1.2638364543917349e-21, disciminator loss fake = 4.63757565682954e-09, generator loss = 19.737659454345703\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 13, Batch: 332/468, discriminator loss real = 6.686363312661094e-15, disciminator loss fake = 4.786425478187084e-09, generator loss = 19.487369537353516\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 13, Batch: 333/468, discriminator loss real = 8.738206818485728e-16, disciminator loss fake = 6.4124074938831654e-09, generator loss = 19.771907806396484\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 13, Batch: 334/468, discriminator loss real = 1.4547190492139594e-13, disciminator loss fake = 5.065940555937232e-09, generator loss = 19.747024536132812\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 13, Batch: 335/468, discriminator loss real = 2.3886706306930594e-17, disciminator loss fake = 4.117666208003357e-09, generator loss = 19.668048858642578\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 13, Batch: 336/468, discriminator loss real = 2.1875411485900885e-15, disciminator loss fake = 5.852971440845067e-09, generator loss = 19.745708465576172\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 13, Batch: 337/468, discriminator loss real = 1.7162635787375258e-14, disciminator loss fake = 4.208919435200187e-09, generator loss = 19.69263458251953\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 13, Batch: 338/468, discriminator loss real = 1.4687046473753004e-14, disciminator loss fake = 4.5565089479282506e-09, generator loss = 19.808361053466797\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 13, Batch: 339/468, discriminator loss real = 4.3734520128665966e-14, disciminator loss fake = 4.238461137617833e-09, generator loss = 19.754743576049805\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 13, Batch: 340/468, discriminator loss real = 1.1311714759321134e-10, disciminator loss fake = 4.477468174002297e-09, generator loss = 19.831893920898438\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 13, Batch: 341/468, discriminator loss real = 1.9566818868291258e-13, disciminator loss fake = 5.446177731016633e-09, generator loss = 19.508899688720703\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 13, Batch: 342/468, discriminator loss real = 9.13550309076909e-14, disciminator loss fake = 5.784380086026886e-09, generator loss = 19.690736770629883\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 13, Batch: 343/468, discriminator loss real = 6.100706627600223e-16, disciminator loss fake = 6.102965244281222e-09, generator loss = 19.785140991210938\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 13, Batch: 344/468, discriminator loss real = 3.4725513277053012e-15, disciminator loss fake = 4.720393853574478e-09, generator loss = 19.79584503173828\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 13, Batch: 345/468, discriminator loss real = 4.557441923846994e-11, disciminator loss fake = 3.5822391719619873e-09, generator loss = 19.640222549438477\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 13, Batch: 346/468, discriminator loss real = 3.579399534211616e-20, disciminator loss fake = 4.634246764112504e-09, generator loss = 19.72164535522461\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 13, Batch: 347/468, discriminator loss real = 2.816612740296539e-14, disciminator loss fake = 6.990805268003442e-09, generator loss = 19.79678726196289\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 13, Batch: 348/468, discriminator loss real = 6.204622926553327e-11, disciminator loss fake = 4.9106523292152815e-09, generator loss = 19.72821617126465\n",
      "2/2 [==============================] - 0s 161ms/step\n",
      "Epoch: 13, Batch: 349/468, discriminator loss real = 4.2022961521488906e-16, disciminator loss fake = 3.857685282326884e-09, generator loss = 19.650936126708984\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 13, Batch: 350/468, discriminator loss real = 7.193878197135628e-13, disciminator loss fake = 4.022278066173612e-09, generator loss = 19.765125274658203\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 13, Batch: 351/468, discriminator loss real = 2.095125850587465e-09, disciminator loss fake = 5.182289264382689e-09, generator loss = 19.76401710510254\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 13, Batch: 352/468, discriminator loss real = 2.7939969782231344e-11, disciminator loss fake = 4.962816380071899e-09, generator loss = 19.4642391204834\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 13, Batch: 353/468, discriminator loss real = 5.982739951989423e-17, disciminator loss fake = 5.167771099934271e-09, generator loss = 19.780303955078125\n",
      "2/2 [==============================] - 0s 174ms/step\n",
      "Epoch: 13, Batch: 354/468, discriminator loss real = 7.086301857611788e-20, disciminator loss fake = 4.709235668087786e-09, generator loss = 19.74576187133789\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 13, Batch: 355/468, discriminator loss real = 2.5074657045262745e-15, disciminator loss fake = 4.720872581742697e-09, generator loss = 19.668697357177734\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 13, Batch: 356/468, discriminator loss real = 6.363930910024962e-11, disciminator loss fake = 4.678177845107712e-09, generator loss = 19.640342712402344\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 13, Batch: 357/468, discriminator loss real = 2.7657304002559613e-08, disciminator loss fake = 3.8383478617731726e-09, generator loss = 19.79351043701172\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 13, Batch: 358/468, discriminator loss real = 3.5824821752757205e-17, disciminator loss fake = 3.964138350909252e-09, generator loss = 19.75965690612793\n",
      "2/2 [==============================] - 0s 161ms/step\n",
      "Epoch: 13, Batch: 359/468, discriminator loss real = 1.7850813052267494e-16, disciminator loss fake = 5.38914113334954e-09, generator loss = 19.698684692382812\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 13, Batch: 360/468, discriminator loss real = 2.222656466429468e-13, disciminator loss fake = 5.384229950777808e-09, generator loss = 19.702796936035156\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 13, Batch: 361/468, discriminator loss real = 2.939422040909646e-17, disciminator loss fake = 3.996473374456855e-09, generator loss = 19.7813777923584\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 13, Batch: 362/468, discriminator loss real = 4.967270084837994e-13, disciminator loss fake = 4.193889679982021e-09, generator loss = 19.651851654052734\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 13, Batch: 363/468, discriminator loss real = 2.1500597537312672e-18, disciminator loss fake = 4.332864733669339e-09, generator loss = 19.677204132080078\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 13, Batch: 364/468, discriminator loss real = 2.3188404321694556e-12, disciminator loss fake = 4.580155366085137e-09, generator loss = 19.753786087036133\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 13, Batch: 365/468, discriminator loss real = 2.1739959204757448e-17, disciminator loss fake = 6.029688748299122e-09, generator loss = 19.872180938720703\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 13, Batch: 366/468, discriminator loss real = 1.1033788466230376e-11, disciminator loss fake = 6.361879023586425e-09, generator loss = 19.68344497680664\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 13, Batch: 367/468, discriminator loss real = 2.697133281130017e-19, disciminator loss fake = 5.727690322032686e-09, generator loss = 19.833171844482422\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 13, Batch: 368/468, discriminator loss real = 1.818400834098124e-20, disciminator loss fake = 4.787401142181125e-09, generator loss = 19.767719268798828\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 13, Batch: 369/468, discriminator loss real = 1.2274447082890672e-17, disciminator loss fake = 4.958694788115281e-09, generator loss = 19.790618896484375\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 13, Batch: 370/468, discriminator loss real = 2.900551503083777e-14, disciminator loss fake = 4.634232553257789e-09, generator loss = 19.643077850341797\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 13, Batch: 371/468, discriminator loss real = 6.958918292175912e-17, disciminator loss fake = 3.797742564870532e-09, generator loss = 19.65550994873047\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 13, Batch: 372/468, discriminator loss real = 4.385100962900346e-11, disciminator loss fake = 3.6654439483641e-09, generator loss = 19.763347625732422\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 13, Batch: 373/468, discriminator loss real = 9.49096266937002e-15, disciminator loss fake = 3.8608374275383994e-09, generator loss = 19.922792434692383\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 13, Batch: 374/468, discriminator loss real = 9.811186693804708e-14, disciminator loss fake = 3.6591991658951883e-09, generator loss = 19.846027374267578\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 13, Batch: 375/468, discriminator loss real = 2.2575081452640144e-14, disciminator loss fake = 4.939098463552227e-09, generator loss = 19.7396297454834\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 13, Batch: 376/468, discriminator loss real = 5.766041130813191e-17, disciminator loss fake = 3.7225964533149636e-09, generator loss = 19.807666778564453\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 13, Batch: 377/468, discriminator loss real = 3.7387411722588585e-15, disciminator loss fake = 5.843327599563963e-09, generator loss = 19.680736541748047\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 13, Batch: 378/468, discriminator loss real = 8.925802805204164e-14, disciminator loss fake = 3.910974655241262e-09, generator loss = 19.88349151611328\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 13, Batch: 379/468, discriminator loss real = 3.216509947279178e-09, disciminator loss fake = 4.6450985280444e-09, generator loss = 19.886240005493164\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 13, Batch: 380/468, discriminator loss real = 4.206403021039806e-12, disciminator loss fake = 5.2605129141625184e-09, generator loss = 19.718042373657227\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 13, Batch: 381/468, discriminator loss real = 1.1724483851720757e-20, disciminator loss fake = 5.823445281549766e-09, generator loss = 19.898590087890625\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 13, Batch: 382/468, discriminator loss real = 6.478693991875117e-13, disciminator loss fake = 4.518324825397713e-09, generator loss = 19.807083129882812\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 13, Batch: 383/468, discriminator loss real = 5.958669972369601e-13, disciminator loss fake = 4.5848684848692756e-09, generator loss = 19.83647918701172\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 13, Batch: 384/468, discriminator loss real = 9.9435359945943e-10, disciminator loss fake = 4.2302250591319535e-09, generator loss = 19.849340438842773\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 13, Batch: 385/468, discriminator loss real = 3.4303106416586765e-14, disciminator loss fake = 4.178652535102856e-09, generator loss = 19.78875160217285\n",
      "2/2 [==============================] - 0s 170ms/step\n",
      "Epoch: 13, Batch: 386/468, discriminator loss real = 1.3994610732520474e-18, disciminator loss fake = 3.9530387851982596e-09, generator loss = 19.847702026367188\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 13, Batch: 387/468, discriminator loss real = 2.006798319100639e-13, disciminator loss fake = 3.941201587309706e-09, generator loss = 19.846914291381836\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 13, Batch: 388/468, discriminator loss real = 2.976343082114828e-18, disciminator loss fake = 4.261832664553822e-09, generator loss = 19.964521408081055\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 13, Batch: 389/468, discriminator loss real = 6.865627177887745e-09, disciminator loss fake = 4.165406686240658e-09, generator loss = 20.018756866455078\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 13, Batch: 390/468, discriminator loss real = 7.526985721682395e-21, disciminator loss fake = 3.7194751723035324e-09, generator loss = 19.79798698425293\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 13, Batch: 391/468, discriminator loss real = 4.255442241807627e-18, disciminator loss fake = 5.804708269607772e-09, generator loss = 19.758056640625\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 13, Batch: 392/468, discriminator loss real = 1.2135186925428185e-14, disciminator loss fake = 4.169360856565163e-09, generator loss = 19.955537796020508\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 13, Batch: 393/468, discriminator loss real = 6.306691551372784e-14, disciminator loss fake = 7.210409602720347e-09, generator loss = 19.902883529663086\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 13, Batch: 394/468, discriminator loss real = 7.627666537670177e-14, disciminator loss fake = 3.2721261256085654e-09, generator loss = 19.928611755371094\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 13, Batch: 395/468, discriminator loss real = 1.2822272269560203e-13, disciminator loss fake = 4.597891400948129e-09, generator loss = 19.877670288085938\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 13, Batch: 396/468, discriminator loss real = 2.896037793256867e-12, disciminator loss fake = 4.16412770931629e-09, generator loss = 19.88662338256836\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 13, Batch: 397/468, discriminator loss real = 5.7303933521813e-16, disciminator loss fake = 3.2838396446521756e-09, generator loss = 20.031505584716797\n",
      "2/2 [==============================] - 0s 170ms/step\n",
      "Epoch: 13, Batch: 398/468, discriminator loss real = 8.63358253703865e-14, disciminator loss fake = 3.552499627801353e-09, generator loss = 19.849319458007812\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 13, Batch: 399/468, discriminator loss real = 1.5021094368350418e-09, disciminator loss fake = 3.428506145652932e-09, generator loss = 20.03219223022461\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 13, Batch: 400/468, discriminator loss real = 3.211455522752919e-18, disciminator loss fake = 3.5129348319173914e-09, generator loss = 19.858417510986328\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 13, Batch: 401/468, discriminator loss real = 6.306923366423346e-18, disciminator loss fake = 5.312826623082856e-09, generator loss = 19.848909378051758\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 13, Batch: 402/468, discriminator loss real = 4.199181717880955e-16, disciminator loss fake = 5.72163694201322e-09, generator loss = 19.873252868652344\n",
      "2/2 [==============================] - 0s 158ms/step\n",
      "Epoch: 13, Batch: 403/468, discriminator loss real = 1.0047967512077948e-15, disciminator loss fake = 3.269230663960343e-09, generator loss = 19.9769287109375\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 13, Batch: 404/468, discriminator loss real = 1.193378285080371e-09, disciminator loss fake = 2.987447622615491e-09, generator loss = 19.814048767089844\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 13, Batch: 405/468, discriminator loss real = 1.4646275654567662e-16, disciminator loss fake = 5.521349599746372e-09, generator loss = 19.82313346862793\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 13, Batch: 406/468, discriminator loss real = 9.03005358747315e-14, disciminator loss fake = 3.78255338162603e-09, generator loss = 19.857990264892578\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 13, Batch: 407/468, discriminator loss real = 7.151441575427644e-15, disciminator loss fake = 3.626750899599074e-09, generator loss = 19.994857788085938\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 13, Batch: 408/468, discriminator loss real = 4.986529547298165e-15, disciminator loss fake = 5.074467068766353e-09, generator loss = 19.983318328857422\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 13, Batch: 409/468, discriminator loss real = 4.470214261552202e-16, disciminator loss fake = 4.495517735847443e-09, generator loss = 19.912633895874023\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 13, Batch: 410/468, discriminator loss real = 1.322097636445136e-19, disciminator loss fake = 4.682994436677745e-09, generator loss = 19.855024337768555\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 13, Batch: 411/468, discriminator loss real = 1.3647423306468315e-13, disciminator loss fake = 6.474791813815273e-09, generator loss = 19.85139274597168\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 13, Batch: 412/468, discriminator loss real = 1.3867824943947227e-10, disciminator loss fake = 3.951569294002866e-09, generator loss = 20.023975372314453\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 13, Batch: 413/468, discriminator loss real = 8.836464757949595e-17, disciminator loss fake = 4.92810237062713e-09, generator loss = 19.850908279418945\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 13, Batch: 414/468, discriminator loss real = 6.65708200370263e-12, disciminator loss fake = 4.179346202448642e-09, generator loss = 19.86919593811035\n",
      "2/2 [==============================] - 0s 175ms/step\n",
      "Epoch: 13, Batch: 415/468, discriminator loss real = 1.1912892276377124e-13, disciminator loss fake = 4.009442555741316e-09, generator loss = 19.95594024658203\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 13, Batch: 416/468, discriminator loss real = 4.657035174160384e-12, disciminator loss fake = 3.1515741127918773e-09, generator loss = 19.955360412597656\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 13, Batch: 417/468, discriminator loss real = 1.3349061439571486e-12, disciminator loss fake = 4.299376410443756e-09, generator loss = 20.046409606933594\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 13, Batch: 418/468, discriminator loss real = 1.3719100651921671e-18, disciminator loss fake = 3.540448378913652e-09, generator loss = 19.906503677368164\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 13, Batch: 419/468, discriminator loss real = 3.1737947773363695e-13, disciminator loss fake = 4.09088096731125e-09, generator loss = 19.902297973632812\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 13, Batch: 420/468, discriminator loss real = 2.651206077591839e-13, disciminator loss fake = 3.8671519320132575e-09, generator loss = 20.113557815551758\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 13, Batch: 421/468, discriminator loss real = 7.077381249684465e-15, disciminator loss fake = 2.584725100618357e-09, generator loss = 19.977174758911133\n",
      "2/2 [==============================] - 0s 134ms/step\n",
      "Epoch: 13, Batch: 422/468, discriminator loss real = 5.866910326442474e-20, disciminator loss fake = 4.183273283331346e-09, generator loss = 19.915061950683594\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 13, Batch: 423/468, discriminator loss real = 2.0830273116366544e-18, disciminator loss fake = 3.237124124311208e-09, generator loss = 19.926042556762695\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 13, Batch: 424/468, discriminator loss real = 2.597639117696282e-11, disciminator loss fake = 4.055760172150258e-09, generator loss = 20.028650283813477\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 13, Batch: 425/468, discriminator loss real = 1.158975594091154e-16, disciminator loss fake = 3.5986196245119118e-09, generator loss = 19.80943489074707\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 13, Batch: 426/468, discriminator loss real = 2.035960579272432e-14, disciminator loss fake = 4.41866587763684e-09, generator loss = 20.043092727661133\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 13, Batch: 427/468, discriminator loss real = 2.0536009958521673e-12, disciminator loss fake = 5.83631720729727e-09, generator loss = 19.79752540588379\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 13, Batch: 428/468, discriminator loss real = 1.5838205413842843e-08, disciminator loss fake = 4.55425874790194e-09, generator loss = 19.99565315246582\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 13, Batch: 429/468, discriminator loss real = 2.1750645989165873e-12, disciminator loss fake = 4.235784611950066e-09, generator loss = 19.97766876220703\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 13, Batch: 430/468, discriminator loss real = 5.579307026588366e-16, disciminator loss fake = 4.3805705729482725e-09, generator loss = 19.904037475585938\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 13, Batch: 431/468, discriminator loss real = 2.0091874344818628e-11, disciminator loss fake = 4.2481200779320716e-09, generator loss = 20.163833618164062\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 13, Batch: 432/468, discriminator loss real = 5.357475768086924e-15, disciminator loss fake = 3.221403144237911e-09, generator loss = 19.97134780883789\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 13, Batch: 433/468, discriminator loss real = 6.663614972313159e-13, disciminator loss fake = 4.058380298488373e-09, generator loss = 19.88587188720703\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 13, Batch: 434/468, discriminator loss real = 3.1511099475188195e-14, disciminator loss fake = 5.257029034311245e-09, generator loss = 20.057300567626953\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 13, Batch: 435/468, discriminator loss real = 4.238038808779265e-09, disciminator loss fake = 4.325948044225925e-09, generator loss = 19.845972061157227\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 13, Batch: 436/468, discriminator loss real = 2.6904021630018643e-15, disciminator loss fake = 4.5193413455990594e-09, generator loss = 19.876129150390625\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 13, Batch: 437/468, discriminator loss real = 1.670374044160719e-14, disciminator loss fake = 5.694599014560708e-09, generator loss = 20.053932189941406\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 13, Batch: 438/468, discriminator loss real = 8.524380762489668e-17, disciminator loss fake = 3.676671855856739e-09, generator loss = 19.932147979736328\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 13, Batch: 439/468, discriminator loss real = 9.215187640743139e-12, disciminator loss fake = 3.1582723103440458e-09, generator loss = 20.180137634277344\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 13, Batch: 440/468, discriminator loss real = 2.5902560096824345e-08, disciminator loss fake = 3.3469942373187678e-09, generator loss = 19.9081974029541\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 13, Batch: 441/468, discriminator loss real = 9.271745476966536e-19, disciminator loss fake = 5.373871125868845e-09, generator loss = 19.991653442382812\n",
      "2/2 [==============================] - 0s 146ms/step\n",
      "Epoch: 13, Batch: 442/468, discriminator loss real = 2.1960539595838127e-22, disciminator loss fake = 4.96346741485354e-09, generator loss = 19.963592529296875\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 13, Batch: 443/468, discriminator loss real = 1.090314497758163e-13, disciminator loss fake = 3.773250600858091e-09, generator loss = 19.98727035522461\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 13, Batch: 444/468, discriminator loss real = 8.333113523219596e-15, disciminator loss fake = 4.191127001007544e-09, generator loss = 19.88348388671875\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 13, Batch: 445/468, discriminator loss real = 1.9019197328162818e-10, disciminator loss fake = 4.177313606135158e-09, generator loss = 19.872026443481445\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 13, Batch: 446/468, discriminator loss real = 1.2181737823330208e-13, disciminator loss fake = 3.87540843860279e-09, generator loss = 20.03169059753418\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 13, Batch: 447/468, discriminator loss real = 1.2426419087309079e-15, disciminator loss fake = 5.8730402763274014e-09, generator loss = 20.054943084716797\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 13, Batch: 448/468, discriminator loss real = 1.6909025652637848e-14, disciminator loss fake = 3.9821270725326485e-09, generator loss = 19.96429443359375\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 13, Batch: 449/468, discriminator loss real = 1.5688898156336874e-19, disciminator loss fake = 3.937845605150869e-09, generator loss = 19.935745239257812\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 13, Batch: 450/468, discriminator loss real = 4.784092501493309e-13, disciminator loss fake = 3.1878710782251574e-09, generator loss = 20.148653030395508\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 13, Batch: 451/468, discriminator loss real = 7.332014070826566e-16, disciminator loss fake = 2.6139486131171452e-09, generator loss = 20.061107635498047\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 13, Batch: 452/468, discriminator loss real = 1.4102523681258376e-18, disciminator loss fake = 2.8316717859411256e-09, generator loss = 20.06962013244629\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 13, Batch: 453/468, discriminator loss real = 5.103868523104984e-20, disciminator loss fake = 3.1982876347314004e-09, generator loss = 20.024578094482422\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 13, Batch: 454/468, discriminator loss real = 6.082645751038781e-18, disciminator loss fake = 3.765090461627096e-09, generator loss = 20.06372833251953\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 13, Batch: 455/468, discriminator loss real = 7.88643069848504e-15, disciminator loss fake = 4.235175765643362e-09, generator loss = 20.03897476196289\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 13, Batch: 456/468, discriminator loss real = 2.7693474548068017e-14, disciminator loss fake = 4.807894082858866e-09, generator loss = 20.21282958984375\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 13, Batch: 457/468, discriminator loss real = 4.335869770860645e-12, disciminator loss fake = 3.966798001187044e-09, generator loss = 20.104572296142578\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 13, Batch: 458/468, discriminator loss real = 4.05545144133157e-08, disciminator loss fake = 4.047722157451972e-09, generator loss = 20.060039520263672\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 13, Batch: 459/468, discriminator loss real = 8.996863019657508e-17, disciminator loss fake = 3.9903729209811445e-09, generator loss = 20.00312042236328\n",
      "2/2 [==============================] - 0s 147ms/step\n",
      "Epoch: 13, Batch: 460/468, discriminator loss real = 3.285948735332056e-10, disciminator loss fake = 3.430223438627422e-09, generator loss = 20.01996421813965\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 13, Batch: 461/468, discriminator loss real = 7.723722207353051e-17, disciminator loss fake = 3.123733716137167e-09, generator loss = 20.136411666870117\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 13, Batch: 462/468, discriminator loss real = 1.3734502754927409e-18, disciminator loss fake = 3.629413214412125e-09, generator loss = 20.010047912597656\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 13, Batch: 463/468, discriminator loss real = 9.72666144540479e-16, disciminator loss fake = 3.816385429900038e-09, generator loss = 20.023969650268555\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 13, Batch: 464/468, discriminator loss real = 8.92117369560852e-12, disciminator loss fake = 2.608138149895467e-09, generator loss = 20.075557708740234\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 13, Batch: 465/468, discriminator loss real = 1.2627315185365301e-15, disciminator loss fake = 3.71635744400578e-09, generator loss = 20.04715919494629\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 13, Batch: 466/468, discriminator loss real = 2.7552777399210513e-17, disciminator loss fake = 5.062491315044326e-09, generator loss = 20.225906372070312\n",
      "2/2 [==============================] - 0s 166ms/step\n",
      "Epoch: 13, Batch: 467/468, discriminator loss real = 1.110345209127798e-15, disciminator loss fake = 4.016571963916249e-09, generator loss = 20.004152297973633\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 13, Batch: 468/468, discriminator loss real = 3.2840472563577805e-09, disciminator loss fake = 4.034752532078301e-09, generator loss = 19.915771484375\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 14, Batch: 1/468, discriminator loss real = 3.958620542476865e-09, disciminator loss fake = 3.3634428575624042e-09, generator loss = 20.14104461669922\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 14, Batch: 2/468, discriminator loss real = 1.4631648757174043e-12, disciminator loss fake = 3.77118203331861e-09, generator loss = 20.003131866455078\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 14, Batch: 3/468, discriminator loss real = 4.096692213570842e-15, disciminator loss fake = 3.758163114042645e-09, generator loss = 20.186742782592773\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 14, Batch: 4/468, discriminator loss real = 6.135152715719405e-12, disciminator loss fake = 4.119026897342337e-09, generator loss = 20.018779754638672\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 14, Batch: 5/468, discriminator loss real = 9.186838572858291e-13, disciminator loss fake = 3.889560673542292e-09, generator loss = 20.10757827758789\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 14, Batch: 6/468, discriminator loss real = 9.693426023224124e-18, disciminator loss fake = 2.9568596460194385e-09, generator loss = 19.987770080566406\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 14, Batch: 7/468, discriminator loss real = 1.246734269641503e-12, disciminator loss fake = 2.680522026565768e-09, generator loss = 19.99929428100586\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 14, Batch: 8/468, discriminator loss real = 2.4821013029207445e-15, disciminator loss fake = 3.5779437190797125e-09, generator loss = 20.03885841369629\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 14, Batch: 9/468, discriminator loss real = 5.435473252046741e-12, disciminator loss fake = 4.835521316692848e-09, generator loss = 20.068897247314453\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 14, Batch: 10/468, discriminator loss real = 4.384857626491753e-17, disciminator loss fake = 3.3184992531687385e-09, generator loss = 20.06443214416504\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 14, Batch: 11/468, discriminator loss real = 6.930056029898213e-13, disciminator loss fake = 4.144523835236669e-09, generator loss = 19.92485237121582\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 14, Batch: 12/468, discriminator loss real = 5.833286679449016e-16, disciminator loss fake = 3.688830130244014e-09, generator loss = 20.096031188964844\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 14, Batch: 13/468, discriminator loss real = 2.3066059759472245e-16, disciminator loss fake = 4.897827032834812e-09, generator loss = 20.044906616210938\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 14, Batch: 14/468, discriminator loss real = 2.4970916685047775e-15, disciminator loss fake = 3.534183834474902e-09, generator loss = 19.995023727416992\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 14, Batch: 15/468, discriminator loss real = 2.118051942025885e-16, disciminator loss fake = 3.0981834875376535e-09, generator loss = 19.92254638671875\n",
      "2/2 [==============================] - 0s 177ms/step\n",
      "Epoch: 14, Batch: 16/468, discriminator loss real = 1.726977529080756e-14, disciminator loss fake = 3.1946147949213355e-09, generator loss = 20.06463050842285\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 14, Batch: 17/468, discriminator loss real = 9.070648827316438e-15, disciminator loss fake = 4.71553240899425e-09, generator loss = 20.06720733642578\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 14, Batch: 18/468, discriminator loss real = 1.331405011196704e-13, disciminator loss fake = 2.8030402443590674e-09, generator loss = 20.017501831054688\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 14, Batch: 19/468, discriminator loss real = 2.333875497376181e-12, disciminator loss fake = 2.5254269786501027e-09, generator loss = 20.014957427978516\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 14, Batch: 20/468, discriminator loss real = 8.885466147579013e-12, disciminator loss fake = 3.550085780901213e-09, generator loss = 19.981586456298828\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 14, Batch: 21/468, discriminator loss real = 6.2700270236680324e-21, disciminator loss fake = 2.499332740768523e-09, generator loss = 20.019371032714844\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 14, Batch: 22/468, discriminator loss real = 3.0057313110893116e-14, disciminator loss fake = 2.797842846291587e-09, generator loss = 20.024261474609375\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 14, Batch: 23/468, discriminator loss real = 6.754668896560628e-15, disciminator loss fake = 3.7322669399486585e-09, generator loss = 19.87412452697754\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 14, Batch: 24/468, discriminator loss real = 5.463074547539492e-19, disciminator loss fake = 3.810296078654574e-09, generator loss = 20.126365661621094\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 14, Batch: 25/468, discriminator loss real = 1.287081068792131e-15, disciminator loss fake = 3.763815037416407e-09, generator loss = 20.070552825927734\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 14, Batch: 26/468, discriminator loss real = 1.4918074371303436e-13, disciminator loss fake = 3.5832328215690268e-09, generator loss = 20.040618896484375\n",
      "2/2 [==============================] - 0s 158ms/step\n",
      "Epoch: 14, Batch: 27/468, discriminator loss real = 5.463260399629633e-10, disciminator loss fake = 3.848763974190206e-09, generator loss = 20.22423553466797\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 14, Batch: 28/468, discriminator loss real = 4.062978184687753e-15, disciminator loss fake = 3.6082874466103476e-09, generator loss = 19.966339111328125\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 14, Batch: 29/468, discriminator loss real = 1.3336901895366626e-11, disciminator loss fake = 3.917527635621809e-09, generator loss = 20.11758804321289\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 14, Batch: 30/468, discriminator loss real = 1.8436070202475056e-14, disciminator loss fake = 2.996792813902971e-09, generator loss = 20.177825927734375\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 14, Batch: 31/468, discriminator loss real = 6.23018618032406e-14, disciminator loss fake = 3.744343501921321e-09, generator loss = 20.08194351196289\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 14, Batch: 32/468, discriminator loss real = 1.5127744774141553e-18, disciminator loss fake = 3.3655502829077477e-09, generator loss = 20.20975685119629\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 14, Batch: 33/468, discriminator loss real = 3.7614975945749686e-19, disciminator loss fake = 3.691066119415609e-09, generator loss = 20.103504180908203\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 14, Batch: 34/468, discriminator loss real = 3.65902690091513e-11, disciminator loss fake = 3.3217568695675936e-09, generator loss = 20.112451553344727\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 14, Batch: 35/468, discriminator loss real = 5.107403757732831e-13, disciminator loss fake = 3.2144269468403763e-09, generator loss = 20.05597686767578\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 14, Batch: 36/468, discriminator loss real = 8.698219385662588e-18, disciminator loss fake = 2.9742373008900813e-09, generator loss = 20.066423416137695\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 14, Batch: 37/468, discriminator loss real = 5.268340055827631e-16, disciminator loss fake = 3.2358047352687436e-09, generator loss = 20.25018310546875\n",
      "2/2 [==============================] - 0s 146ms/step\n",
      "Epoch: 14, Batch: 38/468, discriminator loss real = 1.2662434301091707e-07, disciminator loss fake = 2.1417614348706593e-09, generator loss = 20.12307357788086\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 14, Batch: 39/468, discriminator loss real = 1.269841301337546e-13, disciminator loss fake = 3.918628976862237e-09, generator loss = 20.106399536132812\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 14, Batch: 40/468, discriminator loss real = 1.0022432645091783e-14, disciminator loss fake = 3.3095988172249236e-09, generator loss = 20.185787200927734\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 14, Batch: 41/468, discriminator loss real = 4.147507414142522e-15, disciminator loss fake = 3.5194203107380417e-09, generator loss = 19.936532974243164\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 14, Batch: 42/468, discriminator loss real = 2.2176863100290402e-16, disciminator loss fake = 3.2610516509379295e-09, generator loss = 20.069303512573242\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 14, Batch: 43/468, discriminator loss real = 1.181492078651536e-12, disciminator loss fake = 4.469533188000696e-09, generator loss = 20.133604049682617\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 14, Batch: 44/468, discriminator loss real = 1.0025658525592007e-08, disciminator loss fake = 3.279768456820875e-09, generator loss = 20.05156707763672\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 14, Batch: 45/468, discriminator loss real = 1.1832968382261933e-17, disciminator loss fake = 4.053247515400926e-09, generator loss = 19.964008331298828\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 14, Batch: 46/468, discriminator loss real = 4.588639039050657e-13, disciminator loss fake = 3.6633631683713475e-09, generator loss = 19.960575103759766\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 14, Batch: 47/468, discriminator loss real = 4.668320444838406e-14, disciminator loss fake = 4.828652144794887e-09, generator loss = 20.12727165222168\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 14, Batch: 48/468, discriminator loss real = 2.1045929855407081e-16, disciminator loss fake = 2.7364996935119734e-09, generator loss = 19.980512619018555\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 14, Batch: 49/468, discriminator loss real = 7.742933999857742e-15, disciminator loss fake = 3.814578430905158e-09, generator loss = 20.075651168823242\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 14, Batch: 50/468, discriminator loss real = 4.523565902284435e-15, disciminator loss fake = 2.85375367781171e-09, generator loss = 19.913320541381836\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 14, Batch: 51/468, discriminator loss real = 4.2679239836607455e-18, disciminator loss fake = 3.755687316697731e-09, generator loss = 19.963016510009766\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 14, Batch: 52/468, discriminator loss real = 5.006904395448775e-17, disciminator loss fake = 3.869701448167007e-09, generator loss = 20.031816482543945\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 14, Batch: 53/468, discriminator loss real = 1.3043190659478565e-13, disciminator loss fake = 3.6531588865074127e-09, generator loss = 19.951059341430664\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 14, Batch: 54/468, discriminator loss real = 1.9777585367166452e-16, disciminator loss fake = 3.923958491469648e-09, generator loss = 20.091594696044922\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 14, Batch: 55/468, discriminator loss real = 1.1070940849179992e-15, disciminator loss fake = 3.5265359521474693e-09, generator loss = 20.126224517822266\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 14, Batch: 56/468, discriminator loss real = 2.353163497392785e-10, disciminator loss fake = 4.0974992288056455e-09, generator loss = 19.931182861328125\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 14, Batch: 57/468, discriminator loss real = 4.428804514826834e-15, disciminator loss fake = 2.7928335200044785e-09, generator loss = 19.98459243774414\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 14, Batch: 58/468, discriminator loss real = 6.596568926406192e-15, disciminator loss fake = 4.658019303604988e-09, generator loss = 19.969995498657227\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 14, Batch: 59/468, discriminator loss real = 1.0425824293518529e-13, disciminator loss fake = 3.4581668639788177e-09, generator loss = 20.12729263305664\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 14, Batch: 60/468, discriminator loss real = 1.3053713688595484e-14, disciminator loss fake = 3.440237872354146e-09, generator loss = 20.048076629638672\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 14, Batch: 61/468, discriminator loss real = 2.658555884119118e-14, disciminator loss fake = 3.721839503256774e-09, generator loss = 19.971668243408203\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 14, Batch: 62/468, discriminator loss real = 1.0922306895727596e-12, disciminator loss fake = 5.61871127402469e-09, generator loss = 20.024534225463867\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 14, Batch: 63/468, discriminator loss real = 3.569796910331269e-13, disciminator loss fake = 3.2024449758694118e-09, generator loss = 19.881778717041016\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 14, Batch: 64/468, discriminator loss real = 4.918350264779181e-19, disciminator loss fake = 4.001787345941921e-09, generator loss = 19.909564971923828\n",
      "2/2 [==============================] - 0s 172ms/step\n",
      "Epoch: 14, Batch: 65/468, discriminator loss real = 4.247549284402646e-18, disciminator loss fake = 2.946829447125765e-09, generator loss = 20.163558959960938\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 14, Batch: 66/468, discriminator loss real = 4.877003124872835e-19, disciminator loss fake = 4.885538196219841e-09, generator loss = 20.1754207611084\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 14, Batch: 67/468, discriminator loss real = 3.488617728031329e-10, disciminator loss fake = 5.423310245333823e-09, generator loss = 20.076107025146484\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 14, Batch: 68/468, discriminator loss real = 2.82682124236322e-12, disciminator loss fake = 4.179030455020438e-09, generator loss = 20.15851593017578\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 14, Batch: 69/468, discriminator loss real = 4.1652322403083086e-17, disciminator loss fake = 2.687076783303155e-09, generator loss = 20.16836166381836\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 14, Batch: 70/468, discriminator loss real = 8.290118580803221e-17, disciminator loss fake = 3.527549363724347e-09, generator loss = 20.054401397705078\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 14, Batch: 71/468, discriminator loss real = 1.950706882537876e-14, disciminator loss fake = 2.6686404197562297e-09, generator loss = 20.07595443725586\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 14, Batch: 72/468, discriminator loss real = 2.8597511511629925e-11, disciminator loss fake = 3.606793752553017e-09, generator loss = 19.97049903869629\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 14, Batch: 73/468, discriminator loss real = 1.4685685185927648e-17, disciminator loss fake = 3.775602497313457e-09, generator loss = 20.169113159179688\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 14, Batch: 74/468, discriminator loss real = 6.560872179740829e-13, disciminator loss fake = 2.44753906031292e-09, generator loss = 19.88215446472168\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 14, Batch: 75/468, discriminator loss real = 4.882685442090768e-18, disciminator loss fake = 2.281157485128915e-09, generator loss = 20.184350967407227\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 14, Batch: 76/468, discriminator loss real = 1.2408591161351744e-15, disciminator loss fake = 3.713905627478198e-09, generator loss = 19.85085678100586\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 14, Batch: 77/468, discriminator loss real = 1.1108368058745607e-15, disciminator loss fake = 4.665014152749336e-09, generator loss = 20.012924194335938\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 14, Batch: 78/468, discriminator loss real = 7.263669205774103e-15, disciminator loss fake = 3.964186312543916e-09, generator loss = 20.155353546142578\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 14, Batch: 79/468, discriminator loss real = 3.57873273099514e-17, disciminator loss fake = 2.344075600291262e-09, generator loss = 19.903650283813477\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 14, Batch: 80/468, discriminator loss real = 2.3435647953512495e-12, disciminator loss fake = 3.0183850974196957e-09, generator loss = 20.123485565185547\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 14, Batch: 81/468, discriminator loss real = 3.994515924094805e-19, disciminator loss fake = 3.5498335382300183e-09, generator loss = 20.077239990234375\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 14, Batch: 82/468, discriminator loss real = 1.8780732177758885e-12, disciminator loss fake = 4.049581114884404e-09, generator loss = 20.12331771850586\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 14, Batch: 83/468, discriminator loss real = 9.11765662969799e-11, disciminator loss fake = 3.361554146152912e-09, generator loss = 20.13475799560547\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 14, Batch: 84/468, discriminator loss real = 1.945476115275402e-14, disciminator loss fake = 3.3542626454163837e-09, generator loss = 20.07577896118164\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 14, Batch: 85/468, discriminator loss real = 2.5674449578630212e-18, disciminator loss fake = 2.8348381420073565e-09, generator loss = 20.006484985351562\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 14, Batch: 86/468, discriminator loss real = 8.061434820464536e-14, disciminator loss fake = 3.2589462239940303e-09, generator loss = 20.05328369140625\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 14, Batch: 87/468, discriminator loss real = 6.166017141318036e-10, disciminator loss fake = 3.265363091031759e-09, generator loss = 19.926673889160156\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 14, Batch: 88/468, discriminator loss real = 4.098133334251477e-17, disciminator loss fake = 2.8389557371610863e-09, generator loss = 20.11324119567871\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 14, Batch: 89/468, discriminator loss real = 1.8162681081346221e-10, disciminator loss fake = 3.4266562920493016e-09, generator loss = 20.268508911132812\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 14, Batch: 90/468, discriminator loss real = 4.720676821857615e-15, disciminator loss fake = 3.0946474272042224e-09, generator loss = 20.04425048828125\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 14, Batch: 91/468, discriminator loss real = 1.890072820476263e-11, disciminator loss fake = 3.5140299559088817e-09, generator loss = 20.06121063232422\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 14, Batch: 92/468, discriminator loss real = 5.0189151744100755e-14, disciminator loss fake = 2.9641431531501894e-09, generator loss = 20.2646484375\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 14, Batch: 93/468, discriminator loss real = 1.1082223601007021e-18, disciminator loss fake = 3.0327325095669266e-09, generator loss = 20.010709762573242\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 14, Batch: 94/468, discriminator loss real = 9.175165109415763e-18, disciminator loss fake = 2.3051200948032147e-09, generator loss = 20.103038787841797\n",
      "2/2 [==============================] - 0s 176ms/step\n",
      "Epoch: 14, Batch: 95/468, discriminator loss real = 2.3922280449944356e-18, disciminator loss fake = 3.2410445438557645e-09, generator loss = 20.17310333251953\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 14, Batch: 96/468, discriminator loss real = 1.0029175159700826e-16, disciminator loss fake = 2.8998057288731616e-09, generator loss = 20.125593185424805\n",
      "2/2 [==============================] - 0s 174ms/step\n",
      "Epoch: 14, Batch: 97/468, discriminator loss real = 6.4685838230279534e-18, disciminator loss fake = 3.2805307359495828e-09, generator loss = 20.020145416259766\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 14, Batch: 98/468, discriminator loss real = 2.7327329310024295e-14, disciminator loss fake = 2.405516896786253e-09, generator loss = 20.026145935058594\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 14, Batch: 99/468, discriminator loss real = 1.081596610101512e-21, disciminator loss fake = 2.694042766648863e-09, generator loss = 20.183935165405273\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 14, Batch: 100/468, discriminator loss real = 1.074618952850992e-11, disciminator loss fake = 3.2569587027353464e-09, generator loss = 20.214645385742188\n",
      "2/2 [==============================] - 0s 135ms/step\n",
      "Epoch: 14, Batch: 101/468, discriminator loss real = 5.4837564823566096e-17, disciminator loss fake = 3.0150986152222004e-09, generator loss = 20.150711059570312\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 14, Batch: 102/468, discriminator loss real = 4.109281274630727e-13, disciminator loss fake = 3.348477495279667e-09, generator loss = 20.274721145629883\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 14, Batch: 103/468, discriminator loss real = 3.733415174670311e-18, disciminator loss fake = 2.630547335513711e-09, generator loss = 20.134361267089844\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 14, Batch: 104/468, discriminator loss real = 2.0728713952017537e-14, disciminator loss fake = 3.953848359827816e-09, generator loss = 20.306589126586914\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 14, Batch: 105/468, discriminator loss real = 1.943216400778717e-15, disciminator loss fake = 3.512661050919519e-09, generator loss = 20.115718841552734\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 14, Batch: 106/468, discriminator loss real = 1.7856924977317085e-13, disciminator loss fake = 3.202349718733899e-09, generator loss = 20.153749465942383\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 14, Batch: 107/468, discriminator loss real = 4.711106366158614e-19, disciminator loss fake = 4.79058481772654e-09, generator loss = 20.167802810668945\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 14, Batch: 108/468, discriminator loss real = 1.9724278566240865e-14, disciminator loss fake = 3.3584424130594925e-09, generator loss = 20.254680633544922\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 14, Batch: 109/468, discriminator loss real = 1.508599467570093e-07, disciminator loss fake = 3.961285521825175e-09, generator loss = 20.117029190063477\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 14, Batch: 110/468, discriminator loss real = 1.0942127122586212e-17, disciminator loss fake = 3.3668274834752765e-09, generator loss = 20.24070930480957\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 14, Batch: 111/468, discriminator loss real = 1.1663823254676534e-14, disciminator loss fake = 3.44726047707411e-09, generator loss = 19.871339797973633\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 14, Batch: 112/468, discriminator loss real = 3.5988458740865426e-11, disciminator loss fake = 2.5191662089696365e-09, generator loss = 20.182537078857422\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 14, Batch: 113/468, discriminator loss real = 5.31141894384129e-18, disciminator loss fake = 4.09496880848792e-09, generator loss = 20.18985366821289\n",
      "2/2 [==============================] - 0s 194ms/step\n",
      "Epoch: 14, Batch: 114/468, discriminator loss real = 1.6331136443170635e-10, disciminator loss fake = 3.3979854485721717e-09, generator loss = 20.121706008911133\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 14, Batch: 115/468, discriminator loss real = 8.448346189293687e-12, disciminator loss fake = 2.6109807649277172e-09, generator loss = 19.969104766845703\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 14, Batch: 116/468, discriminator loss real = 3.638632093110744e-13, disciminator loss fake = 4.137147513461059e-09, generator loss = 20.05546760559082\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 14, Batch: 117/468, discriminator loss real = 1.834451441120634e-14, disciminator loss fake = 3.6275902282056904e-09, generator loss = 19.98611831665039\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 14, Batch: 118/468, discriminator loss real = 1.167869837084018e-18, disciminator loss fake = 3.6110803236510947e-09, generator loss = 19.88610076904297\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 14, Batch: 119/468, discriminator loss real = 1.3482975742213815e-18, disciminator loss fake = 4.413392318269871e-09, generator loss = 19.993045806884766\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 14, Batch: 120/468, discriminator loss real = 4.127425957029017e-15, disciminator loss fake = 3.3407756561132373e-09, generator loss = 20.099349975585938\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 14, Batch: 121/468, discriminator loss real = 3.297810945315801e-17, disciminator loss fake = 4.092713723480301e-09, generator loss = 19.983718872070312\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 14, Batch: 122/468, discriminator loss real = 9.372789545360194e-14, disciminator loss fake = 4.704210354589122e-09, generator loss = 20.136409759521484\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 14, Batch: 123/468, discriminator loss real = 1.0565151184471766e-11, disciminator loss fake = 2.9700464310167263e-09, generator loss = 20.034236907958984\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 14, Batch: 124/468, discriminator loss real = 1.5044659040699265e-13, disciminator loss fake = 4.855347679466604e-09, generator loss = 19.895069122314453\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 14, Batch: 125/468, discriminator loss real = 8.364413762312894e-14, disciminator loss fake = 3.3597964410603254e-09, generator loss = 19.962358474731445\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 14, Batch: 126/468, discriminator loss real = 2.1502863102292394e-14, disciminator loss fake = 3.90920140702633e-09, generator loss = 19.983314514160156\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 14, Batch: 127/468, discriminator loss real = 1.1625556847218426e-14, disciminator loss fake = 3.1103410957911137e-09, generator loss = 20.06943130493164\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 14, Batch: 128/468, discriminator loss real = 5.283093569823788e-15, disciminator loss fake = 4.138785314466986e-09, generator loss = 20.03582000732422\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 14, Batch: 129/468, discriminator loss real = 1.676186045431599e-13, disciminator loss fake = 3.3974971724859415e-09, generator loss = 19.984024047851562\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 14, Batch: 130/468, discriminator loss real = 7.890080949701783e-12, disciminator loss fake = 4.039248047149613e-09, generator loss = 19.98209571838379\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 14, Batch: 131/468, discriminator loss real = 7.760019189728684e-12, disciminator loss fake = 3.160573358584884e-09, generator loss = 20.035730361938477\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 14, Batch: 132/468, discriminator loss real = 3.831486451895405e-14, disciminator loss fake = 3.128476144809156e-09, generator loss = 20.18791961669922\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 14, Batch: 133/468, discriminator loss real = 3.919846927837636e-16, disciminator loss fake = 3.3436862167945947e-09, generator loss = 20.14006805419922\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 14, Batch: 134/468, discriminator loss real = 7.112052319918833e-16, disciminator loss fake = 3.6883645027074863e-09, generator loss = 19.9648380279541\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 14, Batch: 135/468, discriminator loss real = 4.490886524146417e-15, disciminator loss fake = 4.071260217841655e-09, generator loss = 19.943092346191406\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 14, Batch: 136/468, discriminator loss real = 1.490384540363569e-15, disciminator loss fake = 2.6347541925986206e-09, generator loss = 19.961929321289062\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 14, Batch: 137/468, discriminator loss real = 9.3648229414183e-19, disciminator loss fake = 3.176255258807714e-09, generator loss = 20.18474006652832\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 14, Batch: 138/468, discriminator loss real = 1.897185586400264e-16, disciminator loss fake = 3.3930049880837032e-09, generator loss = 19.95309829711914\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 14, Batch: 139/468, discriminator loss real = 1.4941856007143726e-15, disciminator loss fake = 4.6681729592989996e-09, generator loss = 20.004053115844727\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 14, Batch: 140/468, discriminator loss real = 1.014132536594195e-15, disciminator loss fake = 3.297993433903912e-09, generator loss = 20.098712921142578\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 14, Batch: 141/468, discriminator loss real = 1.9675618482184796e-16, disciminator loss fake = 3.8685525893811246e-09, generator loss = 20.259859085083008\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 14, Batch: 142/468, discriminator loss real = 1.2179955831062736e-20, disciminator loss fake = 2.8083118053245926e-09, generator loss = 20.178741455078125\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 14, Batch: 143/468, discriminator loss real = 5.651114138812731e-15, disciminator loss fake = 3.1681841594632942e-09, generator loss = 20.07938003540039\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 14, Batch: 144/468, discriminator loss real = 2.932095687665885e-14, disciminator loss fake = 4.268733810874892e-09, generator loss = 20.27758026123047\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 14, Batch: 145/468, discriminator loss real = 4.7838272785368646e-14, disciminator loss fake = 3.1648035303533106e-09, generator loss = 20.070341110229492\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 14, Batch: 146/468, discriminator loss real = 4.803576359921867e-14, disciminator loss fake = 4.441808254540547e-09, generator loss = 20.19695472717285\n",
      "2/2 [==============================] - 0s 176ms/step\n",
      "Epoch: 14, Batch: 147/468, discriminator loss real = 6.679025388311999e-11, disciminator loss fake = 2.418436118034606e-09, generator loss = 20.167980194091797\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 14, Batch: 148/468, discriminator loss real = 2.8906947500831684e-14, disciminator loss fake = 3.8275667080256426e-09, generator loss = 20.25714111328125\n",
      "2/2 [==============================] - 0s 174ms/step\n",
      "Epoch: 14, Batch: 149/468, discriminator loss real = 6.1626093835723435e-15, disciminator loss fake = 3.6492708854751754e-09, generator loss = 20.027618408203125\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 14, Batch: 150/468, discriminator loss real = 3.175319165590884e-14, disciminator loss fake = 3.1316174098350302e-09, generator loss = 20.336137771606445\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 14, Batch: 151/468, discriminator loss real = 1.3403375117892072e-18, disciminator loss fake = 2.8496764947760767e-09, generator loss = 20.190200805664062\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 14, Batch: 152/468, discriminator loss real = 3.373107304582845e-08, disciminator loss fake = 3.142921034537949e-09, generator loss = 20.079004287719727\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 14, Batch: 153/468, discriminator loss real = 1.1613949801869694e-09, disciminator loss fake = 3.764313305509859e-09, generator loss = 20.169374465942383\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 14, Batch: 154/468, discriminator loss real = 8.560395773314633e-13, disciminator loss fake = 3.5500966610868545e-09, generator loss = 20.242130279541016\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 14, Batch: 155/468, discriminator loss real = 5.059517258279578e-13, disciminator loss fake = 4.174232959286428e-09, generator loss = 20.19583511352539\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 14, Batch: 156/468, discriminator loss real = 1.2877937411381272e-15, disciminator loss fake = 2.6910023098736247e-09, generator loss = 20.076663970947266\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 14, Batch: 157/468, discriminator loss real = 2.357907646910462e-08, disciminator loss fake = 2.828750123029522e-09, generator loss = 20.188989639282227\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 14, Batch: 158/468, discriminator loss real = 4.448286006208946e-08, disciminator loss fake = 3.0500499903496348e-09, generator loss = 20.279319763183594\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 14, Batch: 159/468, discriminator loss real = 4.087523981889321e-16, disciminator loss fake = 4.038350986945716e-09, generator loss = 20.04816246032715\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 14, Batch: 160/468, discriminator loss real = 1.846677739674429e-17, disciminator loss fake = 2.78967493549942e-09, generator loss = 20.225982666015625\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 14, Batch: 161/468, discriminator loss real = 2.1396861230282703e-17, disciminator loss fake = 3.781120749835054e-09, generator loss = 19.990690231323242\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 14, Batch: 162/468, discriminator loss real = 1.1104198539062748e-15, disciminator loss fake = 3.1298923452993677e-09, generator loss = 19.984792709350586\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 14, Batch: 163/468, discriminator loss real = 8.517938090979449e-12, disciminator loss fake = 2.962991851873653e-09, generator loss = 20.079513549804688\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 14, Batch: 164/468, discriminator loss real = 3.6037078269407496e-12, disciminator loss fake = 3.297528472501199e-09, generator loss = 20.169021606445312\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 14, Batch: 165/468, discriminator loss real = 3.0594093924918297e-09, disciminator loss fake = 2.5886834897903555e-09, generator loss = 20.019140243530273\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 14, Batch: 166/468, discriminator loss real = 4.6567578495383436e-17, disciminator loss fake = 3.209134735726593e-09, generator loss = 20.008495330810547\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 14, Batch: 167/468, discriminator loss real = 9.034506947896634e-14, disciminator loss fake = 3.3942180177604087e-09, generator loss = 20.185760498046875\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 14, Batch: 168/468, discriminator loss real = 9.033888270110235e-20, disciminator loss fake = 3.7674623420969056e-09, generator loss = 20.07815170288086\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 14, Batch: 169/468, discriminator loss real = 1.2476617469224145e-18, disciminator loss fake = 3.4866338705086264e-09, generator loss = 20.127784729003906\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 14, Batch: 170/468, discriminator loss real = 1.1989084329938659e-15, disciminator loss fake = 2.582026148445493e-09, generator loss = 20.165863037109375\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 14, Batch: 171/468, discriminator loss real = 5.500496301848968e-18, disciminator loss fake = 3.020037331324943e-09, generator loss = 19.951562881469727\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 14, Batch: 172/468, discriminator loss real = 4.309053548007258e-12, disciminator loss fake = 4.55168303048481e-09, generator loss = 20.282011032104492\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 14, Batch: 173/468, discriminator loss real = 4.188644873656666e-13, disciminator loss fake = 2.598441684042996e-09, generator loss = 20.146228790283203\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 14, Batch: 174/468, discriminator loss real = 1.6324656904043167e-11, disciminator loss fake = 3.737279818949446e-09, generator loss = 20.080520629882812\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 14, Batch: 175/468, discriminator loss real = 2.915970848503947e-15, disciminator loss fake = 3.3877551874894607e-09, generator loss = 20.183002471923828\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 14, Batch: 176/468, discriminator loss real = 7.769725228462922e-16, disciminator loss fake = 3.44837136623255e-09, generator loss = 19.92225456237793\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 14, Batch: 177/468, discriminator loss real = 5.980937858689195e-13, disciminator loss fake = 3.751348121028286e-09, generator loss = 20.13141632080078\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 14, Batch: 178/468, discriminator loss real = 1.3400403426873722e-14, disciminator loss fake = 3.494661893199691e-09, generator loss = 20.17000961303711\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 14, Batch: 179/468, discriminator loss real = 3.2010413188408764e-18, disciminator loss fake = 2.7845907801804515e-09, generator loss = 20.088003158569336\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 14, Batch: 180/468, discriminator loss real = 2.843365265459141e-10, disciminator loss fake = 3.135163684220288e-09, generator loss = 20.087900161743164\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 14, Batch: 181/468, discriminator loss real = 1.2298336058981204e-15, disciminator loss fake = 2.7987070438939554e-09, generator loss = 19.916412353515625\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 14, Batch: 182/468, discriminator loss real = 3.955362648739094e-14, disciminator loss fake = 3.0478322088356435e-09, generator loss = 20.32414436340332\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 14, Batch: 183/468, discriminator loss real = 1.2500465648766865e-15, disciminator loss fake = 2.939069432272845e-09, generator loss = 20.01860809326172\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 14, Batch: 184/468, discriminator loss real = 4.362611619798329e-20, disciminator loss fake = 2.8623419190410004e-09, generator loss = 20.147537231445312\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 14, Batch: 185/468, discriminator loss real = 1.8134987955775728e-10, disciminator loss fake = 3.6719938201201785e-09, generator loss = 19.978694915771484\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 14, Batch: 186/468, discriminator loss real = 1.455579384151906e-19, disciminator loss fake = 2.8602409329891998e-09, generator loss = 20.091087341308594\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 14, Batch: 187/468, discriminator loss real = 1.252616674596893e-15, disciminator loss fake = 2.744604099547132e-09, generator loss = 20.277189254760742\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 14, Batch: 188/468, discriminator loss real = 1.2557440472930979e-14, disciminator loss fake = 4.446924606327229e-09, generator loss = 20.09471893310547\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 14, Batch: 189/468, discriminator loss real = 9.802016975868355e-10, disciminator loss fake = 2.660841103008238e-09, generator loss = 19.994131088256836\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 14, Batch: 190/468, discriminator loss real = 1.0977184466314308e-14, disciminator loss fake = 5.816583215079163e-09, generator loss = 20.003929138183594\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 14, Batch: 191/468, discriminator loss real = 5.972154554777806e-16, disciminator loss fake = 4.188760893697463e-09, generator loss = 20.17706298828125\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 14, Batch: 192/468, discriminator loss real = 2.4925220998284203e-08, disciminator loss fake = 5.2817492601775484e-09, generator loss = 20.224082946777344\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 14, Batch: 193/468, discriminator loss real = 3.106000541205218e-18, disciminator loss fake = 2.5705220174643273e-09, generator loss = 20.220294952392578\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 14, Batch: 194/468, discriminator loss real = 1.4863560781362071e-16, disciminator loss fake = 4.547149323741451e-09, generator loss = 20.04764175415039\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 14, Batch: 195/468, discriminator loss real = 1.0675301818033757e-17, disciminator loss fake = 3.199185805158322e-09, generator loss = 19.902141571044922\n",
      "2/2 [==============================] - 0s 182ms/step\n",
      "Epoch: 14, Batch: 196/468, discriminator loss real = 4.181202259423422e-12, disciminator loss fake = 2.7209208219858283e-09, generator loss = 20.14216423034668\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 14, Batch: 197/468, discriminator loss real = 1.0507359958652575e-18, disciminator loss fake = 2.5640647383085025e-09, generator loss = 20.041072845458984\n",
      "2/2 [==============================] - 0s 174ms/step\n",
      "Epoch: 14, Batch: 198/468, discriminator loss real = 5.840718398297459e-14, disciminator loss fake = 2.8578908128906733e-09, generator loss = 20.241580963134766\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 14, Batch: 199/468, discriminator loss real = 4.969611334726181e-15, disciminator loss fake = 3.709731632994817e-09, generator loss = 20.00439453125\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 14, Batch: 200/468, discriminator loss real = 4.7734041993077216e-15, disciminator loss fake = 3.237026202640436e-09, generator loss = 20.223663330078125\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 14, Batch: 201/468, discriminator loss real = 5.68336145073831e-17, disciminator loss fake = 2.8019135900336778e-09, generator loss = 20.16309356689453\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 14, Batch: 202/468, discriminator loss real = 1.2556979720094897e-17, disciminator loss fake = 2.961496381459483e-09, generator loss = 20.196216583251953\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 14, Batch: 203/468, discriminator loss real = 3.949257036731938e-17, disciminator loss fake = 3.71657971065531e-09, generator loss = 20.153018951416016\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 14, Batch: 204/468, discriminator loss real = 1.3214197877825429e-18, disciminator loss fake = 3.825127325995936e-09, generator loss = 20.003320693969727\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 14, Batch: 205/468, discriminator loss real = 2.1901913029238104e-15, disciminator loss fake = 2.849326108389505e-09, generator loss = 20.093017578125\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 14, Batch: 206/468, discriminator loss real = 9.654461881640139e-14, disciminator loss fake = 2.979637203637253e-09, generator loss = 20.13580894470215\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 14, Batch: 207/468, discriminator loss real = 7.145334765249371e-20, disciminator loss fake = 3.241040325008271e-09, generator loss = 20.01857566833496\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 14, Batch: 208/468, discriminator loss real = 2.189984372774796e-14, disciminator loss fake = 3.150161687059949e-09, generator loss = 20.24831771850586\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 14, Batch: 209/468, discriminator loss real = 5.399137083597627e-15, disciminator loss fake = 2.7367961230595483e-09, generator loss = 20.144569396972656\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 14, Batch: 210/468, discriminator loss real = 3.449837394762126e-18, disciminator loss fake = 2.6368454086878046e-09, generator loss = 20.33819580078125\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 14, Batch: 211/468, discriminator loss real = 1.3641556605397888e-17, disciminator loss fake = 2.8646043315205816e-09, generator loss = 20.095008850097656\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 14, Batch: 212/468, discriminator loss real = 4.0687697459948247e-17, disciminator loss fake = 3.3465308302282892e-09, generator loss = 20.123340606689453\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 14, Batch: 213/468, discriminator loss real = 1.1552866001697389e-17, disciminator loss fake = 4.660756225405294e-09, generator loss = 20.114952087402344\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 14, Batch: 214/468, discriminator loss real = 6.445960433274628e-17, disciminator loss fake = 2.6678359521525863e-09, generator loss = 20.213722229003906\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 14, Batch: 215/468, discriminator loss real = 1.2035078489347484e-10, disciminator loss fake = 4.004677478519625e-09, generator loss = 20.129749298095703\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 14, Batch: 216/468, discriminator loss real = 7.300952377387038e-13, disciminator loss fake = 2.8850015709736e-09, generator loss = 20.226591110229492\n",
      "2/2 [==============================] - 0s 141ms/step\n",
      "Epoch: 14, Batch: 217/468, discriminator loss real = 6.982378231157327e-09, disciminator loss fake = 2.2984618652799327e-09, generator loss = 20.114349365234375\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 14, Batch: 218/468, discriminator loss real = 8.886403612962113e-09, disciminator loss fake = 3.1017322044135653e-09, generator loss = 20.108036041259766\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 14, Batch: 219/468, discriminator loss real = 6.527867135730503e-09, disciminator loss fake = 3.3100646668060563e-09, generator loss = 20.077051162719727\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 14, Batch: 220/468, discriminator loss real = 2.411100832877544e-13, disciminator loss fake = 3.6827429994445993e-09, generator loss = 20.346050262451172\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 14, Batch: 221/468, discriminator loss real = 6.572809638782928e-07, disciminator loss fake = 3.678368720727576e-09, generator loss = 19.9049015045166\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 14, Batch: 222/468, discriminator loss real = 8.508270619349365e-15, disciminator loss fake = 3.2230369484409493e-09, generator loss = 19.97603416442871\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 14, Batch: 223/468, discriminator loss real = 1.0262069277298339e-14, disciminator loss fake = 3.977052465131692e-09, generator loss = 19.521806716918945\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 14, Batch: 224/468, discriminator loss real = 2.3112223940247034e-11, disciminator loss fake = 4.582963786248229e-09, generator loss = 19.734325408935547\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 14, Batch: 225/468, discriminator loss real = 2.9246900040691415e-11, disciminator loss fake = 5.5938667031796285e-09, generator loss = 19.505264282226562\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 14, Batch: 226/468, discriminator loss real = 7.591228736268068e-21, disciminator loss fake = 1.25578072385224e-08, generator loss = 19.570215225219727\n",
      "2/2 [==============================] - 0s 144ms/step\n",
      "Epoch: 14, Batch: 227/468, discriminator loss real = 2.1483738433206105e-20, disciminator loss fake = 8.968974007927955e-09, generator loss = 19.41342544555664\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 14, Batch: 228/468, discriminator loss real = 3.159482265601352e-19, disciminator loss fake = 1.139816241391145e-08, generator loss = 19.369678497314453\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 14, Batch: 229/468, discriminator loss real = 9.352136963502062e-20, disciminator loss fake = 9.712943338513469e-09, generator loss = 19.214221954345703\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 14, Batch: 230/468, discriminator loss real = 1.5113534909817143e-21, disciminator loss fake = 1.2433629237307287e-08, generator loss = 19.364656448364258\n",
      "2/2 [==============================] - 0s 192ms/step\n",
      "Epoch: 14, Batch: 231/468, discriminator loss real = 9.131104506907513e-17, disciminator loss fake = 1.0441119080439876e-08, generator loss = 19.175575256347656\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 14, Batch: 232/468, discriminator loss real = 1.6464743954550522e-15, disciminator loss fake = 9.09889141809117e-09, generator loss = 19.312280654907227\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 14, Batch: 233/468, discriminator loss real = 5.894716519721327e-19, disciminator loss fake = 1.3605826687523859e-08, generator loss = 19.295387268066406\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 14, Batch: 234/468, discriminator loss real = 1.7339764987964472e-15, disciminator loss fake = 8.079112490122498e-09, generator loss = 19.36203384399414\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch: 14, Batch: 235/468, discriminator loss real = 2.1253198672843602e-19, disciminator loss fake = 9.183759530628777e-09, generator loss = 19.303661346435547\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 14, Batch: 236/468, discriminator loss real = 6.345471223739236e-17, disciminator loss fake = 8.069874546379197e-09, generator loss = 19.241477966308594\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 14, Batch: 237/468, discriminator loss real = 5.09733757027736e-18, disciminator loss fake = 1.738968435915922e-08, generator loss = 19.147144317626953\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 14, Batch: 238/468, discriminator loss real = 6.154656862281116e-13, disciminator loss fake = 8.617533353572071e-09, generator loss = 19.37020492553711\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 14, Batch: 239/468, discriminator loss real = 6.880361809669588e-15, disciminator loss fake = 8.80220518695296e-09, generator loss = 19.29296875\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 14, Batch: 240/468, discriminator loss real = 7.177766707609985e-20, disciminator loss fake = 8.869997181193412e-09, generator loss = 19.291107177734375\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 14, Batch: 241/468, discriminator loss real = 8.74945715878539e-09, disciminator loss fake = 8.352488478635678e-09, generator loss = 19.4199161529541\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 14, Batch: 242/468, discriminator loss real = 2.812558996465042e-12, disciminator loss fake = 1.4593836361598278e-08, generator loss = 19.48801040649414\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 14, Batch: 243/468, discriminator loss real = 4.753191971556817e-18, disciminator loss fake = 7.812920088667852e-09, generator loss = 19.459829330444336\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 14, Batch: 244/468, discriminator loss real = 8.40651231623097e-15, disciminator loss fake = 8.281178409674794e-09, generator loss = 19.422025680541992\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 14, Batch: 245/468, discriminator loss real = 8.743688180445647e-15, disciminator loss fake = 8.045583754778818e-09, generator loss = 19.503253936767578\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 14, Batch: 246/468, discriminator loss real = 1.7038568906474483e-12, disciminator loss fake = 8.598448175689555e-09, generator loss = 19.476900100708008\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 14, Batch: 247/468, discriminator loss real = 4.183237646137873e-17, disciminator loss fake = 8.01900768010455e-09, generator loss = 19.444196701049805\n",
      "2/2 [==============================] - 0s 168ms/step\n",
      "Epoch: 14, Batch: 248/468, discriminator loss real = 3.841882127623471e-18, disciminator loss fake = 8.525321781860384e-09, generator loss = 19.36760139465332\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 14, Batch: 249/468, discriminator loss real = 4.4648714688884974e-17, disciminator loss fake = 5.787488710495836e-09, generator loss = 19.415542602539062\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 14, Batch: 250/468, discriminator loss real = 1.440810090593686e-13, disciminator loss fake = 4.876533843400921e-09, generator loss = 19.50148582458496\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 14, Batch: 251/468, discriminator loss real = 2.1036993287236634e-14, disciminator loss fake = 7.721382644376718e-09, generator loss = 19.40157699584961\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 14, Batch: 252/468, discriminator loss real = 5.575185278716699e-12, disciminator loss fake = 8.214261271177747e-09, generator loss = 19.31964874267578\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 14, Batch: 253/468, discriminator loss real = 3.3435012590669027e-18, disciminator loss fake = 8.769257320295765e-09, generator loss = 19.422788619995117\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 14, Batch: 254/468, discriminator loss real = 1.1095138462900679e-15, disciminator loss fake = 5.049422213687649e-09, generator loss = 19.606407165527344\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 14, Batch: 255/468, discriminator loss real = 1.9431520262747255e-15, disciminator loss fake = 1.0665960559208543e-08, generator loss = 19.546539306640625\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 14, Batch: 256/468, discriminator loss real = 3.928731645563843e-11, disciminator loss fake = 1.168451113642277e-08, generator loss = 19.62533187866211\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 14, Batch: 257/468, discriminator loss real = 6.904828621048825e-17, disciminator loss fake = 7.84307552237351e-09, generator loss = 19.59339141845703\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 14, Batch: 258/468, discriminator loss real = 8.348790170779362e-18, disciminator loss fake = 9.021603020187285e-09, generator loss = 19.465744018554688\n",
      "2/2 [==============================] - 0s 172ms/step\n",
      "Epoch: 14, Batch: 259/468, discriminator loss real = 2.0233982891970648e-11, disciminator loss fake = 9.793842181693435e-09, generator loss = 19.622940063476562\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 14, Batch: 260/468, discriminator loss real = 9.547674913320484e-16, disciminator loss fake = 8.956929420378401e-09, generator loss = 19.50986099243164\n",
      "2/2 [==============================] - 0s 175ms/step\n",
      "Epoch: 14, Batch: 261/468, discriminator loss real = 4.152137772688247e-16, disciminator loss fake = 8.300048648379743e-09, generator loss = 19.288284301757812\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 14, Batch: 262/468, discriminator loss real = 1.558760639755962e-15, disciminator loss fake = 9.059342609418763e-09, generator loss = 19.387632369995117\n",
      "2/2 [==============================] - 0s 150ms/step\n",
      "Epoch: 14, Batch: 263/468, discriminator loss real = 2.9967312810928737e-13, disciminator loss fake = 7.713249594587523e-09, generator loss = 19.47279930114746\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 14, Batch: 264/468, discriminator loss real = 3.334649930204218e-17, disciminator loss fake = 6.215127079656213e-09, generator loss = 19.601531982421875\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 14, Batch: 265/468, discriminator loss real = 2.843918290285142e-18, disciminator loss fake = 9.273539269827324e-09, generator loss = 19.594970703125\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 14, Batch: 266/468, discriminator loss real = 5.341100715392367e-16, disciminator loss fake = 4.3523264992018085e-09, generator loss = 19.568920135498047\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 14, Batch: 267/468, discriminator loss real = 6.0683760239044204e-09, disciminator loss fake = 6.292935061935623e-09, generator loss = 19.599740982055664\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 14, Batch: 268/468, discriminator loss real = 3.026429662298302e-15, disciminator loss fake = 7.568941029489906e-09, generator loss = 19.649497985839844\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 14, Batch: 269/468, discriminator loss real = 3.84321784466235e-12, disciminator loss fake = 8.684718721951867e-09, generator loss = 19.867769241333008\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 14, Batch: 270/468, discriminator loss real = 3.635125783284926e-13, disciminator loss fake = 6.150691955753018e-09, generator loss = 19.61622428894043\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 14, Batch: 271/468, discriminator loss real = 3.279386324351795e-17, disciminator loss fake = 5.031139949096541e-09, generator loss = 19.476600646972656\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 14, Batch: 272/468, discriminator loss real = 8.706060774642949e-14, disciminator loss fake = 6.565509025335814e-09, generator loss = 19.893796920776367\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 14, Batch: 273/468, discriminator loss real = 3.4125363667682207e-13, disciminator loss fake = 6.7192917896363724e-09, generator loss = 19.592830657958984\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 14, Batch: 274/468, discriminator loss real = 1.7621459558859283e-15, disciminator loss fake = 9.273835033241085e-09, generator loss = 19.680479049682617\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 14, Batch: 275/468, discriminator loss real = 2.7379786805836748e-12, disciminator loss fake = 4.706266487630728e-09, generator loss = 19.68052864074707\n",
      "2/2 [==============================] - 0s 160ms/step\n",
      "Epoch: 14, Batch: 276/468, discriminator loss real = 3.2594251326819104e-15, disciminator loss fake = 7.3913843934292345e-09, generator loss = 19.724332809448242\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 14, Batch: 277/468, discriminator loss real = 8.652914539400425e-13, disciminator loss fake = 5.55106360877744e-09, generator loss = 19.72785186767578\n",
      "2/2 [==============================] - 0s 151ms/step\n",
      "Epoch: 14, Batch: 278/468, discriminator loss real = 2.3336389662843965e-17, disciminator loss fake = 4.238430051373143e-09, generator loss = 19.8187313079834\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 14, Batch: 279/468, discriminator loss real = 2.0052395413084657e-15, disciminator loss fake = 7.522034550788703e-09, generator loss = 19.68021583557129\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 14, Batch: 280/468, discriminator loss real = 9.766699206998326e-20, disciminator loss fake = 4.802039654805412e-09, generator loss = 19.716232299804688\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 14, Batch: 281/468, discriminator loss real = 2.1112640317448258e-17, disciminator loss fake = 4.813038856354979e-09, generator loss = 19.890369415283203\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 14, Batch: 282/468, discriminator loss real = 3.427519159877705e-14, disciminator loss fake = 8.655621996922491e-09, generator loss = 19.758472442626953\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 14, Batch: 283/468, discriminator loss real = 1.5404514469574693e-11, disciminator loss fake = 4.466852665530041e-09, generator loss = 19.79389190673828\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 14, Batch: 284/468, discriminator loss real = 3.858159723759413e-20, disciminator loss fake = 5.119551005350331e-09, generator loss = 19.628780364990234\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 14, Batch: 285/468, discriminator loss real = 1.1533765987763233e-18, disciminator loss fake = 6.261180907074504e-09, generator loss = 19.604087829589844\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 14, Batch: 286/468, discriminator loss real = 6.600664507722818e-19, disciminator loss fake = 6.850088496435092e-09, generator loss = 19.74258041381836\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 14, Batch: 287/468, discriminator loss real = 2.362008261472775e-20, disciminator loss fake = 6.097003790728195e-09, generator loss = 19.837724685668945\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 14, Batch: 288/468, discriminator loss real = 2.5549495245164033e-15, disciminator loss fake = 5.584343654163604e-09, generator loss = 19.60971450805664\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 14, Batch: 289/468, discriminator loss real = 4.670405734075427e-16, disciminator loss fake = 6.40173025701074e-09, generator loss = 19.914249420166016\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 14, Batch: 290/468, discriminator loss real = 2.425611361073221e-12, disciminator loss fake = 4.536521380771319e-09, generator loss = 19.73863983154297\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 14, Batch: 291/468, discriminator loss real = 1.2293993405763926e-13, disciminator loss fake = 5.148864445914114e-09, generator loss = 19.907041549682617\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 14, Batch: 292/468, discriminator loss real = 1.184574628058238e-13, disciminator loss fake = 4.940112319218315e-09, generator loss = 19.836910247802734\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 14, Batch: 293/468, discriminator loss real = 2.8160451987742487e-18, disciminator loss fake = 4.380359186484384e-09, generator loss = 19.664306640625\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 14, Batch: 294/468, discriminator loss real = 5.48367948272066e-12, disciminator loss fake = 5.253579349329129e-09, generator loss = 19.904788970947266\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 14, Batch: 295/468, discriminator loss real = 1.4121022927360283e-11, disciminator loss fake = 8.576411580918375e-09, generator loss = 19.82300567626953\n",
      "2/2 [==============================] - 0s 136ms/step\n",
      "Epoch: 14, Batch: 296/468, discriminator loss real = 2.615332646629942e-12, disciminator loss fake = 4.855444046825141e-09, generator loss = 19.979991912841797\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 14, Batch: 297/468, discriminator loss real = 2.7146279405680478e-14, disciminator loss fake = 6.189134538203689e-09, generator loss = 19.793731689453125\n",
      "2/2 [==============================] - 0s 152ms/step\n",
      "Epoch: 14, Batch: 298/468, discriminator loss real = 3.2575726716262653e-15, disciminator loss fake = 4.827650279537465e-09, generator loss = 19.699153900146484\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 14, Batch: 299/468, discriminator loss real = 1.1922454667933692e-20, disciminator loss fake = 4.934032737935468e-09, generator loss = 20.1121826171875\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 14, Batch: 300/468, discriminator loss real = 1.6750150528752061e-12, disciminator loss fake = 4.093141825478597e-09, generator loss = 19.875085830688477\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 14, Batch: 301/468, discriminator loss real = 2.933027273030121e-17, disciminator loss fake = 4.012163934419277e-09, generator loss = 19.79012107849121\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 14, Batch: 302/468, discriminator loss real = 5.5473922439160106e-14, disciminator loss fake = 4.303492673329856e-09, generator loss = 19.94745635986328\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 14, Batch: 303/468, discriminator loss real = 8.167692217009304e-11, disciminator loss fake = 4.7362687105589885e-09, generator loss = 19.828311920166016\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 14, Batch: 304/468, discriminator loss real = 7.372391136158465e-14, disciminator loss fake = 3.7493421700673935e-09, generator loss = 19.896860122680664\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 14, Batch: 305/468, discriminator loss real = 9.792885657594684e-16, disciminator loss fake = 6.7737477849050265e-09, generator loss = 19.762557983398438\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 14, Batch: 306/468, discriminator loss real = 8.806310385027342e-18, disciminator loss fake = 7.434098669989453e-09, generator loss = 20.078908920288086\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 14, Batch: 307/468, discriminator loss real = 1.9446199360266785e-18, disciminator loss fake = 4.610629211754258e-09, generator loss = 19.85552978515625\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 14, Batch: 308/468, discriminator loss real = 2.2210048199449578e-13, disciminator loss fake = 3.799963899098202e-09, generator loss = 19.870548248291016\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 14, Batch: 309/468, discriminator loss real = 3.106281046422741e-16, disciminator loss fake = 5.4520867820428975e-09, generator loss = 20.011110305786133\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 14, Batch: 310/468, discriminator loss real = 3.696347490886136e-16, disciminator loss fake = 3.711852603061061e-09, generator loss = 19.863943099975586\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 14, Batch: 311/468, discriminator loss real = 2.4807863901492506e-16, disciminator loss fake = 4.762334526731138e-09, generator loss = 19.801677703857422\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 14, Batch: 312/468, discriminator loss real = 8.243590994836093e-19, disciminator loss fake = 4.66523886188952e-09, generator loss = 20.1794376373291\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 14, Batch: 313/468, discriminator loss real = 3.5560514121291565e-15, disciminator loss fake = 4.218364324515278e-09, generator loss = 19.827411651611328\n",
      "2/2 [==============================] - 0s 175ms/step\n",
      "Epoch: 14, Batch: 314/468, discriminator loss real = 3.414816238531468e-16, disciminator loss fake = 4.296296651773446e-09, generator loss = 20.118061065673828\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 14, Batch: 315/468, discriminator loss real = 1.7813134644493458e-16, disciminator loss fake = 5.494571908570833e-09, generator loss = 19.725727081298828\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Epoch: 14, Batch: 316/468, discriminator loss real = 1.2982199358603294e-17, disciminator loss fake = 4.2431178570723205e-09, generator loss = 19.815635681152344\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 14, Batch: 317/468, discriminator loss real = 1.173484161405558e-12, disciminator loss fake = 3.6780423151583364e-09, generator loss = 19.88558578491211\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 14, Batch: 318/468, discriminator loss real = 5.515640705668415e-14, disciminator loss fake = 4.433316380669794e-09, generator loss = 20.044679641723633\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 14, Batch: 319/468, discriminator loss real = 1.0622441294627638e-11, disciminator loss fake = 4.953657484207952e-09, generator loss = 19.888397216796875\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 14, Batch: 320/468, discriminator loss real = 7.455777661924401e-11, disciminator loss fake = 4.497645367251835e-09, generator loss = 19.958974838256836\n",
      "2/2 [==============================] - 0s 163ms/step\n",
      "Epoch: 14, Batch: 321/468, discriminator loss real = 1.3328580461546835e-09, disciminator loss fake = 3.574035289943822e-09, generator loss = 19.920757293701172\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 14, Batch: 322/468, discriminator loss real = 1.592695042518244e-08, disciminator loss fake = 3.4586822295068487e-09, generator loss = 19.768909454345703\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 14, Batch: 323/468, discriminator loss real = 7.830563454602757e-12, disciminator loss fake = 3.852260732628565e-09, generator loss = 19.911296844482422\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 14, Batch: 324/468, discriminator loss real = 8.10893863043222e-15, disciminator loss fake = 3.824188965495523e-09, generator loss = 19.95517921447754\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 14, Batch: 325/468, discriminator loss real = 1.6253074656196408e-16, disciminator loss fake = 5.8127120894369e-09, generator loss = 20.070035934448242\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 14, Batch: 326/468, discriminator loss real = 1.5353002411609175e-14, disciminator loss fake = 5.029732186301317e-09, generator loss = 19.929134368896484\n",
      "2/2 [==============================] - 0s 137ms/step\n",
      "Epoch: 14, Batch: 327/468, discriminator loss real = 3.791622995496267e-19, disciminator loss fake = 2.8306117449972135e-09, generator loss = 20.00164222717285\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 14, Batch: 328/468, discriminator loss real = 1.726576677521349e-20, disciminator loss fake = 4.609720605230905e-09, generator loss = 20.10760498046875\n",
      "2/2 [==============================] - 0s 160ms/step\n",
      "Epoch: 14, Batch: 329/468, discriminator loss real = 3.414858239930707e-12, disciminator loss fake = 3.380402624486578e-09, generator loss = 20.149972915649414\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 14, Batch: 330/468, discriminator loss real = 5.745366205359148e-14, disciminator loss fake = 4.012858489943483e-09, generator loss = 20.196386337280273\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 14, Batch: 331/468, discriminator loss real = 4.244403067399883e-21, disciminator loss fake = 4.078096083048877e-09, generator loss = 19.963754653930664\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 14, Batch: 332/468, discriminator loss real = 1.5258714092052615e-15, disciminator loss fake = 4.584496338111421e-09, generator loss = 19.904306411743164\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 14, Batch: 333/468, discriminator loss real = 1.8809747985404703e-18, disciminator loss fake = 2.8336266666428855e-09, generator loss = 19.86756134033203\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 14, Batch: 334/468, discriminator loss real = 7.900189478163766e-16, disciminator loss fake = 5.455373042195788e-09, generator loss = 20.023643493652344\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 14, Batch: 335/468, discriminator loss real = 2.7298406590769986e-12, disciminator loss fake = 4.847620083126003e-09, generator loss = 20.120277404785156\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 14, Batch: 336/468, discriminator loss real = 9.39025771127854e-18, disciminator loss fake = 4.953473187185864e-09, generator loss = 19.957012176513672\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 14, Batch: 337/468, discriminator loss real = 6.533485406505599e-16, disciminator loss fake = 5.718184592495845e-09, generator loss = 20.163721084594727\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 14, Batch: 338/468, discriminator loss real = 1.5777581064552182e-14, disciminator loss fake = 2.5460182850878255e-09, generator loss = 20.047847747802734\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 14, Batch: 339/468, discriminator loss real = 3.18137465156465e-12, disciminator loss fake = 3.2990066234361848e-09, generator loss = 20.143402099609375\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 14, Batch: 340/468, discriminator loss real = 8.33531824410218e-16, disciminator loss fake = 3.344304611019311e-09, generator loss = 19.894433975219727\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 14, Batch: 341/468, discriminator loss real = 1.5067641458602174e-15, disciminator loss fake = 3.2317650777713425e-09, generator loss = 20.185325622558594\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 14, Batch: 342/468, discriminator loss real = 1.2504767517347733e-15, disciminator loss fake = 4.531139019547936e-09, generator loss = 20.032001495361328\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 14, Batch: 343/468, discriminator loss real = 1.0924238130847336e-13, disciminator loss fake = 3.216581667686569e-09, generator loss = 20.20244026184082\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 14, Batch: 344/468, discriminator loss real = 1.2923242060443577e-17, disciminator loss fake = 2.293472745051872e-09, generator loss = 19.892417907714844\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 14, Batch: 345/468, discriminator loss real = 4.6341168309118035e-15, disciminator loss fake = 3.3435512136748002e-09, generator loss = 20.23299789428711\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 14, Batch: 346/468, discriminator loss real = 3.218622629170385e-17, disciminator loss fake = 4.0362309050578915e-09, generator loss = 20.052305221557617\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 14, Batch: 347/468, discriminator loss real = 7.846548602149825e-17, disciminator loss fake = 3.497868661384018e-09, generator loss = 19.948240280151367\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 14, Batch: 348/468, discriminator loss real = 1.5712456089369588e-14, disciminator loss fake = 3.8906686761208675e-09, generator loss = 20.182201385498047\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 14, Batch: 349/468, discriminator loss real = 6.43268273687708e-19, disciminator loss fake = 3.8282630399066875e-09, generator loss = 20.036998748779297\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 14, Batch: 350/468, discriminator loss real = 2.8771790934689284e-20, disciminator loss fake = 4.8333190783012014e-09, generator loss = 20.189273834228516\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 14, Batch: 351/468, discriminator loss real = 3.751496929270414e-18, disciminator loss fake = 3.282019545025605e-09, generator loss = 20.23651123046875\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 14, Batch: 352/468, discriminator loss real = 1.011645059173158e-13, disciminator loss fake = 4.142330034540009e-09, generator loss = 20.10974884033203\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 14, Batch: 353/468, discriminator loss real = 7.32199403104955e-14, disciminator loss fake = 4.016690979824489e-09, generator loss = 20.152006149291992\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 14, Batch: 354/468, discriminator loss real = 6.424853989367149e-20, disciminator loss fake = 3.861354347378665e-09, generator loss = 20.094284057617188\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 14, Batch: 355/468, discriminator loss real = 2.1420953661040187e-13, disciminator loss fake = 3.4964366957268567e-09, generator loss = 20.146217346191406\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 14, Batch: 356/468, discriminator loss real = 3.21278940443022e-15, disciminator loss fake = 4.6904666817226826e-09, generator loss = 20.050161361694336\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 14, Batch: 357/468, discriminator loss real = 1.468400901360415e-14, disciminator loss fake = 3.220111732815667e-09, generator loss = 20.34966468811035\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 14, Batch: 358/468, discriminator loss real = 1.2612529034130895e-17, disciminator loss fake = 2.4641377827094857e-09, generator loss = 20.257164001464844\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 14, Batch: 359/468, discriminator loss real = 1.0405298154695628e-16, disciminator loss fake = 3.6006251313835946e-09, generator loss = 20.059118270874023\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 14, Batch: 360/468, discriminator loss real = 1.1923070684845497e-17, disciminator loss fake = 3.384662550232065e-09, generator loss = 20.082439422607422\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 14, Batch: 361/468, discriminator loss real = 2.0866934482416388e-14, disciminator loss fake = 2.826496148244928e-09, generator loss = 20.05584144592285\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 14, Batch: 362/468, discriminator loss real = 3.833979439265764e-15, disciminator loss fake = 2.607027038692422e-09, generator loss = 20.206592559814453\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 14, Batch: 363/468, discriminator loss real = 1.2277024015461269e-12, disciminator loss fake = 4.043988255375552e-09, generator loss = 20.043210983276367\n",
      "2/2 [==============================] - 0s 153ms/step\n",
      "Epoch: 14, Batch: 364/468, discriminator loss real = 6.529407681199473e-09, disciminator loss fake = 4.849196155731761e-09, generator loss = 19.963815689086914\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 14, Batch: 365/468, discriminator loss real = 3.816272396138979e-20, disciminator loss fake = 4.4697361367695976e-09, generator loss = 20.20351791381836\n",
      "2/2 [==============================] - 0s 160ms/step\n",
      "Epoch: 14, Batch: 366/468, discriminator loss real = 7.052888273406666e-10, disciminator loss fake = 2.4667561326907617e-09, generator loss = 20.20566177368164\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 14, Batch: 367/468, discriminator loss real = 1.598668808824085e-14, disciminator loss fake = 4.578908807673088e-09, generator loss = 20.100692749023438\n",
      "2/2 [==============================] - 0s 150ms/step\n",
      "Epoch: 14, Batch: 368/468, discriminator loss real = 5.7542819047553574e-15, disciminator loss fake = 3.879458976285832e-09, generator loss = 19.89895248413086\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 14, Batch: 369/468, discriminator loss real = 3.2841205883232805e-12, disciminator loss fake = 2.0529087318976735e-09, generator loss = 20.12254524230957\n",
      "2/2 [==============================] - 0s 159ms/step\n",
      "Epoch: 14, Batch: 370/468, discriminator loss real = 1.1813612561068984e-14, disciminator loss fake = 2.9491151742888633e-09, generator loss = 20.107576370239258\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 14, Batch: 371/468, discriminator loss real = 2.198677937780588e-15, disciminator loss fake = 3.2602600619213717e-09, generator loss = 20.178037643432617\n",
      "2/2 [==============================] - 0s 175ms/step\n",
      "Epoch: 14, Batch: 372/468, discriminator loss real = 1.4359665529133786e-13, disciminator loss fake = 4.373092110654397e-09, generator loss = 20.192825317382812\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 14, Batch: 373/468, discriminator loss real = 3.885423070521671e-13, disciminator loss fake = 4.208638770819562e-09, generator loss = 20.28021812438965\n",
      "2/2 [==============================] - 0s 150ms/step\n",
      "Epoch: 14, Batch: 374/468, discriminator loss real = 4.901888357028428e-13, disciminator loss fake = 4.336047076947125e-09, generator loss = 20.189350128173828\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 14, Batch: 375/468, discriminator loss real = 4.663069857004966e-14, disciminator loss fake = 4.341583093037116e-09, generator loss = 20.200063705444336\n",
      "2/2 [==============================] - 0s 137ms/step\n",
      "Epoch: 14, Batch: 376/468, discriminator loss real = 4.388392860904533e-12, disciminator loss fake = 4.031658118464065e-09, generator loss = 20.343782424926758\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 14, Batch: 377/468, discriminator loss real = 3.537890263410372e-14, disciminator loss fake = 2.738905546806336e-09, generator loss = 20.19004249572754\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 14, Batch: 378/468, discriminator loss real = 5.692273909174705e-13, disciminator loss fake = 3.1475158035476625e-09, generator loss = 19.949478149414062\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 14, Batch: 379/468, discriminator loss real = 5.37823702208016e-17, disciminator loss fake = 2.7526509960296153e-09, generator loss = 20.033710479736328\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 14, Batch: 380/468, discriminator loss real = 4.058106389988325e-14, disciminator loss fake = 2.799655618446195e-09, generator loss = 20.093244552612305\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 14, Batch: 381/468, discriminator loss real = 3.350659845524059e-16, disciminator loss fake = 2.739491966607943e-09, generator loss = 20.13221549987793\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 14, Batch: 382/468, discriminator loss real = 5.335786443916184e-17, disciminator loss fake = 4.350322324597755e-09, generator loss = 20.372644424438477\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 14, Batch: 383/468, discriminator loss real = 3.5450285827513806e-13, disciminator loss fake = 1.963910367663857e-09, generator loss = 20.222990036010742\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 14, Batch: 384/468, discriminator loss real = 1.688523016780887e-15, disciminator loss fake = 3.1353550866697333e-09, generator loss = 20.393939971923828\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 14, Batch: 385/468, discriminator loss real = 6.551606617620921e-17, disciminator loss fake = 3.3222733453186493e-09, generator loss = 20.136924743652344\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 14, Batch: 386/468, discriminator loss real = 3.8177406657020907e-13, disciminator loss fake = 2.454600300794141e-09, generator loss = 20.270736694335938\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 14, Batch: 387/468, discriminator loss real = 6.074108734265254e-16, disciminator loss fake = 3.1202200823088333e-09, generator loss = 20.075910568237305\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 14, Batch: 388/468, discriminator loss real = 2.1070698422273777e-15, disciminator loss fake = 2.4713529001019197e-09, generator loss = 20.24219512939453\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 14, Batch: 389/468, discriminator loss real = 5.49841530812778e-13, disciminator loss fake = 2.9315780913918843e-09, generator loss = 20.306882858276367\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 14, Batch: 390/468, discriminator loss real = 6.437214043059081e-13, disciminator loss fake = 3.330182352101474e-09, generator loss = 20.11901092529297\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 14, Batch: 391/468, discriminator loss real = 5.3079102587498e-16, disciminator loss fake = 3.390137948144911e-09, generator loss = 20.374473571777344\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 14, Batch: 392/468, discriminator loss real = 2.00512593724958e-13, disciminator loss fake = 3.776979617953202e-09, generator loss = 20.354772567749023\n",
      "2/2 [==============================] - 0s 176ms/step\n",
      "Epoch: 14, Batch: 393/468, discriminator loss real = 2.965335971021575e-14, disciminator loss fake = 4.001321052271578e-09, generator loss = 20.220033645629883\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 14, Batch: 394/468, discriminator loss real = 1.6785551330575983e-16, disciminator loss fake = 3.6083143140075435e-09, generator loss = 20.244300842285156\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 14, Batch: 395/468, discriminator loss real = 4.0462110658529005e-13, disciminator loss fake = 3.6521665691680028e-09, generator loss = 20.319110870361328\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 14, Batch: 396/468, discriminator loss real = 1.2824753059656122e-14, disciminator loss fake = 2.714855451557696e-09, generator loss = 20.468055725097656\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 14, Batch: 397/468, discriminator loss real = 2.8905256081915136e-16, disciminator loss fake = 3.152270888762132e-09, generator loss = 20.1959228515625\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 14, Batch: 398/468, discriminator loss real = 1.815932495097017e-16, disciminator loss fake = 2.4601396475532056e-09, generator loss = 20.27816390991211\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 14, Batch: 399/468, discriminator loss real = 4.01113510963458e-17, disciminator loss fake = 3.398979764313026e-09, generator loss = 20.294912338256836\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 14, Batch: 400/468, discriminator loss real = 1.401245942898299e-17, disciminator loss fake = 5.0437618526189e-09, generator loss = 20.482616424560547\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 14, Batch: 401/468, discriminator loss real = 1.9010584129410127e-17, disciminator loss fake = 2.807967192097749e-09, generator loss = 20.3674259185791\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 14, Batch: 402/468, discriminator loss real = 1.4286270286733153e-20, disciminator loss fake = 2.8991360423447077e-09, generator loss = 20.319869995117188\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 14, Batch: 403/468, discriminator loss real = 1.7749209795883115e-17, disciminator loss fake = 2.677436272691125e-09, generator loss = 20.503713607788086\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 14, Batch: 404/468, discriminator loss real = 2.325890131535391e-13, disciminator loss fake = 3.0380080673353405e-09, generator loss = 20.35329246520996\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 14, Batch: 405/468, discriminator loss real = 8.833596153818776e-14, disciminator loss fake = 3.0475977297328427e-09, generator loss = 20.281513214111328\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 14, Batch: 406/468, discriminator loss real = 6.2284204554422136e-15, disciminator loss fake = 3.3469009785846993e-09, generator loss = 20.441116333007812\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 14, Batch: 407/468, discriminator loss real = 3.731423156572156e-12, disciminator loss fake = 4.4060657344857646e-09, generator loss = 20.459253311157227\n",
      "2/2 [==============================] - 0s 159ms/step\n",
      "Epoch: 14, Batch: 408/468, discriminator loss real = 3.2772402413366875e-12, disciminator loss fake = 2.990889313991829e-09, generator loss = 20.114482879638672\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 14, Batch: 409/468, discriminator loss real = 1.0513869641440646e-13, disciminator loss fake = 2.267361631780318e-09, generator loss = 20.265357971191406\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 14, Batch: 410/468, discriminator loss real = 4.1308117660948745e-18, disciminator loss fake = 2.6801330044179394e-09, generator loss = 20.160541534423828\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 14, Batch: 411/468, discriminator loss real = 3.222413655357137e-13, disciminator loss fake = 2.536479470904851e-09, generator loss = 20.259315490722656\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 14, Batch: 412/468, discriminator loss real = 3.6094265597197417e-12, disciminator loss fake = 3.3404545796145158e-09, generator loss = 20.244953155517578\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 14, Batch: 413/468, discriminator loss real = 5.5634780772107276e-14, disciminator loss fake = 2.0182548965408387e-09, generator loss = 20.392868041992188\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 14, Batch: 414/468, discriminator loss real = 8.678232220521469e-18, disciminator loss fake = 2.8449285149889647e-09, generator loss = 20.347604751586914\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 14, Batch: 415/468, discriminator loss real = 4.2520316694688587e-13, disciminator loss fake = 2.5580368934186026e-09, generator loss = 20.342681884765625\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 14, Batch: 416/468, discriminator loss real = 1.1011683747679061e-16, disciminator loss fake = 2.76255951447979e-09, generator loss = 20.26861000061035\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 14, Batch: 417/468, discriminator loss real = 1.5543437864525044e-15, disciminator loss fake = 3.0082054625069077e-09, generator loss = 20.251163482666016\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Epoch: 14, Batch: 418/468, discriminator loss real = 1.1798789484492034e-13, disciminator loss fake = 2.921156205815123e-09, generator loss = 20.31228256225586\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 14, Batch: 419/468, discriminator loss real = 1.6724157861435206e-18, disciminator loss fake = 3.360440370414608e-09, generator loss = 20.34270477294922\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 14, Batch: 420/468, discriminator loss real = 1.8216601838094704e-10, disciminator loss fake = 3.0295783659539666e-09, generator loss = 20.439048767089844\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 14, Batch: 421/468, discriminator loss real = 2.2910869382219978e-11, disciminator loss fake = 3.1887705809197087e-09, generator loss = 20.42782974243164\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 14, Batch: 422/468, discriminator loss real = 8.126611112608844e-19, disciminator loss fake = 2.9280819990873397e-09, generator loss = 20.329730987548828\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 14, Batch: 423/468, discriminator loss real = 8.341235982609313e-21, disciminator loss fake = 2.972756929509046e-09, generator loss = 20.410778045654297\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 14, Batch: 424/468, discriminator loss real = 3.696738078953939e-15, disciminator loss fake = 2.273140342623492e-09, generator loss = 20.282093048095703\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 14, Batch: 425/468, discriminator loss real = 2.4946711363327267e-13, disciminator loss fake = 2.713940627785405e-09, generator loss = 20.39959716796875\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 14, Batch: 426/468, discriminator loss real = 8.551360140829356e-12, disciminator loss fake = 3.718969354693513e-09, generator loss = 20.427885055541992\n",
      "2/2 [==============================] - 0s 199ms/step\n",
      "Epoch: 14, Batch: 427/468, discriminator loss real = 1.757129509134933e-15, disciminator loss fake = 2.6468542912994053e-09, generator loss = 20.61941146850586\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 14, Batch: 428/468, discriminator loss real = 2.638793419613549e-14, disciminator loss fake = 2.513333097198256e-09, generator loss = 20.370254516601562\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 14, Batch: 429/468, discriminator loss real = 7.083070675123482e-12, disciminator loss fake = 2.6909967587585015e-09, generator loss = 20.467453002929688\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 14, Batch: 430/468, discriminator loss real = 6.8471173877638574e-18, disciminator loss fake = 2.4887392147121545e-09, generator loss = 20.544300079345703\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 14, Batch: 431/468, discriminator loss real = 3.0027220401969423e-13, disciminator loss fake = 1.9627124370202864e-09, generator loss = 20.46926498413086\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 14, Batch: 432/468, discriminator loss real = 4.519528096224874e-15, disciminator loss fake = 3.293372463630817e-09, generator loss = 20.339597702026367\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 14, Batch: 433/468, discriminator loss real = 6.777477465583324e-19, disciminator loss fake = 3.4386877789671644e-09, generator loss = 20.39983558654785\n",
      "2/2 [==============================] - 0s 159ms/step\n",
      "Epoch: 14, Batch: 434/468, discriminator loss real = 1.3472599009583522e-16, disciminator loss fake = 2.730544901297094e-09, generator loss = 20.419166564941406\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 14, Batch: 435/468, discriminator loss real = 1.1564584669435428e-19, disciminator loss fake = 2.3829276329934146e-09, generator loss = 20.42983627319336\n",
      "2/2 [==============================] - 0s 157ms/step\n",
      "Epoch: 14, Batch: 436/468, discriminator loss real = 4.114575368723316e-17, disciminator loss fake = 2.290037492969077e-09, generator loss = 20.36763572692871\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 14, Batch: 437/468, discriminator loss real = 2.430261200614403e-11, disciminator loss fake = 2.5308362072706814e-09, generator loss = 20.466764450073242\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Epoch: 14, Batch: 438/468, discriminator loss real = 4.666616353514873e-18, disciminator loss fake = 2.2238011432307303e-09, generator loss = 20.479158401489258\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 14, Batch: 439/468, discriminator loss real = 1.3654365691053727e-20, disciminator loss fake = 1.780676717189067e-09, generator loss = 20.47530174255371\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 14, Batch: 440/468, discriminator loss real = 4.208557398519171e-14, disciminator loss fake = 2.778449914586645e-09, generator loss = 20.571849822998047\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 14, Batch: 441/468, discriminator loss real = 1.3074608236351981e-11, disciminator loss fake = 2.3940525117893685e-09, generator loss = 20.4403018951416\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 14, Batch: 442/468, discriminator loss real = 1.4288390349365132e-12, disciminator loss fake = 3.368478829202104e-09, generator loss = 20.519004821777344\n",
      "2/2 [==============================] - 0s 161ms/step\n",
      "Epoch: 14, Batch: 443/468, discriminator loss real = 4.953053534673254e-15, disciminator loss fake = 2.1650725656741088e-09, generator loss = 20.51512908935547\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 14, Batch: 444/468, discriminator loss real = 2.068703696639731e-15, disciminator loss fake = 1.9694652575452665e-09, generator loss = 20.490413665771484\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 14, Batch: 445/468, discriminator loss real = 1.721493218387389e-17, disciminator loss fake = 1.9819015317779076e-09, generator loss = 20.403682708740234\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 14, Batch: 446/468, discriminator loss real = 2.2267040345437463e-18, disciminator loss fake = 1.6085104359575553e-09, generator loss = 20.48076820373535\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 14, Batch: 447/468, discriminator loss real = 8.577182340025954e-14, disciminator loss fake = 3.304950535465423e-09, generator loss = 20.462406158447266\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 14, Batch: 448/468, discriminator loss real = 3.686421641172855e-15, disciminator loss fake = 1.944969740819147e-09, generator loss = 20.418560028076172\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 14, Batch: 449/468, discriminator loss real = 1.1182926736323304e-13, disciminator loss fake = 2.1047550369246437e-09, generator loss = 20.317188262939453\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 14, Batch: 450/468, discriminator loss real = 2.414378647095511e-13, disciminator loss fake = 1.7089332171593696e-09, generator loss = 20.60869598388672\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 14, Batch: 451/468, discriminator loss real = 2.3096462100462626e-19, disciminator loss fake = 2.969271495345538e-09, generator loss = 20.3880615234375\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 14, Batch: 452/468, discriminator loss real = 2.9673316441727773e-16, disciminator loss fake = 2.2673489752378373e-09, generator loss = 20.592111587524414\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 14, Batch: 453/468, discriminator loss real = 7.814079244772287e-12, disciminator loss fake = 2.148917932487393e-09, generator loss = 20.34200096130371\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 14, Batch: 454/468, discriminator loss real = 1.887949881117963e-21, disciminator loss fake = 2.1991495291473484e-09, generator loss = 20.307174682617188\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 14, Batch: 455/468, discriminator loss real = 1.5214515574051707e-13, disciminator loss fake = 2.069259430470538e-09, generator loss = 20.524974822998047\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 14, Batch: 456/468, discriminator loss real = 5.813938219745296e-09, disciminator loss fake = 2.866694215342136e-09, generator loss = 20.44451141357422\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 14, Batch: 457/468, discriminator loss real = 2.690962263538236e-16, disciminator loss fake = 2.6248172524390156e-09, generator loss = 20.379756927490234\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 14, Batch: 458/468, discriminator loss real = 3.829532092776205e-15, disciminator loss fake = 1.3851212399274004e-09, generator loss = 20.434871673583984\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 14, Batch: 459/468, discriminator loss real = 6.708662791954367e-11, disciminator loss fake = 2.9646995969301315e-09, generator loss = 20.529386520385742\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 14, Batch: 460/468, discriminator loss real = 3.621478811277612e-11, disciminator loss fake = 2.018629707833952e-09, generator loss = 20.425098419189453\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 14, Batch: 461/468, discriminator loss real = 1.5088466500529085e-12, disciminator loss fake = 2.809092514155509e-09, generator loss = 20.532028198242188\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 14, Batch: 462/468, discriminator loss real = 2.145117884591683e-14, disciminator loss fake = 2.1774622105397157e-09, generator loss = 20.516212463378906\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 14, Batch: 463/468, discriminator loss real = 9.100449987499686e-16, disciminator loss fake = 2.676425747694111e-09, generator loss = 20.45128631591797\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 14, Batch: 464/468, discriminator loss real = 2.2371715088872373e-16, disciminator loss fake = 2.4651514163309685e-09, generator loss = 20.43151092529297\n",
      "2/2 [==============================] - 0s 167ms/step\n",
      "Epoch: 14, Batch: 465/468, discriminator loss real = 6.721045839016074e-14, disciminator loss fake = 2.8433893017876244e-09, generator loss = 20.57427406311035\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 14, Batch: 466/468, discriminator loss real = 1.3323756160865674e-11, disciminator loss fake = 2.377465113667654e-09, generator loss = 20.449756622314453\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 14, Batch: 467/468, discriminator loss real = 3.484764777086924e-12, disciminator loss fake = 2.2762314255686533e-09, generator loss = 20.522573471069336\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 14, Batch: 468/468, discriminator loss real = 4.162239434677643e-15, disciminator loss fake = 2.285420297454266e-09, generator loss = 20.685611724853516\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 15, Batch: 1/468, discriminator loss real = 8.102229282457019e-15, disciminator loss fake = 1.7332033586114903e-09, generator loss = 20.500282287597656\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 15, Batch: 2/468, discriminator loss real = 1.8215592367809563e-09, disciminator loss fake = 2.376034036188912e-09, generator loss = 20.512102127075195\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 15, Batch: 3/468, discriminator loss real = 5.870903942032171e-14, disciminator loss fake = 2.360425410685707e-09, generator loss = 20.57363510131836\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 15, Batch: 4/468, discriminator loss real = 4.553973300888692e-13, disciminator loss fake = 2.27665597485327e-09, generator loss = 20.47855567932129\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 15, Batch: 5/468, discriminator loss real = 2.084714401107135e-09, disciminator loss fake = 3.4383704772267265e-09, generator loss = 20.490741729736328\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 15, Batch: 6/468, discriminator loss real = 8.422192522387906e-13, disciminator loss fake = 2.167757751081467e-09, generator loss = 20.592496871948242\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 15, Batch: 7/468, discriminator loss real = 6.912450382326896e-15, disciminator loss fake = 2.1769390734505123e-09, generator loss = 20.436622619628906\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 15, Batch: 8/468, discriminator loss real = 1.3544931388114302e-15, disciminator loss fake = 1.9122246008862476e-09, generator loss = 20.361467361450195\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 15, Batch: 9/468, discriminator loss real = 2.607854253725006e-12, disciminator loss fake = 1.737747723495886e-09, generator loss = 20.512798309326172\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 15, Batch: 10/468, discriminator loss real = 1.1863598516385302e-15, disciminator loss fake = 3.926451608293746e-09, generator loss = 20.485010147094727\n",
      "2/2 [==============================] - 0s 130ms/step\n",
      "Epoch: 15, Batch: 11/468, discriminator loss real = 1.1119764159131974e-17, disciminator loss fake = 2.5404711667675883e-09, generator loss = 20.40229034423828\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 15, Batch: 12/468, discriminator loss real = 1.7638094110261626e-11, disciminator loss fake = 1.894117751533031e-09, generator loss = 20.656639099121094\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 15, Batch: 13/468, discriminator loss real = 7.61347995936923e-19, disciminator loss fake = 2.731774140229959e-09, generator loss = 20.629901885986328\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 15, Batch: 14/468, discriminator loss real = 1.8228229384216583e-21, disciminator loss fake = 2.102749530052961e-09, generator loss = 20.469396591186523\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 15, Batch: 15/468, discriminator loss real = 1.4103949670489502e-13, disciminator loss fake = 1.4806351700258347e-09, generator loss = 20.553693771362305\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 15, Batch: 16/468, discriminator loss real = 2.5364149613228215e-15, disciminator loss fake = 2.112739316828538e-09, generator loss = 20.46957015991211\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 15, Batch: 17/468, discriminator loss real = 2.2884710619563986e-12, disciminator loss fake = 2.178823121923301e-09, generator loss = 20.66210174560547\n",
      "2/2 [==============================] - 0s 166ms/step\n",
      "Epoch: 15, Batch: 18/468, discriminator loss real = 3.3355572232590966e-18, disciminator loss fake = 1.8813248736648802e-09, generator loss = 20.61759376525879\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 15, Batch: 19/468, discriminator loss real = 2.448047507946688e-16, disciminator loss fake = 3.29408900157091e-09, generator loss = 20.57851219177246\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 15, Batch: 20/468, discriminator loss real = 6.779290670499982e-12, disciminator loss fake = 2.461329140501789e-09, generator loss = 20.79691505432129\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 15, Batch: 21/468, discriminator loss real = 1.891685463984052e-17, disciminator loss fake = 2.1145556416968248e-09, generator loss = 20.46598243713379\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 15, Batch: 22/468, discriminator loss real = 5.55088353754174e-12, disciminator loss fake = 2.5161752681412963e-09, generator loss = 20.552967071533203\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 15, Batch: 23/468, discriminator loss real = 3.3801828083236934e-15, disciminator loss fake = 1.966898866001543e-09, generator loss = 20.6546573638916\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 15, Batch: 24/468, discriminator loss real = 1.0327044751165743e-15, disciminator loss fake = 2.0030310743379687e-09, generator loss = 20.67339515686035\n",
      "2/2 [==============================] - 0s 166ms/step\n",
      "Epoch: 15, Batch: 25/468, discriminator loss real = 4.4951026234585356e-10, disciminator loss fake = 2.3487924938336846e-09, generator loss = 20.521963119506836\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 15, Batch: 26/468, discriminator loss real = 4.189850549840557e-11, disciminator loss fake = 1.933106785756422e-09, generator loss = 20.611461639404297\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 15, Batch: 27/468, discriminator loss real = 1.9141028857648515e-17, disciminator loss fake = 1.9818990892872534e-09, generator loss = 20.585487365722656\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 15, Batch: 28/468, discriminator loss real = 9.500496364004546e-14, disciminator loss fake = 2.261680398518706e-09, generator loss = 20.66310691833496\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 15, Batch: 29/468, discriminator loss real = 1.1787463315609013e-18, disciminator loss fake = 1.6061254548560555e-09, generator loss = 20.230121612548828\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 15, Batch: 30/468, discriminator loss real = 1.881729220346343e-15, disciminator loss fake = 1.3860460557069132e-09, generator loss = 20.72661590576172\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 15, Batch: 31/468, discriminator loss real = 6.883424892565096e-16, disciminator loss fake = 2.2285397971444354e-09, generator loss = 20.651987075805664\n",
      "2/2 [==============================] - 0s 150ms/step\n",
      "Epoch: 15, Batch: 32/468, discriminator loss real = 1.5344096707201743e-14, disciminator loss fake = 2.0573214243313487e-09, generator loss = 20.483896255493164\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 15, Batch: 33/468, discriminator loss real = 8.53170919329349e-12, disciminator loss fake = 2.021825373788033e-09, generator loss = 20.682775497436523\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 15, Batch: 34/468, discriminator loss real = 1.3270588434544394e-17, disciminator loss fake = 1.8112864541564022e-09, generator loss = 20.840919494628906\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 15, Batch: 35/468, discriminator loss real = 1.4325082231536612e-09, disciminator loss fake = 1.6685368642299636e-09, generator loss = 20.608577728271484\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 15, Batch: 36/468, discriminator loss real = 3.0830788287639755e-17, disciminator loss fake = 1.4002725645667624e-09, generator loss = 20.593017578125\n",
      "2/2 [==============================] - 0s 175ms/step\n",
      "Epoch: 15, Batch: 37/468, discriminator loss real = 7.773609533856529e-11, disciminator loss fake = 1.3713341573406979e-09, generator loss = 20.58688735961914\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 15, Batch: 38/468, discriminator loss real = 8.1200743178181435e-19, disciminator loss fake = 1.781802261291432e-09, generator loss = 20.678014755249023\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 15, Batch: 39/468, discriminator loss real = 3.023897243714657e-10, disciminator loss fake = 1.8050413386205832e-09, generator loss = 20.542692184448242\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 15, Batch: 40/468, discriminator loss real = 5.999418491295025e-14, disciminator loss fake = 2.3976924889979045e-09, generator loss = 20.64809799194336\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 15, Batch: 41/468, discriminator loss real = 5.140549783262151e-14, disciminator loss fake = 2.4239943385850893e-09, generator loss = 20.637161254882812\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 15, Batch: 42/468, discriminator loss real = 7.387577528883416e-12, disciminator loss fake = 1.7002403929211596e-09, generator loss = 20.770509719848633\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 15, Batch: 43/468, discriminator loss real = 9.6400964988419e-10, disciminator loss fake = 2.4101440843082855e-09, generator loss = 20.58452796936035\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 15, Batch: 44/468, discriminator loss real = 1.3363247175490756e-09, disciminator loss fake = 1.910455349474205e-09, generator loss = 20.62713050842285\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 15, Batch: 45/468, discriminator loss real = 8.78347687551656e-13, disciminator loss fake = 2.2385970854799098e-09, generator loss = 20.550973892211914\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 15, Batch: 46/468, discriminator loss real = 4.697470660201689e-15, disciminator loss fake = 1.3567995615915152e-09, generator loss = 20.814380645751953\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 15, Batch: 47/468, discriminator loss real = 1.1022359506100793e-17, disciminator loss fake = 2.4853443747474557e-09, generator loss = 20.500247955322266\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 15, Batch: 48/468, discriminator loss real = 1.0627588219180861e-11, disciminator loss fake = 2.3029107509842106e-09, generator loss = 20.521434783935547\n",
      "2/2 [==============================] - 0s 158ms/step\n",
      "Epoch: 15, Batch: 49/468, discriminator loss real = 1.0936139282569438e-13, disciminator loss fake = 2.129921128357637e-09, generator loss = 20.582490921020508\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 15, Batch: 50/468, discriminator loss real = 3.006121429070372e-19, disciminator loss fake = 2.5312065776716963e-09, generator loss = 20.7755126953125\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 15, Batch: 51/468, discriminator loss real = 6.229703385096652e-12, disciminator loss fake = 1.5517898077632708e-09, generator loss = 20.599891662597656\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 15, Batch: 52/468, discriminator loss real = 2.949081069950586e-14, disciminator loss fake = 1.712132102760222e-09, generator loss = 20.957008361816406\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 15, Batch: 53/468, discriminator loss real = 5.0911552751387035e-11, disciminator loss fake = 1.9902830494800128e-09, generator loss = 20.71558380126953\n",
      "2/2 [==============================] - 0s 157ms/step\n",
      "Epoch: 15, Batch: 54/468, discriminator loss real = 2.094077203849444e-18, disciminator loss fake = 2.057980896807976e-09, generator loss = 20.58233070373535\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 15, Batch: 55/468, discriminator loss real = 2.5369248035644887e-08, disciminator loss fake = 2.2556643219928674e-09, generator loss = 20.774620056152344\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 15, Batch: 56/468, discriminator loss real = 5.422359233000433e-16, disciminator loss fake = 2.0366297537321998e-09, generator loss = 20.633411407470703\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 15, Batch: 57/468, discriminator loss real = 2.0596068253664335e-12, disciminator loss fake = 1.6556551685198428e-09, generator loss = 20.716571807861328\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 15, Batch: 58/468, discriminator loss real = 2.9717664418692225e-13, disciminator loss fake = 1.8941939128325203e-09, generator loss = 20.628707885742188\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 15, Batch: 59/468, discriminator loss real = 1.5861603697153726e-11, disciminator loss fake = 2.123843101387024e-09, generator loss = 20.67748260498047\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 15, Batch: 60/468, discriminator loss real = 1.6421087876449035e-15, disciminator loss fake = 1.5271131026395324e-09, generator loss = 20.7221622467041\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 15, Batch: 61/468, discriminator loss real = 2.71208617336435e-18, disciminator loss fake = 2.421703060306868e-09, generator loss = 20.53571319580078\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 15, Batch: 62/468, discriminator loss real = 7.739203666758034e-15, disciminator loss fake = 2.148799804757573e-09, generator loss = 20.61773681640625\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 15, Batch: 63/468, discriminator loss real = 2.1046296244719654e-19, disciminator loss fake = 2.2596124971130394e-09, generator loss = 20.653884887695312\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 15, Batch: 64/468, discriminator loss real = 1.7831845602298306e-15, disciminator loss fake = 1.8023491588081697e-09, generator loss = 20.761455535888672\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 15, Batch: 65/468, discriminator loss real = 9.89969137776825e-08, disciminator loss fake = 1.6415262482638582e-09, generator loss = 20.929624557495117\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 15, Batch: 66/468, discriminator loss real = 2.167499686678287e-12, disciminator loss fake = 3.5210225846071808e-09, generator loss = 20.75896453857422\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 15, Batch: 67/468, discriminator loss real = 7.73571235576813e-17, disciminator loss fake = 1.7851295996962335e-09, generator loss = 20.611038208007812\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 15, Batch: 68/468, discriminator loss real = 2.683450250201558e-13, disciminator loss fake = 2.6114754803074902e-09, generator loss = 20.51261329650879\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 15, Batch: 69/468, discriminator loss real = 7.438796338113363e-16, disciminator loss fake = 2.3972988039133725e-09, generator loss = 20.7309627532959\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 15, Batch: 70/468, discriminator loss real = 3.953111036641945e-18, disciminator loss fake = 1.767641810701548e-09, generator loss = 20.718547821044922\n",
      "2/2 [==============================] - 0s 173ms/step\n",
      "Epoch: 15, Batch: 71/468, discriminator loss real = 4.9138099053038994e-14, disciminator loss fake = 2.015664746224388e-09, generator loss = 20.54819107055664\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 15, Batch: 72/468, discriminator loss real = 1.2180897058426763e-15, disciminator loss fake = 2.075212446328578e-09, generator loss = 20.530492782592773\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 15, Batch: 73/468, discriminator loss real = 1.7882762328239044e-12, disciminator loss fake = 1.9231887193882358e-09, generator loss = 20.473499298095703\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 15, Batch: 74/468, discriminator loss real = 1.0981432505951377e-13, disciminator loss fake = 2.2820503264853187e-09, generator loss = 20.42128562927246\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 15, Batch: 75/468, discriminator loss real = 2.370967403867428e-15, disciminator loss fake = 2.138774046755998e-09, generator loss = 20.274106979370117\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 15, Batch: 76/468, discriminator loss real = 5.715613553693998e-17, disciminator loss fake = 1.8434800352906677e-09, generator loss = 20.68149185180664\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 15, Batch: 77/468, discriminator loss real = 5.235711155559313e-17, disciminator loss fake = 2.848419722312201e-09, generator loss = 20.684410095214844\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 15, Batch: 78/468, discriminator loss real = 1.4109456401086191e-14, disciminator loss fake = 1.973424090806475e-09, generator loss = 20.490806579589844\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 15, Batch: 79/468, discriminator loss real = 3.348893495955414e-14, disciminator loss fake = 3.0003133311140573e-09, generator loss = 20.423629760742188\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 15, Batch: 80/468, discriminator loss real = 3.4828580246074915e-15, disciminator loss fake = 1.9158648001393885e-09, generator loss = 20.588211059570312\n",
      "2/2 [==============================] - 0s 159ms/step\n",
      "Epoch: 15, Batch: 81/468, discriminator loss real = 1.1287672228185133e-16, disciminator loss fake = 2.7251800815975002e-09, generator loss = 20.52773666381836\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 15, Batch: 82/468, discriminator loss real = 3.334122528845379e-13, disciminator loss fake = 2.0175157100510432e-09, generator loss = 20.6793212890625\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 15, Batch: 83/468, discriminator loss real = 2.0295561896280218e-16, disciminator loss fake = 3.1989948467980867e-09, generator loss = 20.51862335205078\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 15, Batch: 84/468, discriminator loss real = 9.621371014896345e-15, disciminator loss fake = 1.7445966893347986e-09, generator loss = 20.781898498535156\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 15, Batch: 85/468, discriminator loss real = 2.0034577479469122e-17, disciminator loss fake = 2.176181901347718e-09, generator loss = 20.616565704345703\n",
      "2/2 [==============================] - 0s 146ms/step\n",
      "Epoch: 15, Batch: 86/468, discriminator loss real = 8.413958418884704e-10, disciminator loss fake = 2.2587083314817846e-09, generator loss = 20.472593307495117\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 15, Batch: 87/468, discriminator loss real = 2.6436701716647804e-08, disciminator loss fake = 2.2501522867202084e-09, generator loss = 20.491567611694336\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 15, Batch: 88/468, discriminator loss real = 5.4102261001299015e-14, disciminator loss fake = 2.2410475697398624e-09, generator loss = 20.500988006591797\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 15, Batch: 89/468, discriminator loss real = 3.799653259671694e-14, disciminator loss fake = 2.125211118197967e-09, generator loss = 20.516225814819336\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 15, Batch: 90/468, discriminator loss real = 4.457682832614048e-15, disciminator loss fake = 2.475038840543675e-09, generator loss = 20.627273559570312\n",
      "2/2 [==============================] - 0s 156ms/step\n",
      "Epoch: 15, Batch: 91/468, discriminator loss real = 8.862148618031182e-14, disciminator loss fake = 2.294542778003006e-09, generator loss = 20.619213104248047\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 15, Batch: 92/468, discriminator loss real = 5.207868424700335e-12, disciminator loss fake = 2.3521453673680526e-09, generator loss = 20.760974884033203\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 15, Batch: 93/468, discriminator loss real = 5.166230110376091e-09, disciminator loss fake = 2.1369159775019853e-09, generator loss = 20.508623123168945\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 15, Batch: 94/468, discriminator loss real = 2.7948019807179196e-14, disciminator loss fake = 1.8814989566351414e-09, generator loss = 20.35699462890625\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 15, Batch: 95/468, discriminator loss real = 7.140624329416497e-16, disciminator loss fake = 1.8704453541573685e-09, generator loss = 20.43306541442871\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 15, Batch: 96/468, discriminator loss real = 3.0006902518309175e-10, disciminator loss fake = 2.378608421338413e-09, generator loss = 20.425277709960938\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 15, Batch: 97/468, discriminator loss real = 8.73786656601256e-19, disciminator loss fake = 2.3732729115266693e-09, generator loss = 20.55221176147461\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 15, Batch: 98/468, discriminator loss real = 1.4269909799345014e-16, disciminator loss fake = 2.009670874159042e-09, generator loss = 20.679039001464844\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 15, Batch: 99/468, discriminator loss real = 1.2067223450195113e-17, disciminator loss fake = 2.408726551550444e-09, generator loss = 20.635379791259766\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 15, Batch: 100/468, discriminator loss real = 2.3828993452371626e-15, disciminator loss fake = 2.8449971267718865e-09, generator loss = 20.556474685668945\n",
      "2/2 [==============================] - 0s 167ms/step\n",
      "Epoch: 15, Batch: 101/468, discriminator loss real = 4.3339173959161244e-16, disciminator loss fake = 1.9671495543605033e-09, generator loss = 20.467233657836914\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 15, Batch: 102/468, discriminator loss real = 1.8403539438914612e-17, disciminator loss fake = 3.49232465168825e-09, generator loss = 20.56199073791504\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 15, Batch: 103/468, discriminator loss real = 4.445080147029207e-16, disciminator loss fake = 2.8960025488800056e-09, generator loss = 20.53227996826172\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 15, Batch: 104/468, discriminator loss real = 4.1349737770457233e-20, disciminator loss fake = 1.980019703751168e-09, generator loss = 20.472522735595703\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 15, Batch: 105/468, discriminator loss real = 2.6049997714494566e-08, disciminator loss fake = 1.822838102683022e-09, generator loss = 20.593050003051758\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 15, Batch: 106/468, discriminator loss real = 3.134362214218811e-10, disciminator loss fake = 1.989651554623606e-09, generator loss = 20.553804397583008\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 15, Batch: 107/468, discriminator loss real = 1.2470863371919633e-13, disciminator loss fake = 2.2849622194343056e-09, generator loss = 20.6027774810791\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 15, Batch: 108/468, discriminator loss real = 7.57263633174637e-15, disciminator loss fake = 3.2458018495162833e-09, generator loss = 20.516616821289062\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 15, Batch: 109/468, discriminator loss real = 8.819211921041332e-18, disciminator loss fake = 2.7141107139527776e-09, generator loss = 20.58612060546875\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 15, Batch: 110/468, discriminator loss real = 1.2032033135529188e-15, disciminator loss fake = 2.8239295346565996e-09, generator loss = 20.469533920288086\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 15, Batch: 111/468, discriminator loss real = 9.75541038883548e-19, disciminator loss fake = 2.320019509838289e-09, generator loss = 20.301992416381836\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 15, Batch: 112/468, discriminator loss real = 2.8676533370131096e-10, disciminator loss fake = 2.500890161627467e-09, generator loss = 20.404708862304688\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 15, Batch: 113/468, discriminator loss real = 6.846195676950902e-16, disciminator loss fake = 2.1786532578005335e-09, generator loss = 20.526226043701172\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 15, Batch: 114/468, discriminator loss real = 1.4426321262258658e-14, disciminator loss fake = 2.07030459442592e-09, generator loss = 20.501617431640625\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 15, Batch: 115/468, discriminator loss real = 8.513718735266105e-17, disciminator loss fake = 3.235924861400008e-09, generator loss = 20.586101531982422\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 15, Batch: 116/468, discriminator loss real = 1.277583860101808e-13, disciminator loss fake = 2.561542089551949e-09, generator loss = 20.590229034423828\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 15, Batch: 117/468, discriminator loss real = 1.2131639009343997e-12, disciminator loss fake = 1.6434972271994752e-09, generator loss = 20.62195587158203\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 15, Batch: 118/468, discriminator loss real = 1.4686873679031764e-15, disciminator loss fake = 2.461941761566777e-09, generator loss = 20.417831420898438\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 15, Batch: 119/468, discriminator loss real = 9.306975762984893e-13, disciminator loss fake = 1.8065351437002164e-09, generator loss = 20.611995697021484\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 15, Batch: 120/468, discriminator loss real = 4.6458177440451744e-15, disciminator loss fake = 3.481516852588129e-09, generator loss = 20.733049392700195\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 15, Batch: 121/468, discriminator loss real = 6.41442194498909e-14, disciminator loss fake = 2.3009056882017376e-09, generator loss = 20.510452270507812\n",
      "2/2 [==============================] - 0s 175ms/step\n",
      "Epoch: 15, Batch: 122/468, discriminator loss real = 1.315492036150698e-15, disciminator loss fake = 1.972973784347687e-09, generator loss = 20.677589416503906\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 15, Batch: 123/468, discriminator loss real = 2.953907951575019e-12, disciminator loss fake = 2.0098531727796853e-09, generator loss = 20.586477279663086\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 15, Batch: 124/468, discriminator loss real = 3.166304712740937e-16, disciminator loss fake = 2.7548390235665465e-09, generator loss = 20.57488250732422\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 15, Batch: 125/468, discriminator loss real = 1.828186785442741e-14, disciminator loss fake = 2.4581252588973257e-09, generator loss = 20.657394409179688\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 15, Batch: 126/468, discriminator loss real = 8.841888945185575e-14, disciminator loss fake = 1.2954350925298286e-09, generator loss = 20.708072662353516\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 15, Batch: 127/468, discriminator loss real = 9.160387527772503e-18, disciminator loss fake = 1.5547607645771677e-09, generator loss = 20.48574447631836\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 15, Batch: 128/468, discriminator loss real = 4.867819600276149e-17, disciminator loss fake = 2.1640818026469333e-09, generator loss = 20.600475311279297\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 15, Batch: 129/468, discriminator loss real = 2.594200131319661e-16, disciminator loss fake = 1.8007662028196592e-09, generator loss = 20.69929313659668\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 15, Batch: 130/468, discriminator loss real = 2.186837403177263e-17, disciminator loss fake = 1.713228336974737e-09, generator loss = 20.544185638427734\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 15, Batch: 131/468, discriminator loss real = 6.217373621150712e-13, disciminator loss fake = 1.936724114415256e-09, generator loss = 20.685230255126953\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 15, Batch: 132/468, discriminator loss real = 1.928937148898413e-10, disciminator loss fake = 2.126600229246378e-09, generator loss = 20.67466926574707\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 15, Batch: 133/468, discriminator loss real = 6.721253446791446e-15, disciminator loss fake = 2.697789991401578e-09, generator loss = 20.679046630859375\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 15, Batch: 134/468, discriminator loss real = 1.529520427142033e-14, disciminator loss fake = 4.015615395758232e-09, generator loss = 20.53763771057129\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 15, Batch: 135/468, discriminator loss real = 1.4479238120979065e-12, disciminator loss fake = 2.3968818041453233e-09, generator loss = 20.78225326538086\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 15, Batch: 136/468, discriminator loss real = 5.4434771408040216e-15, disciminator loss fake = 1.9159742681296166e-09, generator loss = 20.557342529296875\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 15, Batch: 137/468, discriminator loss real = 2.0809420720304695e-17, disciminator loss fake = 1.9166677134307974e-09, generator loss = 20.62069320678711\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 15, Batch: 138/468, discriminator loss real = 5.367135003098156e-08, disciminator loss fake = 2.3445012597989034e-09, generator loss = 20.617794036865234\n",
      "2/2 [==============================] - 0s 157ms/step\n",
      "Epoch: 15, Batch: 139/468, discriminator loss real = 8.149483865516061e-10, disciminator loss fake = 1.494914747546261e-09, generator loss = 20.698352813720703\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 15, Batch: 140/468, discriminator loss real = 6.443839351000236e-10, disciminator loss fake = 2.3824751060885774e-09, generator loss = 20.623619079589844\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 15, Batch: 141/468, discriminator loss real = 6.660570397087548e-14, disciminator loss fake = 2.6488056192874865e-09, generator loss = 20.493152618408203\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 15, Batch: 142/468, discriminator loss real = 1.457662556468304e-14, disciminator loss fake = 2.639853446950724e-09, generator loss = 20.747783660888672\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 15, Batch: 143/468, discriminator loss real = 4.31718862755675e-17, disciminator loss fake = 2.2804982346968927e-09, generator loss = 20.626197814941406\n",
      "2/2 [==============================] - 0s 175ms/step\n",
      "Epoch: 15, Batch: 144/468, discriminator loss real = 5.438855477102322e-10, disciminator loss fake = 2.3740751586842634e-09, generator loss = 20.579322814941406\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 15, Batch: 145/468, discriminator loss real = 2.5766374278646254e-07, disciminator loss fake = 1.7059558210519299e-09, generator loss = 20.31414794921875\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 15, Batch: 146/468, discriminator loss real = 1.5270605522148452e-20, disciminator loss fake = 3.441760654254722e-09, generator loss = 20.295665740966797\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 15, Batch: 147/468, discriminator loss real = 4.0039507913980246e-21, disciminator loss fake = 3.456246400190821e-09, generator loss = 20.24921989440918\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 15, Batch: 148/468, discriminator loss real = 1.871231614103408e-09, disciminator loss fake = 3.4161031781110296e-09, generator loss = 20.39463233947754\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 15, Batch: 149/468, discriminator loss real = 2.9496394476219434e-12, disciminator loss fake = 2.8987421352155707e-09, generator loss = 20.189998626708984\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 15, Batch: 150/468, discriminator loss real = 1.3433382542178505e-17, disciminator loss fake = 4.8275494712868294e-09, generator loss = 20.091873168945312\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 15, Batch: 151/468, discriminator loss real = 1.0194915051053854e-10, disciminator loss fake = 3.7446890033265845e-09, generator loss = 20.18028450012207\n",
      "2/2 [==============================] - 0s 158ms/step\n",
      "Epoch: 15, Batch: 152/468, discriminator loss real = 6.419556553005634e-11, disciminator loss fake = 3.675984849849101e-09, generator loss = 19.978559494018555\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 15, Batch: 153/468, discriminator loss real = 2.1884854468104407e-19, disciminator loss fake = 3.4332883203092024e-09, generator loss = 20.07988739013672\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 15, Batch: 154/468, discriminator loss real = 5.344414764885724e-18, disciminator loss fake = 4.285150012606209e-09, generator loss = 20.304784774780273\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 15, Batch: 155/468, discriminator loss real = 9.633767172672822e-14, disciminator loss fake = 3.3069951221875726e-09, generator loss = 20.12433433532715\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 15, Batch: 156/468, discriminator loss real = 6.726056380571205e-21, disciminator loss fake = 5.0365804860064145e-09, generator loss = 19.931766510009766\n",
      "2/2 [==============================] - 0s 160ms/step\n",
      "Epoch: 15, Batch: 157/468, discriminator loss real = 6.946115521527061e-17, disciminator loss fake = 6.0160312287393936e-09, generator loss = 20.11960220336914\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 15, Batch: 158/468, discriminator loss real = 3.248398796587733e-14, disciminator loss fake = 4.0360088604529665e-09, generator loss = 20.084060668945312\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 15, Batch: 159/468, discriminator loss real = 7.458418648312315e-13, disciminator loss fake = 5.86596549112528e-09, generator loss = 20.182674407958984\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 15, Batch: 160/468, discriminator loss real = 1.4100452886293638e-19, disciminator loss fake = 5.14061415657352e-09, generator loss = 20.06557846069336\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 15, Batch: 161/468, discriminator loss real = 6.29224671735843e-16, disciminator loss fake = 4.419073551531483e-09, generator loss = 20.168975830078125\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 15, Batch: 162/468, discriminator loss real = 4.093911489108301e-14, disciminator loss fake = 5.098709898732068e-09, generator loss = 19.8231258392334\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 15, Batch: 163/468, discriminator loss real = 4.892335777794343e-16, disciminator loss fake = 6.9697083660003045e-09, generator loss = 20.17864990234375\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 15, Batch: 164/468, discriminator loss real = 9.30100905908713e-19, disciminator loss fake = 3.3130027610184243e-09, generator loss = 20.11345672607422\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 15, Batch: 165/468, discriminator loss real = 2.9932245976461165e-18, disciminator loss fake = 7.686644210025406e-09, generator loss = 19.96881103515625\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 15, Batch: 166/468, discriminator loss real = 5.2720304724996996e-15, disciminator loss fake = 5.87369530791193e-09, generator loss = 19.947433471679688\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 15, Batch: 167/468, discriminator loss real = 3.195792113391676e-17, disciminator loss fake = 4.410380505248668e-09, generator loss = 20.292810440063477\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 15, Batch: 168/468, discriminator loss real = 7.158981307070489e-12, disciminator loss fake = 3.7470733182942695e-09, generator loss = 20.080577850341797\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 15, Batch: 169/468, discriminator loss real = 3.210287938260059e-11, disciminator loss fake = 3.0556868146902616e-09, generator loss = 20.10599136352539\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 15, Batch: 170/468, discriminator loss real = 1.4049320458234731e-18, disciminator loss fake = 5.063890640144564e-09, generator loss = 20.121051788330078\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 15, Batch: 171/468, discriminator loss real = 1.8685108410705212e-18, disciminator loss fake = 3.857263841666736e-09, generator loss = 19.99906349182129\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 15, Batch: 172/468, discriminator loss real = 1.7031452745515374e-13, disciminator loss fake = 4.620251736753289e-09, generator loss = 20.198665618896484\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 15, Batch: 173/468, discriminator loss real = 1.9361721427524348e-12, disciminator loss fake = 4.714608259348552e-09, generator loss = 20.36095428466797\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 15, Batch: 174/468, discriminator loss real = 2.718103346566192e-11, disciminator loss fake = 4.451878865552317e-09, generator loss = 20.142017364501953\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 15, Batch: 175/468, discriminator loss real = 8.839282631424318e-18, disciminator loss fake = 4.009525156334348e-09, generator loss = 20.250255584716797\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 15, Batch: 176/468, discriminator loss real = 7.258065679163877e-18, disciminator loss fake = 3.7123100149472066e-09, generator loss = 20.060588836669922\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 15, Batch: 177/468, discriminator loss real = 2.0042865498334658e-16, disciminator loss fake = 3.196627851309586e-09, generator loss = 20.277055740356445\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 15, Batch: 178/468, discriminator loss real = 8.130792833722726e-21, disciminator loss fake = 4.089198313295128e-09, generator loss = 20.052785873413086\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 15, Batch: 179/468, discriminator loss real = 1.7134510375999034e-16, disciminator loss fake = 4.5796202385872675e-09, generator loss = 20.14438247680664\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 15, Batch: 180/468, discriminator loss real = 1.9751656480967304e-18, disciminator loss fake = 3.917056901059368e-09, generator loss = 20.185142517089844\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 15, Batch: 181/468, discriminator loss real = 5.634741925002036e-18, disciminator loss fake = 3.878010357283301e-09, generator loss = 20.13775634765625\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 15, Batch: 182/468, discriminator loss real = 8.389721714466446e-17, disciminator loss fake = 4.394530517259909e-09, generator loss = 20.273502349853516\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 15, Batch: 183/468, discriminator loss real = 2.181694080155192e-15, disciminator loss fake = 2.599794157731594e-09, generator loss = 20.34625244140625\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 15, Batch: 184/468, discriminator loss real = 7.653473768100532e-15, disciminator loss fake = 3.351685373687019e-09, generator loss = 20.426223754882812\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 15, Batch: 185/468, discriminator loss real = 4.706121407691997e-16, disciminator loss fake = 2.4207571502898872e-09, generator loss = 20.10484504699707\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 15, Batch: 186/468, discriminator loss real = 9.093936134728711e-14, disciminator loss fake = 3.54214302333844e-09, generator loss = 20.349761962890625\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 15, Batch: 187/468, discriminator loss real = 1.7687128236549785e-17, disciminator loss fake = 4.5931916048402854e-09, generator loss = 20.16010284423828\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 15, Batch: 188/468, discriminator loss real = 5.577965281732162e-19, disciminator loss fake = 3.702952611206456e-09, generator loss = 20.34805679321289\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 15, Batch: 189/468, discriminator loss real = 5.735525444340583e-13, disciminator loss fake = 3.906056811331382e-09, generator loss = 20.276084899902344\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 15, Batch: 190/468, discriminator loss real = 1.313047582610164e-18, disciminator loss fake = 5.177705375558617e-09, generator loss = 20.432567596435547\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 15, Batch: 191/468, discriminator loss real = 7.517981373009389e-23, disciminator loss fake = 3.0779163662231213e-09, generator loss = 20.243545532226562\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 15, Batch: 192/468, discriminator loss real = 2.725608965192805e-07, disciminator loss fake = 2.595849979414311e-09, generator loss = 20.198240280151367\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 15, Batch: 193/468, discriminator loss real = 6.034158531187123e-15, disciminator loss fake = 4.733353264896323e-09, generator loss = 20.09337615966797\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 15, Batch: 194/468, discriminator loss real = 2.1188758718186306e-18, disciminator loss fake = 4.4164085721831725e-09, generator loss = 20.150848388671875\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 15, Batch: 195/468, discriminator loss real = 3.2702383685214486e-17, disciminator loss fake = 4.8961776855094286e-09, generator loss = 19.965526580810547\n",
      "2/2 [==============================] - 0s 186ms/step\n",
      "Epoch: 15, Batch: 196/468, discriminator loss real = 1.758804554904611e-13, disciminator loss fake = 4.979860968035155e-09, generator loss = 19.948843002319336\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 15, Batch: 197/468, discriminator loss real = 2.8298655256536316e-18, disciminator loss fake = 7.565367887707453e-09, generator loss = 19.84624481201172\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 15, Batch: 198/468, discriminator loss real = 8.628102030582008e-13, disciminator loss fake = 3.0584836885338973e-09, generator loss = 20.069988250732422\n",
      "2/2 [==============================] - 0s 160ms/step\n",
      "Epoch: 15, Batch: 199/468, discriminator loss real = 5.63808333353677e-10, disciminator loss fake = 4.314283152950793e-09, generator loss = 19.806957244873047\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 15, Batch: 200/468, discriminator loss real = 3.2644351208066828e-15, disciminator loss fake = 7.061274676090079e-09, generator loss = 19.788660049438477\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 15, Batch: 201/468, discriminator loss real = 1.2235503419651676e-17, disciminator loss fake = 6.5176055663584975e-09, generator loss = 19.864105224609375\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 15, Batch: 202/468, discriminator loss real = 1.8359570421843784e-15, disciminator loss fake = 7.601731688566815e-09, generator loss = 19.727794647216797\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 15, Batch: 203/468, discriminator loss real = 7.434184344512484e-12, disciminator loss fake = 7.1230363829499765e-09, generator loss = 19.746150970458984\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 15, Batch: 204/468, discriminator loss real = 2.0543990042265004e-15, disciminator loss fake = 4.964128663687006e-09, generator loss = 19.616777420043945\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 15, Batch: 205/468, discriminator loss real = 5.673077703135035e-14, disciminator loss fake = 7.582551475593391e-09, generator loss = 19.891338348388672\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 15, Batch: 206/468, discriminator loss real = 1.127001561464138e-14, disciminator loss fake = 7.324155504306873e-09, generator loss = 19.78042984008789\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 15, Batch: 207/468, discriminator loss real = 1.1346988886690168e-15, disciminator loss fake = 7.3749015783164396e-09, generator loss = 19.660926818847656\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 15, Batch: 208/468, discriminator loss real = 5.97870515947808e-21, disciminator loss fake = 9.09181263608616e-09, generator loss = 19.76385498046875\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 15, Batch: 209/468, discriminator loss real = 1.2780672353773781e-11, disciminator loss fake = 6.9716810102704585e-09, generator loss = 19.61246681213379\n",
      "2/2 [==============================] - 0s 130ms/step\n",
      "Epoch: 15, Batch: 210/468, discriminator loss real = 6.6896417412757325e-19, disciminator loss fake = 5.911820366577558e-09, generator loss = 19.708236694335938\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 15, Batch: 211/468, discriminator loss real = 7.278059130877651e-17, disciminator loss fake = 6.433203303402024e-09, generator loss = 19.90911102294922\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 15, Batch: 212/468, discriminator loss real = 1.0486857633697764e-15, disciminator loss fake = 8.853426436417067e-09, generator loss = 19.80037498474121\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 15, Batch: 213/468, discriminator loss real = 6.1650489401043895e-12, disciminator loss fake = 5.877526465525307e-09, generator loss = 19.751501083374023\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 15, Batch: 214/468, discriminator loss real = 6.688512949932327e-18, disciminator loss fake = 7.332847662411268e-09, generator loss = 19.754779815673828\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 15, Batch: 215/468, discriminator loss real = 2.6137020350903288e-20, disciminator loss fake = 5.892726306910845e-09, generator loss = 20.046161651611328\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 15, Batch: 216/468, discriminator loss real = 3.7090029572115033e-16, disciminator loss fake = 3.726777109136492e-09, generator loss = 19.925979614257812\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 15, Batch: 217/468, discriminator loss real = 6.164193868715204e-19, disciminator loss fake = 5.2561230923231506e-09, generator loss = 19.881135940551758\n",
      "2/2 [==============================] - 0s 187ms/step\n",
      "Epoch: 15, Batch: 218/468, discriminator loss real = 2.519939247790263e-24, disciminator loss fake = 6.897973747754804e-09, generator loss = 20.39899444580078\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 15, Batch: 219/468, discriminator loss real = 7.231321878103936e-12, disciminator loss fake = 3.773482415425633e-09, generator loss = 19.923677444458008\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 15, Batch: 220/468, discriminator loss real = 9.12423137044982e-10, disciminator loss fake = 7.702013249399897e-09, generator loss = 20.15727996826172\n",
      "2/2 [==============================] - 0s 166ms/step\n",
      "Epoch: 15, Batch: 221/468, discriminator loss real = 2.928309895083956e-16, disciminator loss fake = 5.044273443388647e-09, generator loss = 19.942142486572266\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 15, Batch: 222/468, discriminator loss real = 2.350773145426259e-20, disciminator loss fake = 6.711256439473345e-09, generator loss = 20.17923927307129\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 15, Batch: 223/468, discriminator loss real = 4.0001332559358643e-19, disciminator loss fake = 3.5607532478110215e-09, generator loss = 20.0417537689209\n",
      "2/2 [==============================] - 0s 171ms/step\n",
      "Epoch: 15, Batch: 224/468, discriminator loss real = 5.911253415265814e-16, disciminator loss fake = 4.12052969522847e-09, generator loss = 19.87302589416504\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 15, Batch: 225/468, discriminator loss real = 2.9572209264694393e-11, disciminator loss fake = 3.6922207513612193e-09, generator loss = 20.12839126586914\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 15, Batch: 226/468, discriminator loss real = 2.439557090134475e-20, disciminator loss fake = 5.625106602735741e-09, generator loss = 19.8762149810791\n",
      "2/2 [==============================] - 0s 146ms/step\n",
      "Epoch: 15, Batch: 227/468, discriminator loss real = 5.057845155419996e-17, disciminator loss fake = 4.590527069581185e-09, generator loss = 20.1129207611084\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 15, Batch: 228/468, discriminator loss real = 1.857604027942646e-15, disciminator loss fake = 5.036333128316528e-09, generator loss = 20.044837951660156\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 15, Batch: 229/468, discriminator loss real = 6.4845284903410766e-15, disciminator loss fake = 4.605408499003261e-09, generator loss = 20.031749725341797\n",
      "2/2 [==============================] - 0s 164ms/step\n",
      "Epoch: 15, Batch: 230/468, discriminator loss real = 7.24370446980073e-14, disciminator loss fake = 4.22641388553302e-09, generator loss = 20.15326690673828\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 15, Batch: 231/468, discriminator loss real = 1.2067781218760842e-09, disciminator loss fake = 3.715753926769594e-09, generator loss = 20.039873123168945\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 15, Batch: 232/468, discriminator loss real = 5.395467008124002e-19, disciminator loss fake = 3.990265007303151e-09, generator loss = 20.032379150390625\n",
      "2/2 [==============================] - 0s 176ms/step\n",
      "Epoch: 15, Batch: 233/468, discriminator loss real = 6.536871738349603e-14, disciminator loss fake = 5.8685234449740165e-09, generator loss = 19.97650909423828\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 15, Batch: 234/468, discriminator loss real = 3.7410337728097207e-16, disciminator loss fake = 3.322733643784659e-09, generator loss = 20.17159080505371\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 15, Batch: 235/468, discriminator loss real = 1.1574653111851423e-17, disciminator loss fake = 5.6237396961478225e-09, generator loss = 20.072998046875\n",
      "2/2 [==============================] - 0s 147ms/step\n",
      "Epoch: 15, Batch: 236/468, discriminator loss real = 1.6591811602132875e-15, disciminator loss fake = 4.360359184829576e-09, generator loss = 20.120052337646484\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 15, Batch: 237/468, discriminator loss real = 4.896443689065179e-17, disciminator loss fake = 3.43862716079002e-09, generator loss = 19.967796325683594\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 15, Batch: 238/468, discriminator loss real = 1.4640386128606284e-16, disciminator loss fake = 3.260122838355528e-09, generator loss = 20.185056686401367\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 15, Batch: 239/468, discriminator loss real = 1.410482122504058e-15, disciminator loss fake = 5.440122130551117e-09, generator loss = 20.144180297851562\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 15, Batch: 240/468, discriminator loss real = 1.244270541330241e-15, disciminator loss fake = 4.64184157777936e-09, generator loss = 19.785825729370117\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 15, Batch: 241/468, discriminator loss real = 2.1729859329478176e-17, disciminator loss fake = 4.793475838482664e-09, generator loss = 20.23992919921875\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 15, Batch: 242/468, discriminator loss real = 2.552765926517941e-16, disciminator loss fake = 3.794013547775421e-09, generator loss = 20.18470001220703\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 15, Batch: 243/468, discriminator loss real = 6.9331620319531585e-15, disciminator loss fake = 2.5667510339388855e-09, generator loss = 20.162200927734375\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 15, Batch: 244/468, discriminator loss real = 2.3335221948516836e-15, disciminator loss fake = 5.608532305245717e-09, generator loss = 20.133594512939453\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 15, Batch: 245/468, discriminator loss real = 7.82748991085035e-15, disciminator loss fake = 5.426533888908125e-09, generator loss = 20.086772918701172\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 15, Batch: 246/468, discriminator loss real = 3.6832323499546153e-19, disciminator loss fake = 2.301961732342761e-09, generator loss = 20.262460708618164\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 15, Batch: 247/468, discriminator loss real = 6.808886204964955e-15, disciminator loss fake = 4.246055063106269e-09, generator loss = 20.2032470703125\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 15, Batch: 248/468, discriminator loss real = 7.804091075668703e-17, disciminator loss fake = 5.5178634994490494e-09, generator loss = 20.167205810546875\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 15, Batch: 249/468, discriminator loss real = 1.404390056406613e-17, disciminator loss fake = 6.084001746842205e-09, generator loss = 20.265037536621094\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 15, Batch: 250/468, discriminator loss real = 1.0529477680390475e-12, disciminator loss fake = 4.107095108452086e-09, generator loss = 20.087175369262695\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 15, Batch: 251/468, discriminator loss real = 2.3391771059215615e-17, disciminator loss fake = 2.0991044458185115e-09, generator loss = 20.415725708007812\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 15, Batch: 252/468, discriminator loss real = 1.302426645583529e-17, disciminator loss fake = 4.0886050101107685e-09, generator loss = 20.317302703857422\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 15, Batch: 253/468, discriminator loss real = 3.2536875432554466e-16, disciminator loss fake = 4.04017397315215e-09, generator loss = 20.28963851928711\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 15, Batch: 254/468, discriminator loss real = 1.1690407112410869e-17, disciminator loss fake = 5.421992632648198e-09, generator loss = 19.988563537597656\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 15, Batch: 255/468, discriminator loss real = 1.1002241183201747e-15, disciminator loss fake = 6.1491332026264445e-09, generator loss = 20.271827697753906\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 15, Batch: 256/468, discriminator loss real = 1.1128614263767353e-15, disciminator loss fake = 4.106174955609276e-09, generator loss = 20.303321838378906\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 15, Batch: 257/468, discriminator loss real = 4.42128740513114e-18, disciminator loss fake = 2.4373700835411682e-09, generator loss = 20.24067497253418\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 15, Batch: 258/468, discriminator loss real = 1.1033559697030883e-16, disciminator loss fake = 2.55215093503125e-09, generator loss = 20.228620529174805\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 15, Batch: 259/468, discriminator loss real = 6.918926694597649e-13, disciminator loss fake = 3.924106373176528e-09, generator loss = 20.158916473388672\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 15, Batch: 260/468, discriminator loss real = 1.8550708104777596e-17, disciminator loss fake = 3.7185454715427113e-09, generator loss = 20.253028869628906\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 15, Batch: 261/468, discriminator loss real = 3.3734715015848015e-16, disciminator loss fake = 3.4143179394874323e-09, generator loss = 20.192516326904297\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 15, Batch: 262/468, discriminator loss real = 1.7315113268631105e-19, disciminator loss fake = 3.7261242979980125e-09, generator loss = 20.43535614013672\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 15, Batch: 263/468, discriminator loss real = 5.979445827364316e-10, disciminator loss fake = 3.571121176548786e-09, generator loss = 20.331405639648438\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 15, Batch: 264/468, discriminator loss real = 5.727267535908135e-17, disciminator loss fake = 4.7032173711158975e-09, generator loss = 20.360336303710938\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 15, Batch: 265/468, discriminator loss real = 7.285759272481846e-19, disciminator loss fake = 2.46702791528719e-09, generator loss = 20.26593780517578\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 15, Batch: 266/468, discriminator loss real = 1.2882856673807064e-12, disciminator loss fake = 3.5821938748625826e-09, generator loss = 20.435951232910156\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 15, Batch: 267/468, discriminator loss real = 8.595218881636879e-20, disciminator loss fake = 3.4114000513341125e-09, generator loss = 20.230833053588867\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 15, Batch: 268/468, discriminator loss real = 5.149581390646862e-13, disciminator loss fake = 3.4103015966735484e-09, generator loss = 20.27783966064453\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 15, Batch: 269/468, discriminator loss real = 9.771012090523026e-17, disciminator loss fake = 3.2402032168477035e-09, generator loss = 20.431381225585938\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 15, Batch: 270/468, discriminator loss real = 3.296727786052632e-14, disciminator loss fake = 3.3403189103609066e-09, generator loss = 20.457063674926758\n",
      "2/2 [==============================] - 0s 192ms/step\n",
      "Epoch: 15, Batch: 271/468, discriminator loss real = 1.7547473348498988e-15, disciminator loss fake = 2.734202197984814e-09, generator loss = 20.286502838134766\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 15, Batch: 272/468, discriminator loss real = 9.765514846695345e-15, disciminator loss fake = 3.982687957204689e-09, generator loss = 20.34845733642578\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 15, Batch: 273/468, discriminator loss real = 2.497120641468622e-22, disciminator loss fake = 4.105359163730782e-09, generator loss = 20.470001220703125\n",
      "2/2 [==============================] - 0s 160ms/step\n",
      "Epoch: 15, Batch: 274/468, discriminator loss real = 3.0369089421634953e-15, disciminator loss fake = 2.545788468921728e-09, generator loss = 20.273239135742188\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 15, Batch: 275/468, discriminator loss real = 2.4325316760887006e-10, disciminator loss fake = 3.0995579436421394e-09, generator loss = 20.574111938476562\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 15, Batch: 276/468, discriminator loss real = 7.312780345462497e-14, disciminator loss fake = 2.7133260083189725e-09, generator loss = 20.576879501342773\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 15, Batch: 277/468, discriminator loss real = 2.3734523867764354e-15, disciminator loss fake = 2.642267737940074e-09, generator loss = 20.237213134765625\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 15, Batch: 278/468, discriminator loss real = 4.2027019338701846e-16, disciminator loss fake = 3.1710185588451623e-09, generator loss = 20.60623550415039\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 15, Batch: 279/468, discriminator loss real = 4.596772723748643e-13, disciminator loss fake = 3.3728129178456356e-09, generator loss = 20.555404663085938\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Epoch: 15, Batch: 280/468, discriminator loss real = 1.6254245128674571e-13, disciminator loss fake = 3.728688469095687e-09, generator loss = 20.435190200805664\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 15, Batch: 281/468, discriminator loss real = 6.917749843961393e-17, disciminator loss fake = 2.4226816108807725e-09, generator loss = 20.29913330078125\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 15, Batch: 282/468, discriminator loss real = 7.936420617915552e-13, disciminator loss fake = 2.3701653972807435e-09, generator loss = 20.720619201660156\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 15, Batch: 283/468, discriminator loss real = 1.1348014285174519e-21, disciminator loss fake = 2.0698796010520937e-09, generator loss = 20.37820053100586\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 15, Batch: 284/468, discriminator loss real = 7.896080165582797e-13, disciminator loss fake = 2.41546249668545e-09, generator loss = 20.663818359375\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 15, Batch: 285/468, discriminator loss real = 1.5371546049913754e-11, disciminator loss fake = 2.341143279238622e-09, generator loss = 20.250150680541992\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 15, Batch: 286/468, discriminator loss real = 2.7794344966709686e-21, disciminator loss fake = 2.479310534653223e-09, generator loss = 20.359779357910156\n",
      "2/2 [==============================] - 0s 180ms/step\n",
      "Epoch: 15, Batch: 287/468, discriminator loss real = 7.932869515771527e-20, disciminator loss fake = 3.3387470566026423e-09, generator loss = 20.498008728027344\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 15, Batch: 288/468, discriminator loss real = 1.2500119762612115e-21, disciminator loss fake = 4.219150362416713e-09, generator loss = 20.724502563476562\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 15, Batch: 289/468, discriminator loss real = 2.251633294148448e-14, disciminator loss fake = 3.3173261915209196e-09, generator loss = 20.465682983398438\n",
      "2/2 [==============================] - 0s 181ms/step\n",
      "Epoch: 15, Batch: 290/468, discriminator loss real = 1.7866665178584151e-12, disciminator loss fake = 2.5027016015144454e-09, generator loss = 20.42454719543457\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 15, Batch: 291/468, discriminator loss real = 4.3509643045565316e-14, disciminator loss fake = 1.9765584724495966e-09, generator loss = 20.45587158203125\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 15, Batch: 292/468, discriminator loss real = 1.0937374473658727e-16, disciminator loss fake = 3.00871727532126e-09, generator loss = 20.43014907836914\n",
      "2/2 [==============================] - 0s 186ms/step\n",
      "Epoch: 15, Batch: 293/468, discriminator loss real = 5.71657506843803e-17, disciminator loss fake = 2.6340412073722064e-09, generator loss = 20.5084285736084\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 15, Batch: 294/468, discriminator loss real = 2.6020621768374497e-10, disciminator loss fake = 2.351098871145041e-09, generator loss = 20.38388442993164\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 15, Batch: 295/468, discriminator loss real = 1.6895066942690384e-11, disciminator loss fake = 2.7281064074458072e-09, generator loss = 20.574180603027344\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 15, Batch: 296/468, discriminator loss real = 1.9793840178028432e-10, disciminator loss fake = 2.4956055000302513e-09, generator loss = 20.398767471313477\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 15, Batch: 297/468, discriminator loss real = 9.957603318289099e-13, disciminator loss fake = 2.730331072342551e-09, generator loss = 20.43163299560547\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 15, Batch: 298/468, discriminator loss real = 6.82102079896732e-14, disciminator loss fake = 2.9364142228871515e-09, generator loss = 20.660322189331055\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 15, Batch: 299/468, discriminator loss real = 2.0561983288539564e-18, disciminator loss fake = 2.1854533738263626e-09, generator loss = 20.70381736755371\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 15, Batch: 300/468, discriminator loss real = 2.999135216713114e-17, disciminator loss fake = 2.1828796548106766e-09, generator loss = 20.61684799194336\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 15, Batch: 301/468, discriminator loss real = 4.009084442869277e-15, disciminator loss fake = 3.194094766456601e-09, generator loss = 20.44839096069336\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 15, Batch: 302/468, discriminator loss real = 6.842072744080142e-17, disciminator loss fake = 2.1649433357140424e-09, generator loss = 20.73627471923828\n",
      "2/2 [==============================] - 0s 155ms/step\n",
      "Epoch: 15, Batch: 303/468, discriminator loss real = 7.0447126381293e-19, disciminator loss fake = 4.037854495209103e-09, generator loss = 20.666339874267578\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 15, Batch: 304/468, discriminator loss real = 9.16755339341905e-18, disciminator loss fake = 2.4586288560612957e-09, generator loss = 20.50476837158203\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 15, Batch: 305/468, discriminator loss real = 2.7565109007782453e-17, disciminator loss fake = 3.275258286805638e-09, generator loss = 20.628265380859375\n",
      "2/2 [==============================] - 0s 160ms/step\n",
      "Epoch: 15, Batch: 306/468, discriminator loss real = 2.9329078228557126e-14, disciminator loss fake = 2.5304389694724705e-09, generator loss = 20.548908233642578\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 15, Batch: 307/468, discriminator loss real = 1.34654310271487e-11, disciminator loss fake = 2.6444286760352043e-09, generator loss = 20.63332748413086\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 15, Batch: 308/468, discriminator loss real = 1.2281732942665598e-14, disciminator loss fake = 2.015019040513266e-09, generator loss = 20.531631469726562\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 15, Batch: 309/468, discriminator loss real = 6.1391237010438235e-15, disciminator loss fake = 2.1875381506220037e-09, generator loss = 20.66615867614746\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 15, Batch: 310/468, discriminator loss real = 1.75902264894787e-14, disciminator loss fake = 1.5177139545130558e-09, generator loss = 20.61635971069336\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 15, Batch: 311/468, discriminator loss real = 3.3259861878520702e-12, disciminator loss fake = 1.9909300874587643e-09, generator loss = 20.894052505493164\n",
      "2/2 [==============================] - 0s 181ms/step\n",
      "Epoch: 15, Batch: 312/468, discriminator loss real = 2.0214885978521186e-15, disciminator loss fake = 1.9303572074136355e-09, generator loss = 20.506954193115234\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 15, Batch: 313/468, discriminator loss real = 1.8206521902076889e-13, disciminator loss fake = 2.5143411797046156e-09, generator loss = 20.662975311279297\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 15, Batch: 314/468, discriminator loss real = 7.2767001723929e-16, disciminator loss fake = 1.5971652889135157e-09, generator loss = 20.54387664794922\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 15, Batch: 315/468, discriminator loss real = 1.6119222926921917e-12, disciminator loss fake = 2.8392832529533507e-09, generator loss = 20.745616912841797\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 15, Batch: 316/468, discriminator loss real = 1.3516115581358595e-13, disciminator loss fake = 2.3886821409746517e-09, generator loss = 20.54383087158203\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 15, Batch: 317/468, discriminator loss real = 2.7826254755253244e-13, disciminator loss fake = 2.7947026914887374e-09, generator loss = 20.685657501220703\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 15, Batch: 318/468, discriminator loss real = 2.3558884877650232e-12, disciminator loss fake = 1.9212669233326096e-09, generator loss = 20.705780029296875\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 15, Batch: 319/468, discriminator loss real = 6.123730537412053e-13, disciminator loss fake = 1.7188608314455678e-09, generator loss = 20.60015869140625\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 15, Batch: 320/468, discriminator loss real = 1.2788943807924034e-19, disciminator loss fake = 2.3025472639659483e-09, generator loss = 20.665279388427734\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 15, Batch: 321/468, discriminator loss real = 2.609923995672281e-12, disciminator loss fake = 2.8058719792056763e-09, generator loss = 20.712656021118164\n",
      "2/2 [==============================] - 0s 192ms/step\n",
      "Epoch: 15, Batch: 322/468, discriminator loss real = 3.48907111715472e-16, disciminator loss fake = 5.24726928574637e-09, generator loss = 20.64441680908203\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 15, Batch: 323/468, discriminator loss real = 2.6164196584107136e-16, disciminator loss fake = 1.5007681763989922e-09, generator loss = 20.63543701171875\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 15, Batch: 324/468, discriminator loss real = 7.998629728234639e-19, disciminator loss fake = 2.623530948042685e-09, generator loss = 20.572628021240234\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 15, Batch: 325/468, discriminator loss real = 1.3571828919354363e-15, disciminator loss fake = 1.8446975058594717e-09, generator loss = 20.865928649902344\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 15, Batch: 326/468, discriminator loss real = 2.7639561646364275e-12, disciminator loss fake = 1.9228334480203557e-09, generator loss = 20.813705444335938\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 15, Batch: 327/468, discriminator loss real = 7.806143972512937e-18, disciminator loss fake = 1.6231442856451395e-09, generator loss = 20.795913696289062\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 15, Batch: 328/468, discriminator loss real = 4.391211899397039e-23, disciminator loss fake = 2.1054749055338107e-09, generator loss = 20.850021362304688\n",
      "2/2 [==============================] - 0s 154ms/step\n",
      "Epoch: 15, Batch: 329/468, discriminator loss real = 1.3113383586309303e-17, disciminator loss fake = 2.0136519118807428e-09, generator loss = 20.73175811767578\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 15, Batch: 330/468, discriminator loss real = 1.9497217792497524e-17, disciminator loss fake = 2.0588122318088153e-09, generator loss = 20.805620193481445\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 15, Batch: 331/468, discriminator loss real = 2.2500782433012428e-13, disciminator loss fake = 2.5214053067657005e-09, generator loss = 20.764293670654297\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 15, Batch: 332/468, discriminator loss real = 1.6928096387687041e-16, disciminator loss fake = 2.011784738797928e-09, generator loss = 20.60643768310547\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 15, Batch: 333/468, discriminator loss real = 1.1926996716649096e-11, disciminator loss fake = 1.948769368098624e-09, generator loss = 20.80208969116211\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 15, Batch: 334/468, discriminator loss real = 2.7313596884319886e-19, disciminator loss fake = 2.567475121395546e-09, generator loss = 20.77634048461914\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 15, Batch: 335/468, discriminator loss real = 1.563667598181162e-11, disciminator loss fake = 1.8014300051660825e-09, generator loss = 20.675060272216797\n",
      "2/2 [==============================] - 0s 177ms/step\n",
      "Epoch: 15, Batch: 336/468, discriminator loss real = 3.0543265833182787e-11, disciminator loss fake = 2.15461382069293e-09, generator loss = 20.564720153808594\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 15, Batch: 337/468, discriminator loss real = 7.949447636963768e-19, disciminator loss fake = 1.7677662667026084e-09, generator loss = 20.49941062927246\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 15, Batch: 338/468, discriminator loss real = 1.9215495080521228e-12, disciminator loss fake = 2.401461252077297e-09, generator loss = 20.68168830871582\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 15, Batch: 339/468, discriminator loss real = 1.60634556189646e-18, disciminator loss fake = 1.9322061728388462e-09, generator loss = 20.74105453491211\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 15, Batch: 340/468, discriminator loss real = 3.282127391049383e-12, disciminator loss fake = 2.459696890610985e-09, generator loss = 20.685787200927734\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 15, Batch: 341/468, discriminator loss real = 2.6724040257737787e-14, disciminator loss fake = 1.8867445383818904e-09, generator loss = 20.567188262939453\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 15, Batch: 342/468, discriminator loss real = 2.852122902544281e-14, disciminator loss fake = 2.2315427283814415e-09, generator loss = 20.758926391601562\n",
      "2/2 [==============================] - 0s 197ms/step\n",
      "Epoch: 15, Batch: 343/468, discriminator loss real = 3.4281750069008524e-16, disciminator loss fake = 1.6568124650007121e-09, generator loss = 20.81671905517578\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 15, Batch: 344/468, discriminator loss real = 2.6447288759364916e-15, disciminator loss fake = 1.8909656063215152e-09, generator loss = 20.777847290039062\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 15, Batch: 345/468, discriminator loss real = 5.408383295249855e-15, disciminator loss fake = 2.290811096372636e-09, generator loss = 20.741226196289062\n",
      "2/2 [==============================] - 0s 141ms/step\n",
      "Epoch: 15, Batch: 346/468, discriminator loss real = 7.623994268679004e-16, disciminator loss fake = 1.7395824780663816e-09, generator loss = 20.818500518798828\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 15, Batch: 347/468, discriminator loss real = 2.940373571252812e-14, disciminator loss fake = 1.2930461146254402e-09, generator loss = 20.829345703125\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 15, Batch: 348/468, discriminator loss real = 5.72468708179806e-14, disciminator loss fake = 1.858270426424724e-09, generator loss = 20.52216339111328\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 15, Batch: 349/468, discriminator loss real = 1.9694163834460543e-12, disciminator loss fake = 1.5015195753420585e-09, generator loss = 20.81005096435547\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 15, Batch: 350/468, discriminator loss real = 5.459393101641167e-16, disciminator loss fake = 1.933507576268312e-09, generator loss = 20.81097984313965\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 15, Batch: 351/468, discriminator loss real = 1.058332396612929e-16, disciminator loss fake = 2.223245143539998e-09, generator loss = 20.61577033996582\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 15, Batch: 352/468, discriminator loss real = 1.6516952736078672e-14, disciminator loss fake = 1.5202172853889806e-09, generator loss = 20.626815795898438\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 15, Batch: 353/468, discriminator loss real = 2.297915113400051e-12, disciminator loss fake = 1.4932149960955599e-09, generator loss = 20.762359619140625\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 15, Batch: 354/468, discriminator loss real = 2.469542279004422e-11, disciminator loss fake = 1.6674956970774701e-09, generator loss = 20.745777130126953\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 15, Batch: 355/468, discriminator loss real = 7.329849753415565e-14, disciminator loss fake = 3.945042514885699e-09, generator loss = 20.89396095275879\n",
      "2/2 [==============================] - 0s 170ms/step\n",
      "Epoch: 15, Batch: 356/468, discriminator loss real = 5.832107715465556e-16, disciminator loss fake = 2.3803545801115433e-09, generator loss = 20.7957820892334\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 15, Batch: 357/468, discriminator loss real = 8.36967354734009e-21, disciminator loss fake = 3.209558174788185e-09, generator loss = 20.733009338378906\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 15, Batch: 358/468, discriminator loss real = 2.1060432382953055e-15, disciminator loss fake = 1.850888220467084e-09, generator loss = 20.7017822265625\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 15, Batch: 359/468, discriminator loss real = 1.6007137835279822e-13, disciminator loss fake = 1.6411544345729112e-09, generator loss = 20.70538330078125\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 15, Batch: 360/468, discriminator loss real = 6.435787775101176e-13, disciminator loss fake = 1.1130772969991654e-09, generator loss = 20.729604721069336\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 15, Batch: 361/468, discriminator loss real = 1.4324710306823363e-08, disciminator loss fake = 1.5365813066381406e-09, generator loss = 20.68613052368164\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 15, Batch: 362/468, discriminator loss real = 3.6861248454603484e-18, disciminator loss fake = 2.1534516392307523e-09, generator loss = 20.759788513183594\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 15, Batch: 363/468, discriminator loss real = 8.924343902760867e-11, disciminator loss fake = 1.9577839349693704e-09, generator loss = 20.726585388183594\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 15, Batch: 364/468, discriminator loss real = 1.5443162970207175e-13, disciminator loss fake = 2.1809813954831725e-09, generator loss = 20.730403900146484\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 15, Batch: 365/468, discriminator loss real = 5.688859938679514e-10, disciminator loss fake = 1.5388275098615622e-09, generator loss = 20.87198829650879\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 15, Batch: 366/468, discriminator loss real = 1.961307601781415e-17, disciminator loss fake = 1.740092181456987e-09, generator loss = 21.019573211669922\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 15, Batch: 367/468, discriminator loss real = 1.1726054130036597e-16, disciminator loss fake = 1.9093868708353057e-09, generator loss = 20.92548370361328\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 15, Batch: 368/468, discriminator loss real = 3.710924960995607e-18, disciminator loss fake = 2.3195454446067743e-09, generator loss = 20.792015075683594\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 15, Batch: 369/468, discriminator loss real = 6.701943319055534e-16, disciminator loss fake = 1.7745310776362544e-09, generator loss = 20.89708709716797\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 15, Batch: 370/468, discriminator loss real = 1.756387749809877e-18, disciminator loss fake = 1.98353822256081e-09, generator loss = 20.906494140625\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 15, Batch: 371/468, discriminator loss real = 4.987490252066941e-14, disciminator loss fake = 1.2399128390683245e-09, generator loss = 21.001306533813477\n",
      "2/2 [==============================] - 0s 176ms/step\n",
      "Epoch: 15, Batch: 372/468, discriminator loss real = 2.9577073235032003e-08, disciminator loss fake = 1.9075949708735607e-09, generator loss = 20.68132972717285\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 15, Batch: 373/468, discriminator loss real = 6.73263714608607e-15, disciminator loss fake = 2.7246083167398183e-09, generator loss = 20.821840286254883\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 15, Batch: 374/468, discriminator loss real = 7.57118028211004e-15, disciminator loss fake = 1.6915417955232215e-09, generator loss = 20.840381622314453\n",
      "2/2 [==============================] - 0s 176ms/step\n",
      "Epoch: 15, Batch: 375/468, discriminator loss real = 6.885877285034425e-12, disciminator loss fake = 2.172139135225848e-09, generator loss = 20.882843017578125\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 15, Batch: 376/468, discriminator loss real = 3.022403344123088e-16, disciminator loss fake = 1.798477144987487e-09, generator loss = 20.751487731933594\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 15, Batch: 377/468, discriminator loss real = 9.888042523502342e-22, disciminator loss fake = 2.062882753506301e-09, generator loss = 20.937767028808594\n",
      "2/2 [==============================] - 0s 202ms/step\n",
      "Epoch: 15, Batch: 378/468, discriminator loss real = 1.0909442159324698e-14, disciminator loss fake = 2.0709309822564137e-09, generator loss = 20.77737808227539\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 15, Batch: 379/468, discriminator loss real = 3.1695081146781495e-21, disciminator loss fake = 2.506212348762915e-09, generator loss = 20.74740219116211\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 15, Batch: 380/468, discriminator loss real = 1.4817615884288315e-11, disciminator loss fake = 1.905692492698563e-09, generator loss = 20.816120147705078\n",
      "2/2 [==============================] - 0s 198ms/step\n",
      "Epoch: 15, Batch: 381/468, discriminator loss real = 1.4951509006368873e-15, disciminator loss fake = 1.6967804938872177e-09, generator loss = 20.78847312927246\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 15, Batch: 382/468, discriminator loss real = 1.419965503381517e-16, disciminator loss fake = 1.6362204924291746e-09, generator loss = 20.851991653442383\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 15, Batch: 383/468, discriminator loss real = 9.782670440250797e-16, disciminator loss fake = 2.453347303088549e-09, generator loss = 20.605979919433594\n",
      "2/2 [==============================] - 0s 185ms/step\n",
      "Epoch: 15, Batch: 384/468, discriminator loss real = 4.794010026063859e-19, disciminator loss fake = 2.2926955889346345e-09, generator loss = 20.858505249023438\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 15, Batch: 385/468, discriminator loss real = 2.3954902189475547e-13, disciminator loss fake = 2.3449833186361957e-09, generator loss = 20.95073699951172\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 15, Batch: 386/468, discriminator loss real = 4.743481181358174e-19, disciminator loss fake = 1.333531729486026e-09, generator loss = 20.91445541381836\n",
      "2/2 [==============================] - 0s 160ms/step\n",
      "Epoch: 15, Batch: 387/468, discriminator loss real = 1.572888322698418e-06, disciminator loss fake = 2.4444355428698827e-09, generator loss = 20.0711669921875\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 15, Batch: 388/468, discriminator loss real = 1.1753886245087895e-19, disciminator loss fake = 1.3326944880986957e-08, generator loss = 19.296859741210938\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 15, Batch: 389/468, discriminator loss real = 1.9092541404201052e-13, disciminator loss fake = 2.3013555505713157e-08, generator loss = 18.87094497680664\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 15, Batch: 390/468, discriminator loss real = 4.1883954274498707e-20, disciminator loss fake = 1.4788480484639877e-07, generator loss = 18.287330627441406\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 15, Batch: 391/468, discriminator loss real = 1.1768776354313735e-16, disciminator loss fake = 9.449577476061677e-08, generator loss = 17.84624481201172\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 15, Batch: 392/468, discriminator loss real = 5.262557467775844e-16, disciminator loss fake = 1.0008885453771654e-07, generator loss = 17.98336410522461\n",
      "2/2 [==============================] - 0s 180ms/step\n",
      "Epoch: 15, Batch: 393/468, discriminator loss real = 6.205161604139027e-21, disciminator loss fake = 7.771266723466397e-07, generator loss = 18.308895111083984\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 15, Batch: 394/468, discriminator loss real = 1.1016568304772384e-20, disciminator loss fake = 3.0923160920792725e-08, generator loss = 19.009756088256836\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 15, Batch: 395/468, discriminator loss real = 1.1141487117552096e-20, disciminator loss fake = 1.4035001605350317e-08, generator loss = 19.417903900146484\n",
      "2/2 [==============================] - 0s 162ms/step\n",
      "Epoch: 15, Batch: 396/468, discriminator loss real = 7.708662533856456e-21, disciminator loss fake = 8.006149521122552e-09, generator loss = 19.70878791809082\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 15, Batch: 397/468, discriminator loss real = 5.680519877246568e-21, disciminator loss fake = 3.23283844139155e-09, generator loss = 19.91668701171875\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 15, Batch: 398/468, discriminator loss real = 1.2327182328482765e-17, disciminator loss fake = 3.1922335885781195e-09, generator loss = 20.634441375732422\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 15, Batch: 399/468, discriminator loss real = 3.1678225580894503e-12, disciminator loss fake = 1.6214490861088393e-09, generator loss = 20.646596908569336\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 15, Batch: 400/468, discriminator loss real = 1.499520703621144e-22, disciminator loss fake = 2.17638307375978e-09, generator loss = 20.795135498046875\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 15, Batch: 401/468, discriminator loss real = 1.9404580379859832e-15, disciminator loss fake = 1.8523420575178307e-09, generator loss = 20.777969360351562\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 15, Batch: 402/468, discriminator loss real = 1.0291206125422923e-16, disciminator loss fake = 1.768878044039468e-09, generator loss = 20.901927947998047\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 15, Batch: 403/468, discriminator loss real = 1.6482171869198516e-14, disciminator loss fake = 2.0413193357882164e-09, generator loss = 21.01993751525879\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 15, Batch: 404/468, discriminator loss real = 1.8285689517779322e-19, disciminator loss fake = 2.050760228300419e-09, generator loss = 21.26448631286621\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 15, Batch: 405/468, discriminator loss real = 2.7670533590442643e-18, disciminator loss fake = 1.5650650775356212e-09, generator loss = 21.024616241455078\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 15, Batch: 406/468, discriminator loss real = 1.5674404049009771e-12, disciminator loss fake = 1.6373059574803506e-09, generator loss = 21.214197158813477\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 15, Batch: 407/468, discriminator loss real = 2.4226541589901854e-14, disciminator loss fake = 1.206596822456163e-09, generator loss = 21.209075927734375\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 15, Batch: 408/468, discriminator loss real = 1.0470087717238818e-19, disciminator loss fake = 9.558075442228642e-10, generator loss = 21.225465774536133\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 15, Batch: 409/468, discriminator loss real = 2.0948831556987565e-15, disciminator loss fake = 2.0524226762574926e-09, generator loss = 21.2285099029541\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 15, Batch: 410/468, discriminator loss real = 1.5680228391550693e-15, disciminator loss fake = 1.136306382321095e-09, generator loss = 21.277912139892578\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 15, Batch: 411/468, discriminator loss real = 7.497029039238434e-12, disciminator loss fake = 1.012416372958569e-09, generator loss = 21.267364501953125\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 15, Batch: 412/468, discriminator loss real = 6.541585984920842e-14, disciminator loss fake = 1.0960859997410921e-09, generator loss = 21.238906860351562\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 15, Batch: 413/468, discriminator loss real = 2.896720992456189e-17, disciminator loss fake = 8.821914310175316e-10, generator loss = 21.22641372680664\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 15, Batch: 414/468, discriminator loss real = 3.6081421864167586e-19, disciminator loss fake = 1.6193980600931468e-09, generator loss = 21.392255783081055\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 15, Batch: 415/468, discriminator loss real = 5.001493807062066e-19, disciminator loss fake = 1.3298082635060382e-09, generator loss = 21.29576301574707\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 15, Batch: 416/468, discriminator loss real = 1.992282986534085e-14, disciminator loss fake = 8.967511178070708e-10, generator loss = 21.505199432373047\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 15, Batch: 417/468, discriminator loss real = 3.869898321380336e-18, disciminator loss fake = 6.648083750171452e-10, generator loss = 21.490480422973633\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 15, Batch: 418/468, discriminator loss real = 7.166456555789125e-13, disciminator loss fake = 7.270478663556901e-10, generator loss = 21.317398071289062\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 15, Batch: 419/468, discriminator loss real = 1.380826625517958e-16, disciminator loss fake = 9.40754363298879e-10, generator loss = 21.479530334472656\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 15, Batch: 420/468, discriminator loss real = 6.552786640395564e-16, disciminator loss fake = 8.510971372110987e-10, generator loss = 21.45735740661621\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 15, Batch: 421/468, discriminator loss real = 2.150205333879482e-14, disciminator loss fake = 9.960184899071578e-10, generator loss = 21.370800018310547\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 15, Batch: 422/468, discriminator loss real = 1.993663926909345e-20, disciminator loss fake = 7.375028365785852e-10, generator loss = 21.42306137084961\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 15, Batch: 423/468, discriminator loss real = 3.105917775167487e-15, disciminator loss fake = 8.948116692053532e-10, generator loss = 21.332664489746094\n",
      "2/2 [==============================] - 0s 136ms/step\n",
      "Epoch: 15, Batch: 424/468, discriminator loss real = 3.520880689864697e-13, disciminator loss fake = 1.1124681176255535e-09, generator loss = 21.240093231201172\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 15, Batch: 425/468, discriminator loss real = 1.3994632614756398e-14, disciminator loss fake = 1.1512766295851407e-09, generator loss = 21.293638229370117\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 15, Batch: 426/468, discriminator loss real = 6.237800432125659e-18, disciminator loss fake = 8.44582292991447e-10, generator loss = 21.289569854736328\n",
      "2/2 [==============================] - 0s 155ms/step\n",
      "Epoch: 15, Batch: 427/468, discriminator loss real = 4.671002083386777e-13, disciminator loss fake = 7.58942686474029e-10, generator loss = 21.26688575744629\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 15, Batch: 428/468, discriminator loss real = 1.1162637247917953e-14, disciminator loss fake = 8.734969414447846e-10, generator loss = 21.454708099365234\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 15, Batch: 429/468, discriminator loss real = 1.9879075796115278e-16, disciminator loss fake = 1.2178168473653272e-09, generator loss = 21.44469451904297\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 15, Batch: 430/468, discriminator loss real = 5.5523223636555485e-06, disciminator loss fake = 4.753551774427933e-09, generator loss = 18.62950897216797\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 15, Batch: 431/468, discriminator loss real = 3.016579770264566e-14, disciminator loss fake = 5.235053208707541e-07, generator loss = 16.27835464477539\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 15, Batch: 432/468, discriminator loss real = 7.583368199620031e-25, disciminator loss fake = 0.0003851033980026841, generator loss = 30.315406799316406\n",
      "2/2 [==============================] - 0s 168ms/step\n",
      "Epoch: 15, Batch: 433/468, discriminator loss real = 4.0924707199463395e-12, disciminator loss fake = 3.4073487456104567e-19, generator loss = 57.62873840332031\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 15, Batch: 434/468, discriminator loss real = 0.5777702331542969, disciminator loss fake = 3.07647607459123e-16, generator loss = 22.522241592407227\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 15, Batch: 435/468, discriminator loss real = 8.68408457505407e-20, disciminator loss fake = 0.0024057202972471714, generator loss = 1.1061208248138428\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 15, Batch: 436/468, discriminator loss real = 5.437073566700162e-28, disciminator loss fake = 20.023208618164062, generator loss = 10.678647994995117\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 15, Batch: 437/468, discriminator loss real = 9.379479806390915e-20, disciminator loss fake = 2.8108676275451216e-08, generator loss = 23.405834197998047\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 15, Batch: 438/468, discriminator loss real = 5.519250390051411e-09, disciminator loss fake = 9.26766801322143e-13, generator loss = 32.2779541015625\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 15, Batch: 439/468, discriminator loss real = 0.042541708797216415, disciminator loss fake = 7.441204029265934e-16, generator loss = 38.00324249267578\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 15, Batch: 440/468, discriminator loss real = 0.00877646915614605, disciminator loss fake = 1.2136734745790394e-17, generator loss = 40.8334846496582\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 15, Batch: 441/468, discriminator loss real = 0.8073576092720032, disciminator loss fake = 2.8590479051078532e-15, generator loss = 27.81943130493164\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 15, Batch: 442/468, discriminator loss real = 0.7095239162445068, disciminator loss fake = 2.250957891192229e-07, generator loss = 5.006669044494629\n",
      "2/2 [==============================] - 0s 184ms/step\n",
      "Epoch: 15, Batch: 443/468, discriminator loss real = 0.0024861132260411978, disciminator loss fake = 6.374231338500977, generator loss = 11.658534049987793\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 15, Batch: 444/468, discriminator loss real = 0.0006544486386701465, disciminator loss fake = 2.697806821688742e-12, generator loss = 41.15274429321289\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 15, Batch: 445/468, discriminator loss real = 1.5979893207550049, disciminator loss fake = 5.699493534495395e-22, generator loss = 58.581459045410156\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 15, Batch: 446/468, discriminator loss real = 2.3423080444335938, disciminator loss fake = 8.572036848555595e-27, generator loss = 65.0103759765625\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 15, Batch: 447/468, discriminator loss real = 3.334275722503662, disciminator loss fake = 3.496915237069782e-27, generator loss = 60.270751953125\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 15, Batch: 448/468, discriminator loss real = 1.2233262062072754, disciminator loss fake = 9.200920583242795e-25, generator loss = 53.70410919189453\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 15, Batch: 449/468, discriminator loss real = 0.4844285547733307, disciminator loss fake = 1.1420975209883068e-21, generator loss = 46.21955108642578\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 15, Batch: 450/468, discriminator loss real = 0.4829464256763458, disciminator loss fake = 4.287750262172723e-18, generator loss = 36.79679489135742\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 15, Batch: 451/468, discriminator loss real = 0.004615026526153088, disciminator loss fake = 4.297385743697729e-14, generator loss = 28.47779083251953\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 15, Batch: 452/468, discriminator loss real = 0.00019684527069330215, disciminator loss fake = 5.876744924027122e-11, generator loss = 21.59042739868164\n",
      "2/2 [==============================] - 0s 176ms/step\n",
      "Epoch: 15, Batch: 453/468, discriminator loss real = 1.6778618772139708e-10, disciminator loss fake = 6.619500680926649e-08, generator loss = 15.67853832244873\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 15, Batch: 454/468, discriminator loss real = 3.930645948578347e-21, disciminator loss fake = 5.893981779081514e-06, generator loss = 11.05468463897705\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 15, Batch: 455/468, discriminator loss real = 3.82674664525795e-12, disciminator loss fake = 0.0005696426378563046, generator loss = 6.9281511306762695\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 15, Batch: 456/468, discriminator loss real = 5.941173773470426e-25, disciminator loss fake = 0.01968992128968239, generator loss = 5.782318592071533\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 15, Batch: 457/468, discriminator loss real = 3.5142361776959266e-23, disciminator loss fake = 0.037967439740896225, generator loss = 8.182132720947266\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 15, Batch: 458/468, discriminator loss real = 2.188349090966827e-14, disciminator loss fake = 0.000150392297655344, generator loss = 12.734492301940918\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 15, Batch: 459/468, discriminator loss real = 8.770761027176999e-12, disciminator loss fake = 2.986915433211834e-06, generator loss = 15.74548625946045\n",
      "2/2 [==============================] - 0s 137ms/step\n",
      "Epoch: 15, Batch: 460/468, discriminator loss real = 7.121904914788485e-22, disciminator loss fake = 1.0798216720786513e-07, generator loss = 18.475677490234375\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 15, Batch: 461/468, discriminator loss real = 1.2532985716948164e-12, disciminator loss fake = 2.160611778379007e-08, generator loss = 20.229276657104492\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 15, Batch: 462/468, discriminator loss real = 1.9247053603677067e-11, disciminator loss fake = 2.5891835342406466e-09, generator loss = 21.356304168701172\n",
      "2/2 [==============================] - 0s 156ms/step\n",
      "Epoch: 15, Batch: 463/468, discriminator loss real = 1.532688542123001e-15, disciminator loss fake = 3.521719027510528e-10, generator loss = 22.855880737304688\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 15, Batch: 464/468, discriminator loss real = 1.1324248205824006e-09, disciminator loss fake = 2.1182418319387608e-10, generator loss = 23.901723861694336\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 15, Batch: 465/468, discriminator loss real = 7.493844655925841e-09, disciminator loss fake = 1.10296202726623e-10, generator loss = 24.53699493408203\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 15, Batch: 466/468, discriminator loss real = 9.125516453600824e-10, disciminator loss fake = 9.715754589745274e-11, generator loss = 25.158063888549805\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 15, Batch: 467/468, discriminator loss real = 8.112745142341282e-09, disciminator loss fake = 5.778932887778865e-11, generator loss = 25.585952758789062\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 15, Batch: 468/468, discriminator loss real = 2.721728821052788e-13, disciminator loss fake = 3.0388740135389725e-11, generator loss = 25.815628051757812\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 16, Batch: 1/468, discriminator loss real = 1.5139423053959003e-14, disciminator loss fake = 3.17701837060369e-11, generator loss = 26.11488151550293\n",
      "2/2 [==============================] - 0s 159ms/step\n",
      "Epoch: 16, Batch: 2/468, discriminator loss real = 1.5920548028774267e-13, disciminator loss fake = 2.9845900056946206e-11, generator loss = 26.395301818847656\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 16, Batch: 3/468, discriminator loss real = 9.681713208919973e-07, disciminator loss fake = 2.257853973230972e-11, generator loss = 26.65264129638672\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 16, Batch: 4/468, discriminator loss real = 0.006207945290952921, disciminator loss fake = 9.191499991678675e-12, generator loss = 26.115848541259766\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 16, Batch: 5/468, discriminator loss real = 1.1866189454645681e-11, disciminator loss fake = 1.9934911360541818e-11, generator loss = 26.310768127441406\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 16, Batch: 6/468, discriminator loss real = 0.0013387928484007716, disciminator loss fake = 2.157857573181765e-11, generator loss = 25.94329833984375\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 16, Batch: 7/468, discriminator loss real = 1.183899228651697e-10, disciminator loss fake = 3.961764943882784e-11, generator loss = 25.9205379486084\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 16, Batch: 8/468, discriminator loss real = 4.500213091063188e-09, disciminator loss fake = 2.253722902745281e-11, generator loss = 25.752819061279297\n",
      "2/2 [==============================] - 0s 167ms/step\n",
      "Epoch: 16, Batch: 9/468, discriminator loss real = 1.3018651934260106e-08, disciminator loss fake = 3.555257477305673e-11, generator loss = 25.488040924072266\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 16, Batch: 10/468, discriminator loss real = 1.3881677925209335e-12, disciminator loss fake = 2.4595256387094366e-11, generator loss = 25.729398727416992\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 16, Batch: 11/468, discriminator loss real = 1.9263289693840363e-13, disciminator loss fake = 2.641410007386824e-11, generator loss = 25.549785614013672\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 16, Batch: 12/468, discriminator loss real = 7.177492378218631e-09, disciminator loss fake = 1.9099780784737064e-11, generator loss = 25.42505645751953\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 16, Batch: 13/468, discriminator loss real = 5.937786720644489e-12, disciminator loss fake = 3.618224123091984e-11, generator loss = 25.37844467163086\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 16, Batch: 14/468, discriminator loss real = 3.3462490496642273e-19, disciminator loss fake = 6.192135693083856e-11, generator loss = 25.42567253112793\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 16, Batch: 15/468, discriminator loss real = 1.8810380944009428e-16, disciminator loss fake = 3.381856600315203e-11, generator loss = 25.49396324157715\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 16, Batch: 16/468, discriminator loss real = 1.01576635727033e-15, disciminator loss fake = 2.0425116459277248e-11, generator loss = 25.34998893737793\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 16, Batch: 17/468, discriminator loss real = 4.936186182025182e-11, disciminator loss fake = 4.9188188244730924e-11, generator loss = 25.48992919921875\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 16, Batch: 18/468, discriminator loss real = 1.1089160145694166e-10, disciminator loss fake = 2.9098962822660113e-11, generator loss = 25.239303588867188\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 16, Batch: 19/468, discriminator loss real = 2.532116269115506e-15, disciminator loss fake = 4.565828964908647e-11, generator loss = 25.341745376586914\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 16, Batch: 20/468, discriminator loss real = 4.2477859337614055e-13, disciminator loss fake = 5.136974873254374e-11, generator loss = 25.359445571899414\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 16, Batch: 21/468, discriminator loss real = 1.1979796495087403e-11, disciminator loss fake = 5.106018732825568e-11, generator loss = 24.930435180664062\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 16, Batch: 22/468, discriminator loss real = 8.807607404227825e-16, disciminator loss fake = 3.731326359002196e-11, generator loss = 25.468721389770508\n",
      "2/2 [==============================] - 0s 134ms/step\n",
      "Epoch: 16, Batch: 23/468, discriminator loss real = 9.017529833954541e-08, disciminator loss fake = 6.761693288614978e-11, generator loss = 25.425739288330078\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 16, Batch: 24/468, discriminator loss real = 5.083856002841003e-09, disciminator loss fake = 3.537879711412728e-11, generator loss = 25.289756774902344\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 16, Batch: 25/468, discriminator loss real = 1.8128884507972824e-20, disciminator loss fake = 2.6983781528655548e-11, generator loss = 24.97829818725586\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 16, Batch: 26/468, discriminator loss real = 4.1924929782173603e-13, disciminator loss fake = 4.884194784726681e-11, generator loss = 25.064186096191406\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 16, Batch: 27/468, discriminator loss real = 7.977426358385387e-11, disciminator loss fake = 4.8955242637482854e-11, generator loss = 25.004470825195312\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 16, Batch: 28/468, discriminator loss real = 0.0015595013974234462, disciminator loss fake = 8.053142874775432e-11, generator loss = 25.17181396484375\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 16, Batch: 29/468, discriminator loss real = 1.497976311381352e-16, disciminator loss fake = 3.53234247407741e-11, generator loss = 24.825199127197266\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 16, Batch: 30/468, discriminator loss real = 4.0081064867081295e-07, disciminator loss fake = 6.02792538106911e-11, generator loss = 24.839059829711914\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 16, Batch: 31/468, discriminator loss real = 4.3426511800719215e-25, disciminator loss fake = 8.968305265089072e-11, generator loss = 25.21558380126953\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 16, Batch: 32/468, discriminator loss real = 1.0732096100696253e-08, disciminator loss fake = 3.823908550915078e-11, generator loss = 24.662471771240234\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 16, Batch: 33/468, discriminator loss real = 1.4063309529959075e-17, disciminator loss fake = 3.8619739350931326e-11, generator loss = 25.03022575378418\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 16, Batch: 34/468, discriminator loss real = 1.762413999462087e-13, disciminator loss fake = 1.1202510447061442e-10, generator loss = 25.05370330810547\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 16, Batch: 35/468, discriminator loss real = 1.1695996954145041e-14, disciminator loss fake = 5.843041328557064e-11, generator loss = 24.569639205932617\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 16, Batch: 36/468, discriminator loss real = 6.172553938088751e-30, disciminator loss fake = 5.3927372983819666e-11, generator loss = 24.77766990661621\n",
      "2/2 [==============================] - 0s 171ms/step\n",
      "Epoch: 16, Batch: 37/468, discriminator loss real = 2.43647342301756e-08, disciminator loss fake = 7.059680617871322e-11, generator loss = 24.901901245117188\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 16, Batch: 38/468, discriminator loss real = 2.8169373233219268e-14, disciminator loss fake = 1.6153876847280202e-10, generator loss = 24.761247634887695\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 16, Batch: 39/468, discriminator loss real = 1.7830965070604194e-19, disciminator loss fake = 3.817713159492975e-11, generator loss = 24.549327850341797\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 16, Batch: 40/468, discriminator loss real = 2.1748720976455423e-21, disciminator loss fake = 5.734736296947318e-11, generator loss = 24.680828094482422\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 16, Batch: 41/468, discriminator loss real = 2.1694808310712688e-05, disciminator loss fake = 1.8033044502097084e-10, generator loss = 24.497802734375\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 16, Batch: 42/468, discriminator loss real = 1.0599684401313425e-06, disciminator loss fake = 8.772014364888392e-11, generator loss = 24.691753387451172\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 16, Batch: 43/468, discriminator loss real = 1.634175794698275e-15, disciminator loss fake = 7.350241248982314e-11, generator loss = 24.50640869140625\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 16, Batch: 44/468, discriminator loss real = 8.043576471550296e-09, disciminator loss fake = 6.336033087084303e-11, generator loss = 24.426593780517578\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 16, Batch: 45/468, discriminator loss real = 9.261233202551011e-08, disciminator loss fake = 1.2659051584762437e-10, generator loss = 24.776798248291016\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 16, Batch: 46/468, discriminator loss real = 4.0813127612518185e-19, disciminator loss fake = 5.302507738447204e-11, generator loss = 24.55431365966797\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 16, Batch: 47/468, discriminator loss real = 1.3354917757606166e-14, disciminator loss fake = 8.005199281235775e-11, generator loss = 24.562837600708008\n",
      "2/2 [==============================] - 0s 160ms/step\n",
      "Epoch: 16, Batch: 48/468, discriminator loss real = 3.7894838378349505e-09, disciminator loss fake = 7.726910777883234e-11, generator loss = 24.595176696777344\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 16, Batch: 49/468, discriminator loss real = 3.727974096923211e-20, disciminator loss fake = 8.91076379350153e-11, generator loss = 24.619924545288086\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 16, Batch: 50/468, discriminator loss real = 4.1746210711330305e-17, disciminator loss fake = 5.333767455484306e-11, generator loss = 24.723249435424805\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 16, Batch: 51/468, discriminator loss real = 6.223659107469817e-20, disciminator loss fake = 7.732748469324591e-11, generator loss = 24.65532684326172\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 16, Batch: 52/468, discriminator loss real = 1.1835089928479564e-14, disciminator loss fake = 1.129778492980904e-10, generator loss = 24.59304428100586\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 16, Batch: 53/468, discriminator loss real = 3.7835715463452324e-12, disciminator loss fake = 5.917091816520781e-11, generator loss = 24.55190658569336\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 16, Batch: 54/468, discriminator loss real = 3.028201997702581e-21, disciminator loss fake = 5.454373411262203e-11, generator loss = 24.63787078857422\n",
      "2/2 [==============================] - 0s 202ms/step\n",
      "Epoch: 16, Batch: 55/468, discriminator loss real = 1.3496455063885673e-17, disciminator loss fake = 1.558794204825631e-10, generator loss = 24.78017234802246\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 16, Batch: 56/468, discriminator loss real = 3.879209236820613e-13, disciminator loss fake = 9.490186414495838e-11, generator loss = 24.618240356445312\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 16, Batch: 57/468, discriminator loss real = 2.2604597232739815e-25, disciminator loss fake = 8.484653257756491e-11, generator loss = 24.61050796508789\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 16, Batch: 58/468, discriminator loss real = 1.8949252512699654e-19, disciminator loss fake = 1.0268141892311178e-10, generator loss = 24.673667907714844\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 16, Batch: 59/468, discriminator loss real = 7.625430518920192e-16, disciminator loss fake = 6.964052251534625e-11, generator loss = 24.481958389282227\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 16, Batch: 60/468, discriminator loss real = 4.8857678143211735e-20, disciminator loss fake = 7.126241957644552e-11, generator loss = 24.645645141601562\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 16, Batch: 61/468, discriminator loss real = 1.093821895268584e-19, disciminator loss fake = 7.061970452859612e-11, generator loss = 25.11068344116211\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 16, Batch: 62/468, discriminator loss real = 1.3314137189665135e-23, disciminator loss fake = 9.19583298397697e-11, generator loss = 24.57976722717285\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 16, Batch: 63/468, discriminator loss real = 0.0023018664214760065, disciminator loss fake = 7.455613210138878e-11, generator loss = 24.359867095947266\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 16, Batch: 64/468, discriminator loss real = 1.3280438906804193e-05, disciminator loss fake = 1.4460477260058724e-10, generator loss = 24.25051498413086\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 16, Batch: 65/468, discriminator loss real = 3.4230570750148643e-16, disciminator loss fake = 1.4430606709581184e-10, generator loss = 24.286352157592773\n",
      "2/2 [==============================] - 0s 181ms/step\n",
      "Epoch: 16, Batch: 66/468, discriminator loss real = 4.237569971028525e-14, disciminator loss fake = 8.450359856304601e-11, generator loss = 24.01953887939453\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 16, Batch: 67/468, discriminator loss real = 3.8914953372103057e-23, disciminator loss fake = 1.110578920493488e-10, generator loss = 24.146469116210938\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 16, Batch: 68/468, discriminator loss real = 9.614101736943326e-10, disciminator loss fake = 9.796141675622039e-11, generator loss = 24.181819915771484\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 16, Batch: 69/468, discriminator loss real = 1.3844464684636525e-14, disciminator loss fake = 2.0061829975048795e-10, generator loss = 23.949996948242188\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 16, Batch: 70/468, discriminator loss real = 1.7757868201080662e-13, disciminator loss fake = 1.585699488382275e-10, generator loss = 24.038360595703125\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 16, Batch: 71/468, discriminator loss real = 3.5741336973371673e-11, disciminator loss fake = 2.602066617729548e-10, generator loss = 23.83639907836914\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 16, Batch: 72/468, discriminator loss real = 9.625352408561619e-14, disciminator loss fake = 1.9894932923314457e-10, generator loss = 23.577064514160156\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 16, Batch: 73/468, discriminator loss real = 1.6485416783013824e-21, disciminator loss fake = 9.936203249072406e-11, generator loss = 23.78957176208496\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 16, Batch: 74/468, discriminator loss real = 1.139426823292683e-13, disciminator loss fake = 2.546595712082933e-10, generator loss = 23.79987335205078\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 16, Batch: 75/468, discriminator loss real = 4.676549639122897e-27, disciminator loss fake = 1.0449544007862244e-10, generator loss = 23.72190284729004\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 16, Batch: 76/468, discriminator loss real = 2.3378951083210023e-16, disciminator loss fake = 1.7176966793375215e-10, generator loss = 23.844608306884766\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 16, Batch: 77/468, discriminator loss real = 9.898760429522782e-23, disciminator loss fake = 1.4943701831526823e-10, generator loss = 23.74420928955078\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 16, Batch: 78/468, discriminator loss real = 0.00039327042759396136, disciminator loss fake = 1.8241647081751466e-10, generator loss = 23.71979522705078\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 16, Batch: 79/468, discriminator loss real = 3.4700037288004637e-10, disciminator loss fake = 3.051713048929372e-10, generator loss = 23.693164825439453\n",
      "2/2 [==============================] - 0s 167ms/step\n",
      "Epoch: 16, Batch: 80/468, discriminator loss real = 2.6676953272683447e-16, disciminator loss fake = 1.7720044875879637e-10, generator loss = 23.68889617919922\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 16, Batch: 81/468, discriminator loss real = 1.6831806741034357e-14, disciminator loss fake = 1.5894488503143123e-10, generator loss = 23.505523681640625\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 16, Batch: 82/468, discriminator loss real = 1.2755952781538317e-22, disciminator loss fake = 1.7210199931838588e-10, generator loss = 23.478208541870117\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 16, Batch: 83/468, discriminator loss real = 3.895205085040783e-18, disciminator loss fake = 1.343725963831588e-10, generator loss = 23.728851318359375\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 16, Batch: 84/468, discriminator loss real = 1.6786248913471166e-28, disciminator loss fake = 1.4000113568446437e-10, generator loss = 23.55154037475586\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 16, Batch: 85/468, discriminator loss real = 7.66637420213101e-09, disciminator loss fake = 1.6015824777504406e-10, generator loss = 23.634159088134766\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 16, Batch: 86/468, discriminator loss real = 4.114281953863409e-14, disciminator loss fake = 1.6956019921465781e-10, generator loss = 23.807327270507812\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 16, Batch: 87/468, discriminator loss real = 3.322636388247702e-08, disciminator loss fake = 1.5147949561367113e-10, generator loss = 23.512893676757812\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 16, Batch: 88/468, discriminator loss real = 4.482242344470172e-18, disciminator loss fake = 1.5862847146941306e-10, generator loss = 23.799827575683594\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 16, Batch: 89/468, discriminator loss real = 3.996674085432472e-12, disciminator loss fake = 1.967904172950341e-10, generator loss = 23.600631713867188\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 16, Batch: 90/468, discriminator loss real = 4.0351925902244734e-13, disciminator loss fake = 1.3523257513803344e-10, generator loss = 23.678020477294922\n",
      "2/2 [==============================] - 0s 147ms/step\n",
      "Epoch: 16, Batch: 91/468, discriminator loss real = 0.0004428550892043859, disciminator loss fake = 2.0576118586745906e-10, generator loss = 23.526817321777344\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 16, Batch: 92/468, discriminator loss real = 6.8052769380197e-20, disciminator loss fake = 2.4222368555371077e-10, generator loss = 23.542144775390625\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 16, Batch: 93/468, discriminator loss real = 0.006484195124357939, disciminator loss fake = 1.9020555963589203e-10, generator loss = 23.227481842041016\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 16, Batch: 94/468, discriminator loss real = 3.899079453964969e-27, disciminator loss fake = 3.015080962676109e-10, generator loss = 22.734708786010742\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 16, Batch: 95/468, discriminator loss real = 4.1492561113078144e-24, disciminator loss fake = 4.174135759260622e-10, generator loss = 22.636198043823242\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 16, Batch: 96/468, discriminator loss real = 4.154518305846946e-15, disciminator loss fake = 7.749048069882747e-10, generator loss = 22.354774475097656\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 16, Batch: 97/468, discriminator loss real = 1.581383000893652e-13, disciminator loss fake = 7.375027255562827e-10, generator loss = 22.443470001220703\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 16, Batch: 98/468, discriminator loss real = 2.682124347409184e-19, disciminator loss fake = 5.936241498361028e-10, generator loss = 22.308137893676758\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 16, Batch: 99/468, discriminator loss real = 0.00416146544739604, disciminator loss fake = 1.087534062804707e-09, generator loss = 21.931425094604492\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 16, Batch: 100/468, discriminator loss real = 1.664215444615076e-28, disciminator loss fake = 1.430922713652194e-09, generator loss = 21.638202667236328\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 16, Batch: 101/468, discriminator loss real = 1.6914613698397474e-13, disciminator loss fake = 2.5185238339275884e-09, generator loss = 21.38528060913086\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 16, Batch: 102/468, discriminator loss real = 0.0020228950306773186, disciminator loss fake = 2.095664086709803e-09, generator loss = 21.169296264648438\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 16, Batch: 103/468, discriminator loss real = 4.7244244072430774e-09, disciminator loss fake = 1.933042170776389e-09, generator loss = 20.519893646240234\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 16, Batch: 104/468, discriminator loss real = 1.1710476065035054e-19, disciminator loss fake = 3.996995179278429e-09, generator loss = 20.48696517944336\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 16, Batch: 105/468, discriminator loss real = 8.428328496820452e-15, disciminator loss fake = 4.679447052069463e-09, generator loss = 19.88863182067871\n",
      "2/2 [==============================] - 0s 160ms/step\n",
      "Epoch: 16, Batch: 106/468, discriminator loss real = 1.7084564873925956e-08, disciminator loss fake = 6.288141563004501e-09, generator loss = 20.059810638427734\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 16, Batch: 107/468, discriminator loss real = 2.7610410381209532e-17, disciminator loss fake = 9.254708999151262e-09, generator loss = 19.939193725585938\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 16, Batch: 108/468, discriminator loss real = 2.1604673345471115e-12, disciminator loss fake = 1.2424393958099245e-08, generator loss = 19.83904457092285\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 16, Batch: 109/468, discriminator loss real = 9.305024193780463e-17, disciminator loss fake = 1.705970120724487e-08, generator loss = 19.617355346679688\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 16, Batch: 110/468, discriminator loss real = 1.9404811461035755e-16, disciminator loss fake = 1.497445190068447e-08, generator loss = 19.562408447265625\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 16, Batch: 111/468, discriminator loss real = 4.889859201687337e-14, disciminator loss fake = 1.2981785424415193e-08, generator loss = 19.658241271972656\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 16, Batch: 112/468, discriminator loss real = 2.4237077209223188e-33, disciminator loss fake = 1.3278083521583994e-08, generator loss = 19.358200073242188\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 16, Batch: 113/468, discriminator loss real = 0.0008090102928690612, disciminator loss fake = 1.8678306901165342e-08, generator loss = 19.507701873779297\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 16, Batch: 114/468, discriminator loss real = 0.0013588478323072195, disciminator loss fake = 1.93654035030022e-08, generator loss = 19.303735733032227\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 16, Batch: 115/468, discriminator loss real = 5.965328231383182e-11, disciminator loss fake = 1.6298265848035953e-08, generator loss = 19.225595474243164\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 16, Batch: 116/468, discriminator loss real = 1.3733393762482837e-13, disciminator loss fake = 2.2149746925492764e-08, generator loss = 19.11035919189453\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 16, Batch: 117/468, discriminator loss real = 8.0976233290480865e-16, disciminator loss fake = 3.112307211949883e-08, generator loss = 18.89081573486328\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 16, Batch: 118/468, discriminator loss real = 1.4038722744303794e-16, disciminator loss fake = 1.5996924673800095e-08, generator loss = 19.03672981262207\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 16, Batch: 119/468, discriminator loss real = 3.778498434140792e-21, disciminator loss fake = 2.8045423761113852e-08, generator loss = 18.600902557373047\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 16, Batch: 120/468, discriminator loss real = 2.4090213343039927e-29, disciminator loss fake = 2.9923896249783866e-08, generator loss = 18.60873031616211\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 16, Batch: 121/468, discriminator loss real = 5.608428151663867e-17, disciminator loss fake = 2.1592471810549796e-08, generator loss = 18.335220336914062\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 16, Batch: 122/468, discriminator loss real = 1.3128957691183664e-19, disciminator loss fake = 3.797313752329501e-08, generator loss = 18.50959014892578\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 16, Batch: 123/468, discriminator loss real = 1.2262080416481823e-22, disciminator loss fake = 3.568153061905832e-08, generator loss = 18.49541473388672\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 16, Batch: 124/468, discriminator loss real = 6.214726649966806e-11, disciminator loss fake = 2.4186144642612817e-08, generator loss = 18.293376922607422\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 16, Batch: 125/468, discriminator loss real = 6.648344201554135e-12, disciminator loss fake = 3.2579151820755214e-08, generator loss = 18.532955169677734\n",
      "2/2 [==============================] - 0s 186ms/step\n",
      "Epoch: 16, Batch: 126/468, discriminator loss real = 3.261823252362177e-14, disciminator loss fake = 1.5598570257679967e-07, generator loss = 18.360187530517578\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 16, Batch: 127/468, discriminator loss real = 8.158761038079366e-19, disciminator loss fake = 3.5787024899036624e-07, generator loss = 18.25666618347168\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 16, Batch: 128/468, discriminator loss real = 1.693399110172522e-12, disciminator loss fake = 4.414663123952778e-08, generator loss = 18.437814712524414\n",
      "2/2 [==============================] - 0s 165ms/step\n",
      "Epoch: 16, Batch: 129/468, discriminator loss real = 1.9987998886236702e-13, disciminator loss fake = 4.7878099707077126e-08, generator loss = 18.518665313720703\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 16, Batch: 130/468, discriminator loss real = 1.8058344742532804e-20, disciminator loss fake = 3.917332591640843e-08, generator loss = 18.502521514892578\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 16, Batch: 131/468, discriminator loss real = 4.928091027350332e-20, disciminator loss fake = 7.952142766498582e-08, generator loss = 18.372779846191406\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 16, Batch: 132/468, discriminator loss real = 2.0335945515529547e-16, disciminator loss fake = 3.742938048389988e-08, generator loss = 18.37496566772461\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 16, Batch: 133/468, discriminator loss real = 3.7104140611620698e-16, disciminator loss fake = 6.27616287829369e-08, generator loss = 18.50457191467285\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 16, Batch: 134/468, discriminator loss real = 7.009886382194571e-16, disciminator loss fake = 6.756102521876528e-08, generator loss = 18.16248321533203\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 16, Batch: 135/468, discriminator loss real = 2.775600244082499e-17, disciminator loss fake = 7.400615942287914e-08, generator loss = 18.50891876220703\n",
      "2/2 [==============================] - 0s 192ms/step\n",
      "Epoch: 16, Batch: 136/468, discriminator loss real = 7.707171537047351e-25, disciminator loss fake = 1.1431793467409079e-07, generator loss = 18.569334030151367\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 16, Batch: 137/468, discriminator loss real = 7.300739099784875e-18, disciminator loss fake = 5.661499358211586e-08, generator loss = 18.446727752685547\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 16, Batch: 138/468, discriminator loss real = 6.598497442888984e-11, disciminator loss fake = 4.103246453723841e-08, generator loss = 18.477079391479492\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 16, Batch: 139/468, discriminator loss real = 1.64887737224175e-26, disciminator loss fake = 4.598776115471992e-08, generator loss = 18.474336624145508\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 16, Batch: 140/468, discriminator loss real = 2.413869592105089e-28, disciminator loss fake = 7.519602007732828e-08, generator loss = 18.265060424804688\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 16, Batch: 141/468, discriminator loss real = 1.0769200911940681e-22, disciminator loss fake = 3.257557423808066e-08, generator loss = 18.466556549072266\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 16, Batch: 142/468, discriminator loss real = 4.681397243880583e-17, disciminator loss fake = 5.821713600084877e-08, generator loss = 18.62729835510254\n",
      "2/2 [==============================] - 0s 191ms/step\n",
      "Epoch: 16, Batch: 143/468, discriminator loss real = 1.5160100822267375e-12, disciminator loss fake = 4.4366878171331336e-08, generator loss = 18.03479766845703\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 16, Batch: 144/468, discriminator loss real = 6.071674524994715e-21, disciminator loss fake = 3.382004720720033e-08, generator loss = 18.24704360961914\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 16, Batch: 145/468, discriminator loss real = 7.722523457209339e-18, disciminator loss fake = 5.221533783128507e-08, generator loss = 17.896957397460938\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 16, Batch: 146/468, discriminator loss real = 4.4814227329048606e-10, disciminator loss fake = 4.653531959775137e-08, generator loss = 18.40084457397461\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 16, Batch: 147/468, discriminator loss real = 4.0347561929439784e-19, disciminator loss fake = 6.02095298063432e-08, generator loss = 18.123180389404297\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 16, Batch: 148/468, discriminator loss real = 1.325794229054453e-19, disciminator loss fake = 2.569862367352016e-08, generator loss = 18.17865753173828\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 16, Batch: 149/468, discriminator loss real = 2.613805432666898e-19, disciminator loss fake = 3.616090182845255e-08, generator loss = 18.28998565673828\n",
      "2/2 [==============================] - 0s 184ms/step\n",
      "Epoch: 16, Batch: 150/468, discriminator loss real = 1.576111983980777e-11, disciminator loss fake = 7.617011021920916e-08, generator loss = 18.521974563598633\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 16, Batch: 151/468, discriminator loss real = 1.0745861151465142e-17, disciminator loss fake = 5.599380159537759e-08, generator loss = 18.223312377929688\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 16, Batch: 152/468, discriminator loss real = 1.0786777433669925e-18, disciminator loss fake = 3.749061860958136e-08, generator loss = 18.511978149414062\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 16, Batch: 153/468, discriminator loss real = 2.3913913587531553e-14, disciminator loss fake = 5.142912229416652e-08, generator loss = 18.190011978149414\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 16, Batch: 154/468, discriminator loss real = 5.463757074942425e-18, disciminator loss fake = 2.505703378119506e-08, generator loss = 18.45269012451172\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 16, Batch: 155/468, discriminator loss real = 2.610601318453476e-11, disciminator loss fake = 5.849725681628115e-08, generator loss = 18.31924819946289\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 16, Batch: 156/468, discriminator loss real = 5.231980626518862e-09, disciminator loss fake = 2.6357763971418535e-08, generator loss = 18.404844284057617\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 16, Batch: 157/468, discriminator loss real = 2.241755206174608e-18, disciminator loss fake = 4.407142029094757e-08, generator loss = 18.333419799804688\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 16, Batch: 158/468, discriminator loss real = 1.4466689687440905e-19, disciminator loss fake = 2.8298330789766624e-08, generator loss = 18.195905685424805\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 16, Batch: 159/468, discriminator loss real = 3.991443698357446e-24, disciminator loss fake = 3.257732572592431e-08, generator loss = 18.460834503173828\n",
      "2/2 [==============================] - 0s 154ms/step\n",
      "Epoch: 16, Batch: 160/468, discriminator loss real = 1.5182967323711452e-14, disciminator loss fake = 9.892070806927222e-08, generator loss = 18.57616424560547\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 16, Batch: 161/468, discriminator loss real = 1.1399943294625662e-21, disciminator loss fake = 4.851910873071574e-08, generator loss = 18.212020874023438\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 16, Batch: 162/468, discriminator loss real = 1.6514627887431743e-08, disciminator loss fake = 7.560967674180574e-08, generator loss = 18.337419509887695\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 16, Batch: 163/468, discriminator loss real = 2.5933540988408954e-22, disciminator loss fake = 7.406126201203733e-08, generator loss = 18.491287231445312\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 16, Batch: 164/468, discriminator loss real = 1.5999066329119824e-19, disciminator loss fake = 6.112125561230641e-08, generator loss = 18.522825241088867\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 16, Batch: 165/468, discriminator loss real = 3.614367512965247e-15, disciminator loss fake = 3.700452566590684e-08, generator loss = 18.366214752197266\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 16, Batch: 166/468, discriminator loss real = 1.4859524743483787e-13, disciminator loss fake = 3.7730984558947966e-08, generator loss = 18.517898559570312\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 16, Batch: 167/468, discriminator loss real = 6.908968229880734e-16, disciminator loss fake = 3.821923399982552e-08, generator loss = 18.303743362426758\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 16, Batch: 168/468, discriminator loss real = 1.3722930569670666e-09, disciminator loss fake = 4.516801865861453e-08, generator loss = 18.20735740661621\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 16, Batch: 169/468, discriminator loss real = 1.5314608191034467e-26, disciminator loss fake = 4.709249878942501e-08, generator loss = 18.324146270751953\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 16, Batch: 170/468, discriminator loss real = 7.362734553983952e-13, disciminator loss fake = 6.918118344856339e-08, generator loss = 18.32262420654297\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 16, Batch: 171/468, discriminator loss real = 2.9599188035918253e-21, disciminator loss fake = 3.995881314722283e-08, generator loss = 18.304012298583984\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 16, Batch: 172/468, discriminator loss real = 5.909915963476989e-19, disciminator loss fake = 5.492805144058366e-08, generator loss = 18.340576171875\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 16, Batch: 173/468, discriminator loss real = 3.2589376652207656e-15, disciminator loss fake = 4.268819253638867e-08, generator loss = 18.59239959716797\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 16, Batch: 174/468, discriminator loss real = 3.48636982651553e-18, disciminator loss fake = 1.110337919385529e-07, generator loss = 18.286401748657227\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 16, Batch: 175/468, discriminator loss real = 5.6564208178455644e-11, disciminator loss fake = 6.249587869433526e-08, generator loss = 18.187442779541016\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 16, Batch: 176/468, discriminator loss real = 3.897152268202733e-18, disciminator loss fake = 3.596975517439205e-08, generator loss = 18.320892333984375\n",
      "2/2 [==============================] - 0s 171ms/step\n",
      "Epoch: 16, Batch: 177/468, discriminator loss real = 1.3352311431046228e-22, disciminator loss fake = 3.4852032371190944e-08, generator loss = 18.240636825561523\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 16, Batch: 178/468, discriminator loss real = 3.70050379228104e-11, disciminator loss fake = 5.781117806691327e-08, generator loss = 18.490684509277344\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 16, Batch: 179/468, discriminator loss real = 9.833071856757414e-13, disciminator loss fake = 2.5914387080661072e-08, generator loss = 18.121986389160156\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 16, Batch: 180/468, discriminator loss real = 1.500332244523909e-26, disciminator loss fake = 2.059923609465386e-08, generator loss = 18.35918426513672\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 16, Batch: 181/468, discriminator loss real = 7.415297439458169e-26, disciminator loss fake = 4.154316712856598e-08, generator loss = 18.309240341186523\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 16, Batch: 182/468, discriminator loss real = 1.5522935432036753e-15, disciminator loss fake = 7.85608520459391e-08, generator loss = 18.252857208251953\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 16, Batch: 183/468, discriminator loss real = 1.3108560130721384e-15, disciminator loss fake = 6.515204376000838e-08, generator loss = 18.46619415283203\n",
      "2/2 [==============================] - 0s 171ms/step\n",
      "Epoch: 16, Batch: 184/468, discriminator loss real = 2.501334859725257e-12, disciminator loss fake = 4.432227029838032e-08, generator loss = 18.33929443359375\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 16, Batch: 185/468, discriminator loss real = 3.890328136675267e-14, disciminator loss fake = 6.317329592775422e-08, generator loss = 18.098621368408203\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 16, Batch: 186/468, discriminator loss real = 1.1902857930476598e-23, disciminator loss fake = 5.8948543824044464e-08, generator loss = 18.381973266601562\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 16, Batch: 187/468, discriminator loss real = 1.6799847971094017e-11, disciminator loss fake = 2.9414405133820765e-08, generator loss = 18.14560317993164\n",
      "2/2 [==============================] - 0s 184ms/step\n",
      "Epoch: 16, Batch: 188/468, discriminator loss real = 6.2513762818975924e-21, disciminator loss fake = 3.885012844762059e-08, generator loss = 18.242677688598633\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 16, Batch: 189/468, discriminator loss real = 1.1909507668245167e-12, disciminator loss fake = 3.439473772459678e-08, generator loss = 18.16042709350586\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 16, Batch: 190/468, discriminator loss real = 1.36093683834441e-23, disciminator loss fake = 7.00408406828501e-08, generator loss = 18.381471633911133\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 16, Batch: 191/468, discriminator loss real = 3.7854793735245677e-23, disciminator loss fake = 4.4149658151582116e-08, generator loss = 18.313077926635742\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 16, Batch: 192/468, discriminator loss real = 1.7345138985547237e-05, disciminator loss fake = 4.070820480706061e-08, generator loss = 18.368934631347656\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 16, Batch: 193/468, discriminator loss real = 2.1575940991169773e-05, disciminator loss fake = 3.46085222702186e-08, generator loss = 18.429664611816406\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 16, Batch: 194/468, discriminator loss real = 6.6556341490951754e-21, disciminator loss fake = 5.0030195097860997e-08, generator loss = 18.039703369140625\n",
      "2/2 [==============================] - 0s 198ms/step\n",
      "Epoch: 16, Batch: 195/468, discriminator loss real = 2.4212955859054253e-12, disciminator loss fake = 6.184137646414456e-08, generator loss = 18.129207611083984\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 16, Batch: 196/468, discriminator loss real = 1.1869681966569487e-18, disciminator loss fake = 4.363194960887995e-08, generator loss = 18.413768768310547\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 16, Batch: 197/468, discriminator loss real = 2.328250587697134e-18, disciminator loss fake = 3.698802686358249e-08, generator loss = 18.17413330078125\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 16, Batch: 198/468, discriminator loss real = 4.92383428612477e-15, disciminator loss fake = 3.581686769393855e-08, generator loss = 18.328704833984375\n",
      "2/2 [==============================] - 0s 191ms/step\n",
      "Epoch: 16, Batch: 199/468, discriminator loss real = 0.0007232146454043686, disciminator loss fake = 3.374971413450112e-08, generator loss = 18.24493408203125\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 16, Batch: 200/468, discriminator loss real = 5.600499790928669e-16, disciminator loss fake = 4.540170905897867e-08, generator loss = 18.43170928955078\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 16, Batch: 201/468, discriminator loss real = 9.944653706415899e-21, disciminator loss fake = 2.072669147423767e-08, generator loss = 18.117422103881836\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 16, Batch: 202/468, discriminator loss real = 1.545353320266093e-21, disciminator loss fake = 4.977938417027872e-08, generator loss = 18.091753005981445\n",
      "2/2 [==============================] - 0s 166ms/step\n",
      "Epoch: 16, Batch: 203/468, discriminator loss real = 2.076967929306368e-19, disciminator loss fake = 8.368252224499884e-08, generator loss = 17.895673751831055\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 16, Batch: 204/468, discriminator loss real = 1.240001767932597e-09, disciminator loss fake = 5.640882250190771e-08, generator loss = 18.198427200317383\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 16, Batch: 205/468, discriminator loss real = 9.750950299534072e-24, disciminator loss fake = 6.422690290719402e-08, generator loss = 18.280075073242188\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 16, Batch: 206/468, discriminator loss real = 3.1501584118816977e-16, disciminator loss fake = 4.192235536493172e-08, generator loss = 18.002836227416992\n",
      "2/2 [==============================] - 0s 150ms/step\n",
      "Epoch: 16, Batch: 207/468, discriminator loss real = 1.95343003925319e-12, disciminator loss fake = 3.434641016042406e-08, generator loss = 17.925884246826172\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 16, Batch: 208/468, discriminator loss real = 6.2696651321500405e-21, disciminator loss fake = 8.27683876991614e-08, generator loss = 18.170339584350586\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 16, Batch: 209/468, discriminator loss real = 1.611754285590905e-08, disciminator loss fake = 5.140366710065791e-08, generator loss = 18.04864501953125\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 16, Batch: 210/468, discriminator loss real = 8.792106593089123e-23, disciminator loss fake = 7.172059213189641e-08, generator loss = 17.78549575805664\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 16, Batch: 211/468, discriminator loss real = 4.4213020793152063e-16, disciminator loss fake = 7.837981996772214e-08, generator loss = 18.005924224853516\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 16, Batch: 212/468, discriminator loss real = 1.8055757967811592e-17, disciminator loss fake = 1.182248041686762e-07, generator loss = 18.171344757080078\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 16, Batch: 213/468, discriminator loss real = 4.383958291819096e-22, disciminator loss fake = 2.6782487339005456e-08, generator loss = 17.761810302734375\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 16, Batch: 214/468, discriminator loss real = 4.64194408060121e-23, disciminator loss fake = 5.037242800653985e-08, generator loss = 17.968250274658203\n",
      "2/2 [==============================] - 0s 141ms/step\n",
      "Epoch: 16, Batch: 215/468, discriminator loss real = 3.5238715716717816e-15, disciminator loss fake = 7.72977983842793e-08, generator loss = 17.689300537109375\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 16, Batch: 216/468, discriminator loss real = 1.2076844161351487e-27, disciminator loss fake = 1.92833923051694e-07, generator loss = 17.78248405456543\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 16, Batch: 217/468, discriminator loss real = 3.329620069789012e-20, disciminator loss fake = 5.888600185244286e-08, generator loss = 18.070964813232422\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 16, Batch: 218/468, discriminator loss real = 5.832633868251095e-21, disciminator loss fake = 4.064159497829678e-08, generator loss = 18.15595817565918\n",
      "2/2 [==============================] - 0s 166ms/step\n",
      "Epoch: 16, Batch: 219/468, discriminator loss real = 2.68361957976395e-17, disciminator loss fake = 5.133940916834945e-08, generator loss = 18.03533172607422\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 16, Batch: 220/468, discriminator loss real = 1.7559924055197268e-13, disciminator loss fake = 4.100598260947663e-08, generator loss = 18.05117416381836\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 16, Batch: 221/468, discriminator loss real = 4.6850513513163605e-07, disciminator loss fake = 5.007789383171257e-08, generator loss = 17.958152770996094\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 16, Batch: 222/468, discriminator loss real = 1.9672987963331572e-24, disciminator loss fake = 7.323276918214106e-08, generator loss = 17.77778434753418\n",
      "2/2 [==============================] - 0s 136ms/step\n",
      "Epoch: 16, Batch: 223/468, discriminator loss real = 3.843958751303944e-08, disciminator loss fake = 1.2699804585736274e-07, generator loss = 17.87264633178711\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 16, Batch: 224/468, discriminator loss real = 2.9306537752127326e-10, disciminator loss fake = 5.445536999104661e-08, generator loss = 18.138986587524414\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 16, Batch: 225/468, discriminator loss real = 1.82478602219218e-19, disciminator loss fake = 5.3125166488143805e-08, generator loss = 18.01423454284668\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 16, Batch: 226/468, discriminator loss real = 1.9296193874522583e-13, disciminator loss fake = 8.780337878988576e-08, generator loss = 17.906991958618164\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 16, Batch: 227/468, discriminator loss real = 4.3509544048589606e-16, disciminator loss fake = 6.478467184933834e-08, generator loss = 18.07488441467285\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 16, Batch: 228/468, discriminator loss real = 5.216776867260883e-19, disciminator loss fake = 3.502370304886426e-08, generator loss = 17.686058044433594\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 16, Batch: 229/468, discriminator loss real = 3.733643807391621e-17, disciminator loss fake = 3.5931442710079864e-08, generator loss = 18.069799423217773\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 16, Batch: 230/468, discriminator loss real = 5.809535795139875e-13, disciminator loss fake = 3.7397136054551083e-08, generator loss = 18.084300994873047\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 16, Batch: 231/468, discriminator loss real = 1.2978427180818612e-30, disciminator loss fake = 1.1724986137551241e-07, generator loss = 17.931272506713867\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 16, Batch: 232/468, discriminator loss real = 1.9189965433393307e-22, disciminator loss fake = 7.374275412530551e-08, generator loss = 17.852426528930664\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 16, Batch: 233/468, discriminator loss real = 7.641113219589157e-13, disciminator loss fake = 7.051125550106008e-08, generator loss = 17.774860382080078\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 16, Batch: 234/468, discriminator loss real = 3.691453457577154e-05, disciminator loss fake = 9.696948666260141e-08, generator loss = 17.880542755126953\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 16, Batch: 235/468, discriminator loss real = 1.07028452944968e-27, disciminator loss fake = 5.999531538236624e-08, generator loss = 17.87242889404297\n",
      "2/2 [==============================] - 0s 130ms/step\n",
      "Epoch: 16, Batch: 236/468, discriminator loss real = 4.489736253404045e-16, disciminator loss fake = 4.847018431064498e-08, generator loss = 18.032270431518555\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 16, Batch: 237/468, discriminator loss real = 2.3204307239474422e-23, disciminator loss fake = 8.247103266967315e-08, generator loss = 17.807292938232422\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 16, Batch: 238/468, discriminator loss real = 4.138598441727481e-08, disciminator loss fake = 1.334334598368514e-07, generator loss = 18.156187057495117\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 16, Batch: 239/468, discriminator loss real = 9.524040410491263e-12, disciminator loss fake = 7.670368518120085e-08, generator loss = 17.98130989074707\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 16, Batch: 240/468, discriminator loss real = 1.5774349057876003e-12, disciminator loss fake = 1.6588813878115616e-07, generator loss = 18.01749038696289\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 16, Batch: 241/468, discriminator loss real = 1.5456380271087632e-20, disciminator loss fake = 1.1286303447377577e-07, generator loss = 17.997386932373047\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 16, Batch: 242/468, discriminator loss real = 1.9463737999103614e-07, disciminator loss fake = 5.346061016098247e-08, generator loss = 17.846595764160156\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 16, Batch: 243/468, discriminator loss real = 1.7420911380128246e-09, disciminator loss fake = 4.873513148595521e-08, generator loss = 17.844879150390625\n",
      "2/2 [==============================] - 0s 181ms/step\n",
      "Epoch: 16, Batch: 244/468, discriminator loss real = 6.767480998336184e-13, disciminator loss fake = 6.780541639272997e-08, generator loss = 18.042991638183594\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 16, Batch: 245/468, discriminator loss real = 8.357581446329576e-17, disciminator loss fake = 9.188589444875106e-08, generator loss = 18.028030395507812\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 16, Batch: 246/468, discriminator loss real = 0.0007105408003553748, disciminator loss fake = 1.2867360510426806e-07, generator loss = 17.884668350219727\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 16, Batch: 247/468, discriminator loss real = 8.272286189381362e-10, disciminator loss fake = 8.240443349905036e-08, generator loss = 17.98267364501953\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 16, Batch: 248/468, discriminator loss real = 1.265471061315967e-16, disciminator loss fake = 7.562904613678256e-08, generator loss = 18.059038162231445\n",
      "2/2 [==============================] - 0s 135ms/step\n",
      "Epoch: 16, Batch: 249/468, discriminator loss real = 3.419890230583317e-17, disciminator loss fake = 1.4833614159215358e-07, generator loss = 17.906349182128906\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 16, Batch: 250/468, discriminator loss real = 2.971457197528898e-24, disciminator loss fake = 1.1448211978404288e-07, generator loss = 17.531396865844727\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 16, Batch: 251/468, discriminator loss real = 2.8857385925284973e-10, disciminator loss fake = 8.39510150285605e-08, generator loss = 17.89130401611328\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 16, Batch: 252/468, discriminator loss real = 1.4410271270798167e-29, disciminator loss fake = 5.561927096664476e-08, generator loss = 17.643924713134766\n",
      "2/2 [==============================] - 0s 175ms/step\n",
      "Epoch: 16, Batch: 253/468, discriminator loss real = 1.029922964391719e-21, disciminator loss fake = 1.154981319473336e-07, generator loss = 17.397098541259766\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 16, Batch: 254/468, discriminator loss real = 3.668068893603049e-05, disciminator loss fake = 6.843799127409511e-08, generator loss = 17.63509750366211\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 16, Batch: 255/468, discriminator loss real = 4.898327837093985e-13, disciminator loss fake = 6.669121432878455e-08, generator loss = 17.67730712890625\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 16, Batch: 256/468, discriminator loss real = 2.7284921565747516e-22, disciminator loss fake = 1.1662481824714632e-07, generator loss = 17.83306312561035\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 16, Batch: 257/468, discriminator loss real = 5.693379600573063e-16, disciminator loss fake = 1.621284013708646e-07, generator loss = 17.876861572265625\n",
      "2/2 [==============================] - 0s 190ms/step\n",
      "Epoch: 16, Batch: 258/468, discriminator loss real = 2.184057448784138e-11, disciminator loss fake = 2.755487287231517e-07, generator loss = 17.505943298339844\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 16, Batch: 259/468, discriminator loss real = 2.3445900401455915e-28, disciminator loss fake = 1.5346959969519958e-07, generator loss = 17.510265350341797\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 16, Batch: 260/468, discriminator loss real = 7.749988831396305e-16, disciminator loss fake = 2.4175005819415674e-07, generator loss = 17.685243606567383\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 16, Batch: 261/468, discriminator loss real = 3.9577336527771366e-17, disciminator loss fake = 8.120034777903129e-08, generator loss = 17.73914337158203\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 16, Batch: 262/468, discriminator loss real = 6.177274179139082e-19, disciminator loss fake = 1.2201945764900302e-07, generator loss = 17.567413330078125\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 16, Batch: 263/468, discriminator loss real = 1.053567538499603e-19, disciminator loss fake = 1.4413667770440952e-07, generator loss = 17.33936882019043\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 16, Batch: 264/468, discriminator loss real = 5.410136022311864e-21, disciminator loss fake = 1.4995288211139268e-07, generator loss = 17.50909423828125\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 16, Batch: 265/468, discriminator loss real = 1.8363003562171798e-07, disciminator loss fake = 1.0344747636281681e-07, generator loss = 17.489898681640625\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 16, Batch: 266/468, discriminator loss real = 7.235675660232091e-26, disciminator loss fake = 6.45701021539935e-08, generator loss = 17.489505767822266\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 16, Batch: 267/468, discriminator loss real = 3.7053400039051238e-22, disciminator loss fake = 9.495963126937568e-08, generator loss = 17.520797729492188\n",
      "2/2 [==============================] - 0s 170ms/step\n",
      "Epoch: 16, Batch: 268/468, discriminator loss real = 2.273638871304936e-15, disciminator loss fake = 1.2599014098668704e-07, generator loss = 17.6220703125\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 16, Batch: 269/468, discriminator loss real = 3.237740384065546e-05, disciminator loss fake = 4.8383185458078515e-08, generator loss = 17.522706985473633\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 16, Batch: 270/468, discriminator loss real = 1.0402698938805771e-13, disciminator loss fake = 2.3792628667251847e-07, generator loss = 17.63608169555664\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 16, Batch: 271/468, discriminator loss real = 5.075366412437033e-18, disciminator loss fake = 6.436252419916855e-08, generator loss = 17.30849838256836\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 16, Batch: 272/468, discriminator loss real = 7.218986523740544e-15, disciminator loss fake = 1.0696234653551073e-07, generator loss = 17.280282974243164\n",
      "2/2 [==============================] - 0s 171ms/step\n",
      "Epoch: 16, Batch: 273/468, discriminator loss real = 6.966557857827722e-25, disciminator loss fake = 1.0692112795140929e-07, generator loss = 17.49704360961914\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 16, Batch: 274/468, discriminator loss real = 3.106239517259012e-36, disciminator loss fake = 6.65128965238182e-08, generator loss = 17.443653106689453\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 16, Batch: 275/468, discriminator loss real = 2.212665500647422e-24, disciminator loss fake = 9.550091562005036e-08, generator loss = 17.513778686523438\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 16, Batch: 276/468, discriminator loss real = 1.8658311048597796e-22, disciminator loss fake = 9.244197940461163e-08, generator loss = 17.66583824157715\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 16, Batch: 277/468, discriminator loss real = 3.486021778559792e-23, disciminator loss fake = 1.3073642435301736e-07, generator loss = 17.34801483154297\n",
      "2/2 [==============================] - 0s 156ms/step\n",
      "Epoch: 16, Batch: 278/468, discriminator loss real = 9.418466508871158e-20, disciminator loss fake = 1.4362007050294778e-07, generator loss = 17.73021697998047\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 16, Batch: 279/468, discriminator loss real = 7.203216955531389e-05, disciminator loss fake = 8.531880268947134e-08, generator loss = 17.797405242919922\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 16, Batch: 280/468, discriminator loss real = 1.1049403043297736e-22, disciminator loss fake = 1.9650494209599856e-07, generator loss = 17.61849021911621\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 16, Batch: 281/468, discriminator loss real = 3.097653396600786e-25, disciminator loss fake = 1.2744865784952708e-07, generator loss = 17.30792999267578\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 16, Batch: 282/468, discriminator loss real = 0.0003837809490505606, disciminator loss fake = 2.1352792600737303e-07, generator loss = 17.399436950683594\n",
      "2/2 [==============================] - 0s 183ms/step\n",
      "Epoch: 16, Batch: 283/468, discriminator loss real = 3.265417103381907e-10, disciminator loss fake = 1.4910631307429867e-07, generator loss = 17.318031311035156\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 16, Batch: 284/468, discriminator loss real = 2.247218904016801e-12, disciminator loss fake = 1.943038085983062e-07, generator loss = 17.81560516357422\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 16, Batch: 285/468, discriminator loss real = 3.3401321259621947e-14, disciminator loss fake = 1.4795369907005806e-07, generator loss = 17.313798904418945\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 16, Batch: 286/468, discriminator loss real = 1.9318590130379398e-11, disciminator loss fake = 1.2152511885688e-07, generator loss = 17.428266525268555\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 16, Batch: 287/468, discriminator loss real = 2.8742317226715386e-05, disciminator loss fake = 8.270913554042636e-08, generator loss = 17.33724594116211\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 16, Batch: 288/468, discriminator loss real = 1.302704909141592e-16, disciminator loss fake = 7.952269243105548e-08, generator loss = 17.541622161865234\n",
      "2/2 [==============================] - 0s 153ms/step\n",
      "Epoch: 16, Batch: 289/468, discriminator loss real = 1.3246291658411874e-16, disciminator loss fake = 1.480263733810716e-07, generator loss = 17.181909561157227\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 16, Batch: 290/468, discriminator loss real = 3.1440766094412934e-15, disciminator loss fake = 9.474354101257632e-08, generator loss = 17.51909637451172\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 16, Batch: 291/468, discriminator loss real = 3.351196747945588e-14, disciminator loss fake = 1.1781023800949697e-07, generator loss = 17.51406478881836\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 16, Batch: 292/468, discriminator loss real = 1.5167511999077922e-19, disciminator loss fake = 8.276924745587166e-08, generator loss = 17.284332275390625\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 16, Batch: 293/468, discriminator loss real = 4.947867182636401e-07, disciminator loss fake = 1.0986451570715872e-07, generator loss = 17.026153564453125\n",
      "2/2 [==============================] - 0s 159ms/step\n",
      "Epoch: 16, Batch: 294/468, discriminator loss real = 6.575738416010865e-25, disciminator loss fake = 8.395178952014248e-08, generator loss = 17.279172897338867\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 16, Batch: 295/468, discriminator loss real = 7.354308970615034e-18, disciminator loss fake = 6.540501829022105e-08, generator loss = 17.417970657348633\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 16, Batch: 296/468, discriminator loss real = 9.583667427744463e-18, disciminator loss fake = 1.0226504798538372e-07, generator loss = 17.416505813598633\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 16, Batch: 297/468, discriminator loss real = 1.0970910476038205e-26, disciminator loss fake = 1.7244352079615055e-07, generator loss = 17.461727142333984\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 16, Batch: 298/468, discriminator loss real = 1.3482821803467715e-10, disciminator loss fake = 1.0759760016298969e-07, generator loss = 17.18527603149414\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 16, Batch: 299/468, discriminator loss real = 6.353166218872255e-28, disciminator loss fake = 2.6271112574249855e-07, generator loss = 17.036407470703125\n",
      "2/2 [==============================] - 0s 163ms/step\n",
      "Epoch: 16, Batch: 300/468, discriminator loss real = 4.703715035248024e-07, disciminator loss fake = 1.5361942473646195e-07, generator loss = 17.178098678588867\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 16, Batch: 301/468, discriminator loss real = 1.3250421593280493e-10, disciminator loss fake = 1.370174942394442e-07, generator loss = 17.15867805480957\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 16, Batch: 302/468, discriminator loss real = 2.2603606240051e-16, disciminator loss fake = 9.961442515304952e-08, generator loss = 17.02987289428711\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 16, Batch: 303/468, discriminator loss real = 3.129190329958292e-20, disciminator loss fake = 1.137721596933261e-07, generator loss = 17.19003677368164\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 16, Batch: 304/468, discriminator loss real = 9.025035757345298e-19, disciminator loss fake = 1.0747387335641179e-07, generator loss = 17.133644104003906\n",
      "2/2 [==============================] - 0s 182ms/step\n",
      "Epoch: 16, Batch: 305/468, discriminator loss real = 1.0327929673715188e-25, disciminator loss fake = 9.813364698629812e-08, generator loss = 17.07908058166504\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 16, Batch: 306/468, discriminator loss real = 5.53562765508083e-16, disciminator loss fake = 2.2315138892281539e-07, generator loss = 17.313854217529297\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 16, Batch: 307/468, discriminator loss real = 2.9451869460936805e-23, disciminator loss fake = 1.5396696539937693e-07, generator loss = 16.943798065185547\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 16, Batch: 308/468, discriminator loss real = 3.819051529126701e-20, disciminator loss fake = 1.9206369472613005e-07, generator loss = 17.228759765625\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 16, Batch: 309/468, discriminator loss real = 9.43471221148684e-08, disciminator loss fake = 1.4385636859515216e-07, generator loss = 17.318523406982422\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 16, Batch: 310/468, discriminator loss real = 5.0534889885714725e-28, disciminator loss fake = 1.515405756435939e-07, generator loss = 17.115123748779297\n",
      "2/2 [==============================] - 0s 150ms/step\n",
      "Epoch: 16, Batch: 311/468, discriminator loss real = 1.1390161924271901e-21, disciminator loss fake = 1.1036530622732244e-07, generator loss = 17.007347106933594\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 16, Batch: 312/468, discriminator loss real = 1.0964363805403169e-18, disciminator loss fake = 1.069605914949534e-07, generator loss = 17.304832458496094\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 16, Batch: 313/468, discriminator loss real = 1.440163369128855e-32, disciminator loss fake = 1.0508559000754758e-07, generator loss = 17.310867309570312\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 16, Batch: 314/468, discriminator loss real = 2.7783355339128165e-19, disciminator loss fake = 1.8576824345473142e-07, generator loss = 17.29184341430664\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 16, Batch: 315/468, discriminator loss real = 2.3836309464579477e-22, disciminator loss fake = 1.768122643852621e-07, generator loss = 17.31924819946289\n",
      "2/2 [==============================] - 0s 160ms/step\n",
      "Epoch: 16, Batch: 316/468, discriminator loss real = 1.9852866538834197e-29, disciminator loss fake = 1.337304382786897e-07, generator loss = 17.222402572631836\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 16, Batch: 317/468, discriminator loss real = 2.774491103358275e-25, disciminator loss fake = 1.1883491168873661e-07, generator loss = 17.334550857543945\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 16, Batch: 318/468, discriminator loss real = 2.8012791976595647e-19, disciminator loss fake = 1.6436615624115802e-07, generator loss = 17.13905143737793\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 16, Batch: 319/468, discriminator loss real = 5.046633640934426e-28, disciminator loss fake = 1.2089006418136705e-07, generator loss = 17.223979949951172\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 16, Batch: 320/468, discriminator loss real = 5.409780262644048e-12, disciminator loss fake = 2.629521418384684e-07, generator loss = 17.399921417236328\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 16, Batch: 321/468, discriminator loss real = 2.714138240443032e-20, disciminator loss fake = 1.5989718349374016e-07, generator loss = 17.056243896484375\n",
      "2/2 [==============================] - 0s 137ms/step\n",
      "Epoch: 16, Batch: 322/468, discriminator loss real = 0.0160833653062582, disciminator loss fake = 3.027541310984816e-07, generator loss = 16.3016414642334\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 16, Batch: 323/468, discriminator loss real = 1.3353623703020998e-15, disciminator loss fake = 4.594060101226205e-07, generator loss = 15.28516674041748\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 16, Batch: 324/468, discriminator loss real = 9.488266206156885e-19, disciminator loss fake = 2.608169552331674e-06, generator loss = 14.41084098815918\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 16, Batch: 325/468, discriminator loss real = 4.011471930107921e-23, disciminator loss fake = 2.016493908740813e-06, generator loss = 14.361845970153809\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 16, Batch: 326/468, discriminator loss real = 2.0620068152954474e-11, disciminator loss fake = 3.4524075545050437e-06, generator loss = 13.650947570800781\n",
      "2/2 [==============================] - 0s 192ms/step\n",
      "Epoch: 16, Batch: 327/468, discriminator loss real = 5.682537344046599e-26, disciminator loss fake = 4.173270554019837e-06, generator loss = 13.391525268554688\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 16, Batch: 328/468, discriminator loss real = 1.0982368632206304e-17, disciminator loss fake = 6.134416253189556e-06, generator loss = 12.90485954284668\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 16, Batch: 329/468, discriminator loss real = 1.6970161168813323e-17, disciminator loss fake = 2.0451807358767837e-05, generator loss = 12.673419952392578\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 16, Batch: 330/468, discriminator loss real = 1.3483865510671936e-20, disciminator loss fake = 1.0838258276635315e-05, generator loss = 12.28483772277832\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 16, Batch: 331/468, discriminator loss real = 8.012316396292796e-14, disciminator loss fake = 2.3866617993917316e-05, generator loss = 12.57965087890625\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 16, Batch: 332/468, discriminator loss real = 1.6878917019494746e-14, disciminator loss fake = 1.4103639841778204e-05, generator loss = 12.11780071258545\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 16, Batch: 333/468, discriminator loss real = 3.738113985018998e-12, disciminator loss fake = 3.326961086713709e-05, generator loss = 12.002617835998535\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 16, Batch: 334/468, discriminator loss real = 1.0776602633576999e-27, disciminator loss fake = 1.6214631614275277e-05, generator loss = 12.134403228759766\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 16, Batch: 335/468, discriminator loss real = 1.4867189396752441e-25, disciminator loss fake = 3.256565105402842e-05, generator loss = 11.886307716369629\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 16, Batch: 336/468, discriminator loss real = 5.395857850963433e-19, disciminator loss fake = 2.1089728761580773e-05, generator loss = 11.947230339050293\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 16, Batch: 337/468, discriminator loss real = 5.986826716000158e-22, disciminator loss fake = 2.6118521418538876e-05, generator loss = 12.062248229980469\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 16, Batch: 338/468, discriminator loss real = 4.908572440134308e-23, disciminator loss fake = 1.8090269804815762e-05, generator loss = 11.659393310546875\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 16, Batch: 339/468, discriminator loss real = 3.936604750632036e-25, disciminator loss fake = 2.8020949685014784e-05, generator loss = 11.765582084655762\n",
      "2/2 [==============================] - 0s 174ms/step\n",
      "Epoch: 16, Batch: 340/468, discriminator loss real = 2.6480067660565514e-20, disciminator loss fake = 2.2896158043295145e-05, generator loss = 11.680440902709961\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 16, Batch: 341/468, discriminator loss real = 8.624957963362721e-19, disciminator loss fake = 2.497592504369095e-05, generator loss = 11.514680862426758\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 16, Batch: 342/468, discriminator loss real = 5.057995688950712e-12, disciminator loss fake = 2.589571158750914e-05, generator loss = 11.90386962890625\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 16, Batch: 343/468, discriminator loss real = 4.9645515073151414e-18, disciminator loss fake = 2.4502469386789016e-05, generator loss = 11.73244857788086\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 16, Batch: 344/468, discriminator loss real = 6.75636768754373e-11, disciminator loss fake = 2.9664832254638895e-05, generator loss = 11.991004943847656\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 16, Batch: 345/468, discriminator loss real = 3.309779401661217e-07, disciminator loss fake = 4.660353806684725e-05, generator loss = 11.722267150878906\n",
      "2/2 [==============================] - 0s 179ms/step\n",
      "Epoch: 16, Batch: 346/468, discriminator loss real = 1.3250852732309491e-17, disciminator loss fake = 3.453389217611402e-05, generator loss = 12.013543128967285\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 16, Batch: 347/468, discriminator loss real = 9.495622426741895e-20, disciminator loss fake = 2.027746450039558e-05, generator loss = 11.89320182800293\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 16, Batch: 348/468, discriminator loss real = 5.0783274474497375e-08, disciminator loss fake = 1.4151893083180767e-05, generator loss = 11.749374389648438\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 16, Batch: 349/468, discriminator loss real = 2.0584135433497917e-16, disciminator loss fake = 1.758767757564783e-05, generator loss = 11.658653259277344\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 16, Batch: 350/468, discriminator loss real = 1.691154707467522e-22, disciminator loss fake = 3.2195843232329935e-05, generator loss = 11.864709854125977\n",
      "2/2 [==============================] - 0s 150ms/step\n",
      "Epoch: 16, Batch: 351/468, discriminator loss real = 1.4932488881538278e-15, disciminator loss fake = 1.4261877367971465e-05, generator loss = 11.991168975830078\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 16, Batch: 352/468, discriminator loss real = 1.6245535472414474e-10, disciminator loss fake = 2.6078236260218546e-05, generator loss = 12.033500671386719\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 16, Batch: 353/468, discriminator loss real = 7.469592796544426e-21, disciminator loss fake = 1.9405440980335698e-05, generator loss = 12.110435485839844\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 16, Batch: 354/468, discriminator loss real = 4.070328319704997e-19, disciminator loss fake = 1.1951315173064359e-05, generator loss = 11.993667602539062\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 16, Batch: 355/468, discriminator loss real = 1.3739244981379175e-16, disciminator loss fake = 3.720874883583747e-05, generator loss = 11.953983306884766\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 16, Batch: 356/468, discriminator loss real = 7.977932092728679e-09, disciminator loss fake = 1.1904150596819818e-05, generator loss = 12.003460884094238\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 16, Batch: 357/468, discriminator loss real = 2.2702568713839355e-09, disciminator loss fake = 3.7273173802532256e-05, generator loss = 12.020328521728516\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 16, Batch: 358/468, discriminator loss real = 4.682133834478049e-26, disciminator loss fake = 2.7356309146853164e-05, generator loss = 11.976295471191406\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 16, Batch: 359/468, discriminator loss real = 1.5906703744239585e-31, disciminator loss fake = 1.4436983292398509e-05, generator loss = 12.295469284057617\n",
      "2/2 [==============================] - 0s 170ms/step\n",
      "Epoch: 16, Batch: 360/468, discriminator loss real = 1.9955787854039199e-19, disciminator loss fake = 3.358888716320507e-05, generator loss = 12.285326957702637\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 16, Batch: 361/468, discriminator loss real = 4.5394488168426506e-10, disciminator loss fake = 2.6256648197886534e-05, generator loss = 12.099288940429688\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 16, Batch: 362/468, discriminator loss real = 5.334915257295043e-16, disciminator loss fake = 1.5116540453163907e-05, generator loss = 12.163934707641602\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 16, Batch: 363/468, discriminator loss real = 2.452483515126543e-23, disciminator loss fake = 2.3913624318083748e-05, generator loss = 12.417749404907227\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 16, Batch: 364/468, discriminator loss real = 6.913985603305852e-24, disciminator loss fake = 1.4246508726500906e-05, generator loss = 12.351311683654785\n",
      "2/2 [==============================] - 0s 187ms/step\n",
      "Epoch: 16, Batch: 365/468, discriminator loss real = 5.651606582592441e-16, disciminator loss fake = 4.651218478102237e-05, generator loss = 12.327860832214355\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 16, Batch: 366/468, discriminator loss real = 5.606234082735805e-24, disciminator loss fake = 1.3606132597487886e-05, generator loss = 12.335487365722656\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 16, Batch: 367/468, discriminator loss real = 6.917158401866651e-24, disciminator loss fake = 2.5832563551375642e-05, generator loss = 12.081716537475586\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 16, Batch: 368/468, discriminator loss real = 2.4203198039501883e-13, disciminator loss fake = 1.5007347428763751e-05, generator loss = 12.161471366882324\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 16, Batch: 369/468, discriminator loss real = 8.58508390805024e-17, disciminator loss fake = 1.685370625637006e-05, generator loss = 12.43305492401123\n",
      "2/2 [==============================] - 0s 150ms/step\n",
      "Epoch: 16, Batch: 370/468, discriminator loss real = 7.91809950939637e-11, disciminator loss fake = 2.3266737116500735e-05, generator loss = 12.300491333007812\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 16, Batch: 371/468, discriminator loss real = 2.1818650550790843e-17, disciminator loss fake = 2.489296457497403e-05, generator loss = 12.49003791809082\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 16, Batch: 372/468, discriminator loss real = 1.1460884002073828e-26, disciminator loss fake = 1.8531063687987626e-05, generator loss = 12.414058685302734\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 16, Batch: 373/468, discriminator loss real = 5.480986636813865e-23, disciminator loss fake = 1.3967165614303667e-05, generator loss = 12.470823287963867\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 16, Batch: 374/468, discriminator loss real = 8.154730988285613e-21, disciminator loss fake = 1.4960797670937609e-05, generator loss = 12.275161743164062\n",
      "2/2 [==============================] - 0s 141ms/step\n",
      "Epoch: 16, Batch: 375/468, discriminator loss real = 1.9824450376649053e-15, disciminator loss fake = 1.721759508654941e-05, generator loss = 12.597719192504883\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 16, Batch: 376/468, discriminator loss real = 5.31332051190322e-31, disciminator loss fake = 2.9325385185074992e-05, generator loss = 12.4631929397583\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 16, Batch: 377/468, discriminator loss real = 1.2168709825958937e-18, disciminator loss fake = 1.742953281791415e-05, generator loss = 12.359729766845703\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 16, Batch: 378/468, discriminator loss real = 3.3685219174970802e-15, disciminator loss fake = 2.9973529308335856e-05, generator loss = 12.202829360961914\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 16, Batch: 379/468, discriminator loss real = 1.7674104904170194e-33, disciminator loss fake = 1.2816139133065008e-05, generator loss = 12.78465461730957\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 16, Batch: 380/468, discriminator loss real = 2.307420698954843e-09, disciminator loss fake = 2.795219188556075e-05, generator loss = 12.704737663269043\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 16, Batch: 381/468, discriminator loss real = 1.075893722258838e-17, disciminator loss fake = 1.4520158401865046e-05, generator loss = 12.421443939208984\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 16, Batch: 382/468, discriminator loss real = 6.1875697440507776e-24, disciminator loss fake = 1.7282567569054663e-05, generator loss = 12.478605270385742\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 16, Batch: 383/468, discriminator loss real = 6.290452649463767e-20, disciminator loss fake = 1.529354449303355e-05, generator loss = 12.734457015991211\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 16, Batch: 384/468, discriminator loss real = 3.612081008845153e-29, disciminator loss fake = 2.2457488739746623e-05, generator loss = 12.355949401855469\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 16, Batch: 385/468, discriminator loss real = 6.309006153060182e-07, disciminator loss fake = 1.1774003723985516e-05, generator loss = 12.637656211853027\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 16, Batch: 386/468, discriminator loss real = 5.382258007335938e-12, disciminator loss fake = 1.3404746823653113e-05, generator loss = 12.465108871459961\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 16, Batch: 387/468, discriminator loss real = 1.416154892899346e-23, disciminator loss fake = 1.195058757730294e-05, generator loss = 12.624968528747559\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 16, Batch: 388/468, discriminator loss real = 1.0209865485323644e-17, disciminator loss fake = 1.033779244608013e-05, generator loss = 12.622970581054688\n",
      "2/2 [==============================] - 0s 207ms/step\n",
      "Epoch: 16, Batch: 389/468, discriminator loss real = 1.0614733616327248e-21, disciminator loss fake = 1.0872328857658431e-05, generator loss = 12.662696838378906\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 16, Batch: 390/468, discriminator loss real = 4.182103829908357e-10, disciminator loss fake = 1.335543129243888e-05, generator loss = 12.703601837158203\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 16, Batch: 391/468, discriminator loss real = 5.290508893290746e-17, disciminator loss fake = 8.966459063231014e-06, generator loss = 12.926965713500977\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 16, Batch: 392/468, discriminator loss real = 1.25502152818909e-14, disciminator loss fake = 1.104060447687516e-05, generator loss = 12.794830322265625\n",
      "2/2 [==============================] - 0s 183ms/step\n",
      "Epoch: 16, Batch: 393/468, discriminator loss real = 9.29334268299554e-16, disciminator loss fake = 1.682095171418041e-05, generator loss = 12.566529273986816\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 16, Batch: 394/468, discriminator loss real = 4.120445558510695e-15, disciminator loss fake = 1.2269103535800241e-05, generator loss = 12.478556632995605\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 16, Batch: 395/468, discriminator loss real = 9.568193297410783e-28, disciminator loss fake = 2.011815922742244e-05, generator loss = 12.431681632995605\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 16, Batch: 396/468, discriminator loss real = 9.788859730054488e-29, disciminator loss fake = 1.972018799278885e-05, generator loss = 12.731693267822266\n",
      "2/2 [==============================] - 0s 163ms/step\n",
      "Epoch: 16, Batch: 397/468, discriminator loss real = 1.3938547669853833e-21, disciminator loss fake = 7.8510065577575e-06, generator loss = 12.871127128601074\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 16, Batch: 398/468, discriminator loss real = 1.966556605398546e-15, disciminator loss fake = 1.2985731700609904e-05, generator loss = 12.449305534362793\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 16, Batch: 399/468, discriminator loss real = 2.0707411979984043e-18, disciminator loss fake = 9.981201401387807e-06, generator loss = 12.566164016723633\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 16, Batch: 400/468, discriminator loss real = 1.8860029724038774e-22, disciminator loss fake = 1.8068403733195737e-05, generator loss = 12.728306770324707\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 16, Batch: 401/468, discriminator loss real = 1.2791480508924854e-29, disciminator loss fake = 1.3524489986593835e-05, generator loss = 12.628612518310547\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 16, Batch: 402/468, discriminator loss real = 1.3770396378731675e-08, disciminator loss fake = 9.22432718652999e-06, generator loss = 12.912041664123535\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 16, Batch: 403/468, discriminator loss real = 8.314469481017581e-15, disciminator loss fake = 5.719432920159306e-06, generator loss = 12.548288345336914\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 16, Batch: 404/468, discriminator loss real = 1.859359550317445e-24, disciminator loss fake = 1.5608708054060116e-05, generator loss = 12.436408996582031\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 16, Batch: 405/468, discriminator loss real = 3.8434148441970906e-13, disciminator loss fake = 9.576778211339843e-06, generator loss = 12.893148422241211\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 16, Batch: 406/468, discriminator loss real = 7.77008554109992e-22, disciminator loss fake = 8.959769729699474e-06, generator loss = 13.135470390319824\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 16, Batch: 407/468, discriminator loss real = 6.082132370395974e-25, disciminator loss fake = 6.692365786875598e-06, generator loss = 12.664312362670898\n",
      "2/2 [==============================] - 0s 151ms/step\n",
      "Epoch: 16, Batch: 408/468, discriminator loss real = 2.330850970573399e-16, disciminator loss fake = 6.514882898045471e-06, generator loss = 12.711118698120117\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 16, Batch: 409/468, discriminator loss real = 1.6394376957155167e-16, disciminator loss fake = 1.2182012142147869e-05, generator loss = 12.651838302612305\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 16, Batch: 410/468, discriminator loss real = 1.0538290697448376e-20, disciminator loss fake = 1.1716009794326965e-05, generator loss = 13.028139114379883\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 16, Batch: 411/468, discriminator loss real = 7.355327326089522e-30, disciminator loss fake = 1.0189885870204307e-05, generator loss = 13.073081016540527\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 16, Batch: 412/468, discriminator loss real = 6.554906617495249e-11, disciminator loss fake = 1.8038075722870417e-05, generator loss = 13.012003898620605\n",
      "2/2 [==============================] - 0s 141ms/step\n",
      "Epoch: 16, Batch: 413/468, discriminator loss real = 5.524625818877019e-33, disciminator loss fake = 1.0596080755931325e-05, generator loss = 12.82980728149414\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 16, Batch: 414/468, discriminator loss real = 1.9126742561732107e-13, disciminator loss fake = 7.442914466082584e-06, generator loss = 12.858503341674805\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 16, Batch: 415/468, discriminator loss real = 7.286420499984006e-19, disciminator loss fake = 1.7332091374555603e-05, generator loss = 12.927099227905273\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 16, Batch: 416/468, discriminator loss real = 1.2747205678582263e-26, disciminator loss fake = 1.392890862916829e-05, generator loss = 13.124760627746582\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 16, Batch: 417/468, discriminator loss real = 7.166806564493658e-19, disciminator loss fake = 6.063586624804884e-06, generator loss = 13.020453453063965\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 16, Batch: 418/468, discriminator loss real = 3.096350326270013e-15, disciminator loss fake = 1.2479647011787165e-05, generator loss = 12.811079978942871\n",
      "2/2 [==============================] - 0s 153ms/step\n",
      "Epoch: 16, Batch: 419/468, discriminator loss real = 8.183535614413212e-19, disciminator loss fake = 7.938444468891248e-06, generator loss = 12.786802291870117\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 16, Batch: 420/468, discriminator loss real = 8.761225732920752e-17, disciminator loss fake = 2.562325244070962e-05, generator loss = 12.986270904541016\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 16, Batch: 421/468, discriminator loss real = 5.242169365260452e-09, disciminator loss fake = 5.433033493318362e-06, generator loss = 13.205947875976562\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 16, Batch: 422/468, discriminator loss real = 4.608796579237321e-25, disciminator loss fake = 6.259363544813823e-06, generator loss = 12.86344051361084\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 16, Batch: 423/468, discriminator loss real = 8.708280415764813e-21, disciminator loss fake = 1.0723957529990003e-05, generator loss = 12.904890060424805\n",
      "2/2 [==============================] - 0s 145ms/step\n",
      "Epoch: 16, Batch: 424/468, discriminator loss real = 9.733970280948411e-16, disciminator loss fake = 1.5258384337357711e-05, generator loss = 13.298511505126953\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 16, Batch: 425/468, discriminator loss real = 2.0918291014279353e-20, disciminator loss fake = 9.322950973000843e-06, generator loss = 12.880189895629883\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 16, Batch: 426/468, discriminator loss real = 4.828087799349512e-18, disciminator loss fake = 1.1608641216298565e-05, generator loss = 13.082451820373535\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 16, Batch: 427/468, discriminator loss real = 2.4938193732282343e-08, disciminator loss fake = 5.863634214620106e-06, generator loss = 12.973800659179688\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 16, Batch: 428/468, discriminator loss real = 1.4956795974267398e-14, disciminator loss fake = 8.308528776979074e-06, generator loss = 12.936409950256348\n",
      "2/2 [==============================] - 0s 177ms/step\n",
      "Epoch: 16, Batch: 429/468, discriminator loss real = 2.542413800442919e-19, disciminator loss fake = 2.8102804208174348e-05, generator loss = 13.20130729675293\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 16, Batch: 430/468, discriminator loss real = 6.889624567824592e-27, disciminator loss fake = 5.446154318633489e-06, generator loss = 13.000192642211914\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 16, Batch: 431/468, discriminator loss real = 3.7537395846558904e-15, disciminator loss fake = 1.0231075975752901e-05, generator loss = 12.831006050109863\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 16, Batch: 432/468, discriminator loss real = 5.549675844741808e-13, disciminator loss fake = 4.200876901450101e-06, generator loss = 12.9671630859375\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 16, Batch: 433/468, discriminator loss real = 3.5252013033839493e-19, disciminator loss fake = 1.0233692592009902e-05, generator loss = 13.208841323852539\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 16, Batch: 434/468, discriminator loss real = 5.465742515045248e-32, disciminator loss fake = 1.433431407349417e-05, generator loss = 13.241987228393555\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 16, Batch: 435/468, discriminator loss real = 4.72560529133302e-19, disciminator loss fake = 1.3829110685037449e-05, generator loss = 12.976436614990234\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 16, Batch: 436/468, discriminator loss real = 3.3940374954966046e-09, disciminator loss fake = 5.017815510655055e-06, generator loss = 13.008583068847656\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 16, Batch: 437/468, discriminator loss real = 3.6817321738022452e-25, disciminator loss fake = 8.354573765245732e-06, generator loss = 13.330275535583496\n",
      "2/2 [==============================] - 0s 181ms/step\n",
      "Epoch: 16, Batch: 438/468, discriminator loss real = 1.4989513353741916e-21, disciminator loss fake = 6.4148839555855375e-06, generator loss = 13.146846771240234\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 16, Batch: 439/468, discriminator loss real = 1.0889454329130366e-18, disciminator loss fake = 7.489768449886469e-06, generator loss = 13.266207695007324\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 16, Batch: 440/468, discriminator loss real = 4.2813420939672745e-19, disciminator loss fake = 6.222665888344636e-06, generator loss = 12.915885925292969\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 16, Batch: 441/468, discriminator loss real = 2.9339529344576823e-15, disciminator loss fake = 7.710184036113787e-06, generator loss = 12.707666397094727\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 16, Batch: 442/468, discriminator loss real = 1.5978015264954355e-16, disciminator loss fake = 9.162149581243284e-06, generator loss = 13.07857894897461\n",
      "2/2 [==============================] - 0s 173ms/step\n",
      "Epoch: 16, Batch: 443/468, discriminator loss real = 5.325341032133991e-15, disciminator loss fake = 6.230109647731297e-06, generator loss = 13.096908569335938\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 16, Batch: 444/468, discriminator loss real = 1.534997551375794e-31, disciminator loss fake = 4.2572469283186365e-06, generator loss = 13.213653564453125\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 16, Batch: 445/468, discriminator loss real = 9.983338309248233e-23, disciminator loss fake = 8.67065136844758e-06, generator loss = 13.187438011169434\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 16, Batch: 446/468, discriminator loss real = 1.636843993679804e-10, disciminator loss fake = 1.0954307072097436e-05, generator loss = 13.22342300415039\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 16, Batch: 447/468, discriminator loss real = 6.477131287092617e-19, disciminator loss fake = 1.036853063851595e-05, generator loss = 13.021636962890625\n",
      "2/2 [==============================] - 0s 170ms/step\n",
      "Epoch: 16, Batch: 448/468, discriminator loss real = 7.309143122459516e-16, disciminator loss fake = 2.9880184229114093e-06, generator loss = 13.014717102050781\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 16, Batch: 449/468, discriminator loss real = 1.2483270069300603e-18, disciminator loss fake = 1.0753054084489122e-05, generator loss = 13.166097640991211\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 16, Batch: 450/468, discriminator loss real = 1.797304983272364e-17, disciminator loss fake = 1.5095235539774876e-05, generator loss = 13.297947883605957\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 16, Batch: 451/468, discriminator loss real = 1.4972339028849514e-14, disciminator loss fake = 6.58436692901887e-06, generator loss = 13.30516529083252\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 16, Batch: 452/468, discriminator loss real = 1.8823463102374658e-34, disciminator loss fake = 3.6673893646366196e-06, generator loss = 13.225547790527344\n",
      "2/2 [==============================] - 0s 197ms/step\n",
      "Epoch: 16, Batch: 453/468, discriminator loss real = 8.329953232335953e-28, disciminator loss fake = 1.2643195077544078e-05, generator loss = 13.267938613891602\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 16, Batch: 454/468, discriminator loss real = 6.807437316281271e-23, disciminator loss fake = 7.192158136604121e-06, generator loss = 13.237659454345703\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 16, Batch: 455/468, discriminator loss real = 3.0343349360917315e-11, disciminator loss fake = 7.96316089690663e-06, generator loss = 13.259370803833008\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 16, Batch: 456/468, discriminator loss real = 3.2511339506777117e-15, disciminator loss fake = 5.456627150124405e-06, generator loss = 13.339235305786133\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 16, Batch: 457/468, discriminator loss real = 8.634157624975991e-12, disciminator loss fake = 7.568426553916652e-06, generator loss = 13.069368362426758\n",
      "2/2 [==============================] - 0s 145ms/step\n",
      "Epoch: 16, Batch: 458/468, discriminator loss real = 8.695754801027486e-19, disciminator loss fake = 1.1557200195966288e-05, generator loss = 13.536226272583008\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 16, Batch: 459/468, discriminator loss real = 4.781523433623628e-15, disciminator loss fake = 4.703970262198709e-06, generator loss = 13.211746215820312\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 16, Batch: 460/468, discriminator loss real = 4.663304950999476e-16, disciminator loss fake = 1.047728983394336e-05, generator loss = 13.210600852966309\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 16, Batch: 461/468, discriminator loss real = 3.53170221921558e-17, disciminator loss fake = 5.895973117731046e-06, generator loss = 13.258232116699219\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 16, Batch: 462/468, discriminator loss real = 2.467677798212442e-11, disciminator loss fake = 6.581532034033444e-06, generator loss = 13.340590476989746\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 16, Batch: 463/468, discriminator loss real = 2.142192890089434e-12, disciminator loss fake = 5.855394647369394e-06, generator loss = 13.18277645111084\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 16, Batch: 464/468, discriminator loss real = 9.835845686371764e-15, disciminator loss fake = 5.3899989325145725e-06, generator loss = 13.443034172058105\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 16, Batch: 465/468, discriminator loss real = 6.678477802779526e-05, disciminator loss fake = 6.222448973858263e-06, generator loss = 13.432775497436523\n",
      "2/2 [==============================] - 0s 161ms/step\n",
      "Epoch: 16, Batch: 466/468, discriminator loss real = 9.994318605132876e-14, disciminator loss fake = 9.781662811292335e-06, generator loss = 13.468673706054688\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 16, Batch: 467/468, discriminator loss real = 2.853812493244334e-22, disciminator loss fake = 1.4813275811320636e-05, generator loss = 13.622925758361816\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 16, Batch: 468/468, discriminator loss real = 1.5317449014739635e-25, disciminator loss fake = 7.35834601073293e-06, generator loss = 13.317926406860352\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 17, Batch: 1/468, discriminator loss real = 1.4239361820800084e-15, disciminator loss fake = 3.7475913359230617e-06, generator loss = 13.320310592651367\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 17, Batch: 2/468, discriminator loss real = 7.370400643771918e-23, disciminator loss fake = 2.864042471628636e-05, generator loss = 13.23518180847168\n",
      "2/2 [==============================] - 0s 171ms/step\n",
      "Epoch: 17, Batch: 3/468, discriminator loss real = 1.8913483382535998e-15, disciminator loss fake = 1.054612857842585e-05, generator loss = 13.472467422485352\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 17, Batch: 4/468, discriminator loss real = 2.3702844835537043e-14, disciminator loss fake = 7.474439371435437e-06, generator loss = 13.434846878051758\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 17, Batch: 5/468, discriminator loss real = 5.50433666982248e-16, disciminator loss fake = 1.1886004358530045e-05, generator loss = 13.380465507507324\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 17, Batch: 6/468, discriminator loss real = 1.7444254746551383e-24, disciminator loss fake = 5.122195943840779e-06, generator loss = 13.58200454711914\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 17, Batch: 7/468, discriminator loss real = 1.0357254604746041e-14, disciminator loss fake = 4.691981757787289e-06, generator loss = 13.264486312866211\n",
      "2/2 [==============================] - 0s 181ms/step\n",
      "Epoch: 17, Batch: 8/468, discriminator loss real = 1.5735657677047599e-13, disciminator loss fake = 1.0290717000316363e-05, generator loss = 13.497062683105469\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 17, Batch: 9/468, discriminator loss real = 2.951231202206698e-17, disciminator loss fake = 5.41752979188459e-06, generator loss = 13.549692153930664\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 17, Batch: 10/468, discriminator loss real = 2.5482506453390345e-18, disciminator loss fake = 1.091076683223946e-05, generator loss = 13.4052734375\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 17, Batch: 11/468, discriminator loss real = 7.955919746230566e-17, disciminator loss fake = 6.911041509738425e-06, generator loss = 13.313892364501953\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 17, Batch: 12/468, discriminator loss real = 3.723674815904873e-31, disciminator loss fake = 5.711950961995171e-06, generator loss = 13.594669342041016\n",
      "2/2 [==============================] - 0s 199ms/step\n",
      "Epoch: 17, Batch: 13/468, discriminator loss real = 1.5505693017604208e-15, disciminator loss fake = 5.715009592677234e-06, generator loss = 13.262691497802734\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 17, Batch: 14/468, discriminator loss real = 5.4121612706441236e-18, disciminator loss fake = 6.177267096063588e-06, generator loss = 13.389596939086914\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 17, Batch: 15/468, discriminator loss real = 5.149386586833279e-17, disciminator loss fake = 9.540537575958297e-06, generator loss = 13.505363464355469\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 17, Batch: 16/468, discriminator loss real = 4.5950336322296366e-17, disciminator loss fake = 5.870594577572774e-06, generator loss = 13.159517288208008\n",
      "2/2 [==============================] - 0s 155ms/step\n",
      "Epoch: 17, Batch: 17/468, discriminator loss real = 1.5053773941068845e-17, disciminator loss fake = 6.043845132808201e-06, generator loss = 13.264920234680176\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 17, Batch: 18/468, discriminator loss real = 3.3856731691108653e-25, disciminator loss fake = 4.56669476989191e-06, generator loss = 13.504936218261719\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 17, Batch: 19/468, discriminator loss real = 7.903935125685334e-19, disciminator loss fake = 3.8472207961604e-06, generator loss = 13.316387176513672\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 17, Batch: 20/468, discriminator loss real = 4.501256960277888e-16, disciminator loss fake = 8.106385394057725e-06, generator loss = 13.335867881774902\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 17, Batch: 21/468, discriminator loss real = 1.6267180700803425e-29, disciminator loss fake = 8.603774404036812e-06, generator loss = 13.364664077758789\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 17, Batch: 22/468, discriminator loss real = 4.069528713985344e-15, disciminator loss fake = 6.54162977298256e-06, generator loss = 13.493762969970703\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 17, Batch: 23/468, discriminator loss real = 1.4091141067894556e-28, disciminator loss fake = 3.0431604045588756e-06, generator loss = 13.53666877746582\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 17, Batch: 24/468, discriminator loss real = 1.0298969234029844e-25, disciminator loss fake = 5.319097908795811e-06, generator loss = 13.565712928771973\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 17, Batch: 25/468, discriminator loss real = 1.502228365887582e-29, disciminator loss fake = 3.647483936219942e-06, generator loss = 13.631730079650879\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 17, Batch: 26/468, discriminator loss real = 3.8741102943633e-22, disciminator loss fake = 3.4383413094474236e-06, generator loss = 13.621142387390137\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 17, Batch: 27/468, discriminator loss real = 3.28044663054597e-30, disciminator loss fake = 1.0410766662971582e-05, generator loss = 13.367620468139648\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 17, Batch: 28/468, discriminator loss real = 1.1197217259339416e-26, disciminator loss fake = 5.200246505410178e-06, generator loss = 13.37331485748291\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 17, Batch: 29/468, discriminator loss real = 5.762360068842992e-23, disciminator loss fake = 4.0342315514863e-06, generator loss = 13.080343246459961\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 17, Batch: 30/468, discriminator loss real = 2.9598158149526715e-16, disciminator loss fake = 7.2045204433379695e-06, generator loss = 13.543262481689453\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 17, Batch: 31/468, discriminator loss real = 5.807344431864545e-29, disciminator loss fake = 5.3049097914481536e-06, generator loss = 13.258441925048828\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 17, Batch: 32/468, discriminator loss real = 9.689400216265108e-24, disciminator loss fake = 6.7500368459150195e-06, generator loss = 13.439774513244629\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 17, Batch: 33/468, discriminator loss real = 2.2835723139158548e-20, disciminator loss fake = 5.538671757676639e-06, generator loss = 13.653295516967773\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 17, Batch: 34/468, discriminator loss real = 4.1122699956766155e-19, disciminator loss fake = 3.25853397953324e-06, generator loss = 13.635167121887207\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 17, Batch: 35/468, discriminator loss real = 7.631207070695306e-28, disciminator loss fake = 3.97682288166834e-06, generator loss = 13.53193473815918\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 17, Batch: 36/468, discriminator loss real = 4.000871811626894e-08, disciminator loss fake = 7.164079761423636e-06, generator loss = 13.644613265991211\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 17, Batch: 37/468, discriminator loss real = 6.111046583780483e-18, disciminator loss fake = 1.023158802127e-05, generator loss = 13.704343795776367\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 17, Batch: 38/468, discriminator loss real = 5.001971059570565e-13, disciminator loss fake = 4.2633073462639e-06, generator loss = 13.543804168701172\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 17, Batch: 39/468, discriminator loss real = 1.758290976594076e-16, disciminator loss fake = 4.8142746891244315e-06, generator loss = 13.449830055236816\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 17, Batch: 40/468, discriminator loss real = 4.323901178375283e-15, disciminator loss fake = 7.586166702822084e-06, generator loss = 13.822115898132324\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 17, Batch: 41/468, discriminator loss real = 3.328658543008856e-22, disciminator loss fake = 6.367363312165253e-06, generator loss = 13.38355827331543\n",
      "2/2 [==============================] - 0s 150ms/step\n",
      "Epoch: 17, Batch: 42/468, discriminator loss real = 6.646097402867293e-19, disciminator loss fake = 4.2890210352197755e-06, generator loss = 13.60970401763916\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 17, Batch: 43/468, discriminator loss real = 4.924491925351049e-09, disciminator loss fake = 5.762808996223612e-06, generator loss = 13.56547737121582\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 17, Batch: 44/468, discriminator loss real = 4.03941248805495e-06, disciminator loss fake = 4.737948074762244e-06, generator loss = 13.499214172363281\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 17, Batch: 45/468, discriminator loss real = 1.1308320608804934e-05, disciminator loss fake = 6.270158337429166e-06, generator loss = 13.565268516540527\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 17, Batch: 46/468, discriminator loss real = 1.0115623474646497e-16, disciminator loss fake = 3.591416316339746e-06, generator loss = 13.586058616638184\n",
      "2/2 [==============================] - 0s 160ms/step\n",
      "Epoch: 17, Batch: 47/468, discriminator loss real = 4.7411158332621994e-11, disciminator loss fake = 5.516753844858613e-06, generator loss = 13.628071784973145\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 17, Batch: 48/468, discriminator loss real = 3.1214351849800925e-12, disciminator loss fake = 3.795636530412594e-06, generator loss = 13.84343147277832\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 17, Batch: 49/468, discriminator loss real = 2.9048137517838402e-21, disciminator loss fake = 6.659729478997178e-06, generator loss = 13.648225784301758\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 17, Batch: 50/468, discriminator loss real = 2.7240980120060534e-22, disciminator loss fake = 3.6900762552249944e-06, generator loss = 13.811896324157715\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 17, Batch: 51/468, discriminator loss real = 2.2044627492938612e-15, disciminator loss fake = 5.561775651585776e-06, generator loss = 13.628604888916016\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 17, Batch: 52/468, discriminator loss real = 1.8316790216341609e-19, disciminator loss fake = 6.065464276616694e-06, generator loss = 13.554898262023926\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 17, Batch: 53/468, discriminator loss real = 3.683778095288444e-20, disciminator loss fake = 7.008300599409267e-06, generator loss = 13.166102409362793\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 17, Batch: 54/468, discriminator loss real = 4.5957853046818316e-24, disciminator loss fake = 2.7737642085412517e-06, generator loss = 13.553672790527344\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 17, Batch: 55/468, discriminator loss real = 5.3316654883379597e-14, disciminator loss fake = 3.818717232206836e-06, generator loss = 13.635824203491211\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 17, Batch: 56/468, discriminator loss real = 1.4333387178978169e-13, disciminator loss fake = 6.008532636769814e-06, generator loss = 13.655527114868164\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 17, Batch: 57/468, discriminator loss real = 5.718187250252508e-24, disciminator loss fake = 1.3223871974332724e-05, generator loss = 13.85646915435791\n",
      "2/2 [==============================] - 0s 174ms/step\n",
      "Epoch: 17, Batch: 58/468, discriminator loss real = 2.1313007093561916e-32, disciminator loss fake = 5.511346898856573e-06, generator loss = 13.779117584228516\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 17, Batch: 59/468, discriminator loss real = 2.0811513214980635e-29, disciminator loss fake = 2.5870674562611384e-06, generator loss = 13.454231262207031\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 17, Batch: 60/468, discriminator loss real = 5.864445845204949e-19, disciminator loss fake = 3.096167802141281e-06, generator loss = 13.635128021240234\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 17, Batch: 61/468, discriminator loss real = 7.814128749843676e-24, disciminator loss fake = 3.2733846637711395e-06, generator loss = 13.722862243652344\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 17, Batch: 62/468, discriminator loss real = 1.400885518698658e-10, disciminator loss fake = 5.580695869866759e-06, generator loss = 13.65024185180664\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 17, Batch: 63/468, discriminator loss real = 1.0275593922415283e-06, disciminator loss fake = 3.636267592810327e-06, generator loss = 13.499065399169922\n",
      "2/2 [==============================] - 0s 189ms/step\n",
      "Epoch: 17, Batch: 64/468, discriminator loss real = 2.5320104015776278e-18, disciminator loss fake = 6.505881628982024e-06, generator loss = 13.665514945983887\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 17, Batch: 65/468, discriminator loss real = 3.455368783568109e-25, disciminator loss fake = 6.799341917940183e-06, generator loss = 13.614368438720703\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 17, Batch: 66/468, discriminator loss real = 2.964818233134068e-19, disciminator loss fake = 7.2574766818434e-06, generator loss = 13.592292785644531\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 17, Batch: 67/468, discriminator loss real = 1.9282874752321603e-27, disciminator loss fake = 7.187329174485058e-06, generator loss = 13.776264190673828\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 17, Batch: 68/468, discriminator loss real = 4.884239201609776e-16, disciminator loss fake = 2.6447737582202535e-06, generator loss = 13.851627349853516\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 17, Batch: 69/468, discriminator loss real = 4.5021896239961295e-20, disciminator loss fake = 2.8303079488978256e-06, generator loss = 13.954598426818848\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 17, Batch: 70/468, discriminator loss real = 2.489300543473405e-09, disciminator loss fake = 4.273415470379405e-06, generator loss = 13.647188186645508\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 17, Batch: 71/468, discriminator loss real = 2.331661557425876e-20, disciminator loss fake = 5.601092652796069e-06, generator loss = 13.668695449829102\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 17, Batch: 72/468, discriminator loss real = 2.6219735475667416e-15, disciminator loss fake = 3.8915432014619e-06, generator loss = 13.73464584350586\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 17, Batch: 73/468, discriminator loss real = 5.255887470136055e-26, disciminator loss fake = 7.278403700183844e-06, generator loss = 13.506150245666504\n",
      "2/2 [==============================] - 0s 202ms/step\n",
      "Epoch: 17, Batch: 74/468, discriminator loss real = 4.260588866600301e-06, disciminator loss fake = 6.133931947260862e-06, generator loss = 13.667915344238281\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 17, Batch: 75/468, discriminator loss real = 8.720726899044322e-21, disciminator loss fake = 3.6332974104880122e-06, generator loss = 13.86899185180664\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 17, Batch: 76/468, discriminator loss real = 8.055636543824826e-25, disciminator loss fake = 2.241654101453605e-06, generator loss = 13.662572860717773\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 17, Batch: 77/468, discriminator loss real = 7.45915610365948e-21, disciminator loss fake = 4.526935299509205e-06, generator loss = 13.78801155090332\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 17, Batch: 78/468, discriminator loss real = 1.1857291678466636e-13, disciminator loss fake = 2.800484935505665e-06, generator loss = 13.76111888885498\n",
      "2/2 [==============================] - 0s 130ms/step\n",
      "Epoch: 17, Batch: 79/468, discriminator loss real = 4.173279024872891e-20, disciminator loss fake = 6.1780615396855865e-06, generator loss = 13.763096809387207\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 17, Batch: 80/468, discriminator loss real = 2.236151212620926e-19, disciminator loss fake = 7.08828247297788e-06, generator loss = 13.76528263092041\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 17, Batch: 81/468, discriminator loss real = 8.53401104699237e-29, disciminator loss fake = 2.7971616418653866e-06, generator loss = 13.911327362060547\n",
      "2/2 [==============================] - 0s 160ms/step\n",
      "Epoch: 17, Batch: 82/468, discriminator loss real = 3.269869313619352e-16, disciminator loss fake = 5.36098787051742e-06, generator loss = 13.865371704101562\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 17, Batch: 83/468, discriminator loss real = 1.2619512423734313e-16, disciminator loss fake = 4.344674380263314e-06, generator loss = 14.15922737121582\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 17, Batch: 84/468, discriminator loss real = 3.6459354646467546e-08, disciminator loss fake = 4.464359335543122e-06, generator loss = 13.7920503616333\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 17, Batch: 85/468, discriminator loss real = 7.971930636431341e-26, disciminator loss fake = 3.245790594519349e-06, generator loss = 13.625394821166992\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 17, Batch: 86/468, discriminator loss real = 1.5795304619814488e-08, disciminator loss fake = 3.4644185689103324e-06, generator loss = 13.925642967224121\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 17, Batch: 87/468, discriminator loss real = 8.013517287942813e-24, disciminator loss fake = 1.8735127014224418e-06, generator loss = 13.939905166625977\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 17, Batch: 88/468, discriminator loss real = 2.965047762870654e-09, disciminator loss fake = 4.342644842836307e-06, generator loss = 13.953320503234863\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 17, Batch: 89/468, discriminator loss real = 2.6270026792875267e-20, disciminator loss fake = 3.0974097171565518e-06, generator loss = 13.734813690185547\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 17, Batch: 90/468, discriminator loss real = 9.394371601966605e-22, disciminator loss fake = 3.119802840956254e-06, generator loss = 13.848655700683594\n",
      "2/2 [==============================] - 0s 135ms/step\n",
      "Epoch: 17, Batch: 91/468, discriminator loss real = 6.130760714822192e-26, disciminator loss fake = 3.2122363791131647e-06, generator loss = 13.609691619873047\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 17, Batch: 92/468, discriminator loss real = 5.309795395094002e-19, disciminator loss fake = 4.479052222450264e-06, generator loss = 13.73416805267334\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 17, Batch: 93/468, discriminator loss real = 1.4772673696200368e-35, disciminator loss fake = 5.219233116804389e-06, generator loss = 13.955451965332031\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 17, Batch: 94/468, discriminator loss real = 2.8811836736394596e-29, disciminator loss fake = 2.2055996851122472e-06, generator loss = 13.743021011352539\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 17, Batch: 95/468, discriminator loss real = 7.295233210927177e-13, disciminator loss fake = 4.227650151733542e-06, generator loss = 13.689216613769531\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 17, Batch: 96/468, discriminator loss real = 8.950382834882475e-06, disciminator loss fake = 3.434584868955426e-06, generator loss = 13.892967224121094\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 17, Batch: 97/468, discriminator loss real = 8.73012126034692e-18, disciminator loss fake = 4.109539986529853e-06, generator loss = 14.098995208740234\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 17, Batch: 98/468, discriminator loss real = 9.062691153083335e-10, disciminator loss fake = 3.291454959253315e-06, generator loss = 13.740883827209473\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 17, Batch: 99/468, discriminator loss real = 0.00014566551544703543, disciminator loss fake = 4.1059729483095e-06, generator loss = 13.678041458129883\n",
      "2/2 [==============================] - 0s 165ms/step\n",
      "Epoch: 17, Batch: 100/468, discriminator loss real = 3.788373491319698e-15, disciminator loss fake = 5.0895760068669915e-06, generator loss = 13.849555015563965\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 17, Batch: 101/468, discriminator loss real = 1.4476496105922214e-14, disciminator loss fake = 1.2729433365166187e-05, generator loss = 13.600435256958008\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 17, Batch: 102/468, discriminator loss real = 4.986838184928321e-16, disciminator loss fake = 3.972115337091964e-06, generator loss = 13.81132698059082\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 17, Batch: 103/468, discriminator loss real = 5.306525609126088e-29, disciminator loss fake = 3.2398243092757184e-06, generator loss = 13.769684791564941\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 17, Batch: 104/468, discriminator loss real = 1.8132235235688518e-20, disciminator loss fake = 3.7003806028224062e-06, generator loss = 13.590967178344727\n",
      "2/2 [==============================] - 0s 167ms/step\n",
      "Epoch: 17, Batch: 105/468, discriminator loss real = 6.2012979275083225e-22, disciminator loss fake = 5.172251348994905e-06, generator loss = 13.828136444091797\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 17, Batch: 106/468, discriminator loss real = 2.153495241610353e-16, disciminator loss fake = 5.6976114137796685e-06, generator loss = 13.828426361083984\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 17, Batch: 107/468, discriminator loss real = 1.1049262734960912e-14, disciminator loss fake = 4.974178409611341e-06, generator loss = 13.714326858520508\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 17, Batch: 108/468, discriminator loss real = 4.009604163756867e-18, disciminator loss fake = 3.5360421861696523e-06, generator loss = 13.770231246948242\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 17, Batch: 109/468, discriminator loss real = 4.681793823101947e-25, disciminator loss fake = 3.417166226427071e-06, generator loss = 13.885087013244629\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 17, Batch: 110/468, discriminator loss real = 2.6516995416716595e-26, disciminator loss fake = 4.372313014755491e-06, generator loss = 13.50042724609375\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 17, Batch: 111/468, discriminator loss real = 8.392955553910165e-15, disciminator loss fake = 4.323420398577582e-06, generator loss = 13.532193183898926\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 17, Batch: 112/468, discriminator loss real = 1.2540269374808754e-22, disciminator loss fake = 3.899365310644498e-06, generator loss = 13.399128913879395\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 17, Batch: 113/468, discriminator loss real = 9.032333488966562e-26, disciminator loss fake = 6.875370218040189e-06, generator loss = 13.549500465393066\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 17, Batch: 114/468, discriminator loss real = 1.0155138961542162e-22, disciminator loss fake = 1.1770992387027945e-05, generator loss = 13.740045547485352\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 17, Batch: 115/468, discriminator loss real = 1.5819904178319667e-19, disciminator loss fake = 4.250412530382164e-06, generator loss = 13.804099082946777\n",
      "2/2 [==============================] - 0s 202ms/step\n",
      "Epoch: 17, Batch: 116/468, discriminator loss real = 8.018016571892959e-22, disciminator loss fake = 3.133473455818603e-06, generator loss = 13.890158653259277\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 17, Batch: 117/468, discriminator loss real = 1.3802487566250406e-20, disciminator loss fake = 3.752783413801808e-06, generator loss = 13.796302795410156\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 17, Batch: 118/468, discriminator loss real = 9.462831993684029e-13, disciminator loss fake = 4.81726465295651e-06, generator loss = 13.708562850952148\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 17, Batch: 119/468, discriminator loss real = 1.1597271240736053e-15, disciminator loss fake = 3.0981409508967772e-06, generator loss = 14.05156135559082\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 17, Batch: 120/468, discriminator loss real = 6.218120636447555e-12, disciminator loss fake = 1.1357915354892612e-05, generator loss = 13.594148635864258\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 17, Batch: 121/468, discriminator loss real = 4.620148973294511e-28, disciminator loss fake = 2.3333734588959487e-06, generator loss = 13.890949249267578\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 17, Batch: 122/468, discriminator loss real = 8.590210884639238e-21, disciminator loss fake = 3.879342784784967e-06, generator loss = 13.994890213012695\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 17, Batch: 123/468, discriminator loss real = 6.792850787071258e-13, disciminator loss fake = 3.8027546906960197e-06, generator loss = 14.101457595825195\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 17, Batch: 124/468, discriminator loss real = 1.0818451213300346e-18, disciminator loss fake = 3.2454199754283763e-06, generator loss = 13.809508323669434\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 17, Batch: 125/468, discriminator loss real = 5.974507929942634e-15, disciminator loss fake = 5.314082955010235e-06, generator loss = 13.756202697753906\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 17, Batch: 126/468, discriminator loss real = 3.211787423630825e-28, disciminator loss fake = 2.1411410671134945e-06, generator loss = 13.695271492004395\n",
      "2/2 [==============================] - 0s 192ms/step\n",
      "Epoch: 17, Batch: 127/468, discriminator loss real = 2.2343224540658616e-23, disciminator loss fake = 1.6333953681169078e-05, generator loss = 13.878787994384766\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 17, Batch: 128/468, discriminator loss real = 6.872829349373888e-25, disciminator loss fake = 2.3618806608283194e-06, generator loss = 13.973908424377441\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 17, Batch: 129/468, discriminator loss real = 2.1035721984590257e-21, disciminator loss fake = 3.472723165032221e-06, generator loss = 14.000876426696777\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 17, Batch: 130/468, discriminator loss real = 3.3291399676474388e-15, disciminator loss fake = 4.0569411794422194e-06, generator loss = 13.879159927368164\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 17, Batch: 131/468, discriminator loss real = 2.649139252077217e-33, disciminator loss fake = 6.681900686089648e-06, generator loss = 13.731467247009277\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 17, Batch: 132/468, discriminator loss real = 5.2409072332737987e-23, disciminator loss fake = 2.596038484625751e-06, generator loss = 13.979650497436523\n",
      "2/2 [==============================] - 0s 177ms/step\n",
      "Epoch: 17, Batch: 133/468, discriminator loss real = 3.15617424166775e-26, disciminator loss fake = 4.353759777586674e-06, generator loss = 13.732625961303711\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 17, Batch: 134/468, discriminator loss real = 2.511892955490032e-18, disciminator loss fake = 4.953125426254701e-06, generator loss = 14.147445678710938\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 17, Batch: 135/468, discriminator loss real = 5.314358436821209e-13, disciminator loss fake = 5.389119905885309e-06, generator loss = 13.820252418518066\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 17, Batch: 136/468, discriminator loss real = 1.0359194785720708e-20, disciminator loss fake = 3.358194589964114e-06, generator loss = 13.79557991027832\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 17, Batch: 137/468, discriminator loss real = 1.1526659397879382e-15, disciminator loss fake = 3.219402515242109e-06, generator loss = 13.500707626342773\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 17, Batch: 138/468, discriminator loss real = 2.40537109881739e-26, disciminator loss fake = 5.682921255356632e-06, generator loss = 13.942401885986328\n",
      "2/2 [==============================] - 0s 189ms/step\n",
      "Epoch: 17, Batch: 139/468, discriminator loss real = 5.190743939276904e-14, disciminator loss fake = 3.7861282180529088e-06, generator loss = 13.657695770263672\n",
      "2/2 [==============================] - 0s 135ms/step\n",
      "Epoch: 17, Batch: 140/468, discriminator loss real = 1.9004338014383393e-07, disciminator loss fake = 2.7005798983736895e-06, generator loss = 13.916206359863281\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 17, Batch: 141/468, discriminator loss real = 1.620825786600882e-25, disciminator loss fake = 2.3534880710940342e-06, generator loss = 13.835460662841797\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 17, Batch: 142/468, discriminator loss real = 3.8393910988844537e-13, disciminator loss fake = 3.3791479836509097e-06, generator loss = 13.991240501403809\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 17, Batch: 143/468, discriminator loss real = 3.7208045000625134e-07, disciminator loss fake = 2.830046469171066e-06, generator loss = 14.005387306213379\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 17, Batch: 144/468, discriminator loss real = 8.510069297121582e-19, disciminator loss fake = 3.428364834690001e-06, generator loss = 14.0414457321167\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 17, Batch: 145/468, discriminator loss real = 5.3817210758009605e-20, disciminator loss fake = 4.219069523969665e-06, generator loss = 13.621688842773438\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 17, Batch: 146/468, discriminator loss real = 2.0936077013036377e-19, disciminator loss fake = 5.266092557576485e-06, generator loss = 13.99826431274414\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 17, Batch: 147/468, discriminator loss real = 7.116063550319674e-16, disciminator loss fake = 7.834201824152842e-06, generator loss = 14.090004920959473\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 17, Batch: 148/468, discriminator loss real = 3.576781879157927e-21, disciminator loss fake = 2.469088713041856e-06, generator loss = 13.881935119628906\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 17, Batch: 149/468, discriminator loss real = 1.0450222909241802e-08, disciminator loss fake = 4.80018206872046e-06, generator loss = 13.920594215393066\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 17, Batch: 150/468, discriminator loss real = 1.196779902890323e-19, disciminator loss fake = 4.4661001084023155e-06, generator loss = 14.224226951599121\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 17, Batch: 151/468, discriminator loss real = 1.2087826166958942e-20, disciminator loss fake = 5.598380084848031e-06, generator loss = 14.287349700927734\n",
      "2/2 [==============================] - 0s 165ms/step\n",
      "Epoch: 17, Batch: 152/468, discriminator loss real = 2.5703434556255314e-28, disciminator loss fake = 3.4132124255847884e-06, generator loss = 14.118310928344727\n",
      "2/2 [==============================] - 0s 134ms/step\n",
      "Epoch: 17, Batch: 153/468, discriminator loss real = 5.842161599502771e-19, disciminator loss fake = 5.051223070040578e-06, generator loss = 13.639719009399414\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 17, Batch: 154/468, discriminator loss real = 5.7433387472966e-14, disciminator loss fake = 4.297178747947328e-06, generator loss = 13.5767822265625\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 17, Batch: 155/468, discriminator loss real = 1.7233651029673058e-14, disciminator loss fake = 5.071996383776423e-06, generator loss = 13.810461044311523\n",
      "2/2 [==============================] - 0s 136ms/step\n",
      "Epoch: 17, Batch: 156/468, discriminator loss real = 5.025605582728576e-13, disciminator loss fake = 3.229786443625926e-06, generator loss = 13.948822021484375\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 17, Batch: 157/468, discriminator loss real = 4.886616827327883e-13, disciminator loss fake = 4.17040973843541e-06, generator loss = 13.971607208251953\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 17, Batch: 158/468, discriminator loss real = 9.409284027767188e-31, disciminator loss fake = 4.33555669587804e-06, generator loss = 13.840707778930664\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 17, Batch: 159/468, discriminator loss real = 2.2389028971709843e-14, disciminator loss fake = 5.144690476299729e-06, generator loss = 13.769721984863281\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 17, Batch: 160/468, discriminator loss real = 4.942953637510072e-07, disciminator loss fake = 5.619538114842726e-06, generator loss = 13.772115707397461\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 17, Batch: 161/468, discriminator loss real = 3.8466569566740865e-24, disciminator loss fake = 2.243454218842089e-06, generator loss = 14.137001037597656\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 17, Batch: 162/468, discriminator loss real = 2.1799231904299792e-20, disciminator loss fake = 2.5756892227946082e-06, generator loss = 13.738150596618652\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 17, Batch: 163/468, discriminator loss real = 1.7505217369620535e-30, disciminator loss fake = 4.317097591410857e-06, generator loss = 14.047664642333984\n",
      "2/2 [==============================] - 0s 160ms/step\n",
      "Epoch: 17, Batch: 164/468, discriminator loss real = 7.758847225042537e-38, disciminator loss fake = 3.2234172522294102e-06, generator loss = 14.001971244812012\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 17, Batch: 165/468, discriminator loss real = 9.696070795130522e-31, disciminator loss fake = 3.12651081912918e-06, generator loss = 13.847871780395508\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 17, Batch: 166/468, discriminator loss real = 5.111477317319005e-31, disciminator loss fake = 1.9894740034942515e-05, generator loss = 13.791019439697266\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 17, Batch: 167/468, discriminator loss real = 6.912652958726562e-13, disciminator loss fake = 2.9667428407265106e-06, generator loss = 13.847274780273438\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 17, Batch: 168/468, discriminator loss real = 6.673405732726678e-05, disciminator loss fake = 2.1160353753657546e-06, generator loss = 13.881704330444336\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 17, Batch: 169/468, discriminator loss real = 2.534281425949392e-18, disciminator loss fake = 5.141091605764814e-06, generator loss = 13.965957641601562\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 17, Batch: 170/468, discriminator loss real = 1.2273203986334163e-22, disciminator loss fake = 3.3368578442605212e-06, generator loss = 13.928213119506836\n",
      "2/2 [==============================] - 0s 135ms/step\n",
      "Epoch: 17, Batch: 171/468, discriminator loss real = 7.482924002655267e-11, disciminator loss fake = 3.523688292261795e-06, generator loss = 14.188685417175293\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 17, Batch: 172/468, discriminator loss real = 7.179049493891716e-23, disciminator loss fake = 2.841225068550557e-06, generator loss = 13.962874412536621\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 17, Batch: 173/468, discriminator loss real = 2.2061699526693818e-13, disciminator loss fake = 2.5407009616174037e-06, generator loss = 13.886991500854492\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 17, Batch: 174/468, discriminator loss real = 1.8134664776792153e-12, disciminator loss fake = 3.473593096714467e-06, generator loss = 14.104412078857422\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 17, Batch: 175/468, discriminator loss real = 2.27357577209375e-10, disciminator loss fake = 3.6631581679102965e-06, generator loss = 13.749801635742188\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 17, Batch: 176/468, discriminator loss real = 1.787778607821411e-19, disciminator loss fake = 3.761214884434594e-06, generator loss = 14.084381103515625\n",
      "2/2 [==============================] - 0s 165ms/step\n",
      "Epoch: 17, Batch: 177/468, discriminator loss real = 3.5363023016543593e-06, disciminator loss fake = 4.6437148739642e-06, generator loss = 13.869733810424805\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 17, Batch: 178/468, discriminator loss real = 2.4714029297946557e-19, disciminator loss fake = 2.3648749447602313e-06, generator loss = 14.016108512878418\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 17, Batch: 179/468, discriminator loss real = 2.5188404200160727e-26, disciminator loss fake = 3.4406502891215496e-06, generator loss = 14.010417938232422\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 17, Batch: 180/468, discriminator loss real = 1.204168242898519e-16, disciminator loss fake = 2.6635600534063997e-06, generator loss = 14.012285232543945\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 17, Batch: 181/468, discriminator loss real = 4.751915175928977e-25, disciminator loss fake = 4.145002549194032e-06, generator loss = 13.600885391235352\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 17, Batch: 182/468, discriminator loss real = 7.356364514437228e-18, disciminator loss fake = 2.007663397307624e-06, generator loss = 13.719085693359375\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 17, Batch: 183/468, discriminator loss real = 1.1612185811760558e-18, disciminator loss fake = 2.636219960550079e-06, generator loss = 14.181371688842773\n",
      "2/2 [==============================] - 0s 154ms/step\n",
      "Epoch: 17, Batch: 184/468, discriminator loss real = 9.124297183690094e-14, disciminator loss fake = 5.021984634367982e-06, generator loss = 14.34726619720459\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 17, Batch: 185/468, discriminator loss real = 2.4039714247532743e-19, disciminator loss fake = 3.3626383810769767e-06, generator loss = 14.098529815673828\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 17, Batch: 186/468, discriminator loss real = 1.2255397502437153e-23, disciminator loss fake = 3.362574489074177e-06, generator loss = 14.015358924865723\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 17, Batch: 187/468, discriminator loss real = 5.302810888796757e-18, disciminator loss fake = 5.110265192342922e-06, generator loss = 13.91163444519043\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 17, Batch: 188/468, discriminator loss real = 3.946883690118401e-17, disciminator loss fake = 4.844780960411299e-06, generator loss = 14.07930850982666\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 17, Batch: 189/468, discriminator loss real = 3.523975690549845e-17, disciminator loss fake = 4.476512913242914e-06, generator loss = 13.866401672363281\n",
      "2/2 [==============================] - 0s 168ms/step\n",
      "Epoch: 17, Batch: 190/468, discriminator loss real = 5.216857626227575e-14, disciminator loss fake = 4.534073923423421e-06, generator loss = 13.95274829864502\n",
      "2/2 [==============================] - 0s 148ms/step\n",
      "Epoch: 17, Batch: 191/468, discriminator loss real = 5.234173393713353e-16, disciminator loss fake = 2.994984242832288e-06, generator loss = 13.884206771850586\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 17, Batch: 192/468, discriminator loss real = 2.7412364253796506e-23, disciminator loss fake = 4.656148121284787e-06, generator loss = 13.81277084350586\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 17, Batch: 193/468, discriminator loss real = 1.0491305615462033e-15, disciminator loss fake = 2.748045517364517e-06, generator loss = 14.132882118225098\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 17, Batch: 194/468, discriminator loss real = 5.879578829961476e-15, disciminator loss fake = 2.2770577743358444e-06, generator loss = 13.98750114440918\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 17, Batch: 195/468, discriminator loss real = 1.6796230756461289e-22, disciminator loss fake = 3.2072052817966323e-06, generator loss = 14.049532890319824\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 17, Batch: 196/468, discriminator loss real = 4.7546556676507295e-18, disciminator loss fake = 2.4717530777706997e-06, generator loss = 13.924695014953613\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 17, Batch: 197/468, discriminator loss real = 6.540035575814188e-14, disciminator loss fake = 4.758334398502484e-06, generator loss = 14.078469276428223\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 17, Batch: 198/468, discriminator loss real = 1.532839410955944e-10, disciminator loss fake = 1.7942652448255103e-06, generator loss = 13.966150283813477\n",
      "2/2 [==============================] - 0s 200ms/step\n",
      "Epoch: 17, Batch: 199/468, discriminator loss real = 5.053433447076551e-20, disciminator loss fake = 3.3513915695948526e-06, generator loss = 13.995169639587402\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 17, Batch: 200/468, discriminator loss real = 6.297918861524327e-25, disciminator loss fake = 4.472174623515457e-06, generator loss = 14.175308227539062\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 17, Batch: 201/468, discriminator loss real = 5.023999966466688e-32, disciminator loss fake = 3.7277832234394737e-06, generator loss = 13.943689346313477\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 17, Batch: 202/468, discriminator loss real = 6.5209458809168145e-22, disciminator loss fake = 3.153397528876667e-06, generator loss = 14.161096572875977\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 17, Batch: 203/468, discriminator loss real = 6.550550580345224e-26, disciminator loss fake = 1.7682245925243478e-06, generator loss = 14.10819149017334\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 17, Batch: 204/468, discriminator loss real = 2.0437193333066456e-13, disciminator loss fake = 3.496436193017871e-06, generator loss = 13.999914169311523\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 17, Batch: 205/468, discriminator loss real = 3.8512890840433654e-19, disciminator loss fake = 1.6640384501442895e-06, generator loss = 14.049080848693848\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 17, Batch: 206/468, discriminator loss real = 2.4949605509835097e-22, disciminator loss fake = 6.2826279645378236e-06, generator loss = 13.775341033935547\n",
      "2/2 [==============================] - 0s 176ms/step\n",
      "Epoch: 17, Batch: 207/468, discriminator loss real = 1.1063932561228285e-06, disciminator loss fake = 3.167070872223121e-06, generator loss = 13.558514595031738\n",
      "2/2 [==============================] - 0s 162ms/step\n",
      "Epoch: 17, Batch: 208/468, discriminator loss real = 7.87331172480421e-11, disciminator loss fake = 3.6920907859894214e-06, generator loss = 13.95780086517334\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 17, Batch: 209/468, discriminator loss real = 6.114184003536138e-08, disciminator loss fake = 5.258972123556305e-06, generator loss = 14.223458290100098\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 17, Batch: 210/468, discriminator loss real = 1.1077826929256148e-17, disciminator loss fake = 1.4434508557314985e-06, generator loss = 14.100090026855469\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 17, Batch: 211/468, discriminator loss real = 4.228556080165086e-19, disciminator loss fake = 3.533338031047606e-06, generator loss = 14.26242733001709\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 17, Batch: 212/468, discriminator loss real = 1.7377927814678466e-27, disciminator loss fake = 2.084371772070881e-06, generator loss = 14.055570602416992\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 17, Batch: 213/468, discriminator loss real = 2.1865993460323807e-09, disciminator loss fake = 3.9562955862493254e-06, generator loss = 13.952159881591797\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 17, Batch: 214/468, discriminator loss real = 9.630032319475211e-25, disciminator loss fake = 3.5460352592053823e-06, generator loss = 13.918490409851074\n",
      "2/2 [==============================] - 0s 157ms/step\n",
      "Epoch: 17, Batch: 215/468, discriminator loss real = 6.859336334336368e-16, disciminator loss fake = 3.198711965524126e-06, generator loss = 14.196229934692383\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 17, Batch: 216/468, discriminator loss real = 1.6187853337745792e-23, disciminator loss fake = 1.855719006016443e-06, generator loss = 14.253036499023438\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 17, Batch: 217/468, discriminator loss real = 2.7759041955279077e-34, disciminator loss fake = 4.4993321353103966e-06, generator loss = 14.057493209838867\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 17, Batch: 218/468, discriminator loss real = 6.325299360727933e-26, disciminator loss fake = 2.4978210149129154e-06, generator loss = 14.302873611450195\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 17, Batch: 219/468, discriminator loss real = 2.867613168444938e-17, disciminator loss fake = 3.984566319559235e-06, generator loss = 14.011703491210938\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 17, Batch: 220/468, discriminator loss real = 2.411907188754955e-19, disciminator loss fake = 3.026950707862852e-06, generator loss = 14.164654731750488\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 17, Batch: 221/468, discriminator loss real = 3.336440679291286e-09, disciminator loss fake = 1.797514869394945e-06, generator loss = 14.175919532775879\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 17, Batch: 222/468, discriminator loss real = 5.019998861044428e-10, disciminator loss fake = 2.947483835669118e-06, generator loss = 14.123468399047852\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 17, Batch: 223/468, discriminator loss real = 1.9907592434142738e-18, disciminator loss fake = 2.969916977235698e-06, generator loss = 14.172697067260742\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 17, Batch: 224/468, discriminator loss real = 2.854440587975876e-13, disciminator loss fake = 5.707518994313432e-06, generator loss = 14.147359848022461\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 17, Batch: 225/468, discriminator loss real = 2.7464884624350816e-05, disciminator loss fake = 5.164570211491082e-06, generator loss = 13.945331573486328\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 17, Batch: 226/468, discriminator loss real = 6.448797877371095e-24, disciminator loss fake = 3.098954039160162e-06, generator loss = 14.24812126159668\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 17, Batch: 227/468, discriminator loss real = 2.5174613568008734e-23, disciminator loss fake = 3.0664250516565517e-06, generator loss = 14.161941528320312\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 17, Batch: 228/468, discriminator loss real = 8.7130156605289e-13, disciminator loss fake = 4.606337824952789e-06, generator loss = 13.958372116088867\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 17, Batch: 229/468, discriminator loss real = 3.956881584648308e-36, disciminator loss fake = 2.779377382466919e-06, generator loss = 13.98646354675293\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 17, Batch: 230/468, discriminator loss real = 6.7651873067042175e-25, disciminator loss fake = 3.061038796658977e-06, generator loss = 13.934083938598633\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 17, Batch: 231/468, discriminator loss real = 1.3491529048241555e-20, disciminator loss fake = 3.768267106352141e-06, generator loss = 14.030729293823242\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 17, Batch: 232/468, discriminator loss real = 2.269624011128938e-22, disciminator loss fake = 1.6633307495794725e-06, generator loss = 14.273706436157227\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 17, Batch: 233/468, discriminator loss real = 3.1918728998856644e-14, disciminator loss fake = 5.9380909078754485e-06, generator loss = 14.183847427368164\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 17, Batch: 234/468, discriminator loss real = 1.0760308720355736e-20, disciminator loss fake = 3.164755071338732e-06, generator loss = 14.142227172851562\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 17, Batch: 235/468, discriminator loss real = 4.914213431138227e-18, disciminator loss fake = 1.3814574231219012e-06, generator loss = 14.238353729248047\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 17, Batch: 236/468, discriminator loss real = 6.957131582052798e-18, disciminator loss fake = 2.5529002414259594e-06, generator loss = 14.146862030029297\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 17, Batch: 237/468, discriminator loss real = 4.3327230697568756e-24, disciminator loss fake = 7.933031156426296e-06, generator loss = 13.941977500915527\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 17, Batch: 238/468, discriminator loss real = 4.036698464721041e-18, disciminator loss fake = 3.972538706875639e-06, generator loss = 14.224706649780273\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 17, Batch: 239/468, discriminator loss real = 7.75228579247278e-12, disciminator loss fake = 2.4947396468633087e-06, generator loss = 14.215152740478516\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 17, Batch: 240/468, discriminator loss real = 2.4626830890451543e-21, disciminator loss fake = 2.169452727684984e-06, generator loss = 14.082233428955078\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 17, Batch: 241/468, discriminator loss real = 2.9750234444876752e-15, disciminator loss fake = 1.286874748984701e-06, generator loss = 14.117642402648926\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 17, Batch: 242/468, discriminator loss real = 5.545505598099628e-24, disciminator loss fake = 2.6262891879014205e-06, generator loss = 13.964828491210938\n",
      "2/2 [==============================] - 0s 173ms/step\n",
      "Epoch: 17, Batch: 243/468, discriminator loss real = 4.9877563884637155e-11, disciminator loss fake = 2.434123871353222e-06, generator loss = 14.367408752441406\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 17, Batch: 244/468, discriminator loss real = 1.9362712087684777e-22, disciminator loss fake = 3.882994860759936e-06, generator loss = 14.110773086547852\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 17, Batch: 245/468, discriminator loss real = 7.742393948184656e-10, disciminator loss fake = 5.488336228154367e-06, generator loss = 14.192394256591797\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 17, Batch: 246/468, discriminator loss real = 6.732010738751796e-17, disciminator loss fake = 2.7029261673305882e-06, generator loss = 14.151945114135742\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 17, Batch: 247/468, discriminator loss real = 6.62896565227601e-21, disciminator loss fake = 1.982480625883909e-06, generator loss = 14.089729309082031\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 17, Batch: 248/468, discriminator loss real = 1.102221781998803e-14, disciminator loss fake = 2.1386490516306367e-06, generator loss = 14.201598167419434\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 17, Batch: 249/468, discriminator loss real = 5.542389277562022e-18, disciminator loss fake = 2.926116849266691e-06, generator loss = 13.971755981445312\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 17, Batch: 250/468, discriminator loss real = 1.580959321789699e-11, disciminator loss fake = 3.103160452155862e-06, generator loss = 14.222003936767578\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 17, Batch: 251/468, discriminator loss real = 6.283703588012244e-25, disciminator loss fake = 1.1570464266696945e-06, generator loss = 14.014704704284668\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 17, Batch: 252/468, discriminator loss real = 2.1880613874995366e-20, disciminator loss fake = 6.020543423801428e-06, generator loss = 14.047847747802734\n",
      "2/2 [==============================] - 0s 176ms/step\n",
      "Epoch: 17, Batch: 253/468, discriminator loss real = 1.2972721523144661e-17, disciminator loss fake = 2.244712504761992e-06, generator loss = 14.218503952026367\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 17, Batch: 254/468, discriminator loss real = 1.3819080483635853e-16, disciminator loss fake = 3.536668828019174e-06, generator loss = 14.005029678344727\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 17, Batch: 255/468, discriminator loss real = 1.0186126435719138e-18, disciminator loss fake = 4.484834789764136e-06, generator loss = 14.378568649291992\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 17, Batch: 256/468, discriminator loss real = 6.244051601450844e-16, disciminator loss fake = 1.5874095424806e-06, generator loss = 14.296157836914062\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 17, Batch: 257/468, discriminator loss real = 3.3619476452207767e-20, disciminator loss fake = 1.9488970792735927e-06, generator loss = 14.637334823608398\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 17, Batch: 258/468, discriminator loss real = 5.764253473066181e-25, disciminator loss fake = 2.008899173233658e-06, generator loss = 14.355180740356445\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 17, Batch: 259/468, discriminator loss real = 3.887795924896569e-19, disciminator loss fake = 6.521745035570348e-06, generator loss = 14.460336685180664\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 17, Batch: 260/468, discriminator loss real = 9.955232409409914e-20, disciminator loss fake = 1.520642854302423e-06, generator loss = 14.35958194732666\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 17, Batch: 261/468, discriminator loss real = 1.078029789528725e-19, disciminator loss fake = 3.0211340344976634e-06, generator loss = 14.197900772094727\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 17, Batch: 262/468, discriminator loss real = 1.7333113646600395e-05, disciminator loss fake = 1.8521438960306114e-06, generator loss = 14.26966667175293\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 17, Batch: 263/468, discriminator loss real = 1.404234186849655e-34, disciminator loss fake = 2.291717692060047e-06, generator loss = 14.140547752380371\n",
      "2/2 [==============================] - 0s 192ms/step\n",
      "Epoch: 17, Batch: 264/468, discriminator loss real = 1.7935124329557023e-15, disciminator loss fake = 1.4625533140133484e-06, generator loss = 14.184630393981934\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 17, Batch: 265/468, discriminator loss real = 1.0816405930647033e-11, disciminator loss fake = 4.317890216043452e-06, generator loss = 14.401615142822266\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 17, Batch: 266/468, discriminator loss real = 8.074650063792915e-25, disciminator loss fake = 2.011247033806285e-06, generator loss = 13.990171432495117\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 17, Batch: 267/468, discriminator loss real = 2.8497608089718104e-24, disciminator loss fake = 1.6619096641079523e-06, generator loss = 13.98385238647461\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 17, Batch: 268/468, discriminator loss real = 1.0821785281223129e-06, disciminator loss fake = 1.223745130118914e-06, generator loss = 14.493120193481445\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 17, Batch: 269/468, discriminator loss real = 3.865961547827275e-27, disciminator loss fake = 3.7066936329210876e-06, generator loss = 14.239068031311035\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 17, Batch: 270/468, discriminator loss real = 1.1808371121191374e-13, disciminator loss fake = 4.534651907306397e-06, generator loss = 14.206968307495117\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 17, Batch: 271/468, discriminator loss real = 5.200700486840023e-26, disciminator loss fake = 2.070430355161079e-06, generator loss = 14.202773094177246\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 17, Batch: 272/468, discriminator loss real = 3.220607808218645e-11, disciminator loss fake = 4.287123829271877e-06, generator loss = 14.343347549438477\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 17, Batch: 273/468, discriminator loss real = 1.2497444485531917e-12, disciminator loss fake = 1.57354338625737e-06, generator loss = 14.393353462219238\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 17, Batch: 274/468, discriminator loss real = 0.00015367056766990572, disciminator loss fake = 2.4809287424432114e-06, generator loss = 14.188955307006836\n",
      "2/2 [==============================] - 0s 203ms/step\n",
      "Epoch: 17, Batch: 275/468, discriminator loss real = 3.269945874490543e-34, disciminator loss fake = 2.481481487848214e-06, generator loss = 14.083475112915039\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 17, Batch: 276/468, discriminator loss real = 1.7631370660003634e-22, disciminator loss fake = 2.4694861622265307e-06, generator loss = 14.158129692077637\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 17, Batch: 277/468, discriminator loss real = 2.992053133032968e-11, disciminator loss fake = 1.8680842686080723e-06, generator loss = 14.155442237854004\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 17, Batch: 278/468, discriminator loss real = 1.5667523776996761e-21, disciminator loss fake = 2.0009094896522583e-06, generator loss = 14.09249496459961\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 17, Batch: 279/468, discriminator loss real = 7.572408949494248e-26, disciminator loss fake = 2.0062927887920523e-06, generator loss = 14.284246444702148\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 17, Batch: 280/468, discriminator loss real = 1.2416792366951211e-26, disciminator loss fake = 1.94140602616244e-06, generator loss = 14.48495101928711\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 17, Batch: 281/468, discriminator loss real = 4.3822184709255444e-26, disciminator loss fake = 1.7679100210443721e-06, generator loss = 14.105337142944336\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 17, Batch: 282/468, discriminator loss real = 3.429433793151679e-14, disciminator loss fake = 1.955608695425326e-06, generator loss = 14.091988563537598\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 17, Batch: 283/468, discriminator loss real = 7.677578960517788e-20, disciminator loss fake = 2.1490025119419442e-06, generator loss = 14.20035457611084\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 17, Batch: 284/468, discriminator loss real = 1.2906290484976227e-21, disciminator loss fake = 1.981976993192802e-06, generator loss = 14.08442497253418\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 17, Batch: 285/468, discriminator loss real = 2.0302232117686003e-12, disciminator loss fake = 1.309176468566875e-06, generator loss = 14.120662689208984\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 17, Batch: 286/468, discriminator loss real = 8.713768080582506e-20, disciminator loss fake = 2.902970663853921e-06, generator loss = 14.004056930541992\n",
      "2/2 [==============================] - 0s 154ms/step\n",
      "Epoch: 17, Batch: 287/468, discriminator loss real = 4.471489893170767e-15, disciminator loss fake = 4.8101728680194356e-06, generator loss = 13.928525924682617\n",
      "2/2 [==============================] - 0s 194ms/step\n",
      "Epoch: 17, Batch: 288/468, discriminator loss real = 2.321864902655418e-25, disciminator loss fake = 3.402069069124991e-06, generator loss = 14.116594314575195\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 17, Batch: 289/468, discriminator loss real = 1.6939618944888934e-05, disciminator loss fake = 1.98938596440712e-06, generator loss = 14.148150444030762\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 17, Batch: 290/468, discriminator loss real = 2.5742235010284276e-08, disciminator loss fake = 2.2758526938559953e-06, generator loss = 14.186534881591797\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 17, Batch: 291/468, discriminator loss real = 1.3403633671721371e-12, disciminator loss fake = 1.742435642881901e-06, generator loss = 14.022299766540527\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 17, Batch: 292/468, discriminator loss real = 1.3233399421717427e-21, disciminator loss fake = 4.556564817903563e-06, generator loss = 14.29216480255127\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 17, Batch: 293/468, discriminator loss real = 1.0591920516254725e-21, disciminator loss fake = 2.4860191842890345e-06, generator loss = 14.226563453674316\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 17, Batch: 294/468, discriminator loss real = 9.655900625768835e-21, disciminator loss fake = 2.834447968780296e-06, generator loss = 14.111307144165039\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 17, Batch: 295/468, discriminator loss real = 1.8702921195896916e-21, disciminator loss fake = 8.103914296953008e-06, generator loss = 14.182209014892578\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 17, Batch: 296/468, discriminator loss real = 2.3202991735028876e-21, disciminator loss fake = 2.3059160412230995e-06, generator loss = 14.072616577148438\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 17, Batch: 297/468, discriminator loss real = 3.55917587069321e-11, disciminator loss fake = 2.700303184610675e-06, generator loss = 13.949795722961426\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 17, Batch: 298/468, discriminator loss real = 3.973214059610113e-25, disciminator loss fake = 2.5737717805895954e-06, generator loss = 14.097101211547852\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 17, Batch: 299/468, discriminator loss real = 5.139615830891249e-31, disciminator loss fake = 3.3772796541597927e-06, generator loss = 14.07585334777832\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 17, Batch: 300/468, discriminator loss real = 5.81065224019445e-23, disciminator loss fake = 4.127247848373372e-06, generator loss = 14.139059066772461\n",
      "2/2 [==============================] - 0s 174ms/step\n",
      "Epoch: 17, Batch: 301/468, discriminator loss real = 2.260552058414263e-18, disciminator loss fake = 2.634802967804717e-06, generator loss = 14.414163589477539\n",
      "2/2 [==============================] - 0s 134ms/step\n",
      "Epoch: 17, Batch: 302/468, discriminator loss real = 1.041934652783819e-21, disciminator loss fake = 5.465175490826368e-06, generator loss = 14.476892471313477\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 17, Batch: 303/468, discriminator loss real = 7.549217734227273e-14, disciminator loss fake = 3.1158135698206024e-06, generator loss = 14.16370964050293\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 17, Batch: 304/468, discriminator loss real = 1.411420070860119e-24, disciminator loss fake = 2.3889451767900027e-06, generator loss = 14.06500244140625\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 17, Batch: 305/468, discriminator loss real = 4.4682188504729936e-10, disciminator loss fake = 2.1888665742153535e-06, generator loss = 14.093574523925781\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 17, Batch: 306/468, discriminator loss real = 2.1018656133798165e-20, disciminator loss fake = 4.996013103664154e-06, generator loss = 14.191539764404297\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 17, Batch: 307/468, discriminator loss real = 2.546607186095908e-21, disciminator loss fake = 2.0429599771887297e-06, generator loss = 14.20286750793457\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 17, Batch: 308/468, discriminator loss real = 5.915547321736978e-14, disciminator loss fake = 1.999499545490835e-06, generator loss = 14.219098091125488\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 17, Batch: 309/468, discriminator loss real = 7.551528913626925e-22, disciminator loss fake = 2.555689661676297e-06, generator loss = 14.289270401000977\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 17, Batch: 310/468, discriminator loss real = 2.8178509120390773e-23, disciminator loss fake = 2.6109255486517213e-06, generator loss = 14.107933044433594\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 17, Batch: 311/468, discriminator loss real = 5.433195110526867e-05, disciminator loss fake = 2.762407802947564e-06, generator loss = 14.401192665100098\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 17, Batch: 312/468, discriminator loss real = 1.6999178757345912e-13, disciminator loss fake = 2.041214884229703e-06, generator loss = 14.222013473510742\n",
      "2/2 [==============================] - 0s 152ms/step\n",
      "Epoch: 17, Batch: 313/468, discriminator loss real = 3.3896480175423596e-21, disciminator loss fake = 2.9265602279338054e-06, generator loss = 14.053407669067383\n",
      "2/2 [==============================] - 0s 169ms/step\n",
      "Epoch: 17, Batch: 314/468, discriminator loss real = 1.627158269235096e-10, disciminator loss fake = 2.3922711989143863e-06, generator loss = 14.462278366088867\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 17, Batch: 315/468, discriminator loss real = 1.0155682881136312e-24, disciminator loss fake = 4.066327164764516e-06, generator loss = 14.228391647338867\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 17, Batch: 316/468, discriminator loss real = 2.4688653966803593e-14, disciminator loss fake = 1.4856354937364813e-06, generator loss = 14.043153762817383\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 17, Batch: 317/468, discriminator loss real = 3.57178540646643e-17, disciminator loss fake = 1.3600185866380343e-06, generator loss = 13.953048706054688\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 17, Batch: 318/468, discriminator loss real = 2.778279311480557e-20, disciminator loss fake = 2.9758077744190814e-06, generator loss = 14.162712097167969\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 17, Batch: 319/468, discriminator loss real = 1.4879188711347524e-05, disciminator loss fake = 1.834965473790362e-06, generator loss = 14.01600456237793\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 17, Batch: 320/468, discriminator loss real = 1.222382383619758e-18, disciminator loss fake = 3.1540139389107935e-06, generator loss = 14.194822311401367\n",
      "2/2 [==============================] - 0s 173ms/step\n",
      "Epoch: 17, Batch: 321/468, discriminator loss real = 4.333293883197006e-20, disciminator loss fake = 3.213327545381617e-06, generator loss = 14.286027908325195\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 17, Batch: 322/468, discriminator loss real = 2.1193253749163254e-11, disciminator loss fake = 1.4618586646975018e-05, generator loss = 14.24662971496582\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 17, Batch: 323/468, discriminator loss real = 8.191423207055612e-14, disciminator loss fake = 3.705006065501948e-06, generator loss = 14.217756271362305\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 17, Batch: 324/468, discriminator loss real = 9.760674900434734e-15, disciminator loss fake = 3.120767360087484e-06, generator loss = 14.244962692260742\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 17, Batch: 325/468, discriminator loss real = 2.6769486373169717e-27, disciminator loss fake = 2.74895000984543e-06, generator loss = 13.952531814575195\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 17, Batch: 326/468, discriminator loss real = 3.236305198980015e-14, disciminator loss fake = 3.4616232369444333e-06, generator loss = 14.340934753417969\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 17, Batch: 327/468, discriminator loss real = 5.996789436552019e-12, disciminator loss fake = 2.0870534171990585e-06, generator loss = 13.972566604614258\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 17, Batch: 328/468, discriminator loss real = 3.0268860637592493e-27, disciminator loss fake = 2.1711616682296153e-06, generator loss = 14.002647399902344\n",
      "2/2 [==============================] - 0s 158ms/step\n",
      "Epoch: 17, Batch: 329/468, discriminator loss real = 1.1198430385663202e-23, disciminator loss fake = 2.3770912775944453e-06, generator loss = 14.143543243408203\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 17, Batch: 330/468, discriminator loss real = 6.918362524082761e-27, disciminator loss fake = 3.6232972888683435e-06, generator loss = 14.356462478637695\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 17, Batch: 331/468, discriminator loss real = 2.2815894534201098e-17, disciminator loss fake = 2.089335566779482e-06, generator loss = 14.022269248962402\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 17, Batch: 332/468, discriminator loss real = 2.552990736148786e-06, disciminator loss fake = 2.20232823266997e-06, generator loss = 14.39260482788086\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 17, Batch: 333/468, discriminator loss real = 1.066021299012121e-10, disciminator loss fake = 2.406521844022791e-06, generator loss = 14.166776657104492\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 17, Batch: 334/468, discriminator loss real = 3.974582163801984e-18, disciminator loss fake = 4.059411821799586e-06, generator loss = 14.12197494506836\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 17, Batch: 335/468, discriminator loss real = 5.1072941171324065e-26, disciminator loss fake = 3.3957221603486687e-06, generator loss = 14.104785919189453\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 17, Batch: 336/468, discriminator loss real = 2.50462031756854e-13, disciminator loss fake = 2.6795180474437075e-06, generator loss = 14.139810562133789\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 17, Batch: 337/468, discriminator loss real = 1.3628550224241257e-20, disciminator loss fake = 3.453288627497386e-06, generator loss = 14.592690467834473\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 17, Batch: 338/468, discriminator loss real = 1.0091705249237748e-09, disciminator loss fake = 3.484595254121814e-06, generator loss = 14.29891586303711\n",
      "2/2 [==============================] - 0s 179ms/step\n",
      "Epoch: 17, Batch: 339/468, discriminator loss real = 1.9741608606894033e-23, disciminator loss fake = 1.6174009260794264e-06, generator loss = 13.918281555175781\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 17, Batch: 340/468, discriminator loss real = 2.5707113927239005e-22, disciminator loss fake = 1.812602135942143e-06, generator loss = 14.291991233825684\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 17, Batch: 341/468, discriminator loss real = 1.9539114569930073e-25, disciminator loss fake = 3.5017062600672944e-06, generator loss = 14.197114944458008\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 17, Batch: 342/468, discriminator loss real = 4.926855451392598e-11, disciminator loss fake = 2.1435198505059816e-06, generator loss = 14.101338386535645\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 17, Batch: 343/468, discriminator loss real = 9.342048797998336e-17, disciminator loss fake = 3.174803168803919e-06, generator loss = 14.455875396728516\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 17, Batch: 344/468, discriminator loss real = 2.7031259461740224e-19, disciminator loss fake = 2.6376201276434585e-06, generator loss = 14.16232681274414\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 17, Batch: 345/468, discriminator loss real = 2.1022254046345344e-20, disciminator loss fake = 1.442370830773143e-06, generator loss = 14.402867317199707\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 17, Batch: 346/468, discriminator loss real = 1.7805689367378363e-08, disciminator loss fake = 2.0472289179451764e-06, generator loss = 14.289731979370117\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 17, Batch: 347/468, discriminator loss real = 2.9346771494686473e-24, disciminator loss fake = 2.233216946478933e-06, generator loss = 14.311103820800781\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 17, Batch: 348/468, discriminator loss real = 9.395999603367677e-13, disciminator loss fake = 1.986845745705068e-06, generator loss = 14.37914752960205\n",
      "2/2 [==============================] - 0s 166ms/step\n",
      "Epoch: 17, Batch: 349/468, discriminator loss real = 2.40027616670531e-26, disciminator loss fake = 2.394626108070952e-06, generator loss = 14.201729774475098\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 17, Batch: 350/468, discriminator loss real = 6.53272783091019e-11, disciminator loss fake = 2.484281367287622e-06, generator loss = 14.211437225341797\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 17, Batch: 351/468, discriminator loss real = 1.820704144363172e-18, disciminator loss fake = 2.159363702958217e-06, generator loss = 14.406253814697266\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 17, Batch: 352/468, discriminator loss real = 3.041858154251287e-10, disciminator loss fake = 3.966085387219209e-06, generator loss = 14.49267578125\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 17, Batch: 353/468, discriminator loss real = 1.4577375612357833e-15, disciminator loss fake = 1.780092929948296e-06, generator loss = 14.328328132629395\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 17, Batch: 354/468, discriminator loss real = 3.116581137874164e-05, disciminator loss fake = 3.2551181448070565e-06, generator loss = 14.43496036529541\n",
      "2/2 [==============================] - 0s 134ms/step\n",
      "Epoch: 17, Batch: 355/468, discriminator loss real = 4.765661809950049e-14, disciminator loss fake = 2.8589106477738824e-06, generator loss = 13.984987258911133\n",
      "2/2 [==============================] - 0s 134ms/step\n",
      "Epoch: 17, Batch: 356/468, discriminator loss real = 1.239204569621611e-16, disciminator loss fake = 1.9126414372294676e-06, generator loss = 14.379772186279297\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 17, Batch: 357/468, discriminator loss real = 1.2734076707836255e-36, disciminator loss fake = 1.239577613887377e-06, generator loss = 14.24777603149414\n",
      "2/2 [==============================] - 0s 190ms/step\n",
      "Epoch: 17, Batch: 358/468, discriminator loss real = 0.0, disciminator loss fake = 1.6216647509281756e-06, generator loss = 14.10181999206543\n",
      "2/2 [==============================] - 0s 155ms/step\n",
      "Epoch: 17, Batch: 359/468, discriminator loss real = 5.9057004790218515e-15, disciminator loss fake = 4.277677362551913e-06, generator loss = 14.416829109191895\n",
      "2/2 [==============================] - 0s 150ms/step\n",
      "Epoch: 17, Batch: 360/468, discriminator loss real = 1.1556217534320996e-26, disciminator loss fake = 1.5292530406441074e-06, generator loss = 14.242875099182129\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 17, Batch: 361/468, discriminator loss real = 1.7995729536933068e-15, disciminator loss fake = 2.7873547878698446e-06, generator loss = 14.144678115844727\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 17, Batch: 362/468, discriminator loss real = 7.532771568349197e-23, disciminator loss fake = 3.905101948475931e-06, generator loss = 13.810401916503906\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 17, Batch: 363/468, discriminator loss real = 5.8540221518769194e-15, disciminator loss fake = 2.2409540179069154e-06, generator loss = 14.24090576171875\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 17, Batch: 364/468, discriminator loss real = 6.01851207759907e-11, disciminator loss fake = 2.0567501906043617e-06, generator loss = 14.417922973632812\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 17, Batch: 365/468, discriminator loss real = 2.4198433648580167e-14, disciminator loss fake = 1.4795721199334366e-06, generator loss = 14.311258316040039\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 17, Batch: 366/468, discriminator loss real = 1.56943024891702e-18, disciminator loss fake = 4.9726286306395195e-06, generator loss = 14.074442863464355\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 17, Batch: 367/468, discriminator loss real = 3.562897268066486e-18, disciminator loss fake = 2.170694187952904e-06, generator loss = 14.269132614135742\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 17, Batch: 368/468, discriminator loss real = 3.4907862346519616e-26, disciminator loss fake = 8.219983101298567e-06, generator loss = 14.336353302001953\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 17, Batch: 369/468, discriminator loss real = 4.3828171688558645e-32, disciminator loss fake = 2.6926070404442726e-06, generator loss = 14.53016471862793\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 17, Batch: 370/468, discriminator loss real = 4.1738841909966334e-23, disciminator loss fake = 2.5630456548242364e-06, generator loss = 14.264262199401855\n",
      "2/2 [==============================] - 0s 203ms/step\n",
      "Epoch: 17, Batch: 371/468, discriminator loss real = 2.0038660121863697e-26, disciminator loss fake = 2.5119425117736682e-06, generator loss = 14.051287651062012\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 17, Batch: 372/468, discriminator loss real = 1.7281218398079027e-26, disciminator loss fake = 4.639143298845738e-06, generator loss = 14.566341400146484\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 17, Batch: 373/468, discriminator loss real = 9.294660447885786e-18, disciminator loss fake = 2.9492891826521372e-06, generator loss = 14.472655296325684\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 17, Batch: 374/468, discriminator loss real = 3.67285225008906e-26, disciminator loss fake = 2.141827735613333e-06, generator loss = 14.150384902954102\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 17, Batch: 375/468, discriminator loss real = 1.759960293244657e-16, disciminator loss fake = 2.194488160967012e-06, generator loss = 14.374731063842773\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 17, Batch: 376/468, discriminator loss real = 1.726577401304385e-16, disciminator loss fake = 1.987662926694611e-06, generator loss = 14.332023620605469\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 17, Batch: 377/468, discriminator loss real = 1.9028796444408317e-27, disciminator loss fake = 1.9892345335392747e-06, generator loss = 14.104999542236328\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 17, Batch: 378/468, discriminator loss real = 5.105703694845056e-15, disciminator loss fake = 2.496324896128499e-06, generator loss = 14.293004989624023\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 17, Batch: 379/468, discriminator loss real = 2.970376621739038e-15, disciminator loss fake = 2.125037553923903e-06, generator loss = 14.275477409362793\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 17, Batch: 380/468, discriminator loss real = 2.3428651800181353e-15, disciminator loss fake = 2.064604814222548e-06, generator loss = 14.517325401306152\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 17, Batch: 381/468, discriminator loss real = 3.076258662409494e-14, disciminator loss fake = 1.7307452253589872e-06, generator loss = 14.526148796081543\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 17, Batch: 382/468, discriminator loss real = 3.750284709007415e-20, disciminator loss fake = 2.628478796395939e-06, generator loss = 14.498021125793457\n",
      "2/2 [==============================] - 0s 199ms/step\n",
      "Epoch: 17, Batch: 383/468, discriminator loss real = 1.8425847653213978e-11, disciminator loss fake = 2.538661419748678e-06, generator loss = 14.326412200927734\n",
      "2/2 [==============================] - 0s 156ms/step\n",
      "Epoch: 17, Batch: 384/468, discriminator loss real = 7.722000745236655e-16, disciminator loss fake = 2.698266143852379e-06, generator loss = 14.570788383483887\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 17, Batch: 385/468, discriminator loss real = 1.3561859351566758e-31, disciminator loss fake = 1.4779844832446543e-06, generator loss = 14.276700973510742\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 17, Batch: 386/468, discriminator loss real = 3.441836727191734e-14, disciminator loss fake = 1.8567089909993229e-06, generator loss = 14.303719520568848\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 17, Batch: 387/468, discriminator loss real = 2.263128433507477e-32, disciminator loss fake = 1.556086317577865e-06, generator loss = 14.4481201171875\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 17, Batch: 388/468, discriminator loss real = 8.050429212147492e-10, disciminator loss fake = 9.226862857758533e-06, generator loss = 14.29243278503418\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 17, Batch: 389/468, discriminator loss real = 2.8181282463518104e-18, disciminator loss fake = 2.2788383375882404e-06, generator loss = 14.22819995880127\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 17, Batch: 390/468, discriminator loss real = 1.662699879304694e-25, disciminator loss fake = 2.7474252419779077e-06, generator loss = 14.401168823242188\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 17, Batch: 391/468, discriminator loss real = 8.227826586722057e-18, disciminator loss fake = 1.8935476191472844e-06, generator loss = 14.406185150146484\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 17, Batch: 392/468, discriminator loss real = 2.0235661679635086e-07, disciminator loss fake = 1.6603971744189039e-06, generator loss = 14.35551643371582\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 17, Batch: 393/468, discriminator loss real = 1.1603315747256998e-17, disciminator loss fake = 1.387700876875897e-06, generator loss = 14.394002914428711\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 17, Batch: 394/468, discriminator loss real = 2.1403780182516403e-18, disciminator loss fake = 1.4132526757748565e-06, generator loss = 14.4143705368042\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 17, Batch: 395/468, discriminator loss real = 1.3808558523025573e-24, disciminator loss fake = 2.122350451827515e-06, generator loss = 14.171684265136719\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 17, Batch: 396/468, discriminator loss real = 8.254642127819801e-18, disciminator loss fake = 1.9150838852510788e-06, generator loss = 14.661961555480957\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 17, Batch: 397/468, discriminator loss real = 6.122769264038652e-05, disciminator loss fake = 6.402812687156256e-06, generator loss = 14.406354904174805\n",
      "2/2 [==============================] - 0s 187ms/step\n",
      "Epoch: 17, Batch: 398/468, discriminator loss real = 1.718011256104718e-23, disciminator loss fake = 7.109247690095799e-06, generator loss = 14.270123481750488\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 17, Batch: 399/468, discriminator loss real = 1.1372969047941408e-21, disciminator loss fake = 3.406432597330422e-06, generator loss = 14.338127136230469\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 17, Batch: 400/468, discriminator loss real = 1.0282071404482378e-16, disciminator loss fake = 1.7641198155615712e-06, generator loss = 14.512869834899902\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 17, Batch: 401/468, discriminator loss real = 1.9828002666566534e-19, disciminator loss fake = 3.553053829818964e-06, generator loss = 14.289377212524414\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 17, Batch: 402/468, discriminator loss real = 1.547962078571013e-31, disciminator loss fake = 5.389992111304309e-06, generator loss = 14.314522743225098\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 17, Batch: 403/468, discriminator loss real = 8.858677138200155e-16, disciminator loss fake = 1.357590463157976e-06, generator loss = 14.413138389587402\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 17, Batch: 404/468, discriminator loss real = 2.829646778737131e-25, disciminator loss fake = 2.179278453695588e-06, generator loss = 14.280754089355469\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 17, Batch: 405/468, discriminator loss real = 2.5457074950893525e-16, disciminator loss fake = 1.3933236004959326e-06, generator loss = 14.261137008666992\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 17, Batch: 406/468, discriminator loss real = 2.556629562922545e-24, disciminator loss fake = 2.766973921097815e-06, generator loss = 14.263862609863281\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 17, Batch: 407/468, discriminator loss real = 0.0004225880838930607, disciminator loss fake = 2.5788253878999967e-06, generator loss = 14.283647537231445\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 17, Batch: 408/468, discriminator loss real = 6.88806266264911e-17, disciminator loss fake = 2.0890088308078703e-06, generator loss = 14.181852340698242\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 17, Batch: 409/468, discriminator loss real = 5.6855455000685e-31, disciminator loss fake = 2.062458406726364e-06, generator loss = 14.069307327270508\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 17, Batch: 410/468, discriminator loss real = 4.0662026697113607e-14, disciminator loss fake = 4.602695298672188e-06, generator loss = 14.240331649780273\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 17, Batch: 411/468, discriminator loss real = 1.3295164135979467e-16, disciminator loss fake = 2.291785449415329e-06, generator loss = 13.97965145111084\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 17, Batch: 412/468, discriminator loss real = 3.6306954226842097e-29, disciminator loss fake = 4.405927938933019e-06, generator loss = 14.030214309692383\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 17, Batch: 413/468, discriminator loss real = 2.8256433096431344e-25, disciminator loss fake = 2.6310585781175178e-06, generator loss = 14.143109321594238\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 17, Batch: 414/468, discriminator loss real = 3.389657507113443e-15, disciminator loss fake = 3.960878530051559e-06, generator loss = 14.169401168823242\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 17, Batch: 415/468, discriminator loss real = 1.5695788726339702e-23, disciminator loss fake = 2.841312834789278e-06, generator loss = 13.921661376953125\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 17, Batch: 416/468, discriminator loss real = 8.232180399598416e-14, disciminator loss fake = 2.971950834762538e-06, generator loss = 13.792627334594727\n",
      "2/2 [==============================] - 0s 192ms/step\n",
      "Epoch: 17, Batch: 417/468, discriminator loss real = 2.8434345439498083e-29, disciminator loss fake = 2.788000756481779e-06, generator loss = 13.991944313049316\n",
      "2/2 [==============================] - 0s 151ms/step\n",
      "Epoch: 17, Batch: 418/468, discriminator loss real = 4.606431858178439e-08, disciminator loss fake = 5.157480700290762e-06, generator loss = 13.95041275024414\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 17, Batch: 419/468, discriminator loss real = 3.9460386165552227e-20, disciminator loss fake = 7.455911145370919e-06, generator loss = 13.995576858520508\n",
      "2/2 [==============================] - 0s 145ms/step\n",
      "Epoch: 17, Batch: 420/468, discriminator loss real = 3.909743094499132e-19, disciminator loss fake = 6.393217518052552e-06, generator loss = 14.104010581970215\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 17, Batch: 421/468, discriminator loss real = 1.3549739965340253e-23, disciminator loss fake = 3.919962182408199e-06, generator loss = 13.991837501525879\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 17, Batch: 422/468, discriminator loss real = 2.1823483927684205e-24, disciminator loss fake = 2.203637450293172e-06, generator loss = 14.157003402709961\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 17, Batch: 423/468, discriminator loss real = 5.464928504303121e-14, disciminator loss fake = 2.8874605959572364e-06, generator loss = 14.104589462280273\n",
      "2/2 [==============================] - 0s 136ms/step\n",
      "Epoch: 17, Batch: 424/468, discriminator loss real = 2.576128699933603e-18, disciminator loss fake = 3.588441359170247e-06, generator loss = 14.26059341430664\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 17, Batch: 425/468, discriminator loss real = 2.341532621130682e-07, disciminator loss fake = 2.8712645416817395e-06, generator loss = 13.926445007324219\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 17, Batch: 426/468, discriminator loss real = 1.8906891772140465e-14, disciminator loss fake = 2.67292989519774e-06, generator loss = 13.947175979614258\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 17, Batch: 427/468, discriminator loss real = 1.12331648187886e-25, disciminator loss fake = 2.2476624508271925e-06, generator loss = 13.90987491607666\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 17, Batch: 428/468, discriminator loss real = 1.7099414150225145e-29, disciminator loss fake = 2.1044108962087194e-06, generator loss = 13.911099433898926\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 17, Batch: 429/468, discriminator loss real = 1.7802599460016983e-28, disciminator loss fake = 4.675155651057139e-06, generator loss = 13.888994216918945\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 17, Batch: 430/468, discriminator loss real = 2.798263669377472e-17, disciminator loss fake = 2.3823479295970174e-06, generator loss = 14.160694122314453\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 17, Batch: 431/468, discriminator loss real = 6.984061935819564e-15, disciminator loss fake = 5.1538654588512145e-06, generator loss = 14.12855052947998\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 17, Batch: 432/468, discriminator loss real = 1.9330644296644658e-18, disciminator loss fake = 1.8353451878283522e-06, generator loss = 13.922404289245605\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 17, Batch: 433/468, discriminator loss real = 3.53494414729455e-13, disciminator loss fake = 6.463491445174441e-06, generator loss = 14.250226974487305\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 17, Batch: 434/468, discriminator loss real = 5.047278285797999e-29, disciminator loss fake = 2.246367330371868e-06, generator loss = 14.017613410949707\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 17, Batch: 435/468, discriminator loss real = 1.0751583742039149e-19, disciminator loss fake = 3.6815195016970392e-06, generator loss = 13.93265151977539\n",
      "2/2 [==============================] - 0s 172ms/step\n",
      "Epoch: 17, Batch: 436/468, discriminator loss real = 9.103068378097886e-17, disciminator loss fake = 4.09520043831435e-06, generator loss = 14.052373886108398\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 17, Batch: 437/468, discriminator loss real = 6.11824298364129e-14, disciminator loss fake = 1.8745211036730325e-06, generator loss = 14.15921401977539\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 17, Batch: 438/468, discriminator loss real = 5.983635633030246e-29, disciminator loss fake = 2.408178261248395e-06, generator loss = 14.167606353759766\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 17, Batch: 439/468, discriminator loss real = 6.05478539778084e-26, disciminator loss fake = 2.8134895728726406e-06, generator loss = 13.851226806640625\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 17, Batch: 440/468, discriminator loss real = 1.1500037946440567e-16, disciminator loss fake = 2.2814947442384437e-06, generator loss = 14.024957656860352\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 17, Batch: 441/468, discriminator loss real = 1.636650071110829e-13, disciminator loss fake = 2.526310709072277e-06, generator loss = 14.179376602172852\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 17, Batch: 442/468, discriminator loss real = 1.67884305705124e-19, disciminator loss fake = 2.6177790459769312e-06, generator loss = 14.02684497833252\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 17, Batch: 443/468, discriminator loss real = 2.1836029577090388e-23, disciminator loss fake = 4.373142019176157e-06, generator loss = 14.008157730102539\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 17, Batch: 444/468, discriminator loss real = 1.2013595883517228e-18, disciminator loss fake = 3.902477601513965e-06, generator loss = 14.448111534118652\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 17, Batch: 445/468, discriminator loss real = 9.077598697486693e-26, disciminator loss fake = 2.5868480406643357e-06, generator loss = 14.012367248535156\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 17, Batch: 446/468, discriminator loss real = 6.879560660035093e-23, disciminator loss fake = 3.984812792623416e-06, generator loss = 13.922842025756836\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 17, Batch: 447/468, discriminator loss real = 1.1018307759513846e-06, disciminator loss fake = 3.7849204090889543e-06, generator loss = 13.800897598266602\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 17, Batch: 448/468, discriminator loss real = 3.060649156428313e-27, disciminator loss fake = 6.8693752837134525e-06, generator loss = 14.203015327453613\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 17, Batch: 449/468, discriminator loss real = 1.055849098922861e-21, disciminator loss fake = 8.199282092391513e-06, generator loss = 14.119039535522461\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 17, Batch: 450/468, discriminator loss real = 2.9501326401787788e-16, disciminator loss fake = 3.0263995540735777e-06, generator loss = 14.062055587768555\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 17, Batch: 451/468, discriminator loss real = 2.5740473988400403e-11, disciminator loss fake = 4.003977664979175e-06, generator loss = 14.321861267089844\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 17, Batch: 452/468, discriminator loss real = 1.6959088125952796e-27, disciminator loss fake = 1.5228613392537227e-06, generator loss = 14.250223159790039\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 17, Batch: 453/468, discriminator loss real = 3.255179806260777e-11, disciminator loss fake = 2.2577273739443626e-06, generator loss = 14.107905387878418\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 17, Batch: 454/468, discriminator loss real = 6.014830209228978e-26, disciminator loss fake = 1.531222778794472e-06, generator loss = 13.994691848754883\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 17, Batch: 455/468, discriminator loss real = 2.796136396071472e-20, disciminator loss fake = 3.001170853167423e-06, generator loss = 14.20388412475586\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 17, Batch: 456/468, discriminator loss real = 5.697254776306751e-17, disciminator loss fake = 2.1551159079535864e-06, generator loss = 14.220413208007812\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 17, Batch: 457/468, discriminator loss real = 3.959212356383053e-21, disciminator loss fake = 2.1640871636918746e-06, generator loss = 14.232955932617188\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 17, Batch: 458/468, discriminator loss real = 7.893197698323608e-23, disciminator loss fake = 4.809538495464949e-06, generator loss = 14.157892227172852\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 17, Batch: 459/468, discriminator loss real = 2.535325973414184e-14, disciminator loss fake = 3.0730293474334758e-06, generator loss = 13.853214263916016\n",
      "2/2 [==============================] - 0s 208ms/step\n",
      "Epoch: 17, Batch: 460/468, discriminator loss real = 2.7137145934830187e-06, disciminator loss fake = 3.4681086162891006e-06, generator loss = 14.022814750671387\n",
      "2/2 [==============================] - 0s 181ms/step\n",
      "Epoch: 17, Batch: 461/468, discriminator loss real = 1.0930920479647343e-17, disciminator loss fake = 3.7911604522378184e-06, generator loss = 14.284635543823242\n",
      "2/2 [==============================] - 0s 147ms/step\n",
      "Epoch: 17, Batch: 462/468, discriminator loss real = 7.371304885225039e-17, disciminator loss fake = 1.927025323311682e-06, generator loss = 14.338079452514648\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 17, Batch: 463/468, discriminator loss real = 4.097705000249898e-26, disciminator loss fake = 2.3577281353936996e-06, generator loss = 13.852836608886719\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 17, Batch: 464/468, discriminator loss real = 2.381196928524787e-08, disciminator loss fake = 4.258409717294853e-06, generator loss = 14.157665252685547\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 17, Batch: 465/468, discriminator loss real = 2.4657535123931173e-20, disciminator loss fake = 2.096675871143816e-06, generator loss = 14.05753231048584\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 17, Batch: 466/468, discriminator loss real = 6.348680150252794e-27, disciminator loss fake = 1.973897269635927e-06, generator loss = 13.87476921081543\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 17, Batch: 467/468, discriminator loss real = 1.3284707787215215e-18, disciminator loss fake = 3.6567530514730606e-06, generator loss = 14.21474552154541\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 17, Batch: 468/468, discriminator loss real = 6.017560231996589e-22, disciminator loss fake = 2.442523964418797e-06, generator loss = 14.244146347045898\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 18, Batch: 1/468, discriminator loss real = 3.9498249747197957e-23, disciminator loss fake = 2.294482783327112e-06, generator loss = 14.022774696350098\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 18, Batch: 2/468, discriminator loss real = 1.0643899161667472e-31, disciminator loss fake = 4.49431672677747e-06, generator loss = 14.409478187561035\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 18, Batch: 3/468, discriminator loss real = 2.800784825331353e-29, disciminator loss fake = 3.072381105084787e-06, generator loss = 14.095026016235352\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 18, Batch: 4/468, discriminator loss real = 2.4836003831296694e-07, disciminator loss fake = 2.9079237719997764e-06, generator loss = 14.055520057678223\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 18, Batch: 5/468, discriminator loss real = 3.357523521413325e-19, disciminator loss fake = 2.3688569399382686e-06, generator loss = 13.838855743408203\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 18, Batch: 6/468, discriminator loss real = 1.6122526761992023e-15, disciminator loss fake = 2.5247366011171835e-06, generator loss = 13.994087219238281\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 18, Batch: 7/468, discriminator loss real = 4.7277011602100765e-18, disciminator loss fake = 2.5610074771975633e-06, generator loss = 14.561585426330566\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 18, Batch: 8/468, discriminator loss real = 3.508895526238513e-17, disciminator loss fake = 2.714434458539472e-06, generator loss = 14.368562698364258\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 18, Batch: 9/468, discriminator loss real = 1.1395769021368467e-21, disciminator loss fake = 4.255970452504698e-06, generator loss = 13.913543701171875\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 18, Batch: 10/468, discriminator loss real = 5.176574028334427e-18, disciminator loss fake = 1.7264663938476588e-06, generator loss = 14.294485092163086\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 18, Batch: 11/468, discriminator loss real = 9.838270524823336e-21, disciminator loss fake = 3.870619366352912e-06, generator loss = 14.062945365905762\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 18, Batch: 12/468, discriminator loss real = 4.573851273731194e-26, disciminator loss fake = 2.8996873879805207e-06, generator loss = 14.040112495422363\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 18, Batch: 13/468, discriminator loss real = 5.142936315531699e-13, disciminator loss fake = 2.3466009224648587e-06, generator loss = 14.27125358581543\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 18, Batch: 14/468, discriminator loss real = 7.923060558193453e-32, disciminator loss fake = 1.7792481230571866e-06, generator loss = 14.155312538146973\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 18, Batch: 15/468, discriminator loss real = 3.832627271105338e-11, disciminator loss fake = 2.274618736919365e-06, generator loss = 14.190004348754883\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 18, Batch: 16/468, discriminator loss real = 4.2153107481177717e-23, disciminator loss fake = 2.1099926925671753e-06, generator loss = 14.337035179138184\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 18, Batch: 17/468, discriminator loss real = 4.3678237512790466e-23, disciminator loss fake = 4.204427568765823e-06, generator loss = 14.356992721557617\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 18, Batch: 18/468, discriminator loss real = 8.838410992731605e-24, disciminator loss fake = 3.7779996091558132e-06, generator loss = 14.409046173095703\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 18, Batch: 19/468, discriminator loss real = 2.2548615210889927e-19, disciminator loss fake = 1.6320707345585106e-06, generator loss = 14.274280548095703\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 18, Batch: 20/468, discriminator loss real = 1.259720578042163e-26, disciminator loss fake = 5.603051704383688e-06, generator loss = 14.228072166442871\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 18, Batch: 21/468, discriminator loss real = 1.9910478599172166e-08, disciminator loss fake = 1.7104514427046524e-06, generator loss = 14.222853660583496\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 18, Batch: 22/468, discriminator loss real = 6.179780329599964e-18, disciminator loss fake = 2.52542486123275e-06, generator loss = 14.351276397705078\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 18, Batch: 23/468, discriminator loss real = 4.16797173767657e-25, disciminator loss fake = 2.1502842173504177e-06, generator loss = 14.253060340881348\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 18, Batch: 24/468, discriminator loss real = 3.668003915586435e-16, disciminator loss fake = 3.990107870777138e-06, generator loss = 14.383313179016113\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 18, Batch: 25/468, discriminator loss real = 2.1019145177072305e-23, disciminator loss fake = 1.7420076119378791e-06, generator loss = 14.179327011108398\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 18, Batch: 26/468, discriminator loss real = 7.0616917712880145e-28, disciminator loss fake = 1.4025470136402873e-06, generator loss = 14.571372032165527\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 18, Batch: 27/468, discriminator loss real = 3.493952746287169e-21, disciminator loss fake = 1.7221927919308655e-06, generator loss = 14.157349586486816\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 18, Batch: 28/468, discriminator loss real = 1.5966206831576242e-14, disciminator loss fake = 4.012289991806028e-06, generator loss = 14.510005950927734\n",
      "2/2 [==============================] - 0s 200ms/step\n",
      "Epoch: 18, Batch: 29/468, discriminator loss real = 7.232972224703892e-19, disciminator loss fake = 7.372560048679588e-06, generator loss = 14.521408081054688\n",
      "2/2 [==============================] - 0s 205ms/step\n",
      "Epoch: 18, Batch: 30/468, discriminator loss real = 9.515723416080292e-26, disciminator loss fake = 1.2254155308255577e-06, generator loss = 14.401187896728516\n",
      "2/2 [==============================] - 0s 170ms/step\n",
      "Epoch: 18, Batch: 31/468, discriminator loss real = 5.178651947798612e-25, disciminator loss fake = 2.8641088647418655e-06, generator loss = 14.594486236572266\n",
      "2/2 [==============================] - 0s 182ms/step\n",
      "Epoch: 18, Batch: 32/468, discriminator loss real = 7.832970654699557e-21, disciminator loss fake = 2.278174861203297e-06, generator loss = 14.500410079956055\n",
      "2/2 [==============================] - 0s 185ms/step\n",
      "Epoch: 18, Batch: 33/468, discriminator loss real = 4.9696281811950627e-11, disciminator loss fake = 4.747066668642219e-06, generator loss = 14.508880615234375\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 18, Batch: 34/468, discriminator loss real = 7.8998117052141325e-28, disciminator loss fake = 3.323837972857291e-06, generator loss = 14.327041625976562\n",
      "2/2 [==============================] - 0s 134ms/step\n",
      "Epoch: 18, Batch: 35/468, discriminator loss real = 1.7186122723909586e-18, disciminator loss fake = 1.5863602129684296e-06, generator loss = 14.308280944824219\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 18, Batch: 36/468, discriminator loss real = 1.1015273049793051e-17, disciminator loss fake = 3.312512262709788e-06, generator loss = 14.018043518066406\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 18, Batch: 37/468, discriminator loss real = 1.6177937963335505e-14, disciminator loss fake = 1.75608579411346e-06, generator loss = 14.064423561096191\n",
      "2/2 [==============================] - 0s 195ms/step\n",
      "Epoch: 18, Batch: 38/468, discriminator loss real = 1.111899752814026e-16, disciminator loss fake = 4.361227638582932e-06, generator loss = 14.378778457641602\n",
      "2/2 [==============================] - 0s 212ms/step\n",
      "Epoch: 18, Batch: 39/468, discriminator loss real = 0.0002518277324270457, disciminator loss fake = 2.4251094146165997e-06, generator loss = 14.46755599975586\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 18, Batch: 40/468, discriminator loss real = 7.150531067762709e-24, disciminator loss fake = 2.5594877115509007e-06, generator loss = 14.23539924621582\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 18, Batch: 41/468, discriminator loss real = 1.6690163169717913e-21, disciminator loss fake = 2.9600021207443206e-06, generator loss = 14.309011459350586\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 18, Batch: 42/468, discriminator loss real = 3.1982304503071034e-25, disciminator loss fake = 3.2221473702520598e-06, generator loss = 14.301271438598633\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 18, Batch: 43/468, discriminator loss real = 2.38365825997793e-20, disciminator loss fake = 2.0867923922196496e-06, generator loss = 14.106819152832031\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 18, Batch: 44/468, discriminator loss real = 1.134529908904762e-19, disciminator loss fake = 3.965629730373621e-06, generator loss = 14.342259407043457\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 18, Batch: 45/468, discriminator loss real = 3.995692123524852e-13, disciminator loss fake = 5.9282374422764406e-06, generator loss = 14.175739288330078\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 18, Batch: 46/468, discriminator loss real = 2.99958499617119e-18, disciminator loss fake = 3.560142431524582e-06, generator loss = 13.992349624633789\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 18, Batch: 47/468, discriminator loss real = 1.6866884774203934e-18, disciminator loss fake = 1.3269914234115276e-06, generator loss = 13.9849271774292\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 18, Batch: 48/468, discriminator loss real = 2.8176037349635086e-13, disciminator loss fake = 4.351679308456369e-06, generator loss = 14.114992141723633\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 18, Batch: 49/468, discriminator loss real = 3.117727374046808e-06, disciminator loss fake = 2.0811162357858848e-06, generator loss = 14.343690872192383\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 18, Batch: 50/468, discriminator loss real = 2.9165539668841766e-27, disciminator loss fake = 3.6323813219496515e-06, generator loss = 14.351560592651367\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 18, Batch: 51/468, discriminator loss real = 6.31547723121159e-15, disciminator loss fake = 2.4391374608967453e-06, generator loss = 14.201277732849121\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 18, Batch: 52/468, discriminator loss real = 2.8935579719992283e-24, disciminator loss fake = 3.4213599064969458e-06, generator loss = 14.006681442260742\n",
      "2/2 [==============================] - 0s 209ms/step\n",
      "Epoch: 18, Batch: 53/468, discriminator loss real = 2.1305797116676543e-29, disciminator loss fake = 2.2136528059490956e-06, generator loss = 14.24426555633545\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 18, Batch: 54/468, discriminator loss real = 8.059157842377595e-17, disciminator loss fake = 2.5016843210323714e-06, generator loss = 14.265029907226562\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 18, Batch: 55/468, discriminator loss real = 1.3857944737536045e-16, disciminator loss fake = 5.044787030783482e-06, generator loss = 14.234251976013184\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 18, Batch: 56/468, discriminator loss real = 1.8595705179136833e-20, disciminator loss fake = 1.6276717360597104e-06, generator loss = 14.196495056152344\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 18, Batch: 57/468, discriminator loss real = 7.890558581204586e-20, disciminator loss fake = 1.6346740494554979e-06, generator loss = 14.112936019897461\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 18, Batch: 58/468, discriminator loss real = 1.496048161645297e-18, disciminator loss fake = 1.4251729680836434e-06, generator loss = 14.192055702209473\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 18, Batch: 59/468, discriminator loss real = 9.193264002164182e-20, disciminator loss fake = 4.866712515649851e-06, generator loss = 14.048169136047363\n",
      "2/2 [==============================] - 0s 191ms/step\n",
      "Epoch: 18, Batch: 60/468, discriminator loss real = 3.954774682469605e-24, disciminator loss fake = 3.674440222312114e-06, generator loss = 14.101820945739746\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 18, Batch: 61/468, discriminator loss real = 6.0065659043817554e-12, disciminator loss fake = 2.0915158529533073e-06, generator loss = 13.836943626403809\n",
      "2/2 [==============================] - 0s 145ms/step\n",
      "Epoch: 18, Batch: 62/468, discriminator loss real = 1.3933258539692263e-17, disciminator loss fake = 2.137626324838493e-06, generator loss = 14.303369522094727\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 18, Batch: 63/468, discriminator loss real = 4.520247606847144e-21, disciminator loss fake = 2.2086592252890114e-06, generator loss = 14.075698852539062\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 18, Batch: 64/468, discriminator loss real = 7.72031405779321e-18, disciminator loss fake = 1.8184639429819072e-06, generator loss = 14.183629989624023\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 18, Batch: 65/468, discriminator loss real = 1.6357202051175967e-12, disciminator loss fake = 1.3834678611601703e-06, generator loss = 14.37759780883789\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 18, Batch: 66/468, discriminator loss real = 8.00586258264957e-06, disciminator loss fake = 2.432064775348408e-06, generator loss = 14.136697769165039\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 18, Batch: 67/468, discriminator loss real = 7.50239286008361e-31, disciminator loss fake = 2.219093858002452e-06, generator loss = 14.314240455627441\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 18, Batch: 68/468, discriminator loss real = 5.811129595705417e-22, disciminator loss fake = 1.0507019396754913e-05, generator loss = 14.151985168457031\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 18, Batch: 69/468, discriminator loss real = 2.5806039163217553e-12, disciminator loss fake = 2.5380547867825953e-06, generator loss = 13.96487808227539\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 18, Batch: 70/468, discriminator loss real = 4.536169805479138e-17, disciminator loss fake = 4.260985861037625e-06, generator loss = 14.301748275756836\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 18, Batch: 71/468, discriminator loss real = 5.744834729454196e-12, disciminator loss fake = 3.8366724766092375e-06, generator loss = 14.580522537231445\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 18, Batch: 72/468, discriminator loss real = 1.142105876603015e-22, disciminator loss fake = 3.2928649034147384e-06, generator loss = 14.19283676147461\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 18, Batch: 73/468, discriminator loss real = 2.8390075257835677e-18, disciminator loss fake = 2.373027200519573e-06, generator loss = 14.120311737060547\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 18, Batch: 74/468, discriminator loss real = 9.680492793353805e-25, disciminator loss fake = 2.573621259216452e-06, generator loss = 14.323078155517578\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 18, Batch: 75/468, discriminator loss real = 1.4793817284213502e-21, disciminator loss fake = 4.644596629077569e-06, generator loss = 14.107376098632812\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 18, Batch: 76/468, discriminator loss real = 4.512505574361037e-18, disciminator loss fake = 1.548778300275444e-06, generator loss = 14.18613052368164\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 18, Batch: 77/468, discriminator loss real = 6.8841017142416e-14, disciminator loss fake = 3.7317743135645287e-06, generator loss = 14.137981414794922\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 18, Batch: 78/468, discriminator loss real = 8.61208087423726e-30, disciminator loss fake = 1.9284798327134922e-06, generator loss = 14.277242660522461\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 18, Batch: 79/468, discriminator loss real = 7.073946078338162e-27, disciminator loss fake = 2.5785539037315175e-06, generator loss = 14.291810989379883\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 18, Batch: 80/468, discriminator loss real = 1.2023322615295484e-10, disciminator loss fake = 2.684778564798762e-06, generator loss = 14.269991874694824\n",
      "2/2 [==============================] - 0s 208ms/step\n",
      "Epoch: 18, Batch: 81/468, discriminator loss real = 1.2201218437622578e-16, disciminator loss fake = 4.1506655179546215e-06, generator loss = 14.304910659790039\n",
      "2/2 [==============================] - 0s 191ms/step\n",
      "Epoch: 18, Batch: 82/468, discriminator loss real = 2.1166205622241436e-15, disciminator loss fake = 2.708168267417932e-06, generator loss = 14.262450218200684\n",
      "2/2 [==============================] - 0s 147ms/step\n",
      "Epoch: 18, Batch: 83/468, discriminator loss real = 6.401301150526237e-16, disciminator loss fake = 1.0528494840400526e-06, generator loss = 14.394082069396973\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 18, Batch: 84/468, discriminator loss real = 9.670806844847734e-28, disciminator loss fake = 1.5499012988584582e-06, generator loss = 14.104312896728516\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 18, Batch: 85/468, discriminator loss real = 1.5492839911063883e-26, disciminator loss fake = 2.5592137262719916e-06, generator loss = 14.17963981628418\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 18, Batch: 86/468, discriminator loss real = 3.5335047388063145e-11, disciminator loss fake = 2.1531959646381438e-06, generator loss = 14.136963844299316\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 18, Batch: 87/468, discriminator loss real = 5.671253551614028e-26, disciminator loss fake = 2.596133299448411e-06, generator loss = 14.118321418762207\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 18, Batch: 88/468, discriminator loss real = 9.581617674186557e-19, disciminator loss fake = 1.4549074194292189e-06, generator loss = 14.305898666381836\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 18, Batch: 89/468, discriminator loss real = 1.6340352467860348e-17, disciminator loss fake = 2.5374715733050834e-06, generator loss = 14.188950538635254\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 18, Batch: 90/468, discriminator loss real = 7.104498667865218e-19, disciminator loss fake = 3.5985533486382337e-06, generator loss = 14.047706604003906\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 18, Batch: 91/468, discriminator loss real = 4.544911171866063e-26, disciminator loss fake = 2.4478076738887466e-06, generator loss = 14.100260734558105\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 18, Batch: 92/468, discriminator loss real = 2.6430363452892e-16, disciminator loss fake = 2.0718273390230024e-06, generator loss = 14.051810264587402\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 18, Batch: 93/468, discriminator loss real = 1.0942653901058197e-11, disciminator loss fake = 2.652566763572395e-06, generator loss = 14.216331481933594\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 18, Batch: 94/468, discriminator loss real = 2.4063302612335013e-23, disciminator loss fake = 3.0578826226701494e-06, generator loss = 14.332847595214844\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 18, Batch: 95/468, discriminator loss real = 6.986745400038007e-22, disciminator loss fake = 4.727489795186557e-06, generator loss = 14.118358612060547\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 18, Batch: 96/468, discriminator loss real = 1.0436442508809929e-11, disciminator loss fake = 1.7100103377742926e-06, generator loss = 14.385876655578613\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 18, Batch: 97/468, discriminator loss real = 1.3824283118816567e-16, disciminator loss fake = 1.7593395114090526e-06, generator loss = 14.043354034423828\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 18, Batch: 98/468, discriminator loss real = 8.53699383099374e-29, disciminator loss fake = 1.3888429748476483e-06, generator loss = 14.616423606872559\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 18, Batch: 99/468, discriminator loss real = 3.1553221287315785e-20, disciminator loss fake = 2.44843272412254e-06, generator loss = 14.178099632263184\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 18, Batch: 100/468, discriminator loss real = 4.741649788133904e-22, disciminator loss fake = 2.3626782876817742e-06, generator loss = 14.243958473205566\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 18, Batch: 101/468, discriminator loss real = 6.366570898946877e-12, disciminator loss fake = 9.536043762636837e-06, generator loss = 14.532011985778809\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 18, Batch: 102/468, discriminator loss real = 1.8299840283926374e-21, disciminator loss fake = 2.2175590856932104e-06, generator loss = 14.255354881286621\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 18, Batch: 103/468, discriminator loss real = 4.718876793749803e-24, disciminator loss fake = 2.51717074206681e-06, generator loss = 14.362129211425781\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 18, Batch: 104/468, discriminator loss real = 1.193881365296745e-12, disciminator loss fake = 2.1818893856107024e-06, generator loss = 14.482882499694824\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 18, Batch: 105/468, discriminator loss real = 4.1463327505652464e-23, disciminator loss fake = 3.208219368389109e-06, generator loss = 14.587160110473633\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 18, Batch: 106/468, discriminator loss real = 2.894025870645664e-21, disciminator loss fake = 1.951782905962318e-06, generator loss = 14.512535095214844\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 18, Batch: 107/468, discriminator loss real = 1.032427256386239e-26, disciminator loss fake = 2.1198375179665163e-06, generator loss = 14.358695983886719\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 18, Batch: 108/468, discriminator loss real = 3.0540799940702345e-16, disciminator loss fake = 5.607959792541806e-06, generator loss = 14.158462524414062\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 18, Batch: 109/468, discriminator loss real = 2.741498208555504e-20, disciminator loss fake = 2.031860503848293e-06, generator loss = 14.290446281433105\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 18, Batch: 110/468, discriminator loss real = 2.3697888483302453e-21, disciminator loss fake = 3.133617155981483e-06, generator loss = 14.296398162841797\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 18, Batch: 111/468, discriminator loss real = 1.2283324385224591e-17, disciminator loss fake = 2.0968341232219245e-06, generator loss = 14.359695434570312\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 18, Batch: 112/468, discriminator loss real = 2.7192022013789905e-19, disciminator loss fake = 1.8207210814580321e-06, generator loss = 14.444204330444336\n",
      "2/2 [==============================] - 0s 203ms/step\n",
      "Epoch: 18, Batch: 113/468, discriminator loss real = 1.5892833604911746e-27, disciminator loss fake = 3.2558475595578784e-06, generator loss = 14.26656723022461\n",
      "2/2 [==============================] - 0s 182ms/step\n",
      "Epoch: 18, Batch: 114/468, discriminator loss real = 3.4428959249516167e-13, disciminator loss fake = 3.138927240797784e-06, generator loss = 14.243570327758789\n",
      "2/2 [==============================] - 0s 164ms/step\n",
      "Epoch: 18, Batch: 115/468, discriminator loss real = 1.6615008277681537e-20, disciminator loss fake = 3.6790340800507693e-06, generator loss = 14.293739318847656\n",
      "2/2 [==============================] - 0s 146ms/step\n",
      "Epoch: 18, Batch: 116/468, discriminator loss real = 9.63574334899604e-22, disciminator loss fake = 1.7973857211472932e-06, generator loss = 14.407552719116211\n",
      "2/2 [==============================] - 0s 163ms/step\n",
      "Epoch: 18, Batch: 117/468, discriminator loss real = 2.792061363265431e-15, disciminator loss fake = 1.950534169736784e-06, generator loss = 14.355572700500488\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 18, Batch: 118/468, discriminator loss real = 2.761956753528829e-15, disciminator loss fake = 2.850851842595148e-06, generator loss = 14.395469665527344\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 18, Batch: 119/468, discriminator loss real = 1.140213184286365e-11, disciminator loss fake = 3.16870409733383e-06, generator loss = 14.290236473083496\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 18, Batch: 120/468, discriminator loss real = 5.24810717886931e-13, disciminator loss fake = 1.976613020815421e-06, generator loss = 14.642668724060059\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 18, Batch: 121/468, discriminator loss real = 7.847747021421292e-17, disciminator loss fake = 1.8961915202453383e-06, generator loss = 14.1627836227417\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 18, Batch: 122/468, discriminator loss real = 8.04872051711307e-15, disciminator loss fake = 1.5662694750062656e-06, generator loss = 14.44875717163086\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 18, Batch: 123/468, discriminator loss real = 1.7326823650022735e-22, disciminator loss fake = 2.9791290216962807e-06, generator loss = 14.680717468261719\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 18, Batch: 124/468, discriminator loss real = 9.725211608246909e-11, disciminator loss fake = 3.400563855393557e-06, generator loss = 14.621167182922363\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 18, Batch: 125/468, discriminator loss real = 5.474859062815085e-05, disciminator loss fake = 2.240342837467324e-06, generator loss = 14.225142478942871\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 18, Batch: 126/468, discriminator loss real = 3.08819234019677e-14, disciminator loss fake = 2.322828095202567e-06, generator loss = 14.609234809875488\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 18, Batch: 127/468, discriminator loss real = 2.5754909316333396e-09, disciminator loss fake = 1.4751044545846526e-06, generator loss = 14.435702323913574\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 18, Batch: 128/468, discriminator loss real = 1.9071236187359027e-23, disciminator loss fake = 1.561621957080206e-06, generator loss = 14.629433631896973\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 18, Batch: 129/468, discriminator loss real = 1.1159544433973418e-22, disciminator loss fake = 1.8010887288255617e-06, generator loss = 14.346399307250977\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 18, Batch: 130/468, discriminator loss real = 2.7089552818767543e-27, disciminator loss fake = 2.182159505537129e-06, generator loss = 14.214960098266602\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 18, Batch: 131/468, discriminator loss real = 2.9740958780166693e-06, disciminator loss fake = 2.415687049506232e-06, generator loss = 14.558578491210938\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 18, Batch: 132/468, discriminator loss real = 7.135801638469275e-08, disciminator loss fake = 1.711099685053341e-06, generator loss = 14.19898796081543\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 18, Batch: 133/468, discriminator loss real = 1.94016949753599e-18, disciminator loss fake = 1.1490373026390444e-06, generator loss = 14.31202507019043\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 18, Batch: 134/468, discriminator loss real = 2.301917223464127e-24, disciminator loss fake = 2.1573341655312106e-06, generator loss = 14.343461036682129\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 18, Batch: 135/468, discriminator loss real = 3.192682906905212e-17, disciminator loss fake = 4.142403668083716e-06, generator loss = 14.368705749511719\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 18, Batch: 136/468, discriminator loss real = 1.94555692221857e-14, disciminator loss fake = 2.3929464987304527e-06, generator loss = 14.50102424621582\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 18, Batch: 137/468, discriminator loss real = 7.95294819583292e-15, disciminator loss fake = 1.1302236089250073e-06, generator loss = 14.256278991699219\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 18, Batch: 138/468, discriminator loss real = 1.6053473925626421e-13, disciminator loss fake = 4.470195563044399e-06, generator loss = 14.285466194152832\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 18, Batch: 139/468, discriminator loss real = 2.3476688799029375e-29, disciminator loss fake = 1.9152803361066617e-06, generator loss = 14.411136627197266\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 18, Batch: 140/468, discriminator loss real = 8.806918287059783e-32, disciminator loss fake = 2.442323420837056e-06, generator loss = 14.476381301879883\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 18, Batch: 141/468, discriminator loss real = 3.013052047445841e-13, disciminator loss fake = 1.7636223219597014e-06, generator loss = 14.248960494995117\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 18, Batch: 142/468, discriminator loss real = 4.488663034862839e-05, disciminator loss fake = 3.585613740142435e-06, generator loss = 14.196002960205078\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 18, Batch: 143/468, discriminator loss real = 8.19429107526145e-24, disciminator loss fake = 2.7482715267979074e-06, generator loss = 14.422842025756836\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 18, Batch: 144/468, discriminator loss real = 5.49193428301914e-29, disciminator loss fake = 1.5745661130495137e-06, generator loss = 14.244926452636719\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 18, Batch: 145/468, discriminator loss real = 5.880468638072567e-14, disciminator loss fake = 1.9024155335500836e-06, generator loss = 14.614553451538086\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 18, Batch: 146/468, discriminator loss real = 9.830139953325051e-18, disciminator loss fake = 1.8538995618655463e-06, generator loss = 14.29456901550293\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 18, Batch: 147/468, discriminator loss real = 5.894306160589319e-20, disciminator loss fake = 2.812919319694629e-06, generator loss = 14.543521881103516\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 18, Batch: 148/468, discriminator loss real = 2.012737381689114e-24, disciminator loss fake = 1.7730366153045907e-06, generator loss = 14.522248268127441\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 18, Batch: 149/468, discriminator loss real = 2.917371023951056e-20, disciminator loss fake = 1.8681912479223683e-06, generator loss = 14.63609504699707\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 18, Batch: 150/468, discriminator loss real = 1.1820666651453718e-15, disciminator loss fake = 2.4921873773564585e-06, generator loss = 14.370819091796875\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 18, Batch: 151/468, discriminator loss real = 2.018592049068957e-08, disciminator loss fake = 1.971137862710748e-06, generator loss = 14.42058277130127\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 18, Batch: 152/468, discriminator loss real = 6.540267633026176e-11, disciminator loss fake = 3.84242957807146e-06, generator loss = 14.040729522705078\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 18, Batch: 153/468, discriminator loss real = 3.879348878399469e-05, disciminator loss fake = 1.799722554096661e-06, generator loss = 14.13729476928711\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 18, Batch: 154/468, discriminator loss real = 1.0136723965134006e-27, disciminator loss fake = 2.73584828391904e-06, generator loss = 14.350727081298828\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 18, Batch: 155/468, discriminator loss real = 5.799625009980159e-25, disciminator loss fake = 1.3838393897458445e-06, generator loss = 14.598670959472656\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 18, Batch: 156/468, discriminator loss real = 7.068842530573237e-19, disciminator loss fake = 2.5648600967542734e-06, generator loss = 14.335565567016602\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 18, Batch: 157/468, discriminator loss real = 1.6931382518237115e-08, disciminator loss fake = 1.9817334759864025e-06, generator loss = 14.558542251586914\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 18, Batch: 158/468, discriminator loss real = 4.558959934164439e-19, disciminator loss fake = 2.3927227630338166e-06, generator loss = 14.242879867553711\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 18, Batch: 159/468, discriminator loss real = 9.94223636801094e-19, disciminator loss fake = 4.004311449534725e-06, generator loss = 14.628591537475586\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 18, Batch: 160/468, discriminator loss real = 7.531364516595599e-25, disciminator loss fake = 1.6811587784104631e-06, generator loss = 14.626581192016602\n",
      "2/2 [==============================] - 0s 144ms/step\n",
      "Epoch: 18, Batch: 161/468, discriminator loss real = 1.7480657399394567e-28, disciminator loss fake = 1.8428515886625974e-06, generator loss = 14.217144012451172\n",
      "2/2 [==============================] - 0s 172ms/step\n",
      "Epoch: 18, Batch: 162/468, discriminator loss real = 8.867194369495655e-30, disciminator loss fake = 3.1573263186146505e-06, generator loss = 14.309812545776367\n",
      "2/2 [==============================] - 0s 166ms/step\n",
      "Epoch: 18, Batch: 163/468, discriminator loss real = 3.541399056799838e-22, disciminator loss fake = 1.7132040284195682e-06, generator loss = 14.479140281677246\n",
      "2/2 [==============================] - 0s 166ms/step\n",
      "Epoch: 18, Batch: 164/468, discriminator loss real = 1.7077124058161214e-25, disciminator loss fake = 9.022400035973988e-07, generator loss = 14.603178024291992\n",
      "2/2 [==============================] - 0s 156ms/step\n",
      "Epoch: 18, Batch: 165/468, discriminator loss real = 3.5708365689922997e-22, disciminator loss fake = 2.4469097752444213e-06, generator loss = 14.44607162475586\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 18, Batch: 166/468, discriminator loss real = 7.673377877690706e-16, disciminator loss fake = 1.5052060007292312e-06, generator loss = 14.318824768066406\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 18, Batch: 167/468, discriminator loss real = 8.940581693377889e-25, disciminator loss fake = 2.8638344247156056e-06, generator loss = 14.23886489868164\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 18, Batch: 168/468, discriminator loss real = 2.050382336845849e-23, disciminator loss fake = 3.380337830094504e-06, generator loss = 14.232152938842773\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 18, Batch: 169/468, discriminator loss real = 1.3789220970552055e-21, disciminator loss fake = 3.2163659398065647e-06, generator loss = 14.315299034118652\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 18, Batch: 170/468, discriminator loss real = 5.246005138405415e-26, disciminator loss fake = 1.7250076780328527e-06, generator loss = 14.466816902160645\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 18, Batch: 171/468, discriminator loss real = 2.6050374215714124e-17, disciminator loss fake = 1.7553370526002254e-06, generator loss = 14.508634567260742\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 18, Batch: 172/468, discriminator loss real = 1.0981887621497322e-09, disciminator loss fake = 1.6474945141453645e-06, generator loss = 14.336830139160156\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 18, Batch: 173/468, discriminator loss real = 1.6879923622997934e-25, disciminator loss fake = 1.9552330741134938e-06, generator loss = 14.502984046936035\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 18, Batch: 174/468, discriminator loss real = 1.7675635177738513e-08, disciminator loss fake = 1.4365696188178845e-06, generator loss = 14.543928146362305\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 18, Batch: 175/468, discriminator loss real = 7.504062475571782e-12, disciminator loss fake = 2.397327079961542e-06, generator loss = 14.181924819946289\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 18, Batch: 176/468, discriminator loss real = 1.5882310708881603e-26, disciminator loss fake = 1.5252160210366128e-06, generator loss = 14.298910140991211\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 18, Batch: 177/468, discriminator loss real = 1.2274353595055454e-35, disciminator loss fake = 1.2061580036970554e-06, generator loss = 14.570531845092773\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 18, Batch: 178/468, discriminator loss real = 3.3734488161565023e-19, disciminator loss fake = 1.279827301914338e-06, generator loss = 14.353378295898438\n",
      "2/2 [==============================] - 0s 163ms/step\n",
      "Epoch: 18, Batch: 179/468, discriminator loss real = 1.1758632920866629e-21, disciminator loss fake = 1.6566351632718579e-06, generator loss = 14.578044891357422\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 18, Batch: 180/468, discriminator loss real = 2.1463225000249644e-19, disciminator loss fake = 2.101262907672208e-06, generator loss = 14.347732543945312\n",
      "2/2 [==============================] - 0s 163ms/step\n",
      "Epoch: 18, Batch: 181/468, discriminator loss real = 4.130344748826951e-23, disciminator loss fake = 3.314517471153522e-06, generator loss = 14.236589431762695\n",
      "2/2 [==============================] - 0s 183ms/step\n",
      "Epoch: 18, Batch: 182/468, discriminator loss real = 8.522653238793743e-15, disciminator loss fake = 1.4168001598591218e-06, generator loss = 14.507881164550781\n",
      "2/2 [==============================] - 0s 201ms/step\n",
      "Epoch: 18, Batch: 183/468, discriminator loss real = 1.5308348528695823e-14, disciminator loss fake = 1.4083915402807179e-06, generator loss = 14.692163467407227\n",
      "2/2 [==============================] - 0s 181ms/step\n",
      "Epoch: 18, Batch: 184/468, discriminator loss real = 3.435889065293961e-27, disciminator loss fake = 1.072023223969154e-06, generator loss = 14.43006706237793\n",
      "2/2 [==============================] - 0s 174ms/step\n",
      "Epoch: 18, Batch: 185/468, discriminator loss real = 3.156940623922312e-20, disciminator loss fake = 3.799201294896193e-06, generator loss = 14.482131958007812\n",
      "2/2 [==============================] - 0s 165ms/step\n",
      "Epoch: 18, Batch: 186/468, discriminator loss real = 3.0258663146685753e-25, disciminator loss fake = 3.96113546230481e-06, generator loss = 14.240257263183594\n",
      "2/2 [==============================] - 0s 192ms/step\n",
      "Epoch: 18, Batch: 187/468, discriminator loss real = 5.695366951625558e-16, disciminator loss fake = 6.8846557041979395e-06, generator loss = 14.356197357177734\n",
      "2/2 [==============================] - 0s 166ms/step\n",
      "Epoch: 18, Batch: 188/468, discriminator loss real = 3.781442473329706e-29, disciminator loss fake = 1.801418989089143e-06, generator loss = 14.50311279296875\n",
      "2/2 [==============================] - 0s 186ms/step\n",
      "Epoch: 18, Batch: 189/468, discriminator loss real = 2.1500218281289563e-05, disciminator loss fake = 2.477033831382869e-06, generator loss = 14.286846160888672\n",
      "2/2 [==============================] - 0s 171ms/step\n",
      "Epoch: 18, Batch: 190/468, discriminator loss real = 4.149043084875894e-15, disciminator loss fake = 1.246210558747407e-06, generator loss = 14.638463973999023\n",
      "2/2 [==============================] - 0s 197ms/step\n",
      "Epoch: 18, Batch: 191/468, discriminator loss real = 9.790716013557262e-26, disciminator loss fake = 2.9500238269974943e-06, generator loss = 14.388914108276367\n",
      "2/2 [==============================] - 0s 195ms/step\n",
      "Epoch: 18, Batch: 192/468, discriminator loss real = 1.1661620406096404e-27, disciminator loss fake = 1.598352127984981e-06, generator loss = 14.484284400939941\n",
      "2/2 [==============================] - 0s 186ms/step\n",
      "Epoch: 18, Batch: 193/468, discriminator loss real = 8.456781941390545e-09, disciminator loss fake = 1.679584897829045e-06, generator loss = 14.619848251342773\n",
      "2/2 [==============================] - 0s 177ms/step\n",
      "Epoch: 18, Batch: 194/468, discriminator loss real = 1.3892018034645693e-25, disciminator loss fake = 2.2220756363822147e-06, generator loss = 14.543240547180176\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 18, Batch: 195/468, discriminator loss real = 1.9484999805454524e-15, disciminator loss fake = 1.9171525309502613e-06, generator loss = 14.544561386108398\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 18, Batch: 196/468, discriminator loss real = 1.6509489031308824e-21, disciminator loss fake = 1.614122993487399e-06, generator loss = 14.388999938964844\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 18, Batch: 197/468, discriminator loss real = 1.353665985727448e-13, disciminator loss fake = 1.6978002577161533e-06, generator loss = 14.313432693481445\n",
      "2/2 [==============================] - 0s 146ms/step\n",
      "Epoch: 18, Batch: 198/468, discriminator loss real = 3.5122710319426603e-15, disciminator loss fake = 2.8736535568896215e-06, generator loss = 14.176777839660645\n",
      "2/2 [==============================] - 0s 153ms/step\n",
      "Epoch: 18, Batch: 199/468, discriminator loss real = 1.1539767622373298e-12, disciminator loss fake = 1.9189092199667357e-06, generator loss = 14.58987045288086\n",
      "2/2 [==============================] - 0s 136ms/step\n",
      "Epoch: 18, Batch: 200/468, discriminator loss real = 2.4782665730102875e-15, disciminator loss fake = 3.7249078559398185e-06, generator loss = 14.414678573608398\n",
      "2/2 [==============================] - 0s 144ms/step\n",
      "Epoch: 18, Batch: 201/468, discriminator loss real = 3.439022379838036e-21, disciminator loss fake = 2.84074440060067e-06, generator loss = 14.403090476989746\n",
      "2/2 [==============================] - 0s 141ms/step\n",
      "Epoch: 18, Batch: 202/468, discriminator loss real = 2.6156035951055933e-16, disciminator loss fake = 1.3628477972815745e-06, generator loss = 14.465654373168945\n",
      "2/2 [==============================] - 0s 159ms/step\n",
      "Epoch: 18, Batch: 203/468, discriminator loss real = 8.017535328875451e-21, disciminator loss fake = 3.6911503684677882e-06, generator loss = 14.727441787719727\n",
      "2/2 [==============================] - 0s 182ms/step\n",
      "Epoch: 18, Batch: 204/468, discriminator loss real = 6.244883082873187e-13, disciminator loss fake = 2.0190179839119082e-06, generator loss = 14.212906837463379\n",
      "2/2 [==============================] - 0s 164ms/step\n",
      "Epoch: 18, Batch: 205/468, discriminator loss real = 1.0039116795328917e-18, disciminator loss fake = 2.8467688935052138e-06, generator loss = 14.381717681884766\n",
      "2/2 [==============================] - 0s 170ms/step\n",
      "Epoch: 18, Batch: 206/468, discriminator loss real = 5.315760035759686e-23, disciminator loss fake = 4.635211553249974e-06, generator loss = 14.64879322052002\n",
      "2/2 [==============================] - 0s 176ms/step\n",
      "Epoch: 18, Batch: 207/468, discriminator loss real = 2.834217972346706e-31, disciminator loss fake = 1.3383105397224426e-06, generator loss = 14.718403816223145\n",
      "2/2 [==============================] - 0s 199ms/step\n",
      "Epoch: 18, Batch: 208/468, discriminator loss real = 6.8153860953331e-30, disciminator loss fake = 3.4274048630322795e-06, generator loss = 14.214788436889648\n",
      "2/2 [==============================] - 0s 173ms/step\n",
      "Epoch: 18, Batch: 209/468, discriminator loss real = 5.202850942375254e-21, disciminator loss fake = 1.4232705325412098e-06, generator loss = 14.645214080810547\n",
      "2/2 [==============================] - 0s 187ms/step\n",
      "Epoch: 18, Batch: 210/468, discriminator loss real = 8.666992123984585e-10, disciminator loss fake = 1.828386416491412e-06, generator loss = 14.511837005615234\n",
      "2/2 [==============================] - 0s 168ms/step\n",
      "Epoch: 18, Batch: 211/468, discriminator loss real = 9.851292004370293e-10, disciminator loss fake = 1.0448983402966405e-06, generator loss = 14.54123306274414\n",
      "2/2 [==============================] - 0s 179ms/step\n",
      "Epoch: 18, Batch: 212/468, discriminator loss real = 1.2963247914718303e-23, disciminator loss fake = 2.8571023449330823e-06, generator loss = 14.598470687866211\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 18, Batch: 213/468, discriminator loss real = 2.1160664366581816e-12, disciminator loss fake = 2.7573041734285653e-06, generator loss = 14.603303909301758\n",
      "2/2 [==============================] - 0s 166ms/step\n",
      "Epoch: 18, Batch: 214/468, discriminator loss real = 1.788780165127321e-24, disciminator loss fake = 1.6877064581422019e-06, generator loss = 14.487704277038574\n",
      "2/2 [==============================] - 0s 134ms/step\n",
      "Epoch: 18, Batch: 215/468, discriminator loss real = 3.097466288654829e-24, disciminator loss fake = 2.062406565528363e-06, generator loss = 14.720985412597656\n",
      "2/2 [==============================] - 0s 163ms/step\n",
      "Epoch: 18, Batch: 216/468, discriminator loss real = 1.520265069612266e-20, disciminator loss fake = 4.9906284402823076e-06, generator loss = 14.70779037475586\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 18, Batch: 217/468, discriminator loss real = 1.2128435408764737e-11, disciminator loss fake = 3.513828005452524e-06, generator loss = 14.451356887817383\n",
      "2/2 [==============================] - 0s 197ms/step\n",
      "Epoch: 18, Batch: 218/468, discriminator loss real = 7.798025946541403e-29, disciminator loss fake = 2.816815594997024e-06, generator loss = 14.721359252929688\n",
      "2/2 [==============================] - 0s 181ms/step\n",
      "Epoch: 18, Batch: 219/468, discriminator loss real = 1.5064574541724527e-20, disciminator loss fake = 1.5672985682613216e-06, generator loss = 14.6464262008667\n",
      "2/2 [==============================] - 0s 169ms/step\n",
      "Epoch: 18, Batch: 220/468, discriminator loss real = 4.5324524790707795e-20, disciminator loss fake = 1.27040595998551e-06, generator loss = 14.491340637207031\n",
      "2/2 [==============================] - 0s 146ms/step\n",
      "Epoch: 18, Batch: 221/468, discriminator loss real = 2.738973577873024e-24, disciminator loss fake = 2.841508376150159e-06, generator loss = 14.910188674926758\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 18, Batch: 222/468, discriminator loss real = 2.0460230132357538e-07, disciminator loss fake = 1.7995346297539072e-06, generator loss = 14.659245491027832\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 18, Batch: 223/468, discriminator loss real = 3.5733493941592087e-09, disciminator loss fake = 4.6443647079286166e-06, generator loss = 14.69027328491211\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 18, Batch: 224/468, discriminator loss real = 1.2933670363937946e-23, disciminator loss fake = 1.2154812338849297e-06, generator loss = 14.562408447265625\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 18, Batch: 225/468, discriminator loss real = 2.202426947956783e-14, disciminator loss fake = 1.4696179277962074e-06, generator loss = 14.757283210754395\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 18, Batch: 226/468, discriminator loss real = 4.816136096701118e-13, disciminator loss fake = 1.7800410887502949e-06, generator loss = 14.302793502807617\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 18, Batch: 227/468, discriminator loss real = 6.7964293149261595e-15, disciminator loss fake = 2.2390954654838424e-06, generator loss = 14.619064331054688\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 18, Batch: 228/468, discriminator loss real = 4.996417503040405e-19, disciminator loss fake = 1.1128563528473023e-06, generator loss = 14.863298416137695\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 18, Batch: 229/468, discriminator loss real = 4.51490177167356e-14, disciminator loss fake = 1.4077469359108363e-06, generator loss = 14.540349006652832\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 18, Batch: 230/468, discriminator loss real = 2.4730681044693448e-11, disciminator loss fake = 3.751588110390003e-06, generator loss = 14.65308952331543\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 18, Batch: 231/468, discriminator loss real = 2.4985258408682668e-17, disciminator loss fake = 2.7548308025870938e-06, generator loss = 14.80233383178711\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 18, Batch: 232/468, discriminator loss real = 1.6544399534243964e-23, disciminator loss fake = 3.2093896606966155e-06, generator loss = 14.420331001281738\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 18, Batch: 233/468, discriminator loss real = 2.37875779765899e-25, disciminator loss fake = 1.5211422805805341e-06, generator loss = 14.492929458618164\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 18, Batch: 234/468, discriminator loss real = 2.0748690377045582e-15, disciminator loss fake = 1.0431728014737018e-06, generator loss = 14.702831268310547\n",
      "2/2 [==============================] - 0s 136ms/step\n",
      "Epoch: 18, Batch: 235/468, discriminator loss real = 7.46903126014331e-08, disciminator loss fake = 2.765103545243619e-06, generator loss = 14.638631820678711\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 18, Batch: 236/468, discriminator loss real = 4.908465766651902e-18, disciminator loss fake = 1.7090330857172376e-06, generator loss = 14.49527645111084\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 18, Batch: 237/468, discriminator loss real = 3.595891534843522e-25, disciminator loss fake = 4.379045094538014e-06, generator loss = 14.98861026763916\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 18, Batch: 238/468, discriminator loss real = 3.405725340958031e-14, disciminator loss fake = 1.523148284832132e-06, generator loss = 14.883623123168945\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 18, Batch: 239/468, discriminator loss real = 1.2391173186188098e-05, disciminator loss fake = 1.8126066834156518e-06, generator loss = 14.846366882324219\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 18, Batch: 240/468, discriminator loss real = 2.1258910996038255e-16, disciminator loss fake = 3.360003802299616e-06, generator loss = 14.787914276123047\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 18, Batch: 241/468, discriminator loss real = 1.8554453909463482e-16, disciminator loss fake = 1.1937981980736367e-06, generator loss = 14.677911758422852\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 18, Batch: 242/468, discriminator loss real = 2.6593128774640793e-16, disciminator loss fake = 9.692590765553177e-07, generator loss = 14.51230239868164\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 18, Batch: 243/468, discriminator loss real = 9.70750066128984e-22, disciminator loss fake = 2.7854007385030854e-06, generator loss = 14.610042572021484\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 18, Batch: 244/468, discriminator loss real = 2.433856268789304e-22, disciminator loss fake = 1.8528230611991603e-06, generator loss = 14.569769859313965\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 18, Batch: 245/468, discriminator loss real = 3.0789779981591826e-17, disciminator loss fake = 1.439782522538735e-06, generator loss = 14.471029281616211\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 18, Batch: 246/468, discriminator loss real = 1.4198106869345826e-14, disciminator loss fake = 1.6745700577303069e-06, generator loss = 14.67336654663086\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 18, Batch: 247/468, discriminator loss real = 2.3881366675130805e-22, disciminator loss fake = 1.6357445247194846e-06, generator loss = 14.539366722106934\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 18, Batch: 248/468, discriminator loss real = 1.0190900235186365e-22, disciminator loss fake = 1.2755710940837162e-06, generator loss = 14.838072776794434\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 18, Batch: 249/468, discriminator loss real = 2.5189419818750556e-18, disciminator loss fake = 1.1809922852989985e-06, generator loss = 14.835981369018555\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 18, Batch: 250/468, discriminator loss real = 3.00035629411592e-15, disciminator loss fake = 2.1702721824112814e-06, generator loss = 14.511886596679688\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 18, Batch: 251/468, discriminator loss real = 7.833904464062947e-19, disciminator loss fake = 3.058245511056157e-06, generator loss = 14.63543701171875\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 18, Batch: 252/468, discriminator loss real = 2.3968977804527333e-32, disciminator loss fake = 1.319866214544163e-06, generator loss = 14.636646270751953\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 18, Batch: 253/468, discriminator loss real = 2.6581158178707444e-20, disciminator loss fake = 1.0050830496766139e-06, generator loss = 14.53594970703125\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 18, Batch: 254/468, discriminator loss real = 1.600231169796018e-09, disciminator loss fake = 1.3524763744499069e-06, generator loss = 14.705009460449219\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 18, Batch: 255/468, discriminator loss real = 1.2528905024566939e-08, disciminator loss fake = 1.5506354884564644e-06, generator loss = 15.095528602600098\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 18, Batch: 256/468, discriminator loss real = 3.6583239171860944e-16, disciminator loss fake = 1.8716129943641135e-06, generator loss = 14.672298431396484\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 18, Batch: 257/468, discriminator loss real = 4.6160257498765726e-27, disciminator loss fake = 1.4134918728814228e-06, generator loss = 14.379669189453125\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 18, Batch: 258/468, discriminator loss real = 5.9369289129394316e-24, disciminator loss fake = 2.3246811906574294e-06, generator loss = 14.631216049194336\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 18, Batch: 259/468, discriminator loss real = 1.1378720616750674e-29, disciminator loss fake = 2.2116391846793704e-06, generator loss = 14.580106735229492\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 18, Batch: 260/468, discriminator loss real = 5.8962230224119395e-19, disciminator loss fake = 2.193688033003127e-06, generator loss = 14.729263305664062\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 18, Batch: 261/468, discriminator loss real = 4.8091647851522534e-12, disciminator loss fake = 1.8109462871507276e-06, generator loss = 14.57051944732666\n",
      "2/2 [==============================] - 0s 245ms/step\n",
      "Epoch: 18, Batch: 262/468, discriminator loss real = 1.0119935649216222e-24, disciminator loss fake = 2.209173544542864e-06, generator loss = 14.806669235229492\n",
      "2/2 [==============================] - 0s 198ms/step\n",
      "Epoch: 18, Batch: 263/468, discriminator loss real = 1.1680333620884414e-13, disciminator loss fake = 1.5996954516594997e-06, generator loss = 14.498172760009766\n",
      "2/2 [==============================] - 0s 182ms/step\n",
      "Epoch: 18, Batch: 264/468, discriminator loss real = 0.00012139495083829388, disciminator loss fake = 2.1107289285282604e-06, generator loss = 14.959383010864258\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 18, Batch: 265/468, discriminator loss real = 8.862355567991172e-20, disciminator loss fake = 1.0423532330605667e-06, generator loss = 14.667047500610352\n",
      "2/2 [==============================] - 0s 150ms/step\n",
      "Epoch: 18, Batch: 266/468, discriminator loss real = 6.001747900721401e-18, disciminator loss fake = 1.7326351553492714e-06, generator loss = 14.785163879394531\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 18, Batch: 267/468, discriminator loss real = 4.200204191985283e-30, disciminator loss fake = 2.1403552636911627e-06, generator loss = 14.52900505065918\n",
      "2/2 [==============================] - 0s 134ms/step\n",
      "Epoch: 18, Batch: 268/468, discriminator loss real = 2.820640200093013e-28, disciminator loss fake = 1.2565230917971348e-06, generator loss = 14.505332946777344\n",
      "2/2 [==============================] - 0s 145ms/step\n",
      "Epoch: 18, Batch: 269/468, discriminator loss real = 2.5790860663114716e-25, disciminator loss fake = 1.0363404499003082e-06, generator loss = 14.460200309753418\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 18, Batch: 270/468, discriminator loss real = 1.1546986998913295e-23, disciminator loss fake = 9.005209449242102e-07, generator loss = 14.47691535949707\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 18, Batch: 271/468, discriminator loss real = 4.407266218642292e-11, disciminator loss fake = 2.464582621541922e-06, generator loss = 14.479999542236328\n",
      "2/2 [==============================] - 0s 135ms/step\n",
      "Epoch: 18, Batch: 272/468, discriminator loss real = 5.732548167209217e-25, disciminator loss fake = 2.1276248389767716e-06, generator loss = 14.517753601074219\n",
      "2/2 [==============================] - 0s 147ms/step\n",
      "Epoch: 18, Batch: 273/468, discriminator loss real = 5.259301188576468e-18, disciminator loss fake = 1.689559212536551e-06, generator loss = 14.449846267700195\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 18, Batch: 274/468, discriminator loss real = 1.9242373028305337e-08, disciminator loss fake = 1.446301098440017e-06, generator loss = 14.624205589294434\n",
      "2/2 [==============================] - 0s 161ms/step\n",
      "Epoch: 18, Batch: 275/468, discriminator loss real = 2.7985416295450705e-07, disciminator loss fake = 2.182155412810971e-06, generator loss = 14.442790031433105\n",
      "2/2 [==============================] - 0s 156ms/step\n",
      "Epoch: 18, Batch: 276/468, discriminator loss real = 1.8849281592812751e-25, disciminator loss fake = 2.7648093237075955e-06, generator loss = 14.374080657958984\n",
      "2/2 [==============================] - 0s 152ms/step\n",
      "Epoch: 18, Batch: 277/468, discriminator loss real = 1.8216536572335035e-21, disciminator loss fake = 1.6606056760792853e-06, generator loss = 14.342790603637695\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 18, Batch: 278/468, discriminator loss real = 3.144177208043294e-25, disciminator loss fake = 1.2993245945835952e-06, generator loss = 14.838037490844727\n",
      "2/2 [==============================] - 0s 156ms/step\n",
      "Epoch: 18, Batch: 279/468, discriminator loss real = 7.700721726955351e-10, disciminator loss fake = 1.1304566669423366e-06, generator loss = 14.54957103729248\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 18, Batch: 280/468, discriminator loss real = 2.7315228465766404e-21, disciminator loss fake = 2.4146340820152545e-06, generator loss = 14.386297225952148\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 18, Batch: 281/468, discriminator loss real = 2.5617547566212338e-14, disciminator loss fake = 2.406742396487971e-06, generator loss = 14.61773681640625\n",
      "2/2 [==============================] - 0s 160ms/step\n",
      "Epoch: 18, Batch: 282/468, discriminator loss real = 1.0102667089570481e-23, disciminator loss fake = 2.0276913801353658e-06, generator loss = 14.475872039794922\n",
      "2/2 [==============================] - 0s 152ms/step\n",
      "Epoch: 18, Batch: 283/468, discriminator loss real = 5.5152320281532324e-17, disciminator loss fake = 1.0318578915757826e-06, generator loss = 14.620645523071289\n",
      "2/2 [==============================] - 0s 170ms/step\n",
      "Epoch: 18, Batch: 284/468, discriminator loss real = 1.1261722747127437e-22, disciminator loss fake = 4.761106538353488e-06, generator loss = 14.314590454101562\n",
      "2/2 [==============================] - 0s 166ms/step\n",
      "Epoch: 18, Batch: 285/468, discriminator loss real = 2.973540184749134e-25, disciminator loss fake = 2.2708932192472275e-06, generator loss = 14.45008373260498\n",
      "2/2 [==============================] - 0s 181ms/step\n",
      "Epoch: 18, Batch: 286/468, discriminator loss real = 5.761233557093033e-17, disciminator loss fake = 1.488555540163361e-06, generator loss = 14.722362518310547\n",
      "2/2 [==============================] - 0s 180ms/step\n",
      "Epoch: 18, Batch: 287/468, discriminator loss real = 1.0085586892243472e-16, disciminator loss fake = 1.8535763501859037e-06, generator loss = 14.893877983093262\n",
      "2/2 [==============================] - 0s 183ms/step\n",
      "Epoch: 18, Batch: 288/468, discriminator loss real = 9.096298782708207e-30, disciminator loss fake = 2.3881661945779342e-06, generator loss = 14.921157836914062\n",
      "2/2 [==============================] - 0s 171ms/step\n",
      "Epoch: 18, Batch: 289/468, discriminator loss real = 5.523196531581292e-27, disciminator loss fake = 1.1470265235402621e-06, generator loss = 14.603367805480957\n",
      "2/2 [==============================] - 0s 156ms/step\n",
      "Epoch: 18, Batch: 290/468, discriminator loss real = 9.932957510848657e-17, disciminator loss fake = 1.401103531861736e-06, generator loss = 14.594185829162598\n",
      "2/2 [==============================] - 0s 154ms/step\n",
      "Epoch: 18, Batch: 291/468, discriminator loss real = 1.1688401440300422e-13, disciminator loss fake = 1.6718225879230886e-06, generator loss = 15.052444458007812\n",
      "2/2 [==============================] - 0s 208ms/step\n",
      "Epoch: 18, Batch: 292/468, discriminator loss real = 7.542880064309327e-15, disciminator loss fake = 1.7370182376907906e-06, generator loss = 14.463602066040039\n",
      "2/2 [==============================] - 0s 192ms/step\n",
      "Epoch: 18, Batch: 293/468, discriminator loss real = 6.125717605941204e-23, disciminator loss fake = 1.32743639369437e-06, generator loss = 14.6761474609375\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 18, Batch: 294/468, discriminator loss real = 3.014696307803051e-14, disciminator loss fake = 1.248960643351893e-06, generator loss = 14.67227554321289\n",
      "2/2 [==============================] - 0s 183ms/step\n",
      "Epoch: 18, Batch: 295/468, discriminator loss real = 1.3088916013784604e-28, disciminator loss fake = 1.7257617628274602e-06, generator loss = 14.582524299621582\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 18, Batch: 296/468, discriminator loss real = 2.0493840186073392e-14, disciminator loss fake = 1.55407417423703e-06, generator loss = 14.708612442016602\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 18, Batch: 297/468, discriminator loss real = 2.5390047513241618e-17, disciminator loss fake = 1.4529798590956489e-06, generator loss = 14.711833953857422\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 18, Batch: 298/468, discriminator loss real = 3.166360186199202e-12, disciminator loss fake = 1.4961653960199328e-06, generator loss = 14.662081718444824\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 18, Batch: 299/468, discriminator loss real = 1.776084657274051e-17, disciminator loss fake = 2.8690792532870546e-06, generator loss = 14.64065170288086\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 18, Batch: 300/468, discriminator loss real = 1.5142781343628104e-26, disciminator loss fake = 1.559097313474922e-06, generator loss = 14.687713623046875\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 18, Batch: 301/468, discriminator loss real = 1.1211186660931078e-24, disciminator loss fake = 1.6020477460187976e-06, generator loss = 14.749471664428711\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 18, Batch: 302/468, discriminator loss real = 1.3387386224540318e-14, disciminator loss fake = 1.5363093552878127e-06, generator loss = 14.511887550354004\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 18, Batch: 303/468, discriminator loss real = 6.4683944665223384e-21, disciminator loss fake = 2.536365400374052e-06, generator loss = 14.784747123718262\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 18, Batch: 304/468, discriminator loss real = 6.560805527777e-17, disciminator loss fake = 3.3435765089961933e-06, generator loss = 14.75517463684082\n",
      "2/2 [==============================] - 0s 134ms/step\n",
      "Epoch: 18, Batch: 305/468, discriminator loss real = 2.3378129654361146e-08, disciminator loss fake = 1.111113078877679e-06, generator loss = 14.773144721984863\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 18, Batch: 306/468, discriminator loss real = 8.77422995371191e-11, disciminator loss fake = 2.336631041544024e-06, generator loss = 14.736425399780273\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 18, Batch: 307/468, discriminator loss real = 3.52180603270824e-26, disciminator loss fake = 1.7501771480965544e-06, generator loss = 14.382822036743164\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 18, Batch: 308/468, discriminator loss real = 1.7718895280794272e-17, disciminator loss fake = 2.087720531562809e-06, generator loss = 14.764098167419434\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 18, Batch: 309/468, discriminator loss real = 5.567060456319299e-19, disciminator loss fake = 1.4183519851940218e-06, generator loss = 14.391706466674805\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 18, Batch: 310/468, discriminator loss real = 8.392460725605335e-32, disciminator loss fake = 6.776496093152673e-07, generator loss = 14.2976655960083\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 18, Batch: 311/468, discriminator loss real = 4.0224811527878046e-05, disciminator loss fake = 1.5242483186739264e-06, generator loss = 14.803201675415039\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 18, Batch: 312/468, discriminator loss real = 3.458887343210648e-11, disciminator loss fake = 1.2155677495684358e-06, generator loss = 14.671306610107422\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 18, Batch: 313/468, discriminator loss real = 1.7950316580361836e-11, disciminator loss fake = 1.5969192190823378e-06, generator loss = 14.838342666625977\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 18, Batch: 314/468, discriminator loss real = 4.0971495312390575e-25, disciminator loss fake = 1.3457673730954411e-06, generator loss = 14.577596664428711\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 18, Batch: 315/468, discriminator loss real = 3.5562342645428975e-27, disciminator loss fake = 2.3776203761372017e-06, generator loss = 14.735857009887695\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 18, Batch: 316/468, discriminator loss real = 9.955723506539587e-16, disciminator loss fake = 1.813287326513091e-06, generator loss = 14.632101058959961\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 18, Batch: 317/468, discriminator loss real = 5.101713852026133e-17, disciminator loss fake = 9.7276529231749e-07, generator loss = 14.589546203613281\n",
      "2/2 [==============================] - 0s 157ms/step\n",
      "Epoch: 18, Batch: 318/468, discriminator loss real = 5.392760613176506e-06, disciminator loss fake = 1.3882402072340483e-06, generator loss = 14.848780632019043\n",
      "2/2 [==============================] - 0s 181ms/step\n",
      "Epoch: 18, Batch: 319/468, discriminator loss real = 8.26624747181392e-17, disciminator loss fake = 1.9500364487612387e-06, generator loss = 14.940610885620117\n",
      "2/2 [==============================] - 0s 175ms/step\n",
      "Epoch: 18, Batch: 320/468, discriminator loss real = 2.3682564156274344e-13, disciminator loss fake = 2.541576805015211e-06, generator loss = 14.764991760253906\n",
      "2/2 [==============================] - 0s 203ms/step\n",
      "Epoch: 18, Batch: 321/468, discriminator loss real = 1.2675281113823579e-20, disciminator loss fake = 1.6327853700204287e-06, generator loss = 14.718683242797852\n",
      "2/2 [==============================] - 0s 185ms/step\n",
      "Epoch: 18, Batch: 322/468, discriminator loss real = 1.4010367522301068e-15, disciminator loss fake = 2.1376024506025715e-06, generator loss = 14.714353561401367\n",
      "2/2 [==============================] - 0s 157ms/step\n",
      "Epoch: 18, Batch: 323/468, discriminator loss real = 1.0690973515744737e-15, disciminator loss fake = 2.402235395493335e-06, generator loss = 14.799764633178711\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 18, Batch: 324/468, discriminator loss real = 4.4722051582846145e-12, disciminator loss fake = 1.1202357654838124e-06, generator loss = 14.604788780212402\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 18, Batch: 325/468, discriminator loss real = 3.444155100162413e-21, disciminator loss fake = 1.0329968063160777e-06, generator loss = 14.910456657409668\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 18, Batch: 326/468, discriminator loss real = 1.0921156032669784e-23, disciminator loss fake = 1.5442390122188954e-06, generator loss = 14.688471794128418\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 18, Batch: 327/468, discriminator loss real = 8.684939220647899e-21, disciminator loss fake = 1.9004282876267098e-06, generator loss = 14.764169692993164\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 18, Batch: 328/468, discriminator loss real = 1.4462395170333764e-10, disciminator loss fake = 1.4331714055515477e-06, generator loss = 14.48416519165039\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 18, Batch: 329/468, discriminator loss real = 4.044765091748559e-07, disciminator loss fake = 2.300319010828389e-06, generator loss = 14.624088287353516\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 18, Batch: 330/468, discriminator loss real = 1.1686657568868615e-14, disciminator loss fake = 1.5376656392618315e-06, generator loss = 14.730813980102539\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 18, Batch: 331/468, discriminator loss real = 4.027703295435477e-24, disciminator loss fake = 1.286960923607694e-06, generator loss = 14.630203247070312\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 18, Batch: 332/468, discriminator loss real = 2.5970357997758058e-20, disciminator loss fake = 1.5065151046655956e-06, generator loss = 14.633511543273926\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 18, Batch: 333/468, discriminator loss real = 3.3591997635085136e-05, disciminator loss fake = 1.7075958567147609e-06, generator loss = 14.469197273254395\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 18, Batch: 334/468, discriminator loss real = 3.01190432594467e-08, disciminator loss fake = 2.46392755798297e-06, generator loss = 14.740926742553711\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 18, Batch: 335/468, discriminator loss real = 4.643306403853129e-18, disciminator loss fake = 1.4788580529057072e-06, generator loss = 14.502948760986328\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 18, Batch: 336/468, discriminator loss real = 2.4994698193833123e-17, disciminator loss fake = 1.2976461221114732e-06, generator loss = 14.535253524780273\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 18, Batch: 337/468, discriminator loss real = 2.7738599653302918e-24, disciminator loss fake = 2.770267201412935e-06, generator loss = 14.636785507202148\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 18, Batch: 338/468, discriminator loss real = 5.68053460801603e-27, disciminator loss fake = 4.478419668885181e-06, generator loss = 14.48192024230957\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 18, Batch: 339/468, discriminator loss real = 1.063282361203732e-18, disciminator loss fake = 6.98814915267576e-07, generator loss = 14.624669075012207\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 18, Batch: 340/468, discriminator loss real = 9.53369101477347e-30, disciminator loss fake = 8.269344675682078e-07, generator loss = 14.280059814453125\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 18, Batch: 341/468, discriminator loss real = 7.746044730083668e-07, disciminator loss fake = 2.570164724602364e-06, generator loss = 14.287979125976562\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 18, Batch: 342/468, discriminator loss real = 2.2501340246559843e-16, disciminator loss fake = 1.7003477523758193e-06, generator loss = 14.706254959106445\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 18, Batch: 343/468, discriminator loss real = 1.149711151469973e-26, disciminator loss fake = 2.102667622239096e-06, generator loss = 14.562150955200195\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 18, Batch: 344/468, discriminator loss real = 2.872385969560096e-20, disciminator loss fake = 1.1306854048598325e-06, generator loss = 14.652143478393555\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 18, Batch: 345/468, discriminator loss real = 9.273487314157006e-22, disciminator loss fake = 1.5274843008228345e-06, generator loss = 14.563570022583008\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 18, Batch: 346/468, discriminator loss real = 9.418838952111839e-17, disciminator loss fake = 2.1308105715434067e-06, generator loss = 14.648215293884277\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 18, Batch: 347/468, discriminator loss real = 8.6154770383845e-14, disciminator loss fake = 3.0414366847253405e-06, generator loss = 14.80496883392334\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 18, Batch: 348/468, discriminator loss real = 4.28738558801915e-15, disciminator loss fake = 1.8640621419763193e-06, generator loss = 14.642942428588867\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 18, Batch: 349/468, discriminator loss real = 1.0462873564924013e-17, disciminator loss fake = 1.3613821465696674e-06, generator loss = 14.502311706542969\n",
      "2/2 [==============================] - 0s 153ms/step\n",
      "Epoch: 18, Batch: 350/468, discriminator loss real = 9.22666769045903e-17, disciminator loss fake = 1.1680081115628127e-06, generator loss = 14.717681884765625\n",
      "2/2 [==============================] - 0s 186ms/step\n",
      "Epoch: 18, Batch: 351/468, discriminator loss real = 3.663216988294366e-17, disciminator loss fake = 1.930287908180617e-06, generator loss = 14.698114395141602\n",
      "2/2 [==============================] - 0s 171ms/step\n",
      "Epoch: 18, Batch: 352/468, discriminator loss real = 1.1711155362784643e-25, disciminator loss fake = 2.2070537397667067e-06, generator loss = 14.661645889282227\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 18, Batch: 353/468, discriminator loss real = 3.2861951180370717e-37, disciminator loss fake = 3.4655020044738194e-06, generator loss = 14.440191268920898\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 18, Batch: 354/468, discriminator loss real = 2.22059143268121e-25, disciminator loss fake = 1.5272242990249651e-06, generator loss = 14.68476390838623\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 18, Batch: 355/468, discriminator loss real = 9.667374273158251e-23, disciminator loss fake = 2.153692548745312e-06, generator loss = 14.747562408447266\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 18, Batch: 356/468, discriminator loss real = 5.3988449508324265e-05, disciminator loss fake = 9.184381042359746e-07, generator loss = 14.793174743652344\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 18, Batch: 357/468, discriminator loss real = 1.5588638718964085e-15, disciminator loss fake = 1.959103656190564e-06, generator loss = 14.717950820922852\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 18, Batch: 358/468, discriminator loss real = 1.998489373988832e-09, disciminator loss fake = 1.598367248334398e-06, generator loss = 14.56821060180664\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 18, Batch: 359/468, discriminator loss real = 1.0181125591248857e-16, disciminator loss fake = 1.4897358369125868e-06, generator loss = 14.698203086853027\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 18, Batch: 360/468, discriminator loss real = 1.032530727875281e-31, disciminator loss fake = 1.0805356396303978e-06, generator loss = 14.685724258422852\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 18, Batch: 361/468, discriminator loss real = 3.792825373238884e-05, disciminator loss fake = 1.4918302895239322e-06, generator loss = 14.695374488830566\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 18, Batch: 362/468, discriminator loss real = 1.0507823702398205e-26, disciminator loss fake = 2.16604439629009e-06, generator loss = 14.487154960632324\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 18, Batch: 363/468, discriminator loss real = 1.4863441698373137e-19, disciminator loss fake = 1.6785568277555285e-06, generator loss = 14.65334701538086\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 18, Batch: 364/468, discriminator loss real = 1.3651121592088871e-21, disciminator loss fake = 1.0340274911868619e-06, generator loss = 14.532758712768555\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 18, Batch: 365/468, discriminator loss real = 1.6718675432412296e-16, disciminator loss fake = 2.0637376110244077e-06, generator loss = 14.583593368530273\n",
      "2/2 [==============================] - 0s 144ms/step\n",
      "Epoch: 18, Batch: 366/468, discriminator loss real = 2.998619308414163e-08, disciminator loss fake = 1.3114768080413342e-06, generator loss = 14.493093490600586\n",
      "2/2 [==============================] - 0s 211ms/step\n",
      "Epoch: 18, Batch: 367/468, discriminator loss real = 1.9501444526608992e-14, disciminator loss fake = 1.1798276773333782e-06, generator loss = 14.400222778320312\n",
      "2/2 [==============================] - 0s 183ms/step\n",
      "Epoch: 18, Batch: 368/468, discriminator loss real = 9.423152864442426e-17, disciminator loss fake = 2.6949755920213647e-06, generator loss = 14.419178009033203\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 18, Batch: 369/468, discriminator loss real = 3.516855955732084e-20, disciminator loss fake = 1.7788960349207628e-06, generator loss = 14.834604263305664\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 18, Batch: 370/468, discriminator loss real = 4.062213871766308e-20, disciminator loss fake = 2.1555115381488577e-06, generator loss = 14.618616104125977\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 18, Batch: 371/468, discriminator loss real = 2.8846941585809433e-20, disciminator loss fake = 1.481994445384771e-06, generator loss = 14.689202308654785\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 18, Batch: 372/468, discriminator loss real = 1.5505638657486998e-05, disciminator loss fake = 1.2229793355800211e-06, generator loss = 14.400557518005371\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 18, Batch: 373/468, discriminator loss real = 1.388441373131616e-18, disciminator loss fake = 1.3421266658042441e-06, generator loss = 14.621427536010742\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 18, Batch: 374/468, discriminator loss real = 4.672163923011021e-17, disciminator loss fake = 1.4501168834613054e-06, generator loss = 14.49588394165039\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 18, Batch: 375/468, discriminator loss real = 2.709631928486905e-17, disciminator loss fake = 1.4782556263526203e-06, generator loss = 14.378474235534668\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 18, Batch: 376/468, discriminator loss real = 1.1017895623198847e-23, disciminator loss fake = 1.874760187092761e-06, generator loss = 14.485773086547852\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 18, Batch: 377/468, discriminator loss real = 1.8369492347345193e-23, disciminator loss fake = 1.3522883364203153e-06, generator loss = 14.631897926330566\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 18, Batch: 378/468, discriminator loss real = 5.68378483486304e-16, disciminator loss fake = 1.8726429971138714e-06, generator loss = 14.715190887451172\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 18, Batch: 379/468, discriminator loss real = 1.0632860835164886e-17, disciminator loss fake = 1.8139364783564815e-06, generator loss = 14.464214324951172\n",
      "2/2 [==============================] - 0s 135ms/step\n",
      "Epoch: 18, Batch: 380/468, discriminator loss real = 1.3020417991194837e-35, disciminator loss fake = 1.6347623841284076e-06, generator loss = 14.633977890014648\n",
      "2/2 [==============================] - 0s 175ms/step\n",
      "Epoch: 18, Batch: 381/468, discriminator loss real = 8.7854658988801e-21, disciminator loss fake = 1.979422222575522e-06, generator loss = 14.631580352783203\n",
      "2/2 [==============================] - 0s 177ms/step\n",
      "Epoch: 18, Batch: 382/468, discriminator loss real = 7.452646832994958e-11, disciminator loss fake = 1.5125376648938982e-06, generator loss = 14.644136428833008\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 18, Batch: 383/468, discriminator loss real = 2.092750606533356e-26, disciminator loss fake = 1.574975158291636e-06, generator loss = 14.646891593933105\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 18, Batch: 384/468, discriminator loss real = 1.7402048690939864e-09, disciminator loss fake = 1.289007741434034e-06, generator loss = 14.712225914001465\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 18, Batch: 385/468, discriminator loss real = 1.5473760353577266e-22, disciminator loss fake = 2.3761363081575837e-06, generator loss = 14.553930282592773\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 18, Batch: 386/468, discriminator loss real = 1.5550555905897295e-13, disciminator loss fake = 1.8022283256868832e-06, generator loss = 15.013725280761719\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 18, Batch: 387/468, discriminator loss real = 7.058802832683528e-18, disciminator loss fake = 1.5946131952659925e-06, generator loss = 14.688545227050781\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 18, Batch: 388/468, discriminator loss real = 3.795109097316264e-14, disciminator loss fake = 3.884430498146685e-06, generator loss = 14.678855895996094\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 18, Batch: 389/468, discriminator loss real = 8.813897528492376e-11, disciminator loss fake = 3.2948078114714008e-06, generator loss = 14.741693496704102\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 18, Batch: 390/468, discriminator loss real = 8.454014628968381e-26, disciminator loss fake = 1.2022484270346467e-06, generator loss = 14.445472717285156\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 18, Batch: 391/468, discriminator loss real = 2.484882064058406e-22, disciminator loss fake = 2.3512429834227078e-06, generator loss = 14.820039749145508\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 18, Batch: 392/468, discriminator loss real = 7.116224959145825e-28, disciminator loss fake = 1.5791200667081284e-06, generator loss = 14.883661270141602\n",
      "2/2 [==============================] - 0s 158ms/step\n",
      "Epoch: 18, Batch: 393/468, discriminator loss real = 2.0107355145867253e-15, disciminator loss fake = 1.73366811395681e-06, generator loss = 14.654134750366211\n",
      "2/2 [==============================] - 0s 191ms/step\n",
      "Epoch: 18, Batch: 394/468, discriminator loss real = 7.778472284504175e-31, disciminator loss fake = 1.2299226455070311e-06, generator loss = 14.367947578430176\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 18, Batch: 395/468, discriminator loss real = 4.578973093456307e-17, disciminator loss fake = 9.029205898514192e-07, generator loss = 14.893876075744629\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 18, Batch: 396/468, discriminator loss real = 3.33570307439329e-34, disciminator loss fake = 1.1613119568210095e-06, generator loss = 14.481167793273926\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 18, Batch: 397/468, discriminator loss real = 9.1287511780648e-18, disciminator loss fake = 1.427621327820816e-06, generator loss = 14.428844451904297\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 18, Batch: 398/468, discriminator loss real = 1.7335620885473885e-19, disciminator loss fake = 1.9664730643853545e-06, generator loss = 14.566850662231445\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 18, Batch: 399/468, discriminator loss real = 3.807757221522581e-30, disciminator loss fake = 1.8764446849672822e-06, generator loss = 14.576827049255371\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 18, Batch: 400/468, discriminator loss real = 8.750389905124323e-15, disciminator loss fake = 1.889817667688476e-06, generator loss = 14.581162452697754\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 18, Batch: 401/468, discriminator loss real = 2.009055899074297e-12, disciminator loss fake = 3.3811613775469596e-06, generator loss = 14.551141738891602\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 18, Batch: 402/468, discriminator loss real = 3.303019546784837e-14, disciminator loss fake = 1.0857957022381015e-06, generator loss = 14.540484428405762\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 18, Batch: 403/468, discriminator loss real = 2.807510969599386e-19, disciminator loss fake = 1.6397266335843597e-06, generator loss = 14.674181938171387\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 18, Batch: 404/468, discriminator loss real = 1.7222730445642345e-15, disciminator loss fake = 1.0247078989777947e-06, generator loss = 14.748207092285156\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 18, Batch: 405/468, discriminator loss real = 2.6930703760780217e-13, disciminator loss fake = 2.0994575606891885e-06, generator loss = 14.968088150024414\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 18, Batch: 406/468, discriminator loss real = 1.4023497640902605e-11, disciminator loss fake = 1.652904529692023e-06, generator loss = 14.687015533447266\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 18, Batch: 407/468, discriminator loss real = 4.467603023639022e-11, disciminator loss fake = 1.9039049448110745e-06, generator loss = 14.717147827148438\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 18, Batch: 408/468, discriminator loss real = 9.979423700161999e-14, disciminator loss fake = 1.0879660976570449e-06, generator loss = 15.04104995727539\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 18, Batch: 409/468, discriminator loss real = 3.671935014397466e-25, disciminator loss fake = 1.6096354329420137e-06, generator loss = 14.63619613647461\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 18, Batch: 410/468, discriminator loss real = 7.660667061851207e-31, disciminator loss fake = 1.3452041685013683e-06, generator loss = 14.682233810424805\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 18, Batch: 411/468, discriminator loss real = 5.379871034662197e-19, disciminator loss fake = 1.5012391259006108e-06, generator loss = 14.730297088623047\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 18, Batch: 412/468, discriminator loss real = 4.653421504425551e-20, disciminator loss fake = 7.723961061856244e-07, generator loss = 14.322111129760742\n",
      "2/2 [==============================] - 0s 175ms/step\n",
      "Epoch: 18, Batch: 413/468, discriminator loss real = 1.4107124873415703e-18, disciminator loss fake = 2.0518596102192532e-06, generator loss = 14.682906150817871\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 18, Batch: 414/468, discriminator loss real = 7.573315652170069e-15, disciminator loss fake = 1.355382323708909e-06, generator loss = 14.597710609436035\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 18, Batch: 415/468, discriminator loss real = 1.376680277480162e-14, disciminator loss fake = 1.5528474932580139e-06, generator loss = 14.799615859985352\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 18, Batch: 416/468, discriminator loss real = 7.12899229359648e-21, disciminator loss fake = 1.828897325140133e-06, generator loss = 14.720512390136719\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 18, Batch: 417/468, discriminator loss real = 7.154031470791115e-21, disciminator loss fake = 1.0934586498478893e-06, generator loss = 14.721802711486816\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 18, Batch: 418/468, discriminator loss real = 8.946096130557635e-08, disciminator loss fake = 1.8074047147820238e-06, generator loss = 14.852025985717773\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 18, Batch: 419/468, discriminator loss real = 3.2194840543509073e-11, disciminator loss fake = 1.3026647138758563e-06, generator loss = 14.699432373046875\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 18, Batch: 420/468, discriminator loss real = 1.3018035355979717e-19, disciminator loss fake = 1.5792302292538807e-06, generator loss = 14.967192649841309\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 18, Batch: 421/468, discriminator loss real = 1.0588776179795387e-20, disciminator loss fake = 1.4593751984648407e-06, generator loss = 14.837714195251465\n",
      "2/2 [==============================] - 0s 197ms/step\n",
      "Epoch: 18, Batch: 422/468, discriminator loss real = 2.0937610407174833e-22, disciminator loss fake = 1.0034742672360153e-06, generator loss = 14.865732192993164\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 18, Batch: 423/468, discriminator loss real = 5.870739459800772e-23, disciminator loss fake = 1.3682547432836145e-06, generator loss = 14.854366302490234\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 18, Batch: 424/468, discriminator loss real = 2.060981387330685e-06, disciminator loss fake = 1.3488538570527453e-06, generator loss = 14.989300727844238\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 18, Batch: 425/468, discriminator loss real = 4.461558255075761e-24, disciminator loss fake = 8.837610039336141e-07, generator loss = 14.804699897766113\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 18, Batch: 426/468, discriminator loss real = 1.8351966382083156e-17, disciminator loss fake = 1.5583339063596213e-06, generator loss = 14.728231430053711\n",
      "2/2 [==============================] - 0s 213ms/step\n",
      "Epoch: 18, Batch: 427/468, discriminator loss real = 9.312201246837797e-25, disciminator loss fake = 3.571954948711209e-06, generator loss = 14.722626686096191\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 18, Batch: 428/468, discriminator loss real = 1.3357806180613885e-11, disciminator loss fake = 4.20121477873181e-06, generator loss = 14.80276107788086\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 18, Batch: 429/468, discriminator loss real = 1.1196675170149085e-21, disciminator loss fake = 1.4371978522831341e-06, generator loss = 14.911849975585938\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 18, Batch: 430/468, discriminator loss real = 5.103424176058646e-22, disciminator loss fake = 1.5951150089676958e-06, generator loss = 14.375585556030273\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 18, Batch: 431/468, discriminator loss real = 1.4045511291513925e-19, disciminator loss fake = 8.546069807380263e-07, generator loss = 14.875207901000977\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 18, Batch: 432/468, discriminator loss real = 2.3230460913600424e-15, disciminator loss fake = 1.9450126274023205e-06, generator loss = 14.712669372558594\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 18, Batch: 433/468, discriminator loss real = 1.1068199212364915e-25, disciminator loss fake = 1.2367727322271094e-06, generator loss = 14.844852447509766\n",
      "2/2 [==============================] - 0s 207ms/step\n",
      "Epoch: 18, Batch: 434/468, discriminator loss real = 3.225829048325579e-10, disciminator loss fake = 7.932393373266677e-07, generator loss = 15.05741024017334\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 18, Batch: 435/468, discriminator loss real = 2.3076560651912483e-19, disciminator loss fake = 1.0774100474009174e-06, generator loss = 14.798995971679688\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 18, Batch: 436/468, discriminator loss real = 1.1260410102302672e-26, disciminator loss fake = 2.5003705559356604e-06, generator loss = 14.990900039672852\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 18, Batch: 437/468, discriminator loss real = 1.5116761259707455e-26, disciminator loss fake = 1.2621665064216359e-06, generator loss = 14.657976150512695\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 18, Batch: 438/468, discriminator loss real = 1.7917347605589384e-09, disciminator loss fake = 1.6587416666880017e-06, generator loss = 14.795259475708008\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 18, Batch: 439/468, discriminator loss real = 9.198315069625096e-07, disciminator loss fake = 2.643726929818513e-06, generator loss = 14.78353500366211\n",
      "2/2 [==============================] - 0s 146ms/step\n",
      "Epoch: 18, Batch: 440/468, discriminator loss real = 5.034522918894981e-21, disciminator loss fake = 2.5632909910200397e-06, generator loss = 14.834263801574707\n",
      "2/2 [==============================] - 0s 150ms/step\n",
      "Epoch: 18, Batch: 441/468, discriminator loss real = 4.6610830395366065e-06, disciminator loss fake = 1.7785728232411202e-06, generator loss = 14.923054695129395\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 18, Batch: 442/468, discriminator loss real = 4.233241812645616e-10, disciminator loss fake = 3.6628196085075615e-06, generator loss = 14.79422378540039\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 18, Batch: 443/468, discriminator loss real = 9.81689623131129e-23, disciminator loss fake = 1.54661142914847e-06, generator loss = 14.825739860534668\n",
      "2/2 [==============================] - 0s 130ms/step\n",
      "Epoch: 18, Batch: 444/468, discriminator loss real = 2.175363390757146e-28, disciminator loss fake = 2.706482518988196e-06, generator loss = 14.726678848266602\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 18, Batch: 445/468, discriminator loss real = 6.318528176052496e-05, disciminator loss fake = 2.2129745502752485e-06, generator loss = 14.708593368530273\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 18, Batch: 446/468, discriminator loss real = 3.9336799023085846e-17, disciminator loss fake = 1.6445771962025901e-06, generator loss = 15.136201858520508\n",
      "2/2 [==============================] - 0s 144ms/step\n",
      "Epoch: 18, Batch: 447/468, discriminator loss real = 3.961069445344396e-29, disciminator loss fake = 1.6695796603016788e-06, generator loss = 14.84703254699707\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 18, Batch: 448/468, discriminator loss real = 8.826738172737156e-16, disciminator loss fake = 3.1287718229577877e-06, generator loss = 14.835515022277832\n",
      "2/2 [==============================] - 0s 180ms/step\n",
      "Epoch: 18, Batch: 449/468, discriminator loss real = 1.2538065612983929e-22, disciminator loss fake = 1.8751119341686717e-06, generator loss = 14.786494255065918\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 18, Batch: 450/468, discriminator loss real = 2.0063359411040354e-22, disciminator loss fake = 1.7443617252865806e-06, generator loss = 14.636873245239258\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 18, Batch: 451/468, discriminator loss real = 2.213868011234271e-17, disciminator loss fake = 2.560203029133845e-06, generator loss = 14.920557022094727\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 18, Batch: 452/468, discriminator loss real = 1.2973260805199376e-14, disciminator loss fake = 5.087360023026122e-06, generator loss = 14.672142028808594\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 18, Batch: 453/468, discriminator loss real = 2.1593587113824352e-18, disciminator loss fake = 1.577290277054999e-06, generator loss = 14.944576263427734\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 18, Batch: 454/468, discriminator loss real = 1.057958577150504e-16, disciminator loss fake = 1.6550172858842416e-06, generator loss = 14.65054988861084\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 18, Batch: 455/468, discriminator loss real = 1.003081448287933e-23, disciminator loss fake = 1.8553021163825179e-06, generator loss = 14.954127311706543\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 18, Batch: 456/468, discriminator loss real = 1.5539258815721528e-16, disciminator loss fake = 1.141181428465643e-06, generator loss = 14.884018898010254\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 18, Batch: 457/468, discriminator loss real = 4.193660625919227e-20, disciminator loss fake = 1.7247770074391156e-06, generator loss = 14.582393646240234\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 18, Batch: 458/468, discriminator loss real = 4.547668277738115e-17, disciminator loss fake = 1.0481992376298876e-06, generator loss = 14.803686141967773\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 18, Batch: 459/468, discriminator loss real = 8.450673675955273e-17, disciminator loss fake = 1.5217767668218585e-06, generator loss = 14.681045532226562\n",
      "2/2 [==============================] - 0s 184ms/step\n",
      "Epoch: 18, Batch: 460/468, discriminator loss real = 7.414393318902967e-16, disciminator loss fake = 2.0349152691778727e-06, generator loss = 14.49586296081543\n",
      "2/2 [==============================] - 0s 187ms/step\n",
      "Epoch: 18, Batch: 461/468, discriminator loss real = 1.4263079378597915e-13, disciminator loss fake = 2.81613120023394e-06, generator loss = 14.793354988098145\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 18, Batch: 462/468, discriminator loss real = 9.394967349722228e-23, disciminator loss fake = 1.4163542800815776e-06, generator loss = 14.795668601989746\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 18, Batch: 463/468, discriminator loss real = 2.42582316519442e-27, disciminator loss fake = 1.7127714500020375e-06, generator loss = 15.046510696411133\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 18, Batch: 464/468, discriminator loss real = 2.2501827290504514e-17, disciminator loss fake = 9.144333148469741e-07, generator loss = 14.682819366455078\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 18, Batch: 465/468, discriminator loss real = 2.3795631825616516e-30, disciminator loss fake = 1.8988333749803132e-06, generator loss = 14.868168830871582\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 18, Batch: 466/468, discriminator loss real = 1.4727495261599713e-15, disciminator loss fake = 1.0429473604744999e-06, generator loss = 15.015840530395508\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 18, Batch: 467/468, discriminator loss real = 4.361962800005358e-20, disciminator loss fake = 1.636058414078434e-06, generator loss = 14.643115997314453\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 18, Batch: 468/468, discriminator loss real = 9.662484505230966e-18, disciminator loss fake = 2.1693092548957793e-06, generator loss = 14.749683380126953\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2/2 [==============================] - 0s 144ms/step\n",
      "Epoch: 19, Batch: 1/468, discriminator loss real = 9.988505926235638e-14, disciminator loss fake = 2.5905546863214113e-06, generator loss = 14.5817289352417\n",
      "2/2 [==============================] - 0s 224ms/step\n",
      "Epoch: 19, Batch: 2/468, discriminator loss real = 5.355920250246891e-22, disciminator loss fake = 1.8869644691221765e-06, generator loss = 14.833845138549805\n",
      "2/2 [==============================] - 0s 205ms/step\n",
      "Epoch: 19, Batch: 3/468, discriminator loss real = 3.591071617847774e-08, disciminator loss fake = 1.4185086456564022e-06, generator loss = 15.163492202758789\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 19, Batch: 4/468, discriminator loss real = 3.220440306867682e-20, disciminator loss fake = 1.2798017223758507e-06, generator loss = 14.770334243774414\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 19, Batch: 5/468, discriminator loss real = 1.2765197969846764e-12, disciminator loss fake = 1.7173711057694163e-06, generator loss = 15.012415885925293\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 19, Batch: 6/468, discriminator loss real = 8.856615063787025e-20, disciminator loss fake = 9.396030122843513e-07, generator loss = 14.705057144165039\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 19, Batch: 7/468, discriminator loss real = 4.602890117666458e-12, disciminator loss fake = 1.3195638075558236e-06, generator loss = 15.064916610717773\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 19, Batch: 8/468, discriminator loss real = 9.365957870042931e-35, disciminator loss fake = 1.451058778911829e-06, generator loss = 14.845128059387207\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 19, Batch: 9/468, discriminator loss real = 2.261940008436677e-26, disciminator loss fake = 1.9001083728653612e-06, generator loss = 14.83469009399414\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 19, Batch: 10/468, discriminator loss real = 1.0055347424658038e-34, disciminator loss fake = 1.8055784494208638e-06, generator loss = 14.810735702514648\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 19, Batch: 11/468, discriminator loss real = 7.991391971990183e-14, disciminator loss fake = 1.1714710126398131e-06, generator loss = 14.779104232788086\n",
      "2/2 [==============================] - 0s 156ms/step\n",
      "Epoch: 19, Batch: 12/468, discriminator loss real = 9.033538495495747e-21, disciminator loss fake = 1.6573833363509038e-06, generator loss = 14.938206672668457\n",
      "2/2 [==============================] - 0s 216ms/step\n",
      "Epoch: 19, Batch: 13/468, discriminator loss real = 2.8426841843101056e-25, disciminator loss fake = 7.703745836806775e-07, generator loss = 14.839722633361816\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 19, Batch: 14/468, discriminator loss real = 5.109821751075307e-31, disciminator loss fake = 4.157624516665237e-06, generator loss = 14.713796615600586\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 19, Batch: 15/468, discriminator loss real = 5.55983037386909e-09, disciminator loss fake = 1.0253227173961932e-06, generator loss = 14.814620018005371\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 19, Batch: 16/468, discriminator loss real = 4.87274845204814e-25, disciminator loss fake = 1.2083085039193975e-06, generator loss = 14.921684265136719\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 19, Batch: 17/468, discriminator loss real = 1.0785152230561411e-17, disciminator loss fake = 1.2465186500776326e-06, generator loss = 15.189166069030762\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 19, Batch: 18/468, discriminator loss real = 4.842521584050679e-19, disciminator loss fake = 1.0599263760013855e-06, generator loss = 14.66990852355957\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 19, Batch: 19/468, discriminator loss real = 2.2895327297127153e-26, disciminator loss fake = 1.3616704563901294e-06, generator loss = 14.717262268066406\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 19, Batch: 20/468, discriminator loss real = 1.3995792686727517e-25, disciminator loss fake = 2.7858695830218494e-06, generator loss = 15.084218978881836\n",
      "2/2 [==============================] - 0s 160ms/step\n",
      "Epoch: 19, Batch: 21/468, discriminator loss real = 1.496086108555898e-18, disciminator loss fake = 3.87591762773809e-06, generator loss = 14.931048393249512\n",
      "2/2 [==============================] - 0s 192ms/step\n",
      "Epoch: 19, Batch: 22/468, discriminator loss real = 1.716985207167454e-05, disciminator loss fake = 8.993451956484932e-07, generator loss = 14.84578800201416\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 19, Batch: 23/468, discriminator loss real = 3.5409200038859215e-31, disciminator loss fake = 1.0566238870524103e-06, generator loss = 14.783872604370117\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 19, Batch: 24/468, discriminator loss real = 1.1579365794768092e-23, disciminator loss fake = 2.1268897398840636e-06, generator loss = 14.975131034851074\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 19, Batch: 25/468, discriminator loss real = 3.0104281290022072e-09, disciminator loss fake = 1.7699026102491189e-06, generator loss = 14.794984817504883\n",
      "2/2 [==============================] - 0s 135ms/step\n",
      "Epoch: 19, Batch: 26/468, discriminator loss real = 2.2611634786784407e-10, disciminator loss fake = 1.2233631423441693e-06, generator loss = 14.73315143585205\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 19, Batch: 27/468, discriminator loss real = 6.280980180406459e-10, disciminator loss fake = 1.1168290257046465e-06, generator loss = 15.051416397094727\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 19, Batch: 28/468, discriminator loss real = 3.047599344990792e-15, disciminator loss fake = 8.995376674647559e-07, generator loss = 14.903887748718262\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 19, Batch: 29/468, discriminator loss real = 2.918483380312531e-12, disciminator loss fake = 1.1660678183034179e-06, generator loss = 14.93735408782959\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 19, Batch: 30/468, discriminator loss real = 4.4595205137616046e-21, disciminator loss fake = 7.843390221751179e-07, generator loss = 14.74293327331543\n",
      "2/2 [==============================] - 0s 160ms/step\n",
      "Epoch: 19, Batch: 31/468, discriminator loss real = 4.580226971029333e-07, disciminator loss fake = 1.0434705473016948e-06, generator loss = 14.925036430358887\n",
      "2/2 [==============================] - 0s 179ms/step\n",
      "Epoch: 19, Batch: 32/468, discriminator loss real = 8.424172637221452e-25, disciminator loss fake = 2.000452695938293e-06, generator loss = 15.083175659179688\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 19, Batch: 33/468, discriminator loss real = 7.899872506822477e-25, disciminator loss fake = 8.859827858032077e-07, generator loss = 14.712555885314941\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 19, Batch: 34/468, discriminator loss real = 3.725715586889386e-23, disciminator loss fake = 2.7943033273913898e-06, generator loss = 14.683643341064453\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 19, Batch: 35/468, discriminator loss real = 6.416367805557459e-24, disciminator loss fake = 2.548458041928825e-06, generator loss = 14.966649055480957\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 19, Batch: 36/468, discriminator loss real = 1.8504673849327795e-17, disciminator loss fake = 8.817103207547916e-07, generator loss = 15.055912017822266\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 19, Batch: 37/468, discriminator loss real = 2.5304040588333153e-21, disciminator loss fake = 8.657175953885599e-07, generator loss = 14.807926177978516\n",
      "2/2 [==============================] - 0s 130ms/step\n",
      "Epoch: 19, Batch: 38/468, discriminator loss real = 1.4449872764998872e-07, disciminator loss fake = 1.314023506893136e-06, generator loss = 14.801464080810547\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 19, Batch: 39/468, discriminator loss real = 3.370606465580273e-15, disciminator loss fake = 1.1010107527908986e-06, generator loss = 14.852251052856445\n",
      "2/2 [==============================] - 0s 218ms/step\n",
      "Epoch: 19, Batch: 40/468, discriminator loss real = 4.135606104682665e-06, disciminator loss fake = 1.4594380672861007e-06, generator loss = 14.752185821533203\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 19, Batch: 41/468, discriminator loss real = 2.4063212533675937e-10, disciminator loss fake = 1.1653942237899173e-06, generator loss = 14.956669807434082\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 19, Batch: 42/468, discriminator loss real = 7.367277764329201e-22, disciminator loss fake = 2.617966629259172e-06, generator loss = 15.06216812133789\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 19, Batch: 43/468, discriminator loss real = 4.245926566067144e-21, disciminator loss fake = 9.364277957502054e-07, generator loss = 14.976804733276367\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 19, Batch: 44/468, discriminator loss real = 2.505111880211113e-32, disciminator loss fake = 1.35045934257505e-06, generator loss = 15.104752540588379\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 19, Batch: 45/468, discriminator loss real = 1.0884998927556003e-20, disciminator loss fake = 1.3085879118079902e-06, generator loss = 15.077308654785156\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 19, Batch: 46/468, discriminator loss real = 4.324201875071558e-15, disciminator loss fake = 1.4579038634110475e-06, generator loss = 14.915538787841797\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 19, Batch: 47/468, discriminator loss real = 1.2858566366492384e-28, disciminator loss fake = 1.6935439361986937e-06, generator loss = 14.80604362487793\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 19, Batch: 48/468, discriminator loss real = 2.8741571781246606e-21, disciminator loss fake = 1.0915923667198513e-06, generator loss = 14.878883361816406\n",
      "2/2 [==============================] - 0s 154ms/step\n",
      "Epoch: 19, Batch: 49/468, discriminator loss real = 1.0215768614528689e-20, disciminator loss fake = 7.406342206195404e-07, generator loss = 14.669466972351074\n",
      "2/2 [==============================] - 0s 205ms/step\n",
      "Epoch: 19, Batch: 50/468, discriminator loss real = 1.9284908945413363e-22, disciminator loss fake = 7.641765478183515e-07, generator loss = 14.90852165222168\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 19, Batch: 51/468, discriminator loss real = 4.7400106029885786e-14, disciminator loss fake = 1.1641335504464223e-06, generator loss = 14.85116958618164\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 19, Batch: 52/468, discriminator loss real = 1.4370413699608085e-14, disciminator loss fake = 9.448051514482358e-07, generator loss = 14.987130165100098\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 19, Batch: 53/468, discriminator loss real = 2.1552298140603554e-11, disciminator loss fake = 1.1601669029914774e-06, generator loss = 14.816354751586914\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 19, Batch: 54/468, discriminator loss real = 1.3272199544354646e-27, disciminator loss fake = 1.720608906907728e-06, generator loss = 15.03421688079834\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 19, Batch: 55/468, discriminator loss real = 1.3843250547609931e-12, disciminator loss fake = 1.3881115137337474e-06, generator loss = 15.032438278198242\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 19, Batch: 56/468, discriminator loss real = 2.510274134692736e-05, disciminator loss fake = 8.07688593340572e-07, generator loss = 14.732746124267578\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 19, Batch: 57/468, discriminator loss real = 2.2442771518147234e-14, disciminator loss fake = 1.452744982088916e-06, generator loss = 14.959051132202148\n",
      "2/2 [==============================] - 0s 150ms/step\n",
      "Epoch: 19, Batch: 58/468, discriminator loss real = 6.730190478720219e-24, disciminator loss fake = 2.335410272280569e-06, generator loss = 15.109567642211914\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 19, Batch: 59/468, discriminator loss real = 2.1203855389713942e-14, disciminator loss fake = 1.0586441021587234e-06, generator loss = 14.890443801879883\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 19, Batch: 60/468, discriminator loss real = 1.4502742480584072e-15, disciminator loss fake = 7.105616646185808e-07, generator loss = 14.815423011779785\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 19, Batch: 61/468, discriminator loss real = 5.569941009404938e-18, disciminator loss fake = 7.123484238036326e-07, generator loss = 14.715655326843262\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 19, Batch: 62/468, discriminator loss real = 1.993167408897989e-09, disciminator loss fake = 1.4051597645448055e-06, generator loss = 14.814634323120117\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 19, Batch: 63/468, discriminator loss real = 6.138586326705921e-28, disciminator loss fake = 1.9636290744529106e-06, generator loss = 15.069894790649414\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 19, Batch: 64/468, discriminator loss real = 5.899060045117843e-18, disciminator loss fake = 1.122492221838911e-06, generator loss = 14.722187042236328\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 19, Batch: 65/468, discriminator loss real = 3.936797458149357e-20, disciminator loss fake = 1.0485083521416527e-06, generator loss = 14.932254791259766\n",
      "2/2 [==============================] - 0s 220ms/step\n",
      "Epoch: 19, Batch: 66/468, discriminator loss real = 1.702915153139966e-27, disciminator loss fake = 1.171361986962438e-06, generator loss = 15.029655456542969\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 19, Batch: 67/468, discriminator loss real = 4.8060536546135956e-23, disciminator loss fake = 2.332862095499877e-06, generator loss = 14.664691925048828\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 19, Batch: 68/468, discriminator loss real = 4.399859203313455e-22, disciminator loss fake = 1.781293576641474e-06, generator loss = 15.11190414428711\n",
      "2/2 [==============================] - 0s 135ms/step\n",
      "Epoch: 19, Batch: 69/468, discriminator loss real = 1.1762409923771954e-23, disciminator loss fake = 1.1173456186952535e-06, generator loss = 15.039856910705566\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 19, Batch: 70/468, discriminator loss real = 6.619636553234152e-25, disciminator loss fake = 3.4079887427651556e-06, generator loss = 14.769115447998047\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 19, Batch: 71/468, discriminator loss real = 2.5145352992694825e-05, disciminator loss fake = 1.5399311905639479e-06, generator loss = 14.692466735839844\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 19, Batch: 72/468, discriminator loss real = 1.1823034955574241e-14, disciminator loss fake = 1.0281669347023126e-06, generator loss = 15.043603897094727\n",
      "2/2 [==============================] - 0s 187ms/step\n",
      "Epoch: 19, Batch: 73/468, discriminator loss real = 1.182875886012465e-17, disciminator loss fake = 1.0680287232389674e-06, generator loss = 15.000370025634766\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 19, Batch: 74/468, discriminator loss real = 1.5103066366983775e-11, disciminator loss fake = 9.526177109364653e-07, generator loss = 15.145023345947266\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 19, Batch: 75/468, discriminator loss real = 1.1969686282062396e-24, disciminator loss fake = 1.5114651432668325e-06, generator loss = 15.04397964477539\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 19, Batch: 76/468, discriminator loss real = 2.5520661011934546e-26, disciminator loss fake = 2.1233504412521143e-06, generator loss = 14.96597671508789\n",
      "2/2 [==============================] - 0s 188ms/step\n",
      "Epoch: 19, Batch: 77/468, discriminator loss real = 2.4959276334770132e-15, disciminator loss fake = 1.738744686008431e-06, generator loss = 14.56888198852539\n",
      "2/2 [==============================] - 0s 173ms/step\n",
      "Epoch: 19, Batch: 78/468, discriminator loss real = 5.60412111880117e-25, disciminator loss fake = 1.522822003607871e-06, generator loss = 14.911291122436523\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 19, Batch: 79/468, discriminator loss real = 1.415298531753929e-19, disciminator loss fake = 1.5830883057788014e-06, generator loss = 14.834226608276367\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 19, Batch: 80/468, discriminator loss real = 2.0697168048732275e-24, disciminator loss fake = 1.8347030845689005e-06, generator loss = 14.904330253601074\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 19, Batch: 81/468, discriminator loss real = 1.5627326948829926e-15, disciminator loss fake = 1.6273155551971286e-06, generator loss = 14.932872772216797\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 19, Batch: 82/468, discriminator loss real = 4.856857811522767e-22, disciminator loss fake = 2.1486559944605688e-06, generator loss = 14.854969024658203\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 19, Batch: 83/468, discriminator loss real = 1.5249240732373437e-06, disciminator loss fake = 9.868074357655132e-07, generator loss = 14.638130187988281\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 19, Batch: 84/468, discriminator loss real = 9.201758685529679e-14, disciminator loss fake = 3.7694676393584814e-06, generator loss = 15.056756973266602\n",
      "2/2 [==============================] - 0s 187ms/step\n",
      "Epoch: 19, Batch: 85/468, discriminator loss real = 7.62721513188196e-21, disciminator loss fake = 1.1825657111330656e-06, generator loss = 15.031423568725586\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 19, Batch: 86/468, discriminator loss real = 3.820686104191555e-15, disciminator loss fake = 9.455449117012904e-07, generator loss = 14.998321533203125\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 19, Batch: 87/468, discriminator loss real = 1.8066155667816053e-14, disciminator loss fake = 1.2928962860314641e-06, generator loss = 14.887032508850098\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 19, Batch: 88/468, discriminator loss real = 3.8651725049743124e-12, disciminator loss fake = 8.190115750039695e-07, generator loss = 14.780519485473633\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 19, Batch: 89/468, discriminator loss real = 3.042713076615878e-16, disciminator loss fake = 1.0273502084601205e-06, generator loss = 15.125814437866211\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 19, Batch: 90/468, discriminator loss real = 2.0798168407054618e-05, disciminator loss fake = 1.0511184882489033e-06, generator loss = 15.060205459594727\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 19, Batch: 91/468, discriminator loss real = 1.3905958684345869e-18, disciminator loss fake = 1.0670921710698167e-06, generator loss = 15.08160400390625\n",
      "2/2 [==============================] - 0s 144ms/step\n",
      "Epoch: 19, Batch: 92/468, discriminator loss real = 9.676439731265418e-06, disciminator loss fake = 9.770378710527439e-07, generator loss = 14.959774017333984\n",
      "2/2 [==============================] - 0s 162ms/step\n",
      "Epoch: 19, Batch: 93/468, discriminator loss real = 1.6370851702719732e-19, disciminator loss fake = 1.34223614622897e-06, generator loss = 14.793471336364746\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 19, Batch: 94/468, discriminator loss real = 2.6438875106597275e-32, disciminator loss fake = 1.110608309318195e-06, generator loss = 14.886391639709473\n",
      "2/2 [==============================] - 0s 136ms/step\n",
      "Epoch: 19, Batch: 95/468, discriminator loss real = 4.756125468337563e-16, disciminator loss fake = 1.1103014685431845e-06, generator loss = 15.070816040039062\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 19, Batch: 96/468, discriminator loss real = 5.193898999777957e-08, disciminator loss fake = 1.0990447663061786e-06, generator loss = 14.777549743652344\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 19, Batch: 97/468, discriminator loss real = 2.0744018857992577e-17, disciminator loss fake = 1.6750905160733964e-06, generator loss = 14.861982345581055\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 19, Batch: 98/468, discriminator loss real = 1.57099539540434e-14, disciminator loss fake = 1.0536302852415247e-06, generator loss = 14.897802352905273\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 19, Batch: 99/468, discriminator loss real = 1.3255771532669578e-33, disciminator loss fake = 1.3230370541350567e-06, generator loss = 14.79324722290039\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 19, Batch: 100/468, discriminator loss real = 1.1479110093412277e-20, disciminator loss fake = 2.010430307564093e-06, generator loss = 14.852481842041016\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 19, Batch: 101/468, discriminator loss real = 1.0305563995623374e-15, disciminator loss fake = 9.451874802834936e-07, generator loss = 15.050965309143066\n",
      "2/2 [==============================] - 0s 136ms/step\n",
      "Epoch: 19, Batch: 102/468, discriminator loss real = 5.7015253046685706e-15, disciminator loss fake = 1.489826445322251e-06, generator loss = 14.986510276794434\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 19, Batch: 103/468, discriminator loss real = 2.1895913901448516e-12, disciminator loss fake = 1.0045350791187957e-06, generator loss = 14.859600067138672\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 19, Batch: 104/468, discriminator loss real = 4.265986726666146e-18, disciminator loss fake = 1.6918031633395003e-06, generator loss = 14.617660522460938\n",
      "2/2 [==============================] - 0s 200ms/step\n",
      "Epoch: 19, Batch: 105/468, discriminator loss real = 8.517668431708246e-25, disciminator loss fake = 2.192499778175261e-06, generator loss = 14.79198169708252\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 19, Batch: 106/468, discriminator loss real = 5.272856610864681e-18, disciminator loss fake = 1.0298122106178198e-06, generator loss = 14.787849426269531\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 19, Batch: 107/468, discriminator loss real = 5.459130716922722e-11, disciminator loss fake = 2.084787411149591e-06, generator loss = 14.982707977294922\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 19, Batch: 108/468, discriminator loss real = 2.098897350714913e-16, disciminator loss fake = 7.570283173663483e-07, generator loss = 15.205318450927734\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 19, Batch: 109/468, discriminator loss real = 1.8743131581937693e-23, disciminator loss fake = 1.0747367014118936e-06, generator loss = 15.033613204956055\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 19, Batch: 110/468, discriminator loss real = 9.402720047474488e-16, disciminator loss fake = 1.3890957006879034e-06, generator loss = 14.731229782104492\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 19, Batch: 111/468, discriminator loss real = 2.60631171701606e-31, disciminator loss fake = 1.6412931245213258e-06, generator loss = 14.824087142944336\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 19, Batch: 112/468, discriminator loss real = 8.396777234219278e-17, disciminator loss fake = 7.40118196063122e-07, generator loss = 15.16700267791748\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 19, Batch: 113/468, discriminator loss real = 2.4774409276449513e-15, disciminator loss fake = 1.3358774140215246e-06, generator loss = 14.799261093139648\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 19, Batch: 114/468, discriminator loss real = 9.287855232986312e-18, disciminator loss fake = 1.7686390947346808e-06, generator loss = 14.968650817871094\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 19, Batch: 115/468, discriminator loss real = 1.5660864827182763e-09, disciminator loss fake = 9.252237305190647e-07, generator loss = 14.818267822265625\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 19, Batch: 116/468, discriminator loss real = 2.674483301490227e-09, disciminator loss fake = 1.1803244888142217e-06, generator loss = 14.696340560913086\n",
      "2/2 [==============================] - 0s 218ms/step\n",
      "Epoch: 19, Batch: 117/468, discriminator loss real = 2.7286734193927226e-19, disciminator loss fake = 5.910658273933223e-07, generator loss = 14.964384078979492\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 19, Batch: 118/468, discriminator loss real = 1.464337489759556e-17, disciminator loss fake = 1.6751735074649332e-06, generator loss = 15.307199478149414\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 19, Batch: 119/468, discriminator loss real = 3.8109235447336687e-06, disciminator loss fake = 9.367672078042233e-07, generator loss = 15.351258277893066\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 19, Batch: 120/468, discriminator loss real = 3.9191041436067203e-22, disciminator loss fake = 1.6260916027022176e-06, generator loss = 15.037846565246582\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 19, Batch: 121/468, discriminator loss real = 2.377164338073489e-23, disciminator loss fake = 1.3166842336431728e-06, generator loss = 15.121191024780273\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 19, Batch: 122/468, discriminator loss real = 2.940013911821603e-22, disciminator loss fake = 1.2039848797940067e-06, generator loss = 14.955314636230469\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 19, Batch: 123/468, discriminator loss real = 1.0635696410304718e-17, disciminator loss fake = 1.2222499208291993e-06, generator loss = 14.979257583618164\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 19, Batch: 124/468, discriminator loss real = 1.8031568001375668e-20, disciminator loss fake = 5.630698751701857e-07, generator loss = 14.892216682434082\n",
      "2/2 [==============================] - 0s 145ms/step\n",
      "Epoch: 19, Batch: 125/468, discriminator loss real = 7.804611389541218e-26, disciminator loss fake = 1.337861135652929e-06, generator loss = 14.700554847717285\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 19, Batch: 126/468, discriminator loss real = 1.9241053398474805e-19, disciminator loss fake = 8.934747484090622e-07, generator loss = 15.260361671447754\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 19, Batch: 127/468, discriminator loss real = 1.5031536904075438e-08, disciminator loss fake = 7.202322649391135e-07, generator loss = 14.761784553527832\n",
      "2/2 [==============================] - 0s 155ms/step\n",
      "Epoch: 19, Batch: 128/468, discriminator loss real = 3.046993239977472e-16, disciminator loss fake = 1.5204381043076864e-06, generator loss = 15.218657493591309\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 19, Batch: 129/468, discriminator loss real = 1.8269215564475596e-16, disciminator loss fake = 1.0387657312094234e-06, generator loss = 15.250000953674316\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 19, Batch: 130/468, discriminator loss real = 2.1855950903937717e-15, disciminator loss fake = 1.2735738437186228e-06, generator loss = 14.986186981201172\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 19, Batch: 131/468, discriminator loss real = 7.157033011966038e-18, disciminator loss fake = 1.0484377526154276e-06, generator loss = 14.913034439086914\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 19, Batch: 132/468, discriminator loss real = 3.409731915218761e-12, disciminator loss fake = 7.806701205481659e-07, generator loss = 15.019036293029785\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 19, Batch: 133/468, discriminator loss real = 6.555564908462558e-16, disciminator loss fake = 1.0542623840592569e-06, generator loss = 14.882061004638672\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 19, Batch: 134/468, discriminator loss real = 3.4256812393337398e-18, disciminator loss fake = 1.5163519719862961e-06, generator loss = 15.115438461303711\n",
      "2/2 [==============================] - 0s 192ms/step\n",
      "Epoch: 19, Batch: 135/468, discriminator loss real = 1.0026164030746512e-27, disciminator loss fake = 9.644440979172941e-07, generator loss = 15.029294967651367\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 19, Batch: 136/468, discriminator loss real = 8.559177071384295e-21, disciminator loss fake = 9.435478887098725e-07, generator loss = 14.915637969970703\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 19, Batch: 137/468, discriminator loss real = 8.877524237692489e-31, disciminator loss fake = 2.832912059602677e-06, generator loss = 15.053812026977539\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 19, Batch: 138/468, discriminator loss real = 1.8413751079471297e-10, disciminator loss fake = 1.0826801144503406e-06, generator loss = 14.860940933227539\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 19, Batch: 139/468, discriminator loss real = 4.14306350563136e-30, disciminator loss fake = 6.345650263028801e-07, generator loss = 14.986181259155273\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 19, Batch: 140/468, discriminator loss real = 1.2858217392490783e-17, disciminator loss fake = 1.585289624017605e-06, generator loss = 14.965715408325195\n",
      "2/2 [==============================] - 0s 171ms/step\n",
      "Epoch: 19, Batch: 141/468, discriminator loss real = 1.7910256083902262e-25, disciminator loss fake = 8.118560117509332e-07, generator loss = 15.10112190246582\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 19, Batch: 142/468, discriminator loss real = 3.7226548394566646e-32, disciminator loss fake = 8.896670919966709e-07, generator loss = 15.053611755371094\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 19, Batch: 143/468, discriminator loss real = 2.47597276015199e-10, disciminator loss fake = 1.4415234090847662e-06, generator loss = 15.092416763305664\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 19, Batch: 144/468, discriminator loss real = 3.877408364035848e-22, disciminator loss fake = 1.4170841495797504e-06, generator loss = 15.032648086547852\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 19, Batch: 145/468, discriminator loss real = 1.7527801670043496e-17, disciminator loss fake = 1.1699672768372693e-06, generator loss = 15.07469367980957\n",
      "2/2 [==============================] - 0s 155ms/step\n",
      "Epoch: 19, Batch: 146/468, discriminator loss real = 2.0178025486936843e-17, disciminator loss fake = 1.3351095731195528e-06, generator loss = 15.258970260620117\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 19, Batch: 147/468, discriminator loss real = 5.295714561315279e-11, disciminator loss fake = 1.2255138699401869e-06, generator loss = 15.135591506958008\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 19, Batch: 148/468, discriminator loss real = 5.459226606727472e-17, disciminator loss fake = 9.841080554906512e-07, generator loss = 15.13390064239502\n",
      "2/2 [==============================] - 0s 130ms/step\n",
      "Epoch: 19, Batch: 149/468, discriminator loss real = 2.7421799635785396e-16, disciminator loss fake = 2.2721824279869907e-06, generator loss = 15.38112735748291\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 19, Batch: 150/468, discriminator loss real = 6.61537221080229e-15, disciminator loss fake = 5.827047857565049e-07, generator loss = 14.853291511535645\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 19, Batch: 151/468, discriminator loss real = 4.953112978347152e-22, disciminator loss fake = 1.5263203749782406e-06, generator loss = 15.027097702026367\n",
      "2/2 [==============================] - 0s 181ms/step\n",
      "Epoch: 19, Batch: 152/468, discriminator loss real = 1.2779590980135474e-18, disciminator loss fake = 6.314212441793643e-07, generator loss = 15.356298446655273\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 19, Batch: 153/468, discriminator loss real = 4.905428194006485e-17, disciminator loss fake = 1.042484655044973e-06, generator loss = 15.154683113098145\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 19, Batch: 154/468, discriminator loss real = 5.325392974045521e-23, disciminator loss fake = 6.729293318130658e-07, generator loss = 14.981689453125\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 19, Batch: 155/468, discriminator loss real = 1.4877714441348798e-19, disciminator loss fake = 1.166310312328278e-06, generator loss = 15.211881637573242\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 19, Batch: 156/468, discriminator loss real = 4.1906209795061645e-21, disciminator loss fake = 1.0659956615199917e-06, generator loss = 15.290889739990234\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 19, Batch: 157/468, discriminator loss real = 1.3965647838176665e-07, disciminator loss fake = 5.943842893429974e-07, generator loss = 14.949657440185547\n",
      "2/2 [==============================] - 0s 174ms/step\n",
      "Epoch: 19, Batch: 158/468, discriminator loss real = 5.9718242657931835e-30, disciminator loss fake = 7.484539992219652e-07, generator loss = 15.130924224853516\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 19, Batch: 159/468, discriminator loss real = 6.41346581419823e-14, disciminator loss fake = 6.874083169350342e-07, generator loss = 14.867437362670898\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 19, Batch: 160/468, discriminator loss real = 5.25559913133999e-30, disciminator loss fake = 1.0074537613036227e-06, generator loss = 15.323253631591797\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 19, Batch: 161/468, discriminator loss real = 1.9213964680979766e-17, disciminator loss fake = 6.304851467575645e-07, generator loss = 15.116741180419922\n",
      "2/2 [==============================] - 0s 137ms/step\n",
      "Epoch: 19, Batch: 162/468, discriminator loss real = 9.932879842034568e-26, disciminator loss fake = 7.772704293529387e-07, generator loss = 14.969681739807129\n",
      "2/2 [==============================] - 0s 144ms/step\n",
      "Epoch: 19, Batch: 163/468, discriminator loss real = 4.1024241682429734e-18, disciminator loss fake = 7.173565563789452e-07, generator loss = 15.3281888961792\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 19, Batch: 164/468, discriminator loss real = 2.9414503195353617e-14, disciminator loss fake = 9.345947091787821e-07, generator loss = 15.052511215209961\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 19, Batch: 165/468, discriminator loss real = 6.417416911675312e-23, disciminator loss fake = 1.4146960438665701e-06, generator loss = 15.266990661621094\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 19, Batch: 166/468, discriminator loss real = 1.1300876501317325e-21, disciminator loss fake = 1.267097673007811e-06, generator loss = 14.906903266906738\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 19, Batch: 167/468, discriminator loss real = 1.1963665301203297e-24, disciminator loss fake = 1.8091188849211903e-06, generator loss = 15.16163158416748\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 19, Batch: 168/468, discriminator loss real = 2.187741258908956e-22, disciminator loss fake = 1.3654472468260792e-06, generator loss = 15.213305473327637\n",
      "2/2 [==============================] - 0s 172ms/step\n",
      "Epoch: 19, Batch: 169/468, discriminator loss real = 1.7467898573571386e-16, disciminator loss fake = 1.6828757907205727e-06, generator loss = 15.049988746643066\n",
      "2/2 [==============================] - 0s 173ms/step\n",
      "Epoch: 19, Batch: 170/468, discriminator loss real = 1.9641599131114843e-20, disciminator loss fake = 1.000920406113437e-06, generator loss = 15.10650634765625\n",
      "2/2 [==============================] - 0s 192ms/step\n",
      "Epoch: 19, Batch: 171/468, discriminator loss real = 3.1436720963227094e-28, disciminator loss fake = 6.605087605748849e-07, generator loss = 15.12925910949707\n",
      "2/2 [==============================] - 0s 218ms/step\n",
      "Epoch: 19, Batch: 172/468, discriminator loss real = 3.191040222934292e-29, disciminator loss fake = 1.2543223419925198e-06, generator loss = 15.123136520385742\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 19, Batch: 173/468, discriminator loss real = 8.083885709655724e-29, disciminator loss fake = 6.771961125195958e-07, generator loss = 15.112977981567383\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 19, Batch: 174/468, discriminator loss real = 1.493575247042933e-20, disciminator loss fake = 6.53089273328078e-07, generator loss = 15.098949432373047\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 19, Batch: 175/468, discriminator loss real = 1.4054918340278277e-10, disciminator loss fake = 1.1048695114368456e-06, generator loss = 15.043590545654297\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 19, Batch: 176/468, discriminator loss real = 1.909299840858547e-19, disciminator loss fake = 1.3694815379494685e-06, generator loss = 15.039368629455566\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 19, Batch: 177/468, discriminator loss real = 9.832972835965847e-08, disciminator loss fake = 1.0273911357217003e-06, generator loss = 14.946942329406738\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 19, Batch: 178/468, discriminator loss real = 2.381410301020559e-17, disciminator loss fake = 6.369565426211921e-07, generator loss = 15.136451721191406\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 19, Batch: 179/468, discriminator loss real = 5.2191849968191776e-18, disciminator loss fake = 9.001124112728576e-07, generator loss = 14.998580932617188\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 19, Batch: 180/468, discriminator loss real = 1.5271623932959955e-15, disciminator loss fake = 1.1820412737506558e-06, generator loss = 15.214097023010254\n",
      "2/2 [==============================] - 0s 177ms/step\n",
      "Epoch: 19, Batch: 181/468, discriminator loss real = 8.45452701412079e-18, disciminator loss fake = 8.020530799512926e-07, generator loss = 15.32712459564209\n",
      "2/2 [==============================] - 0s 141ms/step\n",
      "Epoch: 19, Batch: 182/468, discriminator loss real = 5.530268496648706e-19, disciminator loss fake = 7.624703357578255e-07, generator loss = 15.059282302856445\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 19, Batch: 183/468, discriminator loss real = 2.1845691545457535e-22, disciminator loss fake = 9.945742931449786e-07, generator loss = 15.057158470153809\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 19, Batch: 184/468, discriminator loss real = 0.0003378087130840868, disciminator loss fake = 9.537759524391731e-07, generator loss = 15.224326133728027\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 19, Batch: 185/468, discriminator loss real = 8.870604109661974e-21, disciminator loss fake = 1.7015868252201471e-06, generator loss = 15.068886756896973\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 19, Batch: 186/468, discriminator loss real = 2.4179038604550522e-22, disciminator loss fake = 1.6327508092217613e-06, generator loss = 14.66223430633545\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 19, Batch: 187/468, discriminator loss real = 4.571094615020768e-14, disciminator loss fake = 9.295163181377575e-07, generator loss = 15.103338241577148\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 19, Batch: 188/468, discriminator loss real = 6.319692165412949e-12, disciminator loss fake = 2.6814473130798433e-06, generator loss = 14.47952651977539\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 19, Batch: 189/468, discriminator loss real = 2.6538570009388327e-19, disciminator loss fake = 1.2244636309333146e-06, generator loss = 14.530036926269531\n",
      "2/2 [==============================] - 0s 162ms/step\n",
      "Epoch: 19, Batch: 190/468, discriminator loss real = 1.7800503909412568e-12, disciminator loss fake = 2.8437530090741348e-06, generator loss = 14.554546356201172\n",
      "2/2 [==============================] - 0s 220ms/step\n",
      "Epoch: 19, Batch: 191/468, discriminator loss real = 9.657538792348511e-18, disciminator loss fake = 3.3931078178284224e-06, generator loss = 14.290848731994629\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 19, Batch: 192/468, discriminator loss real = 5.149383433277876e-24, disciminator loss fake = 2.0444228994165314e-06, generator loss = 14.33431339263916\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 19, Batch: 193/468, discriminator loss real = 4.3425087883119464e-21, disciminator loss fake = 2.6791985874297097e-06, generator loss = 14.670064926147461\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 19, Batch: 194/468, discriminator loss real = 2.5578945628268457e-09, disciminator loss fake = 8.894987786334241e-07, generator loss = 14.422286987304688\n",
      "2/2 [==============================] - 0s 137ms/step\n",
      "Epoch: 19, Batch: 195/468, discriminator loss real = 1.459081046479996e-18, disciminator loss fake = 1.7083980310417246e-06, generator loss = 14.684385299682617\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 19, Batch: 196/468, discriminator loss real = 5.964008448341648e-14, disciminator loss fake = 2.8462500267778523e-06, generator loss = 14.933094024658203\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 19, Batch: 197/468, discriminator loss real = 5.9820825443814825e-21, disciminator loss fake = 3.1906195090414258e-06, generator loss = 14.409337043762207\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 19, Batch: 198/468, discriminator loss real = 1.0521042824657763e-15, disciminator loss fake = 1.592753278600867e-06, generator loss = 14.627954483032227\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 19, Batch: 199/468, discriminator loss real = 2.9909342521648953e-23, disciminator loss fake = 4.03097919843276e-06, generator loss = 14.31710433959961\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 19, Batch: 200/468, discriminator loss real = 1.8980950332266627e-19, disciminator loss fake = 2.3036880065774312e-06, generator loss = 14.626611709594727\n",
      "2/2 [==============================] - 0s 134ms/step\n",
      "Epoch: 19, Batch: 201/468, discriminator loss real = 3.678552573660454e-08, disciminator loss fake = 2.075762267850223e-06, generator loss = 14.513760566711426\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 19, Batch: 202/468, discriminator loss real = 7.392734818790573e-17, disciminator loss fake = 2.275690349051729e-06, generator loss = 14.335962295532227\n",
      "2/2 [==============================] - 0s 238ms/step\n",
      "Epoch: 19, Batch: 203/468, discriminator loss real = 2.6692767801325158e-14, disciminator loss fake = 1.789143084351963e-06, generator loss = 14.405950546264648\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 19, Batch: 204/468, discriminator loss real = 1.1429490565769033e-20, disciminator loss fake = 2.3938964659464546e-06, generator loss = 14.280224800109863\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 19, Batch: 205/468, discriminator loss real = 1.0747289899178175e-18, disciminator loss fake = 1.9346780391060747e-06, generator loss = 14.469404220581055\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 19, Batch: 206/468, discriminator loss real = 1.7277862676084943e-20, disciminator loss fake = 1.7035846440194291e-06, generator loss = 14.32539176940918\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 19, Batch: 207/468, discriminator loss real = 8.274795293417014e-10, disciminator loss fake = 1.7158372429548763e-06, generator loss = 14.21942138671875\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 19, Batch: 208/468, discriminator loss real = 1.866160213195947e-29, disciminator loss fake = 2.1813277726323577e-06, generator loss = 14.435758590698242\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 19, Batch: 209/468, discriminator loss real = 1.4348061801172651e-11, disciminator loss fake = 1.0361245585954748e-06, generator loss = 14.28768253326416\n",
      "2/2 [==============================] - 0s 179ms/step\n",
      "Epoch: 19, Batch: 210/468, discriminator loss real = 1.229573906026925e-23, disciminator loss fake = 1.922992851177696e-06, generator loss = 14.981257438659668\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 19, Batch: 211/468, discriminator loss real = 2.4761874328760314e-07, disciminator loss fake = 1.5182104107225314e-06, generator loss = 14.694425582885742\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 19, Batch: 212/468, discriminator loss real = 4.58097203562529e-14, disciminator loss fake = 1.0171827398153255e-06, generator loss = 14.539064407348633\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 19, Batch: 213/468, discriminator loss real = 1.2306820735830115e-06, disciminator loss fake = 2.284225502080517e-06, generator loss = 14.23415470123291\n",
      "2/2 [==============================] - 0s 141ms/step\n",
      "Epoch: 19, Batch: 214/468, discriminator loss real = 1.9432854610540831e-19, disciminator loss fake = 1.6604733446001774e-06, generator loss = 14.219857215881348\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 19, Batch: 215/468, discriminator loss real = 5.4805356064874506e-18, disciminator loss fake = 1.621553565200884e-06, generator loss = 14.445359230041504\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 19, Batch: 216/468, discriminator loss real = 2.381897866143845e-05, disciminator loss fake = 2.79486266663298e-06, generator loss = 14.604955673217773\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 19, Batch: 217/468, discriminator loss real = 2.7408323870990172e-15, disciminator loss fake = 5.918190254305955e-06, generator loss = 14.803030014038086\n",
      "2/2 [==============================] - 0s 201ms/step\n",
      "Epoch: 19, Batch: 218/468, discriminator loss real = 2.5293318600596443e-14, disciminator loss fake = 1.4684287634736393e-06, generator loss = 14.62325668334961\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 19, Batch: 219/468, discriminator loss real = 2.174678344481101e-16, disciminator loss fake = 5.907488230150193e-06, generator loss = 14.45375919342041\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 19, Batch: 220/468, discriminator loss real = 2.0701419056446096e-17, disciminator loss fake = 2.0168076844129246e-06, generator loss = 14.596681594848633\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 19, Batch: 221/468, discriminator loss real = 4.932174894195507e-12, disciminator loss fake = 1.0198261861660285e-06, generator loss = 14.032543182373047\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 19, Batch: 222/468, discriminator loss real = 6.910002688771602e-21, disciminator loss fake = 2.0158904590061866e-06, generator loss = 14.559070587158203\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 19, Batch: 223/468, discriminator loss real = 2.1224580951848287e-28, disciminator loss fake = 2.1429427761177067e-06, generator loss = 14.510680198669434\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 19, Batch: 224/468, discriminator loss real = 4.488642395055961e-14, disciminator loss fake = 1.2191864016131149e-06, generator loss = 14.486675262451172\n",
      "2/2 [==============================] - 0s 180ms/step\n",
      "Epoch: 19, Batch: 225/468, discriminator loss real = 2.188038992204837e-15, disciminator loss fake = 2.398236574663315e-06, generator loss = 14.530746459960938\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 19, Batch: 226/468, discriminator loss real = 2.5938968351436874e-21, disciminator loss fake = 2.6663187782105524e-06, generator loss = 14.808834075927734\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 19, Batch: 227/468, discriminator loss real = 1.826284620493751e-13, disciminator loss fake = 1.4530395446854527e-06, generator loss = 14.55428695678711\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 19, Batch: 228/468, discriminator loss real = 6.607986433518718e-26, disciminator loss fake = 8.458038109893096e-07, generator loss = 14.556367874145508\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 19, Batch: 229/468, discriminator loss real = 8.555182002081217e-23, disciminator loss fake = 2.7903461159439757e-06, generator loss = 14.505002975463867\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 19, Batch: 230/468, discriminator loss real = 1.444197067922653e-22, disciminator loss fake = 1.1441514971011202e-06, generator loss = 14.43204116821289\n",
      "2/2 [==============================] - 0s 154ms/step\n",
      "Epoch: 19, Batch: 231/468, discriminator loss real = 8.212168342069764e-21, disciminator loss fake = 6.140483037597733e-06, generator loss = 14.622922897338867\n",
      "2/2 [==============================] - 0s 171ms/step\n",
      "Epoch: 19, Batch: 232/468, discriminator loss real = 7.640211076345705e-20, disciminator loss fake = 2.0633901840483304e-06, generator loss = 14.501611709594727\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 19, Batch: 233/468, discriminator loss real = 9.553280577365413e-15, disciminator loss fake = 2.0978702650609193e-06, generator loss = 14.539557456970215\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 19, Batch: 234/468, discriminator loss real = 6.084705765788523e-31, disciminator loss fake = 2.157749804609921e-06, generator loss = 14.92384147644043\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 19, Batch: 235/468, discriminator loss real = 1.1926906670716623e-22, disciminator loss fake = 1.846675786509877e-06, generator loss = 14.673322677612305\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 19, Batch: 236/468, discriminator loss real = 2.4117113826962544e-15, disciminator loss fake = 1.1498381127239554e-06, generator loss = 14.744178771972656\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 19, Batch: 237/468, discriminator loss real = 6.503194197230514e-19, disciminator loss fake = 1.5071523193910252e-06, generator loss = 14.298874855041504\n",
      "2/2 [==============================] - 0s 156ms/step\n",
      "Epoch: 19, Batch: 238/468, discriminator loss real = 2.737201958147306e-11, disciminator loss fake = 2.2448855361290043e-06, generator loss = 14.450606346130371\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 19, Batch: 239/468, discriminator loss real = 2.6351298743065854e-07, disciminator loss fake = 1.3094368114252575e-06, generator loss = 14.630741119384766\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 19, Batch: 240/468, discriminator loss real = 4.396061581256014e-31, disciminator loss fake = 6.1158025346230716e-06, generator loss = 14.851312637329102\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 19, Batch: 241/468, discriminator loss real = 2.3262219948761397e-29, disciminator loss fake = 1.9409401375014568e-06, generator loss = 14.590871810913086\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 19, Batch: 242/468, discriminator loss real = 3.903127459056298e-19, disciminator loss fake = 2.3771324322297005e-06, generator loss = 14.712484359741211\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 19, Batch: 243/468, discriminator loss real = 2.585853998104708e-20, disciminator loss fake = 1.2828729722969001e-06, generator loss = 14.61944580078125\n",
      "2/2 [==============================] - 0s 130ms/step\n",
      "Epoch: 19, Batch: 244/468, discriminator loss real = 2.1443775269862137e-20, disciminator loss fake = 1.253937966794183e-06, generator loss = 14.678584098815918\n",
      "2/2 [==============================] - 0s 229ms/step\n",
      "Epoch: 19, Batch: 245/468, discriminator loss real = 1.8307311863895093e-17, disciminator loss fake = 6.3172419686452486e-06, generator loss = 14.512676239013672\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 19, Batch: 246/468, discriminator loss real = 4.125852011386168e-30, disciminator loss fake = 1.5895682281552581e-06, generator loss = 14.708182334899902\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 19, Batch: 247/468, discriminator loss real = 3.925029382458381e-14, disciminator loss fake = 7.707756594754755e-06, generator loss = 14.653820037841797\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 19, Batch: 248/468, discriminator loss real = 1.853654677269069e-18, disciminator loss fake = 1.0054769745693193e-06, generator loss = 14.593093872070312\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 19, Batch: 249/468, discriminator loss real = 5.527870189860185e-18, disciminator loss fake = 1.061837792803999e-06, generator loss = 14.601982116699219\n",
      "2/2 [==============================] - 0s 135ms/step\n",
      "Epoch: 19, Batch: 250/468, discriminator loss real = 1.383334051752172e-06, disciminator loss fake = 2.802998096740339e-06, generator loss = 14.697118759155273\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 19, Batch: 251/468, discriminator loss real = 1.6669138322654218e-21, disciminator loss fake = 1.1596624744925066e-06, generator loss = 14.393962860107422\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 19, Batch: 252/468, discriminator loss real = 9.002539331544194e-16, disciminator loss fake = 1.4725737855769694e-06, generator loss = 14.692008972167969\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 19, Batch: 253/468, discriminator loss real = 1.0312449185640267e-21, disciminator loss fake = 2.5294027636846295e-06, generator loss = 14.621845245361328\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 19, Batch: 254/468, discriminator loss real = 2.3682628131911844e-19, disciminator loss fake = 7.163228019635426e-07, generator loss = 14.694624900817871\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 19, Batch: 255/468, discriminator loss real = 2.9233278991958045e-11, disciminator loss fake = 1.097279209716362e-06, generator loss = 14.618467330932617\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 19, Batch: 256/468, discriminator loss real = 3.3945578383154334e-27, disciminator loss fake = 1.5064297258504666e-06, generator loss = 14.626272201538086\n",
      "2/2 [==============================] - 0s 141ms/step\n",
      "Epoch: 19, Batch: 257/468, discriminator loss real = 1.1078938046076309e-20, disciminator loss fake = 1.5099026313691866e-06, generator loss = 14.770030975341797\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 19, Batch: 258/468, discriminator loss real = 6.592568269070398e-08, disciminator loss fake = 2.2323804387269774e-06, generator loss = 14.530550003051758\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 19, Batch: 259/468, discriminator loss real = 1.0333695250203445e-17, disciminator loss fake = 1.1552426713024033e-06, generator loss = 14.412269592285156\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 19, Batch: 260/468, discriminator loss real = 5.016646952129438e-22, disciminator loss fake = 2.669044079084415e-06, generator loss = 14.752696990966797\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 19, Batch: 261/468, discriminator loss real = 6.998727250555228e-23, disciminator loss fake = 7.352392117354611e-07, generator loss = 15.045089721679688\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 19, Batch: 262/468, discriminator loss real = 1.2778023569809914e-20, disciminator loss fake = 2.1211394596321043e-06, generator loss = 14.632512092590332\n",
      "2/2 [==============================] - 0s 147ms/step\n",
      "Epoch: 19, Batch: 263/468, discriminator loss real = 1.3997596811617757e-23, disciminator loss fake = 1.1315405572531745e-06, generator loss = 14.619110107421875\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 19, Batch: 264/468, discriminator loss real = 2.9315642800397293e-18, disciminator loss fake = 1.0402347925264621e-06, generator loss = 14.801689147949219\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 19, Batch: 265/468, discriminator loss real = 2.0560245707932097e-25, disciminator loss fake = 8.50379137773416e-07, generator loss = 15.051076889038086\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 19, Batch: 266/468, discriminator loss real = 1.3694916207095565e-25, disciminator loss fake = 1.3945458476882777e-06, generator loss = 14.751805305480957\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 19, Batch: 267/468, discriminator loss real = 5.057417592352342e-12, disciminator loss fake = 1.6733890788600547e-06, generator loss = 14.884178161621094\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 19, Batch: 268/468, discriminator loss real = 4.458980493865505e-12, disciminator loss fake = 2.909756403823849e-06, generator loss = 14.852313995361328\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 19, Batch: 269/468, discriminator loss real = 7.647647272401858e-12, disciminator loss fake = 2.2606427592108957e-06, generator loss = 14.598480224609375\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 19, Batch: 270/468, discriminator loss real = 2.4646478635759195e-08, disciminator loss fake = 1.8312280190002639e-06, generator loss = 14.540245056152344\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 19, Batch: 271/468, discriminator loss real = 2.631232730374975e-24, disciminator loss fake = 1.325998937318218e-06, generator loss = 14.517851829528809\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 19, Batch: 272/468, discriminator loss real = 9.950190899086359e-14, disciminator loss fake = 1.138587776949862e-06, generator loss = 14.730993270874023\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 19, Batch: 273/468, discriminator loss real = 2.550777888905537e-19, disciminator loss fake = 8.891049674275564e-07, generator loss = 14.751625061035156\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 19, Batch: 274/468, discriminator loss real = 1.3568000065734977e-16, disciminator loss fake = 1.638705498407944e-06, generator loss = 14.668156623840332\n",
      "2/2 [==============================] - 0s 159ms/step\n",
      "Epoch: 19, Batch: 275/468, discriminator loss real = 7.526620094119156e-22, disciminator loss fake = 1.3618472394227865e-06, generator loss = 14.593802452087402\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 19, Batch: 276/468, discriminator loss real = 5.334384726187592e-24, disciminator loss fake = 1.0109866934726597e-06, generator loss = 14.916122436523438\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 19, Batch: 277/468, discriminator loss real = 5.642487616464714e-14, disciminator loss fake = 1.2149921531090513e-06, generator loss = 14.998991012573242\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 19, Batch: 278/468, discriminator loss real = 1.984335085580824e-06, disciminator loss fake = 8.447035497738398e-07, generator loss = 14.818924903869629\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 19, Batch: 279/468, discriminator loss real = 1.6804493560562683e-11, disciminator loss fake = 1.2138677902839845e-06, generator loss = 14.849930763244629\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 19, Batch: 280/468, discriminator loss real = 1.9263395307001005e-33, disciminator loss fake = 1.582930053700693e-06, generator loss = 14.499114990234375\n",
      "2/2 [==============================] - 0s 148ms/step\n",
      "Epoch: 19, Batch: 281/468, discriminator loss real = 1.880304478513921e-20, disciminator loss fake = 1.393120101056411e-06, generator loss = 14.980401992797852\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 19, Batch: 282/468, discriminator loss real = 1.429513957565149e-14, disciminator loss fake = 3.0937405881559243e-06, generator loss = 14.702195167541504\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 19, Batch: 283/468, discriminator loss real = 1.9721011994988658e-05, disciminator loss fake = 6.781926913390635e-07, generator loss = 14.53125286102295\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 19, Batch: 284/468, discriminator loss real = 4.202133235917649e-26, disciminator loss fake = 1.886641257442534e-06, generator loss = 14.659610748291016\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 19, Batch: 285/468, discriminator loss real = 1.5385835780337004e-13, disciminator loss fake = 1.3452935263558174e-06, generator loss = 14.734291076660156\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 19, Batch: 286/468, discriminator loss real = 4.403350947757012e-12, disciminator loss fake = 1.681639901107701e-06, generator loss = 14.556371688842773\n",
      "2/2 [==============================] - 0s 201ms/step\n",
      "Epoch: 19, Batch: 287/468, discriminator loss real = 8.73753618014974e-15, disciminator loss fake = 1.015029511108878e-06, generator loss = 14.501846313476562\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 19, Batch: 288/468, discriminator loss real = 3.58795515040274e-24, disciminator loss fake = 2.7009446057491004e-06, generator loss = 14.794534683227539\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 19, Batch: 289/468, discriminator loss real = 4.2864150375676973e-20, disciminator loss fake = 1.016640226225718e-06, generator loss = 14.842506408691406\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 19, Batch: 290/468, discriminator loss real = 7.437625592712625e-28, disciminator loss fake = 1.0968258266075281e-06, generator loss = 14.794601440429688\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 19, Batch: 291/468, discriminator loss real = 9.341673090256854e-25, disciminator loss fake = 2.186875462939497e-06, generator loss = 15.203245162963867\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 19, Batch: 292/468, discriminator loss real = 3.9343859725704533e-07, disciminator loss fake = 1.93878986465279e-06, generator loss = 15.005756378173828\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 19, Batch: 293/468, discriminator loss real = 1.8270483046219628e-21, disciminator loss fake = 2.156999471480958e-06, generator loss = 14.767909049987793\n",
      "2/2 [==============================] - 0s 211ms/step\n",
      "Epoch: 19, Batch: 294/468, discriminator loss real = 2.9032278234808473e-06, disciminator loss fake = 3.469254352239659e-06, generator loss = 15.033477783203125\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 19, Batch: 295/468, discriminator loss real = 2.443593594136928e-08, disciminator loss fake = 1.0042177791547147e-06, generator loss = 14.609600067138672\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 19, Batch: 296/468, discriminator loss real = 8.506634946615839e-21, disciminator loss fake = 9.759103249962209e-07, generator loss = 14.531330108642578\n",
      "2/2 [==============================] - 0s 134ms/step\n",
      "Epoch: 19, Batch: 297/468, discriminator loss real = 1.86303651777138e-21, disciminator loss fake = 1.5489574707316933e-06, generator loss = 14.794291496276855\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 19, Batch: 298/468, discriminator loss real = 2.7941021024657786e-11, disciminator loss fake = 1.1430890936026117e-06, generator loss = 14.670964241027832\n",
      "2/2 [==============================] - 0s 181ms/step\n",
      "Epoch: 19, Batch: 299/468, discriminator loss real = 1.665306633188142e-26, disciminator loss fake = 1.1135236945847282e-06, generator loss = 14.797271728515625\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 19, Batch: 300/468, discriminator loss real = 2.3382931807189874e-18, disciminator loss fake = 1.6276312635454815e-06, generator loss = 14.991291046142578\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 19, Batch: 301/468, discriminator loss real = 2.5092811078904773e-16, disciminator loss fake = 1.8672667465580162e-06, generator loss = 14.878923416137695\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 19, Batch: 302/468, discriminator loss real = 1.8820791151524357e-22, disciminator loss fake = 2.7819801289297175e-06, generator loss = 15.200700759887695\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 19, Batch: 303/468, discriminator loss real = 4.700266821839694e-16, disciminator loss fake = 9.300259762312635e-07, generator loss = 15.288311004638672\n",
      "2/2 [==============================] - 0s 170ms/step\n",
      "Epoch: 19, Batch: 304/468, discriminator loss real = 1.613409498212025e-17, disciminator loss fake = 8.150963139996747e-07, generator loss = 15.045454978942871\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 19, Batch: 305/468, discriminator loss real = 2.343495715195611e-25, disciminator loss fake = 1.240128995050327e-06, generator loss = 14.984134674072266\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 19, Batch: 306/468, discriminator loss real = 6.950856779042169e-09, disciminator loss fake = 1.2881314432888757e-06, generator loss = 14.739724159240723\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 19, Batch: 307/468, discriminator loss real = 5.0918373419820296e-15, disciminator loss fake = 1.1544482276804047e-06, generator loss = 14.651472091674805\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 19, Batch: 308/468, discriminator loss real = 4.767887473722254e-13, disciminator loss fake = 1.2387191645757412e-06, generator loss = 14.825517654418945\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 19, Batch: 309/468, discriminator loss real = 3.1040870828585865e-12, disciminator loss fake = 2.2903991521161515e-06, generator loss = 15.07657241821289\n",
      "2/2 [==============================] - 0s 172ms/step\n",
      "Epoch: 19, Batch: 310/468, discriminator loss real = 1.4513004587003535e-29, disciminator loss fake = 1.2292895235077594e-06, generator loss = 14.963057518005371\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 19, Batch: 311/468, discriminator loss real = 1.5460990127058594e-11, disciminator loss fake = 2.363298790442059e-06, generator loss = 14.797380447387695\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 19, Batch: 312/468, discriminator loss real = 1.7365857530234505e-28, disciminator loss fake = 1.3368244253797457e-06, generator loss = 15.054317474365234\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 19, Batch: 313/468, discriminator loss real = 5.841835121654754e-20, disciminator loss fake = 1.1168203855049796e-06, generator loss = 15.117456436157227\n",
      "2/2 [==============================] - 0s 130ms/step\n",
      "Epoch: 19, Batch: 314/468, discriminator loss real = 1.0798166594010953e-14, disciminator loss fake = 1.0480380296939984e-06, generator loss = 15.359588623046875\n",
      "2/2 [==============================] - 0s 147ms/step\n",
      "Epoch: 19, Batch: 315/468, discriminator loss real = 2.3400157016265678e-17, disciminator loss fake = 1.8189962247561198e-06, generator loss = 14.94957160949707\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 19, Batch: 316/468, discriminator loss real = 2.7687256985229963e-20, disciminator loss fake = 1.8177735228164238e-06, generator loss = 14.824681282043457\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 19, Batch: 317/468, discriminator loss real = 4.009578686594e-15, disciminator loss fake = 9.645419822845724e-07, generator loss = 14.847987174987793\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 19, Batch: 318/468, discriminator loss real = 2.7769794746961123e-19, disciminator loss fake = 3.397207365196664e-06, generator loss = 15.145820617675781\n",
      "2/2 [==============================] - 0s 136ms/step\n",
      "Epoch: 19, Batch: 319/468, discriminator loss real = 3.6971499222547614e-18, disciminator loss fake = 6.499188884845353e-07, generator loss = 15.048500061035156\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 19, Batch: 320/468, discriminator loss real = 7.041529165308091e-11, disciminator loss fake = 8.890576168596453e-07, generator loss = 14.77905559539795\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 19, Batch: 321/468, discriminator loss real = 1.182275988162462e-15, disciminator loss fake = 9.151904123427812e-07, generator loss = 15.061841011047363\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 19, Batch: 322/468, discriminator loss real = 1.1974435224711827e-25, disciminator loss fake = 1.8919112108051195e-06, generator loss = 15.133016586303711\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 19, Batch: 323/468, discriminator loss real = 5.337439812524555e-17, disciminator loss fake = 8.486402975904639e-07, generator loss = 15.022748947143555\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 19, Batch: 324/468, discriminator loss real = 1.0194828383841131e-21, disciminator loss fake = 1.7315662717010127e-06, generator loss = 14.83769416809082\n",
      "2/2 [==============================] - 0s 168ms/step\n",
      "Epoch: 19, Batch: 325/468, discriminator loss real = 8.49888901410239e-21, disciminator loss fake = 8.027935791687923e-07, generator loss = 15.097171783447266\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 19, Batch: 326/468, discriminator loss real = 2.1553829413541864e-13, disciminator loss fake = 1.8989717318618204e-06, generator loss = 15.061534881591797\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 19, Batch: 327/468, discriminator loss real = 1.7826921376259443e-14, disciminator loss fake = 1.5693728983023902e-06, generator loss = 15.017227172851562\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 19, Batch: 328/468, discriminator loss real = 3.9702839265440055e-19, disciminator loss fake = 1.8768316749628866e-06, generator loss = 14.818044662475586\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 19, Batch: 329/468, discriminator loss real = 5.12571771705481e-27, disciminator loss fake = 5.701638201571768e-07, generator loss = 15.034112930297852\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 19, Batch: 330/468, discriminator loss real = 5.471052704547566e-19, disciminator loss fake = 1.0632106750563253e-06, generator loss = 14.961255073547363\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 19, Batch: 331/468, discriminator loss real = 1.9434496736523907e-14, disciminator loss fake = 9.994755600928329e-07, generator loss = 14.992087364196777\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 19, Batch: 332/468, discriminator loss real = 9.434219775896318e-20, disciminator loss fake = 1.3721243021791452e-06, generator loss = 14.79125690460205\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 19, Batch: 333/468, discriminator loss real = 3.724106462104029e-21, disciminator loss fake = 1.1388862048988813e-06, generator loss = 15.115561485290527\n",
      "2/2 [==============================] - 0s 197ms/step\n",
      "Epoch: 19, Batch: 334/468, discriminator loss real = 7.327500874142803e-18, disciminator loss fake = 9.483059102421976e-07, generator loss = 15.163736343383789\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 19, Batch: 335/468, discriminator loss real = 4.8606403410385637e-32, disciminator loss fake = 1.0825576737261144e-06, generator loss = 15.203950881958008\n",
      "2/2 [==============================] - 0s 146ms/step\n",
      "Epoch: 19, Batch: 336/468, discriminator loss real = 1.7329051843262278e-05, disciminator loss fake = 9.848298532233457e-07, generator loss = 15.019611358642578\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 19, Batch: 337/468, discriminator loss real = 7.518456208088428e-14, disciminator loss fake = 1.5240460697896197e-06, generator loss = 15.009963989257812\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 19, Batch: 338/468, discriminator loss real = 9.23799237207131e-19, disciminator loss fake = 7.932645758046419e-07, generator loss = 15.20136547088623\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 19, Batch: 339/468, discriminator loss real = 7.743530866917981e-17, disciminator loss fake = 7.019256145213149e-07, generator loss = 15.040229797363281\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 19, Batch: 340/468, discriminator loss real = 1.8822454701401287e-23, disciminator loss fake = 1.1948334304179298e-06, generator loss = 14.940393447875977\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 19, Batch: 341/468, discriminator loss real = 1.3199476130873516e-18, disciminator loss fake = 3.94662311009597e-06, generator loss = 15.193245887756348\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 19, Batch: 342/468, discriminator loss real = 1.2934288189103693e-11, disciminator loss fake = 1.7688471416477114e-06, generator loss = 15.232046127319336\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 19, Batch: 343/468, discriminator loss real = 5.726717006005436e-25, disciminator loss fake = 1.3204811466493993e-06, generator loss = 14.861352920532227\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 19, Batch: 344/468, discriminator loss real = 1.0575398108584797e-21, disciminator loss fake = 9.67643018157105e-07, generator loss = 14.918891906738281\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 19, Batch: 345/468, discriminator loss real = 3.133149780613777e-23, disciminator loss fake = 1.1678367854983662e-06, generator loss = 14.997668266296387\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 19, Batch: 346/468, discriminator loss real = 8.905823994931339e-11, disciminator loss fake = 9.240839631274866e-07, generator loss = 15.106372833251953\n",
      "2/2 [==============================] - 0s 146ms/step\n",
      "Epoch: 19, Batch: 347/468, discriminator loss real = 9.409827150210319e-18, disciminator loss fake = 1.5755016420371248e-06, generator loss = 15.030416488647461\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 19, Batch: 348/468, discriminator loss real = 2.6234618974759128e-30, disciminator loss fake = 1.6271476397378137e-06, generator loss = 14.916875839233398\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 19, Batch: 349/468, discriminator loss real = 2.759759709647369e-08, disciminator loss fake = 1.231567239301512e-06, generator loss = 15.338653564453125\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 19, Batch: 350/468, discriminator loss real = 0.003080226480960846, disciminator loss fake = 3.942142029700335e-06, generator loss = 13.23582935333252\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 19, Batch: 351/468, discriminator loss real = 5.753691981399952e-26, disciminator loss fake = 8.671078830957413e-06, generator loss = 12.35113525390625\n",
      "2/2 [==============================] - 0s 212ms/step\n",
      "Epoch: 19, Batch: 352/468, discriminator loss real = 6.368651658590101e-28, disciminator loss fake = 2.55240811384283e-05, generator loss = 11.085678100585938\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 19, Batch: 353/468, discriminator loss real = 1.5455261767803096e-18, disciminator loss fake = 0.00011565184831852093, generator loss = 10.233356475830078\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 19, Batch: 354/468, discriminator loss real = 8.711235486191416e-20, disciminator loss fake = 0.00019539678760338575, generator loss = 9.575325965881348\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 19, Batch: 355/468, discriminator loss real = 6.484240770987526e-07, disciminator loss fake = 0.0004761155287269503, generator loss = 9.617615699768066\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 19, Batch: 356/468, discriminator loss real = 8.164974795212902e-23, disciminator loss fake = 0.0009552717674523592, generator loss = 9.836193084716797\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 19, Batch: 357/468, discriminator loss real = 3.691741855114559e-15, disciminator loss fake = 0.00028095999732613564, generator loss = 10.460918426513672\n",
      "2/2 [==============================] - 0s 173ms/step\n",
      "Epoch: 19, Batch: 358/468, discriminator loss real = 1.5314156753055502e-22, disciminator loss fake = 0.00012666548718698323, generator loss = 11.04137134552002\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 19, Batch: 359/468, discriminator loss real = 5.5096549780693e-22, disciminator loss fake = 5.572086593019776e-05, generator loss = 11.807271957397461\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 19, Batch: 360/468, discriminator loss real = 1.4636523104627486e-08, disciminator loss fake = 2.0274173948564567e-05, generator loss = 12.254085540771484\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 19, Batch: 361/468, discriminator loss real = 1.613736000296434e-13, disciminator loss fake = 1.6068386685219593e-05, generator loss = 12.729524612426758\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 19, Batch: 362/468, discriminator loss real = 4.557101776315915e-18, disciminator loss fake = 1.672494545346126e-05, generator loss = 13.020980834960938\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 19, Batch: 363/468, discriminator loss real = 4.237028994577043e-19, disciminator loss fake = 6.7843261604139116e-06, generator loss = 13.317293167114258\n",
      "2/2 [==============================] - 0s 159ms/step\n",
      "Epoch: 19, Batch: 364/468, discriminator loss real = 2.16812061581099e-23, disciminator loss fake = 7.944015123939607e-06, generator loss = 13.44994068145752\n",
      "2/2 [==============================] - 0s 151ms/step\n",
      "Epoch: 19, Batch: 365/468, discriminator loss real = 2.1049487922930726e-23, disciminator loss fake = 3.6030705814482644e-06, generator loss = 13.781051635742188\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 19, Batch: 366/468, discriminator loss real = 4.2298643180026267e-19, disciminator loss fake = 3.1760073397890665e-06, generator loss = 13.545103073120117\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 19, Batch: 367/468, discriminator loss real = 4.2551116845529827e-14, disciminator loss fake = 3.7031663850939367e-06, generator loss = 13.944549560546875\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 19, Batch: 368/468, discriminator loss real = 3.1020718468858974e-18, disciminator loss fake = 2.565338490967406e-06, generator loss = 13.959521293640137\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 19, Batch: 369/468, discriminator loss real = 5.809247752057041e-17, disciminator loss fake = 1.6504807263117982e-06, generator loss = 14.231056213378906\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 19, Batch: 370/468, discriminator loss real = 7.083961848651683e-15, disciminator loss fake = 2.600468633318087e-06, generator loss = 14.133856773376465\n",
      "2/2 [==============================] - 0s 184ms/step\n",
      "Epoch: 19, Batch: 371/468, discriminator loss real = 1.3157321423582423e-20, disciminator loss fake = 1.692282353360497e-06, generator loss = 14.476781845092773\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 19, Batch: 372/468, discriminator loss real = 7.871826579924955e-16, disciminator loss fake = 1.4350146102515282e-06, generator loss = 14.38729476928711\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 19, Batch: 373/468, discriminator loss real = 6.82895912599523e-34, disciminator loss fake = 2.6960844934365014e-06, generator loss = 14.3670015335083\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 19, Batch: 374/468, discriminator loss real = 2.862619241726913e-24, disciminator loss fake = 3.4200234040326905e-06, generator loss = 14.541704177856445\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 19, Batch: 375/468, discriminator loss real = 1.7316800955285153e-25, disciminator loss fake = 1.895926175166096e-06, generator loss = 13.940418243408203\n",
      "2/2 [==============================] - 0s 192ms/step\n",
      "Epoch: 19, Batch: 376/468, discriminator loss real = 9.361253075463765e-22, disciminator loss fake = 3.311552518425742e-06, generator loss = 14.576595306396484\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 19, Batch: 377/468, discriminator loss real = 3.7713861396833945e-16, disciminator loss fake = 1.7254598105864716e-06, generator loss = 14.504100799560547\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 19, Batch: 378/468, discriminator loss real = 4.519626979049659e-19, disciminator loss fake = 1.1786653431045124e-06, generator loss = 14.567506790161133\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 19, Batch: 379/468, discriminator loss real = 3.2295641855251134e-11, disciminator loss fake = 1.7772433693608036e-06, generator loss = 14.300140380859375\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 19, Batch: 380/468, discriminator loss real = 2.1306452043691883e-17, disciminator loss fake = 1.0698179266910302e-06, generator loss = 14.608747482299805\n",
      "2/2 [==============================] - 0s 148ms/step\n",
      "Epoch: 19, Batch: 381/468, discriminator loss real = 2.982061653004648e-15, disciminator loss fake = 1.7409399788448354e-06, generator loss = 14.529635429382324\n",
      "2/2 [==============================] - 0s 135ms/step\n",
      "Epoch: 19, Batch: 382/468, discriminator loss real = 1.3231392307139055e-22, disciminator loss fake = 1.3339310953597305e-06, generator loss = 14.422829627990723\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 19, Batch: 383/468, discriminator loss real = 1.1596090688565817e-15, disciminator loss fake = 1.3848959952156292e-06, generator loss = 14.648494720458984\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 19, Batch: 384/468, discriminator loss real = 2.812019273574449e-21, disciminator loss fake = 1.5524360605922993e-06, generator loss = 14.275213241577148\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 19, Batch: 385/468, discriminator loss real = 6.729789251910812e-14, disciminator loss fake = 2.2700912722939393e-06, generator loss = 14.56124496459961\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 19, Batch: 386/468, discriminator loss real = 1.8143477831245036e-09, disciminator loss fake = 1.4419472336157924e-06, generator loss = 14.464811325073242\n",
      "2/2 [==============================] - 0s 192ms/step\n",
      "Epoch: 19, Batch: 387/468, discriminator loss real = 1.7117865519168452e-24, disciminator loss fake = 1.5864777651586337e-06, generator loss = 14.546463012695312\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 19, Batch: 388/468, discriminator loss real = 8.011904067391636e-24, disciminator loss fake = 1.3658702755492413e-06, generator loss = 14.810611724853516\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 19, Batch: 389/468, discriminator loss real = 8.691795166598964e-22, disciminator loss fake = 1.5662359373891377e-06, generator loss = 14.229463577270508\n",
      "2/2 [==============================] - 0s 137ms/step\n",
      "Epoch: 19, Batch: 390/468, discriminator loss real = 4.33941484091413e-13, disciminator loss fake = 3.627311116360943e-06, generator loss = 14.765420913696289\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 19, Batch: 391/468, discriminator loss real = 2.7129452309425414e-27, disciminator loss fake = 2.6719662855612114e-06, generator loss = 14.77473258972168\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 19, Batch: 392/468, discriminator loss real = 2.3395994048769353e-06, disciminator loss fake = 9.435560173187696e-07, generator loss = 14.535369873046875\n",
      "2/2 [==============================] - 0s 192ms/step\n",
      "Epoch: 19, Batch: 393/468, discriminator loss real = 1.9197277767570208e-36, disciminator loss fake = 4.394934876472689e-06, generator loss = 14.423177719116211\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 19, Batch: 394/468, discriminator loss real = 1.1169782995291232e-19, disciminator loss fake = 2.9801312848576345e-06, generator loss = 14.720399856567383\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 19, Batch: 395/468, discriminator loss real = 1.2743963268905243e-15, disciminator loss fake = 2.1844944058102556e-06, generator loss = 14.65932846069336\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 19, Batch: 396/468, discriminator loss real = 1.0304424700227513e-25, disciminator loss fake = 1.0506157650524983e-06, generator loss = 14.571097373962402\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 19, Batch: 397/468, discriminator loss real = 5.315071644179354e-21, disciminator loss fake = 2.2231583898246754e-06, generator loss = 14.23089599609375\n",
      "2/2 [==============================] - 0s 223ms/step\n",
      "Epoch: 19, Batch: 398/468, discriminator loss real = 8.52357983485723e-26, disciminator loss fake = 2.858927928173216e-06, generator loss = 14.694291114807129\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 19, Batch: 399/468, discriminator loss real = 1.4815747653863463e-26, disciminator loss fake = 2.479542445144034e-06, generator loss = 14.473605155944824\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 19, Batch: 400/468, discriminator loss real = 1.0291232657887444e-27, disciminator loss fake = 2.232726501461002e-06, generator loss = 14.707435607910156\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 19, Batch: 401/468, discriminator loss real = 6.049664103002783e-10, disciminator loss fake = 1.003160718937579e-06, generator loss = 14.917494773864746\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 19, Batch: 402/468, discriminator loss real = 5.2351889383440326e-21, disciminator loss fake = 1.9489489204715937e-06, generator loss = 14.531524658203125\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 19, Batch: 403/468, discriminator loss real = 7.783294841967603e-12, disciminator loss fake = 2.0064458112756256e-06, generator loss = 14.539084434509277\n",
      "2/2 [==============================] - 0s 155ms/step\n",
      "Epoch: 19, Batch: 404/468, discriminator loss real = 2.497359847076812e-17, disciminator loss fake = 1.2069326658092905e-06, generator loss = 14.815910339355469\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 19, Batch: 405/468, discriminator loss real = 6.2820208490937946e-24, disciminator loss fake = 1.4137533526081825e-06, generator loss = 14.309024810791016\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 19, Batch: 406/468, discriminator loss real = 5.267945948629457e-26, disciminator loss fake = 1.9960575627919752e-06, generator loss = 14.616962432861328\n",
      "2/2 [==============================] - 0s 144ms/step\n",
      "Epoch: 19, Batch: 407/468, discriminator loss real = 9.077834221770708e-24, disciminator loss fake = 1.6206997770495946e-06, generator loss = 14.687004089355469\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 19, Batch: 408/468, discriminator loss real = 9.030205955757084e-24, disciminator loss fake = 3.6487103898252826e-06, generator loss = 14.580037117004395\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 19, Batch: 409/468, discriminator loss real = 1.047296120051516e-20, disciminator loss fake = 1.2702578260359587e-06, generator loss = 14.723206520080566\n",
      "2/2 [==============================] - 0s 200ms/step\n",
      "Epoch: 19, Batch: 410/468, discriminator loss real = 3.3201783336545e-12, disciminator loss fake = 1.1957845345023088e-06, generator loss = 14.586099624633789\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 19, Batch: 411/468, discriminator loss real = 0.002283029491081834, disciminator loss fake = 1.647379122005077e-06, generator loss = 13.617805480957031\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 19, Batch: 412/468, discriminator loss real = 5.838535574130186e-25, disciminator loss fake = 1.0428969289932866e-05, generator loss = 12.804609298706055\n",
      "2/2 [==============================] - 0s 141ms/step\n",
      "Epoch: 19, Batch: 413/468, discriminator loss real = 2.1210586269717476e-20, disciminator loss fake = 1.8762406398309395e-05, generator loss = 12.091696739196777\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 19, Batch: 414/468, discriminator loss real = 2.3165327267890688e-26, disciminator loss fake = 2.1350340830394998e-05, generator loss = 11.887470245361328\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 19, Batch: 415/468, discriminator loss real = 3.1877495070585395e-21, disciminator loss fake = 3.688312790472992e-05, generator loss = 11.465778350830078\n",
      "2/2 [==============================] - 0s 179ms/step\n",
      "Epoch: 19, Batch: 416/468, discriminator loss real = 1.4077550323083576e-19, disciminator loss fake = 8.968122710939497e-05, generator loss = 10.905460357666016\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 19, Batch: 417/468, discriminator loss real = 2.993312452829848e-14, disciminator loss fake = 0.00011240835738135502, generator loss = 10.37598705291748\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 19, Batch: 418/468, discriminator loss real = 1.7626570704422024e-31, disciminator loss fake = 0.00010882499191211537, generator loss = 10.495741844177246\n",
      "2/2 [==============================] - 0s 130ms/step\n",
      "Epoch: 19, Batch: 419/468, discriminator loss real = 4.209439677715044e-19, disciminator loss fake = 0.00014378599007613957, generator loss = 10.769989967346191\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 19, Batch: 420/468, discriminator loss real = 2.8354950483617936e-24, disciminator loss fake = 0.00026459258515387774, generator loss = 11.121770858764648\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 19, Batch: 421/468, discriminator loss real = 2.431176619618319e-19, disciminator loss fake = 6.3644016336184e-05, generator loss = 11.215063095092773\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 19, Batch: 422/468, discriminator loss real = 3.535269670526509e-15, disciminator loss fake = 5.1477618399076164e-05, generator loss = 11.52842903137207\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 19, Batch: 423/468, discriminator loss real = 4.223491472363185e-24, disciminator loss fake = 5.0847902457462624e-05, generator loss = 11.611175537109375\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 19, Batch: 424/468, discriminator loss real = 4.461732737224044e-20, disciminator loss fake = 1.6392612451454625e-05, generator loss = 12.00588321685791\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 19, Batch: 425/468, discriminator loss real = 1.6490384107999799e-25, disciminator loss fake = 3.6649376852437854e-05, generator loss = 11.927824020385742\n",
      "2/2 [==============================] - 0s 165ms/step\n",
      "Epoch: 19, Batch: 426/468, discriminator loss real = 1.1214291321631188e-25, disciminator loss fake = 1.8470960640115663e-05, generator loss = 12.281929016113281\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 19, Batch: 427/468, discriminator loss real = 3.9485750500618224e-30, disciminator loss fake = 3.383100192877464e-05, generator loss = 12.536900520324707\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 19, Batch: 428/468, discriminator loss real = 1.138786274183198e-21, disciminator loss fake = 1.0554145774221979e-05, generator loss = 12.57029914855957\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 19, Batch: 429/468, discriminator loss real = 1.7136710014683935e-16, disciminator loss fake = 7.2863731475081295e-06, generator loss = 12.716710090637207\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 19, Batch: 430/468, discriminator loss real = 1.2551581886708656e-25, disciminator loss fake = 1.430227257515071e-05, generator loss = 12.678613662719727\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 19, Batch: 431/468, discriminator loss real = 4.3711237037021896e-29, disciminator loss fake = 1.1167652701260522e-05, generator loss = 12.730990409851074\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 19, Batch: 432/468, discriminator loss real = 3.653301873297113e-25, disciminator loss fake = 1.3681451491720509e-05, generator loss = 12.887557029724121\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 19, Batch: 433/468, discriminator loss real = 1.2017276111136562e-27, disciminator loss fake = 7.192493285401724e-06, generator loss = 12.64513874053955\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 19, Batch: 434/468, discriminator loss real = 6.244392704878802e-29, disciminator loss fake = 5.847536613146076e-06, generator loss = 12.724370956420898\n",
      "2/2 [==============================] - 0s 151ms/step\n",
      "Epoch: 19, Batch: 435/468, discriminator loss real = 5.401710257358905e-26, disciminator loss fake = 9.659690476837568e-06, generator loss = 12.954280853271484\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 19, Batch: 436/468, discriminator loss real = 9.784138371509446e-19, disciminator loss fake = 7.536480552516878e-06, generator loss = 13.393038749694824\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 19, Batch: 437/468, discriminator loss real = 1.9166547861456884e-28, disciminator loss fake = 6.809977548982715e-06, generator loss = 13.245109558105469\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 19, Batch: 438/468, discriminator loss real = 3.805162361960636e-14, disciminator loss fake = 5.646335011988413e-06, generator loss = 13.12037467956543\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 19, Batch: 439/468, discriminator loss real = 1.693057109252463e-35, disciminator loss fake = 6.884195954626193e-06, generator loss = 13.407646179199219\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 19, Batch: 440/468, discriminator loss real = 4.1433439253342474e-13, disciminator loss fake = 5.41701183465193e-06, generator loss = 13.173187255859375\n",
      "2/2 [==============================] - 0s 201ms/step\n",
      "Epoch: 19, Batch: 441/468, discriminator loss real = 1.903795063897028e-15, disciminator loss fake = 9.233914170181379e-06, generator loss = 13.249119758605957\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 19, Batch: 442/468, discriminator loss real = 1.1414051741395147e-27, disciminator loss fake = 7.15260102879256e-06, generator loss = 13.338357925415039\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 19, Batch: 443/468, discriminator loss real = 1.217140419198474e-28, disciminator loss fake = 4.529603756964207e-06, generator loss = 13.35196590423584\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 19, Batch: 444/468, discriminator loss real = 2.6033485247479387e-22, disciminator loss fake = 5.197241080168169e-06, generator loss = 13.404838562011719\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 19, Batch: 445/468, discriminator loss real = 8.267875516023053e-33, disciminator loss fake = 9.51888068811968e-06, generator loss = 13.244977951049805\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 19, Batch: 446/468, discriminator loss real = 5.21845597928088e-20, disciminator loss fake = 1.086096017388627e-05, generator loss = 13.638056755065918\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 19, Batch: 447/468, discriminator loss real = 8.135611168545666e-17, disciminator loss fake = 1.136175160354469e-05, generator loss = 13.30280876159668\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 19, Batch: 448/468, discriminator loss real = 7.871683146806739e-18, disciminator loss fake = 3.205376287951367e-06, generator loss = 13.423041343688965\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 19, Batch: 449/468, discriminator loss real = 1.6892787725690793e-24, disciminator loss fake = 8.956840247265063e-06, generator loss = 13.656888008117676\n",
      "2/2 [==============================] - 0s 157ms/step\n",
      "Epoch: 19, Batch: 450/468, discriminator loss real = 1.8705300147951573e-20, disciminator loss fake = 1.1122315299871843e-05, generator loss = 13.765775680541992\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 19, Batch: 451/468, discriminator loss real = 1.568128742104285e-31, disciminator loss fake = 4.5870810936321504e-06, generator loss = 13.61584758758545\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 19, Batch: 452/468, discriminator loss real = 3.4744609431076874e-25, disciminator loss fake = 6.21003300693701e-06, generator loss = 13.547749519348145\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 19, Batch: 453/468, discriminator loss real = 2.103717916615771e-30, disciminator loss fake = 2.9656353035534266e-06, generator loss = 13.717409133911133\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 19, Batch: 454/468, discriminator loss real = 1.4314789892998074e-23, disciminator loss fake = 2.1503005882550497e-06, generator loss = 13.627461433410645\n",
      "2/2 [==============================] - 0s 174ms/step\n",
      "Epoch: 19, Batch: 455/468, discriminator loss real = 6.226426434005259e-16, disciminator loss fake = 4.439531949174125e-06, generator loss = 13.634783744812012\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 19, Batch: 456/468, discriminator loss real = 2.5288597594817056e-21, disciminator loss fake = 7.421981536026578e-06, generator loss = 13.48004150390625\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 19, Batch: 457/468, discriminator loss real = 4.954646692922893e-10, disciminator loss fake = 3.662720246211393e-06, generator loss = 13.925484657287598\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 19, Batch: 458/468, discriminator loss real = 3.09538026178717e-16, disciminator loss fake = 3.6565534173860215e-06, generator loss = 13.49937629699707\n",
      "2/2 [==============================] - 0s 168ms/step\n",
      "Epoch: 19, Batch: 459/468, discriminator loss real = 4.2078381054208846e-24, disciminator loss fake = 5.439098458737135e-06, generator loss = 13.652013778686523\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 19, Batch: 460/468, discriminator loss real = 5.971239127435579e-20, disciminator loss fake = 5.2238501666579396e-06, generator loss = 13.877279281616211\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 19, Batch: 461/468, discriminator loss real = 7.672299075353259e-14, disciminator loss fake = 3.6674914554168936e-06, generator loss = 13.772722244262695\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 19, Batch: 462/468, discriminator loss real = 1.274915763238571e-11, disciminator loss fake = 4.212714429741027e-06, generator loss = 13.613795280456543\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 19, Batch: 463/468, discriminator loss real = 2.1896367465137953e-21, disciminator loss fake = 1.7440906958654523e-06, generator loss = 13.63776969909668\n",
      "2/2 [==============================] - 0s 192ms/step\n",
      "Epoch: 19, Batch: 464/468, discriminator loss real = 1.3787383442135643e-20, disciminator loss fake = 7.190030828496674e-06, generator loss = 13.622482299804688\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 19, Batch: 465/468, discriminator loss real = 1.3994721367927403e-17, disciminator loss fake = 3.042704975086963e-06, generator loss = 13.923465728759766\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 19, Batch: 466/468, discriminator loss real = 2.236010853061306e-24, disciminator loss fake = 2.806370957841864e-06, generator loss = 13.783759117126465\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 19, Batch: 467/468, discriminator loss real = 2.3345463340262995e-09, disciminator loss fake = 3.09799611386552e-06, generator loss = 14.263718605041504\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 19, Batch: 468/468, discriminator loss real = 8.130698059814236e-15, disciminator loss fake = 3.511121576593723e-06, generator loss = 13.801770210266113\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 20, Batch: 1/468, discriminator loss real = 7.410085067848192e-21, disciminator loss fake = 4.087118213647045e-06, generator loss = 13.929010391235352\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 20, Batch: 2/468, discriminator loss real = 4.25087263716818e-25, disciminator loss fake = 2.935412112492486e-06, generator loss = 14.007698059082031\n",
      "2/2 [==============================] - 0s 130ms/step\n",
      "Epoch: 20, Batch: 3/468, discriminator loss real = 3.3976714411082756e-31, disciminator loss fake = 2.849487827916164e-06, generator loss = 13.830753326416016\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 20, Batch: 4/468, discriminator loss real = 6.17599636571028e-24, disciminator loss fake = 5.59016143597546e-06, generator loss = 13.99073600769043\n",
      "2/2 [==============================] - 0s 148ms/step\n",
      "Epoch: 20, Batch: 5/468, discriminator loss real = 2.305770414555679e-25, disciminator loss fake = 4.531553258857457e-06, generator loss = 14.045058250427246\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 20, Batch: 6/468, discriminator loss real = 3.980160139940462e-20, disciminator loss fake = 2.9085758797009476e-06, generator loss = 13.917069435119629\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 20, Batch: 7/468, discriminator loss real = 5.133228911206642e-20, disciminator loss fake = 4.324121618992649e-06, generator loss = 13.746109008789062\n",
      "2/2 [==============================] - 0s 135ms/step\n",
      "Epoch: 20, Batch: 8/468, discriminator loss real = 3.4055686947355597e-23, disciminator loss fake = 3.8853213482070714e-06, generator loss = 13.72846508026123\n",
      "2/2 [==============================] - 0s 157ms/step\n",
      "Epoch: 20, Batch: 9/468, discriminator loss real = 5.403171125203457e-22, disciminator loss fake = 2.770234459603671e-06, generator loss = 14.058430671691895\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 20, Batch: 10/468, discriminator loss real = 1.9573114017155252e-13, disciminator loss fake = 3.9726091927150264e-06, generator loss = 13.90013313293457\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 20, Batch: 11/468, discriminator loss real = 1.2270894807448851e-19, disciminator loss fake = 1.922928049680195e-06, generator loss = 14.054849624633789\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 20, Batch: 12/468, discriminator loss real = 1.0376563316762334e-19, disciminator loss fake = 1.921274815686047e-06, generator loss = 13.89614486694336\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 20, Batch: 13/468, discriminator loss real = 4.824464683643044e-21, disciminator loss fake = 2.498107505743974e-06, generator loss = 13.99399471282959\n",
      "2/2 [==============================] - 0s 175ms/step\n",
      "Epoch: 20, Batch: 14/468, discriminator loss real = 3.095873529183381e-26, disciminator loss fake = 3.890466359735001e-06, generator loss = 13.804725646972656\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 20, Batch: 15/468, discriminator loss real = 3.1160657826456254e-31, disciminator loss fake = 3.4452164072718006e-06, generator loss = 13.902080535888672\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 20, Batch: 16/468, discriminator loss real = 1.0332431938612923e-18, disciminator loss fake = 2.4678670342836995e-06, generator loss = 14.203559875488281\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 20, Batch: 17/468, discriminator loss real = 1.9050613378818335e-27, disciminator loss fake = 3.124823024336365e-06, generator loss = 14.18160629272461\n",
      "2/2 [==============================] - 0s 205ms/step\n",
      "Epoch: 20, Batch: 18/468, discriminator loss real = 4.756491966788345e-13, disciminator loss fake = 2.816970436470001e-06, generator loss = 14.197296142578125\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 20, Batch: 19/468, discriminator loss real = 2.0701226885846188e-15, disciminator loss fake = 2.8813294647989096e-06, generator loss = 14.06857681274414\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 20, Batch: 20/468, discriminator loss real = 2.516805322654043e-19, disciminator loss fake = 2.8180700155644445e-06, generator loss = 14.122122764587402\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 20, Batch: 21/468, discriminator loss real = 2.2788730636171083e-31, disciminator loss fake = 8.340750355273485e-06, generator loss = 13.959019660949707\n",
      "2/2 [==============================] - 0s 185ms/step\n",
      "Epoch: 20, Batch: 22/468, discriminator loss real = 3.712347411149991e-21, disciminator loss fake = 3.949612164433347e-06, generator loss = 13.983514785766602\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 20, Batch: 23/468, discriminator loss real = 3.0802923881525293e-19, disciminator loss fake = 4.735547463496914e-06, generator loss = 14.207179069519043\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 20, Batch: 24/468, discriminator loss real = 3.6314817437693165e-28, disciminator loss fake = 2.8687113626801874e-06, generator loss = 13.803352355957031\n",
      "2/2 [==============================] - 0s 130ms/step\n",
      "Epoch: 20, Batch: 25/468, discriminator loss real = 3.949933670810424e-05, disciminator loss fake = 2.49873392021982e-06, generator loss = 13.902036666870117\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 20, Batch: 26/468, discriminator loss real = 2.520201825007007e-10, disciminator loss fake = 4.096045813639648e-06, generator loss = 14.145267486572266\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 20, Batch: 27/468, discriminator loss real = 8.593240008458736e-10, disciminator loss fake = 3.3127228107332485e-06, generator loss = 14.08493423461914\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 20, Batch: 28/468, discriminator loss real = 3.7414834943651535e-18, disciminator loss fake = 3.1431220577360364e-06, generator loss = 13.922757148742676\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 20, Batch: 29/468, discriminator loss real = 2.9812089720681712e-18, disciminator loss fake = 3.789964011957636e-06, generator loss = 14.148962020874023\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 20, Batch: 30/468, discriminator loss real = 1.1890187939390799e-16, disciminator loss fake = 4.316193553677294e-06, generator loss = 14.181407928466797\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 20, Batch: 31/468, discriminator loss real = 1.188227649606688e-08, disciminator loss fake = 3.081205022681388e-06, generator loss = 14.125378608703613\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 20, Batch: 32/468, discriminator loss real = 6.600188395822215e-09, disciminator loss fake = 2.287013103341451e-06, generator loss = 13.927459716796875\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 20, Batch: 33/468, discriminator loss real = 3.165635575896886e-08, disciminator loss fake = 3.249599558330374e-06, generator loss = 14.126607894897461\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 20, Batch: 34/468, discriminator loss real = 2.4420550145426597e-16, disciminator loss fake = 1.9633182546385797e-06, generator loss = 14.488349914550781\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 20, Batch: 35/468, discriminator loss real = 1.0835456140301618e-20, disciminator loss fake = 1.7013750266414718e-06, generator loss = 14.280969619750977\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 20, Batch: 36/468, discriminator loss real = 1.4058672355445103e-17, disciminator loss fake = 3.7608710954373237e-06, generator loss = 13.908483505249023\n",
      "2/2 [==============================] - 0s 99ms/step\n",
      "Epoch: 20, Batch: 37/468, discriminator loss real = 8.930977049891893e-19, disciminator loss fake = 3.2083789847092703e-06, generator loss = 14.297807693481445\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 20, Batch: 38/468, discriminator loss real = 1.6702248275240502e-29, disciminator loss fake = 4.870775228482671e-06, generator loss = 14.037724494934082\n",
      "2/2 [==============================] - 0s 208ms/step\n",
      "Epoch: 20, Batch: 39/468, discriminator loss real = 7.191784864345604e-23, disciminator loss fake = 1.5018787280496326e-06, generator loss = 13.836373329162598\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 20, Batch: 40/468, discriminator loss real = 1.162189554730392e-15, disciminator loss fake = 2.5269205252698157e-06, generator loss = 14.130016326904297\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 20, Batch: 41/468, discriminator loss real = 2.5021297427200685e-18, disciminator loss fake = 2.651684553711675e-06, generator loss = 14.0526762008667\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 20, Batch: 42/468, discriminator loss real = 4.143164283876288e-11, disciminator loss fake = 2.5548608846293064e-06, generator loss = 14.33993148803711\n",
      "2/2 [==============================] - 0s 176ms/step\n",
      "Epoch: 20, Batch: 43/468, discriminator loss real = 2.5229854145436548e-05, disciminator loss fake = 1.5983547427822486e-06, generator loss = 14.154696464538574\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 20, Batch: 44/468, discriminator loss real = 1.1714765510190302e-14, disciminator loss fake = 3.0086011975072324e-06, generator loss = 14.149126052856445\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 20, Batch: 45/468, discriminator loss real = 3.1263186484054017e-13, disciminator loss fake = 3.2509879019926302e-06, generator loss = 14.00451946258545\n",
      "2/2 [==============================] - 0s 136ms/step\n",
      "Epoch: 20, Batch: 46/468, discriminator loss real = 3.188571341560738e-25, disciminator loss fake = 2.422940042379196e-06, generator loss = 14.46666145324707\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 20, Batch: 47/468, discriminator loss real = 4.948882018176396e-20, disciminator loss fake = 3.764699613384437e-06, generator loss = 14.224403381347656\n",
      "2/2 [==============================] - 0s 178ms/step\n",
      "Epoch: 20, Batch: 48/468, discriminator loss real = 4.53144594243697e-18, disciminator loss fake = 2.9830921448592562e-06, generator loss = 14.386053085327148\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 20, Batch: 49/468, discriminator loss real = 2.2069765719806567e-12, disciminator loss fake = 2.839305579982465e-06, generator loss = 14.395593643188477\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 20, Batch: 50/468, discriminator loss real = 9.220095027049017e-20, disciminator loss fake = 1.8341040686209453e-06, generator loss = 14.425849914550781\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 20, Batch: 51/468, discriminator loss real = 9.998526008695174e-19, disciminator loss fake = 2.530383426346816e-06, generator loss = 14.26020336151123\n",
      "2/2 [==============================] - 0s 155ms/step\n",
      "Epoch: 20, Batch: 52/468, discriminator loss real = 8.125165817940427e-11, disciminator loss fake = 2.408761019978556e-06, generator loss = 14.29244613647461\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 20, Batch: 53/468, discriminator loss real = 2.561693054076057e-19, disciminator loss fake = 2.376793190705939e-06, generator loss = 14.433130264282227\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 20, Batch: 54/468, discriminator loss real = 1.7703796068064397e-20, disciminator loss fake = 2.647895598784089e-06, generator loss = 14.269510269165039\n",
      "2/2 [==============================] - 0s 162ms/step\n",
      "Epoch: 20, Batch: 55/468, discriminator loss real = 5.693521731410016e-28, disciminator loss fake = 1.7038996702467557e-06, generator loss = 14.480171203613281\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 20, Batch: 56/468, discriminator loss real = 1.8991250424735048e-23, disciminator loss fake = 2.1669347916031256e-06, generator loss = 14.32857894897461\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 20, Batch: 57/468, discriminator loss real = 3.9973208625326994e-17, disciminator loss fake = 9.051254892256111e-07, generator loss = 14.505910873413086\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 20, Batch: 58/468, discriminator loss real = 4.1863626310945216e-19, disciminator loss fake = 1.2170322634119657e-06, generator loss = 14.030769348144531\n",
      "2/2 [==============================] - 0s 224ms/step\n",
      "Epoch: 20, Batch: 59/468, discriminator loss real = 2.90361098608926e-14, disciminator loss fake = 1.521620106359478e-06, generator loss = 14.157176971435547\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 20, Batch: 60/468, discriminator loss real = 9.419659496856525e-11, disciminator loss fake = 2.1823504994245013e-06, generator loss = 14.39162826538086\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 20, Batch: 61/468, discriminator loss real = 2.164277540894982e-18, disciminator loss fake = 2.3786653855495388e-06, generator loss = 14.223812103271484\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 20, Batch: 62/468, discriminator loss real = 1.1796285644541295e-32, disciminator loss fake = 3.2083919450087706e-06, generator loss = 14.682313919067383\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 20, Batch: 63/468, discriminator loss real = 3.3114758764968277e-12, disciminator loss fake = 2.971265530504752e-06, generator loss = 14.317970275878906\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 20, Batch: 64/468, discriminator loss real = 5.373673383922644e-19, disciminator loss fake = 2.318219912922359e-06, generator loss = 14.384321212768555\n",
      "2/2 [==============================] - 0s 135ms/step\n",
      "Epoch: 20, Batch: 65/468, discriminator loss real = 1.3792378350530043e-10, disciminator loss fake = 2.4174016743927496e-06, generator loss = 14.337491989135742\n",
      "2/2 [==============================] - 0s 190ms/step\n",
      "Epoch: 20, Batch: 66/468, discriminator loss real = 9.886568776517437e-27, disciminator loss fake = 2.454507921356708e-06, generator loss = 14.346145629882812\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 20, Batch: 67/468, discriminator loss real = 3.069823359291098e-21, disciminator loss fake = 2.6340685508330353e-06, generator loss = 14.454269409179688\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 20, Batch: 68/468, discriminator loss real = 8.07109505123347e-17, disciminator loss fake = 1.4721106254000915e-06, generator loss = 14.446784019470215\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 69/468, discriminator loss real = 2.6383762086872814e-28, disciminator loss fake = 1.6311838635374443e-06, generator loss = 14.428380966186523\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 20, Batch: 70/468, discriminator loss real = 7.199161261081673e-26, disciminator loss fake = 3.431550567256636e-06, generator loss = 14.513267517089844\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 20, Batch: 71/468, discriminator loss real = 1.1328158561526797e-23, disciminator loss fake = 2.269777269248152e-06, generator loss = 14.238755226135254\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 72/468, discriminator loss real = 2.5712312611816453e-27, disciminator loss fake = 7.024698788882233e-06, generator loss = 14.177876472473145\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 20, Batch: 73/468, discriminator loss real = 1.1071699113074374e-13, disciminator loss fake = 2.274651706102304e-06, generator loss = 14.47535514831543\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 74/468, discriminator loss real = 2.1511402476228586e-28, disciminator loss fake = 1.5893289173618541e-06, generator loss = 14.6116943359375\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 75/468, discriminator loss real = 1.0588485697228713e-19, disciminator loss fake = 1.2922557743877405e-06, generator loss = 14.138286590576172\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 20, Batch: 76/468, discriminator loss real = 8.892549023531426e-12, disciminator loss fake = 1.0414744338049786e-06, generator loss = 14.358941078186035\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 20, Batch: 77/468, discriminator loss real = 1.1253209675782654e-23, disciminator loss fake = 1.5360720908574876e-06, generator loss = 14.514305114746094\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 20, Batch: 78/468, discriminator loss real = 9.663027788410003e-21, disciminator loss fake = 1.860360271166428e-06, generator loss = 14.435909271240234\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 20, Batch: 79/468, discriminator loss real = 2.7231406150705086e-20, disciminator loss fake = 1.3610722362500383e-06, generator loss = 14.59101676940918\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 20, Batch: 80/468, discriminator loss real = 1.2024995157844387e-05, disciminator loss fake = 1.8204625575890532e-06, generator loss = 14.736087799072266\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 20, Batch: 81/468, discriminator loss real = 2.9072905215504595e-32, disciminator loss fake = 1.0590505326035782e-06, generator loss = 14.661039352416992\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 20, Batch: 82/468, discriminator loss real = 2.486192048539509e-15, disciminator loss fake = 3.3043097573681735e-06, generator loss = 14.835277557373047\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 20, Batch: 83/468, discriminator loss real = 4.994598529642226e-21, disciminator loss fake = 2.146061888197437e-06, generator loss = 14.391473770141602\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 84/468, discriminator loss real = 3.692330447119293e-30, disciminator loss fake = 1.7586407921044156e-06, generator loss = 14.532417297363281\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 20, Batch: 85/468, discriminator loss real = 1.369438929286614e-15, disciminator loss fake = 1.911450908664847e-06, generator loss = 14.476842880249023\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 20, Batch: 86/468, discriminator loss real = 2.473108662304213e-10, disciminator loss fake = 1.7500117337476695e-06, generator loss = 14.416831970214844\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 20, Batch: 87/468, discriminator loss real = 2.8947073360541253e-07, disciminator loss fake = 4.07985680794809e-06, generator loss = 14.751445770263672\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 88/468, discriminator loss real = 1.3264502503270736e-21, disciminator loss fake = 9.414932264917297e-07, generator loss = 14.50770378112793\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 20, Batch: 89/468, discriminator loss real = 5.897740447883638e-26, disciminator loss fake = 1.2933746802445967e-06, generator loss = 14.286956787109375\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 20, Batch: 90/468, discriminator loss real = 5.344732567677067e-17, disciminator loss fake = 1.883462005025649e-06, generator loss = 14.789846420288086\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 20, Batch: 91/468, discriminator loss real = 6.004273360679708e-20, disciminator loss fake = 1.0932026270893402e-06, generator loss = 14.60420036315918\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 20, Batch: 92/468, discriminator loss real = 3.2245859810014326e-18, disciminator loss fake = 1.3484469718605396e-06, generator loss = 14.365144729614258\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 20, Batch: 93/468, discriminator loss real = 6.86778350275176e-17, disciminator loss fake = 1.4153609981804038e-06, generator loss = 14.397216796875\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 20, Batch: 94/468, discriminator loss real = 3.55360464587621e-32, disciminator loss fake = 1.031401552609168e-06, generator loss = 14.572389602661133\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 95/468, discriminator loss real = 2.1448491974595177e-28, disciminator loss fake = 3.3240901302633574e-06, generator loss = 14.608322143554688\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 96/468, discriminator loss real = 3.7640145500826026e-19, disciminator loss fake = 5.142505870026071e-06, generator loss = 14.558016777038574\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 20, Batch: 97/468, discriminator loss real = 2.912869057070111e-09, disciminator loss fake = 3.0932224035495892e-06, generator loss = 14.61148738861084\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 98/468, discriminator loss real = 4.355106442079574e-19, disciminator loss fake = 1.5624523257429246e-06, generator loss = 14.629185676574707\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 99/468, discriminator loss real = 1.0533598437945102e-09, disciminator loss fake = 1.8436442132951925e-06, generator loss = 14.534652709960938\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 100/468, discriminator loss real = 1.9461042082383283e-19, disciminator loss fake = 1.4526399354508612e-06, generator loss = 14.514165878295898\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 101/468, discriminator loss real = 4.1085273706826733e-25, disciminator loss fake = 1.3861638308299007e-06, generator loss = 14.598442077636719\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 102/468, discriminator loss real = 1.0193001760637874e-22, disciminator loss fake = 1.5447386658706819e-06, generator loss = 14.603229522705078\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 103/468, discriminator loss real = 3.5904522795442606e-31, disciminator loss fake = 1.969008508240222e-06, generator loss = 14.262645721435547\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 20, Batch: 104/468, discriminator loss real = 4.3101683853655824e-32, disciminator loss fake = 1.5984834362825495e-06, generator loss = 14.609532356262207\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 105/468, discriminator loss real = 6.666711669822689e-06, disciminator loss fake = 1.657046368563897e-06, generator loss = 14.809216499328613\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 20, Batch: 106/468, discriminator loss real = 1.3855091651748808e-07, disciminator loss fake = 1.76449759692332e-06, generator loss = 14.796845436096191\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 20, Batch: 107/468, discriminator loss real = 2.7234487479266203e-22, disciminator loss fake = 1.000114252747153e-06, generator loss = 14.711265563964844\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 108/468, discriminator loss real = 2.60248824479398e-20, disciminator loss fake = 1.0618309715937357e-06, generator loss = 14.852923393249512\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 20, Batch: 109/468, discriminator loss real = 1.174183485364198e-23, disciminator loss fake = 1.6119431620609248e-06, generator loss = 14.646774291992188\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 110/468, discriminator loss real = 4.6089925618684615e-26, disciminator loss fake = 1.5474577139684698e-06, generator loss = 14.697168350219727\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 20, Batch: 111/468, discriminator loss real = 8.990068888978242e-15, disciminator loss fake = 1.5866187368374085e-06, generator loss = 14.73316478729248\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 20, Batch: 112/468, discriminator loss real = 1.623603175772761e-17, disciminator loss fake = 1.7284246496274136e-06, generator loss = 14.541654586791992\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 20, Batch: 113/468, discriminator loss real = 6.593378468242903e-20, disciminator loss fake = 1.4678382740385132e-06, generator loss = 14.597183227539062\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 114/468, discriminator loss real = 3.492864821507461e-25, disciminator loss fake = 1.1966139936703257e-06, generator loss = 14.620647430419922\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 20, Batch: 115/468, discriminator loss real = 2.832172213765305e-12, disciminator loss fake = 1.7901735418490716e-06, generator loss = 14.768721580505371\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 116/468, discriminator loss real = 8.065106158028357e-06, disciminator loss fake = 1.4077147625357611e-06, generator loss = 14.669323921203613\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 20, Batch: 117/468, discriminator loss real = 1.7683292222607833e-23, disciminator loss fake = 2.5376239136676304e-06, generator loss = 14.830009460449219\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 20, Batch: 118/468, discriminator loss real = 1.842466405680733e-14, disciminator loss fake = 1.3949370440968778e-06, generator loss = 14.915486335754395\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 119/468, discriminator loss real = 1.1644451025528954e-18, disciminator loss fake = 3.768011993088294e-06, generator loss = 14.66584587097168\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 20, Batch: 120/468, discriminator loss real = 6.493029990626079e-14, disciminator loss fake = 1.03674403817422e-06, generator loss = 14.735465049743652\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 20, Batch: 121/468, discriminator loss real = 5.905555170685186e-20, disciminator loss fake = 1.0364074114477262e-06, generator loss = 14.780095100402832\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 122/468, discriminator loss real = 1.2712294460630304e-17, disciminator loss fake = 1.7628245814194088e-06, generator loss = 14.610690116882324\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 123/468, discriminator loss real = 8.923032517008055e-34, disciminator loss fake = 1.2022203463857295e-06, generator loss = 15.049468994140625\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 124/468, discriminator loss real = 1.2439353809809244e-16, disciminator loss fake = 1.5912223716441076e-06, generator loss = 14.385184288024902\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 125/468, discriminator loss real = 1.627763757117151e-10, disciminator loss fake = 1.258241127288784e-06, generator loss = 14.587225914001465\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 20, Batch: 126/468, discriminator loss real = 7.962586948787547e-26, disciminator loss fake = 1.8743080545391422e-06, generator loss = 14.564637184143066\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 20, Batch: 127/468, discriminator loss real = 8.366590975800517e-14, disciminator loss fake = 1.7624424799578264e-06, generator loss = 14.914886474609375\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 20, Batch: 128/468, discriminator loss real = 1.1470367281119991e-26, disciminator loss fake = 8.153876365213364e-07, generator loss = 14.787602424621582\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 20, Batch: 129/468, discriminator loss real = 2.126964771254695e-28, disciminator loss fake = 1.1996658031421248e-06, generator loss = 14.764519691467285\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 20, Batch: 130/468, discriminator loss real = 1.0527253534804232e-32, disciminator loss fake = 1.804285375328618e-06, generator loss = 14.342546463012695\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 20, Batch: 131/468, discriminator loss real = 1.7180074999656058e-18, disciminator loss fake = 1.2043644801451592e-06, generator loss = 14.60315227508545\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 132/468, discriminator loss real = 4.41099396958853e-18, disciminator loss fake = 1.448091097699944e-06, generator loss = 14.909051895141602\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 20, Batch: 133/468, discriminator loss real = 1.1580628257077988e-35, disciminator loss fake = 1.7501355387139483e-06, generator loss = 15.062078475952148\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 20, Batch: 134/468, discriminator loss real = 4.6814954272200834e-27, disciminator loss fake = 1.5341682910730015e-06, generator loss = 14.908026695251465\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 20, Batch: 135/468, discriminator loss real = 5.29393389570032e-07, disciminator loss fake = 1.1941735920117935e-06, generator loss = 14.998952865600586\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 20, Batch: 136/468, discriminator loss real = 2.9330257298419704e-14, disciminator loss fake = 9.430649470232311e-07, generator loss = 15.043107986450195\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 20, Batch: 137/468, discriminator loss real = 1.230555157485155e-21, disciminator loss fake = 1.354676669507171e-06, generator loss = 14.672459602355957\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 138/468, discriminator loss real = 2.805134681693744e-05, disciminator loss fake = 1.4380800621438539e-06, generator loss = 14.679336547851562\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 20, Batch: 139/468, discriminator loss real = 1.7573891553389492e-20, disciminator loss fake = 1.3905142850489938e-06, generator loss = 14.784433364868164\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 20, Batch: 140/468, discriminator loss real = 6.389840858783683e-23, disciminator loss fake = 1.596616129972972e-06, generator loss = 14.546575546264648\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 20, Batch: 141/468, discriminator loss real = 4.607908960835375e-22, disciminator loss fake = 2.059061444015242e-06, generator loss = 14.72549057006836\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 20, Batch: 142/468, discriminator loss real = 2.1489108783879366e-30, disciminator loss fake = 1.471329596824944e-06, generator loss = 14.747118949890137\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 143/468, discriminator loss real = 8.577313218675876e-25, disciminator loss fake = 1.2684969306064886e-06, generator loss = 14.541074752807617\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 20, Batch: 144/468, discriminator loss real = 4.922255936179454e-10, disciminator loss fake = 7.641739330210839e-07, generator loss = 14.665495872497559\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 20, Batch: 145/468, discriminator loss real = 1.8668941992813476e-17, disciminator loss fake = 2.8630679480556864e-06, generator loss = 14.748332977294922\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 146/468, discriminator loss real = 1.3935200927709952e-28, disciminator loss fake = 1.8518458091421053e-06, generator loss = 14.808460235595703\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 147/468, discriminator loss real = 4.537949127580987e-09, disciminator loss fake = 1.5625731748514227e-06, generator loss = 14.89012622833252\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 20, Batch: 148/468, discriminator loss real = 1.3750375449478185e-29, disciminator loss fake = 1.2660814263654174e-06, generator loss = 14.84681510925293\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 20, Batch: 149/468, discriminator loss real = 1.1894802181520094e-26, disciminator loss fake = 1.764845592333586e-06, generator loss = 14.824237823486328\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 20, Batch: 150/468, discriminator loss real = 1.2343981060067136e-23, disciminator loss fake = 1.680203240539413e-06, generator loss = 14.71603012084961\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 151/468, discriminator loss real = 3.024030706173e-17, disciminator loss fake = 1.0925168680842035e-06, generator loss = 14.617515563964844\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 152/468, discriminator loss real = 2.7059603714756615e-32, disciminator loss fake = 1.992962097574491e-06, generator loss = 14.982719421386719\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 153/468, discriminator loss real = 2.1155380555609503e-26, disciminator loss fake = 1.897878291856614e-06, generator loss = 14.73265266418457\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 20, Batch: 154/468, discriminator loss real = 2.4991074958802766e-27, disciminator loss fake = 9.235626521331142e-07, generator loss = 14.796747207641602\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 155/468, discriminator loss real = 9.153143060115429e-15, disciminator loss fake = 9.982015853893245e-07, generator loss = 14.831727981567383\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 20, Batch: 156/468, discriminator loss real = 1.80616375940754e-14, disciminator loss fake = 1.7097300997193088e-06, generator loss = 14.675540924072266\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 20, Batch: 157/468, discriminator loss real = 2.0154682367490295e-09, disciminator loss fake = 8.213108912968892e-07, generator loss = 14.897676467895508\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 20, Batch: 158/468, discriminator loss real = 3.9714929750863436e-17, disciminator loss fake = 1.4121937965683173e-06, generator loss = 14.750334739685059\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 159/468, discriminator loss real = 1.3048754692950795e-26, disciminator loss fake = 1.4457211818807991e-06, generator loss = 14.896344184875488\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 20, Batch: 160/468, discriminator loss real = 4.5769631088814594e-30, disciminator loss fake = 1.4232257399271475e-06, generator loss = 14.759710311889648\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 161/468, discriminator loss real = 2.122898422385333e-06, disciminator loss fake = 1.4083909718465293e-06, generator loss = 14.67237377166748\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 20, Batch: 162/468, discriminator loss real = 1.1102484356135742e-13, disciminator loss fake = 1.2788971162080998e-06, generator loss = 14.943460464477539\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 20, Batch: 163/468, discriminator loss real = 3.1217783082861464e-17, disciminator loss fake = 1.9884591893060133e-06, generator loss = 14.711181640625\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 20, Batch: 164/468, discriminator loss real = 1.1693764036660527e-23, disciminator loss fake = 1.659147073951317e-06, generator loss = 14.635407447814941\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 20, Batch: 165/468, discriminator loss real = 3.0065584312537027e-22, disciminator loss fake = 1.3856455325367278e-06, generator loss = 14.641926765441895\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 166/468, discriminator loss real = 2.930432880583332e-25, disciminator loss fake = 1.8174126807934954e-06, generator loss = 14.557888984680176\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 20, Batch: 167/468, discriminator loss real = 3.1460077519168046e-19, disciminator loss fake = 1.400817268404353e-06, generator loss = 14.729510307312012\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 20, Batch: 168/468, discriminator loss real = 1.7115738355737524e-23, disciminator loss fake = 1.3075052720523672e-06, generator loss = 14.673585891723633\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 20, Batch: 169/468, discriminator loss real = 1.437272801861311e-17, disciminator loss fake = 1.5155919754761271e-06, generator loss = 15.001910209655762\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 170/468, discriminator loss real = 1.5201197505615438e-13, disciminator loss fake = 1.3433867707135505e-06, generator loss = 15.053150177001953\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 20, Batch: 171/468, discriminator loss real = 9.321545271778753e-13, disciminator loss fake = 1.0829097618625383e-06, generator loss = 14.65027141571045\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 20, Batch: 172/468, discriminator loss real = 1.3223165367970547e-28, disciminator loss fake = 1.5105879356269725e-06, generator loss = 14.718084335327148\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 173/468, discriminator loss real = 1.1376929700189824e-19, disciminator loss fake = 1.3215735634730663e-06, generator loss = 14.972414016723633\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 174/468, discriminator loss real = 2.1167087128183467e-28, disciminator loss fake = 1.9118074305879418e-06, generator loss = 14.893178939819336\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 175/468, discriminator loss real = 1.501728038680423e-17, disciminator loss fake = 1.3572819170803996e-06, generator loss = 15.078607559204102\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 20, Batch: 176/468, discriminator loss real = 6.500900620771966e-13, disciminator loss fake = 6.560597398674872e-07, generator loss = 14.900805473327637\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 20, Batch: 177/468, discriminator loss real = 3.2973632570737116e-20, disciminator loss fake = 1.6536195062144543e-06, generator loss = 14.783185958862305\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 178/468, discriminator loss real = 3.993743669106209e-10, disciminator loss fake = 1.2322542488618637e-06, generator loss = 14.88986587524414\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 179/468, discriminator loss real = 1.8800723198162114e-26, disciminator loss fake = 1.1726801858458202e-06, generator loss = 14.769622802734375\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 20, Batch: 180/468, discriminator loss real = 7.051497840498966e-12, disciminator loss fake = 2.908746864704881e-06, generator loss = 14.904054641723633\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 20, Batch: 181/468, discriminator loss real = 3.4541194761487656e-20, disciminator loss fake = 2.3968543700902956e-06, generator loss = 15.009648323059082\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 182/468, discriminator loss real = 4.852252497369869e-13, disciminator loss fake = 1.6691735709173372e-06, generator loss = 14.745962142944336\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Epoch: 20, Batch: 183/468, discriminator loss real = 3.8191794443366263e-16, disciminator loss fake = 1.1847786254293169e-06, generator loss = 15.087970733642578\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 184/468, discriminator loss real = 3.0979455804772685e-17, disciminator loss fake = 1.0161194268221152e-06, generator loss = 14.743739128112793\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 185/468, discriminator loss real = 1.8527929380360315e-22, disciminator loss fake = 1.6056351341831032e-06, generator loss = 14.85653305053711\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 186/468, discriminator loss real = 1.4281187248944317e-17, disciminator loss fake = 1.3196738564147381e-06, generator loss = 14.923127174377441\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 187/468, discriminator loss real = 1.0580128749661226e-21, disciminator loss fake = 1.5757718756503891e-06, generator loss = 14.944416046142578\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 188/468, discriminator loss real = 1.5307569186419635e-19, disciminator loss fake = 1.5143114069360308e-06, generator loss = 15.095087051391602\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 20, Batch: 189/468, discriminator loss real = 7.702378184148984e-07, disciminator loss fake = 6.654369713032793e-07, generator loss = 15.02899169921875\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 20, Batch: 190/468, discriminator loss real = 1.2192937292469205e-27, disciminator loss fake = 1.0413666586828185e-06, generator loss = 14.702163696289062\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 20, Batch: 191/468, discriminator loss real = 1.327626649209961e-25, disciminator loss fake = 1.0544085853325669e-06, generator loss = 15.01998519897461\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 192/468, discriminator loss real = 5.559443839277457e-17, disciminator loss fake = 1.3255706790005206e-06, generator loss = 14.855574607849121\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 20, Batch: 193/468, discriminator loss real = 1.0328976036174813e-20, disciminator loss fake = 1.3557865941038472e-06, generator loss = 15.028271675109863\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 20, Batch: 194/468, discriminator loss real = 5.583946831536686e-19, disciminator loss fake = 1.0729062296377379e-06, generator loss = 15.184840202331543\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 195/468, discriminator loss real = 9.524959607257492e-17, disciminator loss fake = 6.932394285286136e-07, generator loss = 14.964418411254883\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 20, Batch: 196/468, discriminator loss real = 8.856883937875783e-22, disciminator loss fake = 1.2973791854165029e-06, generator loss = 15.090913772583008\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 197/468, discriminator loss real = 3.200771028430416e-12, disciminator loss fake = 1.2509703992691357e-06, generator loss = 14.871313095092773\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 20, Batch: 198/468, discriminator loss real = 1.5129279975874107e-30, disciminator loss fake = 1.050607352226507e-06, generator loss = 14.958019256591797\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 20, Batch: 199/468, discriminator loss real = 2.452252539485861e-13, disciminator loss fake = 9.448016839996853e-07, generator loss = 14.645954132080078\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 20, Batch: 200/468, discriminator loss real = 3.2919353159887145e-17, disciminator loss fake = 9.841388646236737e-07, generator loss = 15.023924827575684\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 20, Batch: 201/468, discriminator loss real = 5.915027989880096e-29, disciminator loss fake = 1.498589881521184e-06, generator loss = 14.924391746520996\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 202/468, discriminator loss real = 1.647536329585364e-08, disciminator loss fake = 1.065714968717657e-06, generator loss = 15.161409378051758\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 20, Batch: 203/468, discriminator loss real = 4.565521521726623e-05, disciminator loss fake = 9.734510513226269e-07, generator loss = 14.85589599609375\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 204/468, discriminator loss real = 2.3448205183074222e-12, disciminator loss fake = 1.0195971071880194e-06, generator loss = 14.88204574584961\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 205/468, discriminator loss real = 2.1269576993728759e-16, disciminator loss fake = 7.932991934467282e-07, generator loss = 14.82602596282959\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 20, Batch: 206/468, discriminator loss real = 7.52863052191333e-24, disciminator loss fake = 1.4195502444636077e-06, generator loss = 14.893743515014648\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 207/468, discriminator loss real = 2.279275124770029e-22, disciminator loss fake = 1.1628849279077258e-06, generator loss = 14.774405479431152\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 208/468, discriminator loss real = 4.1346393954869534e-16, disciminator loss fake = 9.359980595036177e-07, generator loss = 15.0838623046875\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 20, Batch: 209/468, discriminator loss real = 4.430572193149132e-24, disciminator loss fake = 1.017721615426126e-06, generator loss = 14.908819198608398\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 20, Batch: 210/468, discriminator loss real = 1.2197301545516237e-13, disciminator loss fake = 9.108618996833684e-07, generator loss = 15.038473129272461\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 211/468, discriminator loss real = 1.4821442961832076e-09, disciminator loss fake = 9.58512828219682e-07, generator loss = 14.747368812561035\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 20, Batch: 212/468, discriminator loss real = 1.917149059695511e-25, disciminator loss fake = 8.324378200086358e-07, generator loss = 14.787622451782227\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 213/468, discriminator loss real = 1.3185524695867044e-18, disciminator loss fake = 7.471716116924654e-07, generator loss = 14.817096710205078\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 20, Batch: 214/468, discriminator loss real = 1.1775331415237594e-13, disciminator loss fake = 1.9452547803666675e-06, generator loss = 15.217314720153809\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 215/468, discriminator loss real = 1.6670167468646468e-09, disciminator loss fake = 2.063661440843134e-06, generator loss = 14.809514999389648\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 216/468, discriminator loss real = 1.257462458277549e-22, disciminator loss fake = 1.3870287602912867e-06, generator loss = 14.947785377502441\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 217/468, discriminator loss real = 2.7870372402783513e-16, disciminator loss fake = 1.0806631962623214e-06, generator loss = 15.12513542175293\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 218/468, discriminator loss real = 2.052553742950907e-15, disciminator loss fake = 1.3311830571183236e-06, generator loss = 14.93011474609375\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 219/468, discriminator loss real = 1.92810247205338e-21, disciminator loss fake = 8.936985409491172e-07, generator loss = 15.027949333190918\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 20, Batch: 220/468, discriminator loss real = 7.506145126493749e-25, disciminator loss fake = 8.542337468497863e-07, generator loss = 14.836259841918945\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 221/468, discriminator loss real = 4.709327443165485e-22, disciminator loss fake = 7.335993927881646e-07, generator loss = 14.894142150878906\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 20, Batch: 222/468, discriminator loss real = 5.445546888083488e-26, disciminator loss fake = 1.3523032293960568e-06, generator loss = 15.113178253173828\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 20, Batch: 223/468, discriminator loss real = 2.3426826283719906e-22, disciminator loss fake = 1.682376591816137e-06, generator loss = 14.735186576843262\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 20, Batch: 224/468, discriminator loss real = 4.1312501718195276e-20, disciminator loss fake = 1.433727902622195e-06, generator loss = 15.050716400146484\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 225/468, discriminator loss real = 9.102988547413956e-21, disciminator loss fake = 1.2192740541649982e-06, generator loss = 15.120832443237305\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 20, Batch: 226/468, discriminator loss real = 4.403582804391598e-13, disciminator loss fake = 1.2178609267721185e-06, generator loss = 14.83812141418457\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 227/468, discriminator loss real = 8.885770635829783e-22, disciminator loss fake = 1.0651197044353466e-06, generator loss = 14.7006254196167\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 20, Batch: 228/468, discriminator loss real = 4.324390079579536e-22, disciminator loss fake = 8.85026224750618e-07, generator loss = 14.872833251953125\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 20, Batch: 229/468, discriminator loss real = 3.010003410963691e-07, disciminator loss fake = 7.481970669687144e-07, generator loss = 14.963153839111328\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 20, Batch: 230/468, discriminator loss real = 4.825340672657525e-24, disciminator loss fake = 1.0632135172272683e-06, generator loss = 14.958457946777344\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 20, Batch: 231/468, discriminator loss real = 6.880947319734291e-24, disciminator loss fake = 1.0649704336174182e-06, generator loss = 14.858110427856445\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 20, Batch: 232/468, discriminator loss real = 5.506268963733404e-16, disciminator loss fake = 9.588966349838302e-07, generator loss = 15.07812786102295\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 20, Batch: 233/468, discriminator loss real = 3.930358616344165e-06, disciminator loss fake = 1.4221476476450334e-06, generator loss = 14.879332542419434\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 20, Batch: 234/468, discriminator loss real = 2.088728323136431e-17, disciminator loss fake = 2.684171704459004e-06, generator loss = 15.180831909179688\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 235/468, discriminator loss real = 1.236958535599797e-09, disciminator loss fake = 8.297999443129811e-07, generator loss = 14.837360382080078\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 20, Batch: 236/468, discriminator loss real = 3.44161963810416e-22, disciminator loss fake = 9.093270136872889e-07, generator loss = 15.074305534362793\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 20, Batch: 237/468, discriminator loss real = 1.9739412418133897e-23, disciminator loss fake = 9.261037803298677e-07, generator loss = 15.084917068481445\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 20, Batch: 238/468, discriminator loss real = 1.6237087409018084e-22, disciminator loss fake = 3.8634962038486265e-06, generator loss = 14.988604545593262\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 239/468, discriminator loss real = 2.6217901000062185e-28, disciminator loss fake = 1.5914075675027561e-06, generator loss = 14.947602272033691\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 240/468, discriminator loss real = 1.4454842585109873e-06, disciminator loss fake = 6.822725708843791e-07, generator loss = 15.044584274291992\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 20, Batch: 241/468, discriminator loss real = 1.3240182464299075e-20, disciminator loss fake = 1.4239568599805352e-06, generator loss = 14.955389022827148\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 20, Batch: 242/468, discriminator loss real = 2.7497863723844424e-15, disciminator loss fake = 1.0316723546566209e-06, generator loss = 15.167481422424316\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 20, Batch: 243/468, discriminator loss real = 6.646804429771898e-25, disciminator loss fake = 1.3482336953529739e-06, generator loss = 15.180156707763672\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 20, Batch: 244/468, discriminator loss real = 6.889763629211041e-24, disciminator loss fake = 8.320300253217283e-07, generator loss = 15.00684928894043\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 20, Batch: 245/468, discriminator loss real = 5.3083048373592234e-11, disciminator loss fake = 6.393442504304403e-07, generator loss = 14.811203002929688\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 246/468, discriminator loss real = 1.7050373428677962e-14, disciminator loss fake = 8.738127235119464e-07, generator loss = 15.140830993652344\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 20, Batch: 247/468, discriminator loss real = 5.5502384440253745e-16, disciminator loss fake = 1.351068249277887e-06, generator loss = 14.993419647216797\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 20, Batch: 248/468, discriminator loss real = 2.4828505579008447e-24, disciminator loss fake = 9.0444393663347e-07, generator loss = 15.052013397216797\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 249/468, discriminator loss real = 1.0165293179114167e-22, disciminator loss fake = 1.503180101281032e-06, generator loss = 14.808038711547852\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 20, Batch: 250/468, discriminator loss real = 2.977522938540649e-27, disciminator loss fake = 1.9225478808948537e-06, generator loss = 14.902095794677734\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 20, Batch: 251/468, discriminator loss real = 2.6749480143735965e-21, disciminator loss fake = 1.2908362805319484e-06, generator loss = 14.897334098815918\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 252/468, discriminator loss real = 1.4081576366221237e-19, disciminator loss fake = 7.18730859716743e-07, generator loss = 15.145964622497559\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 20, Batch: 253/468, discriminator loss real = 9.060938497857397e-19, disciminator loss fake = 1.0424669198982883e-06, generator loss = 14.96377182006836\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 254/468, discriminator loss real = 4.940374722002278e-16, disciminator loss fake = 2.824843249982223e-06, generator loss = 15.19583797454834\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 20, Batch: 255/468, discriminator loss real = 2.3261368001613435e-26, disciminator loss fake = 1.7327065506833605e-06, generator loss = 14.932962417602539\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 20, Batch: 256/468, discriminator loss real = 4.831177044287585e-22, disciminator loss fake = 1.536213630970451e-06, generator loss = 14.952375411987305\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 257/468, discriminator loss real = 3.1563800151868514e-20, disciminator loss fake = 8.683648502483265e-07, generator loss = 15.28471565246582\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 20, Batch: 258/468, discriminator loss real = 5.266196395349376e-28, disciminator loss fake = 1.2584209798660595e-06, generator loss = 15.118223190307617\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 259/468, discriminator loss real = 1.1661136466167843e-14, disciminator loss fake = 9.59185399551643e-07, generator loss = 15.35867977142334\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 20, Batch: 260/468, discriminator loss real = 3.156357590837433e-19, disciminator loss fake = 9.32112982354738e-07, generator loss = 15.069404602050781\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 20, Batch: 261/468, discriminator loss real = 1.9599360329136672e-11, disciminator loss fake = 1.0936273611150682e-06, generator loss = 15.106155395507812\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 262/468, discriminator loss real = 8.35657159637899e-24, disciminator loss fake = 7.161255553000956e-07, generator loss = 15.369661331176758\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 20, Batch: 263/468, discriminator loss real = 2.306457745181455e-16, disciminator loss fake = 1.31077445075789e-06, generator loss = 15.248106002807617\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 20, Batch: 264/468, discriminator loss real = 5.44280671422627e-15, disciminator loss fake = 8.19418914943526e-07, generator loss = 14.953668594360352\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 20, Batch: 265/468, discriminator loss real = 4.922138102647893e-15, disciminator loss fake = 6.164045771583915e-07, generator loss = 15.214279174804688\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 266/468, discriminator loss real = 1.2096965622474518e-15, disciminator loss fake = 7.39628148949123e-07, generator loss = 14.972675323486328\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 267/468, discriminator loss real = 8.78205175247615e-10, disciminator loss fake = 1.4993054264778038e-06, generator loss = 15.446125030517578\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 268/468, discriminator loss real = 1.413882614542672e-06, disciminator loss fake = 1.7941945316124475e-06, generator loss = 15.301933288574219\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 20, Batch: 269/468, discriminator loss real = 1.915434396562303e-27, disciminator loss fake = 1.6571871128689963e-06, generator loss = 15.358449935913086\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 20, Batch: 270/468, discriminator loss real = 6.605323926711648e-13, disciminator loss fake = 6.301474968495313e-07, generator loss = 15.139569282531738\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 20, Batch: 271/468, discriminator loss real = 1.018276221772163e-15, disciminator loss fake = 1.940120000654133e-06, generator loss = 15.239473342895508\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 272/468, discriminator loss real = 3.42399459221535e-21, disciminator loss fake = 1.2667945838984451e-06, generator loss = 15.271282196044922\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 273/468, discriminator loss real = 1.1740843416285524e-18, disciminator loss fake = 4.022466782771517e-06, generator loss = 15.278613090515137\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 274/468, discriminator loss real = 3.357421979321984e-11, disciminator loss fake = 1.5299673350455123e-06, generator loss = 15.265339851379395\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 20, Batch: 275/468, discriminator loss real = 1.8296684578257257e-16, disciminator loss fake = 4.5662483216801775e-07, generator loss = 15.240497589111328\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 20, Batch: 276/468, discriminator loss real = 1.690817974520087e-08, disciminator loss fake = 8.273573257611133e-07, generator loss = 15.315290451049805\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 277/468, discriminator loss real = 6.006319210979099e-19, disciminator loss fake = 9.661865760790533e-07, generator loss = 15.211751937866211\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 20, Batch: 278/468, discriminator loss real = 1.8917408360144736e-25, disciminator loss fake = 6.933038321221829e-07, generator loss = 15.261680603027344\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 20, Batch: 279/468, discriminator loss real = 6.835532129034555e-26, disciminator loss fake = 1.6074832274171058e-06, generator loss = 15.115104675292969\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 20, Batch: 280/468, discriminator loss real = 2.5741632969289805e-27, disciminator loss fake = 5.427066867014219e-07, generator loss = 15.15877914428711\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 20, Batch: 281/468, discriminator loss real = 2.873135236669544e-11, disciminator loss fake = 1.1970523701165803e-06, generator loss = 15.354597091674805\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 20, Batch: 282/468, discriminator loss real = 5.916655400683103e-29, disciminator loss fake = 5.574845545197604e-07, generator loss = 15.323504447937012\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 20, Batch: 283/468, discriminator loss real = 2.9693121130825763e-15, disciminator loss fake = 1.065571268554777e-06, generator loss = 15.449075698852539\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 284/468, discriminator loss real = 8.689017303361755e-24, disciminator loss fake = 8.841521434987953e-07, generator loss = 15.420330047607422\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 285/468, discriminator loss real = 1.7048032907238109e-12, disciminator loss fake = 2.7767850951931905e-06, generator loss = 15.316902160644531\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 20, Batch: 286/468, discriminator loss real = 1.7678703104225912e-15, disciminator loss fake = 9.808433105717995e-07, generator loss = 14.996953964233398\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 20, Batch: 287/468, discriminator loss real = 2.2974171787562455e-26, disciminator loss fake = 9.124011057792814e-07, generator loss = 15.027923583984375\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 288/468, discriminator loss real = 1.06625210503892e-17, disciminator loss fake = 1.0738737046267488e-06, generator loss = 15.434064865112305\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 20, Batch: 289/468, discriminator loss real = 2.391894442550139e-27, disciminator loss fake = 7.102297558958526e-07, generator loss = 15.536166191101074\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 20, Batch: 290/468, discriminator loss real = 2.1084176976832552e-22, disciminator loss fake = 1.7837135146692162e-06, generator loss = 14.98451042175293\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 20, Batch: 291/468, discriminator loss real = 1.9113608468851982e-14, disciminator loss fake = 1.1971801541221794e-06, generator loss = 15.207874298095703\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 20, Batch: 292/468, discriminator loss real = 5.016832548032882e-17, disciminator loss fake = 1.0637172636052128e-06, generator loss = 15.306035995483398\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 293/468, discriminator loss real = 2.562925777351476e-23, disciminator loss fake = 1.085182930182782e-06, generator loss = 15.206977844238281\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 294/468, discriminator loss real = 2.7939814351007897e-10, disciminator loss fake = 9.420525088899012e-07, generator loss = 15.154106140136719\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 20, Batch: 295/468, discriminator loss real = 2.3944981909003894e-15, disciminator loss fake = 8.796691872703377e-07, generator loss = 15.406111717224121\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 296/468, discriminator loss real = 3.6778679879618267e-26, disciminator loss fake = 6.221081321200472e-07, generator loss = 15.141500473022461\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 20, Batch: 297/468, discriminator loss real = 2.2981386904993357e-17, disciminator loss fake = 7.155249477364123e-07, generator loss = 15.137155532836914\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 298/468, discriminator loss real = 5.086748368034926e-16, disciminator loss fake = 6.002977670505061e-07, generator loss = 15.171651840209961\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 20, Batch: 299/468, discriminator loss real = 8.901669142470994e-14, disciminator loss fake = 1.0181175866819103e-06, generator loss = 15.330802917480469\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 20, Batch: 300/468, discriminator loss real = 5.361303931837679e-20, disciminator loss fake = 9.151298172582756e-07, generator loss = 15.28854751586914\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 20, Batch: 301/468, discriminator loss real = 3.7387716898524837e-28, disciminator loss fake = 1.0027704320236808e-06, generator loss = 15.262772560119629\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 20, Batch: 302/468, discriminator loss real = 5.471267113155073e-22, disciminator loss fake = 7.722142072452698e-07, generator loss = 15.526328086853027\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 303/468, discriminator loss real = 3.0220583767204287e-17, disciminator loss fake = 7.143879656723584e-07, generator loss = 15.273995399475098\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 304/468, discriminator loss real = 1.744428711723811e-13, disciminator loss fake = 7.393600753857754e-07, generator loss = 15.253421783447266\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 20, Batch: 305/468, discriminator loss real = 6.150778450881569e-16, disciminator loss fake = 1.2839922192142694e-06, generator loss = 15.263420104980469\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 20, Batch: 306/468, discriminator loss real = 9.758744923260565e-09, disciminator loss fake = 7.647528263987624e-07, generator loss = 15.13198471069336\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 307/468, discriminator loss real = 1.0322161166864359e-28, disciminator loss fake = 7.710082741141377e-07, generator loss = 15.139920234680176\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 20, Batch: 308/468, discriminator loss real = 1.1689896251642229e-22, disciminator loss fake = 1.7949311086340458e-06, generator loss = 15.35916805267334\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 20, Batch: 309/468, discriminator loss real = 6.051823429771891e-17, disciminator loss fake = 9.701881253931788e-07, generator loss = 15.257129669189453\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 20, Batch: 310/468, discriminator loss real = 1.353723538977932e-32, disciminator loss fake = 1.3002642162973643e-06, generator loss = 15.193791389465332\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 20, Batch: 311/468, discriminator loss real = 3.7126244825184427e-29, disciminator loss fake = 7.315820198527945e-07, generator loss = 15.292803764343262\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 312/468, discriminator loss real = 3.3696862520563147e-23, disciminator loss fake = 1.592416765561211e-06, generator loss = 15.14450454711914\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 20, Batch: 313/468, discriminator loss real = 2.0082540455549836e-31, disciminator loss fake = 8.569404030822625e-07, generator loss = 15.348139762878418\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 20, Batch: 314/468, discriminator loss real = 2.624762560077265e-11, disciminator loss fake = 7.418057634822617e-07, generator loss = 15.543150901794434\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 315/468, discriminator loss real = 2.3432354147312484e-12, disciminator loss fake = 7.811975706317753e-07, generator loss = 15.25197982788086\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 316/468, discriminator loss real = 5.534813974055874e-16, disciminator loss fake = 1.0244575605611317e-06, generator loss = 15.442440032958984\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 20, Batch: 317/468, discriminator loss real = 2.894222745908337e-07, disciminator loss fake = 1.0038282880486804e-06, generator loss = 15.341167449951172\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 20, Batch: 318/468, discriminator loss real = 3.741395744327747e-07, disciminator loss fake = 8.248264293797547e-07, generator loss = 15.15588665008545\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 319/468, discriminator loss real = 2.4322474974136324e-23, disciminator loss fake = 1.0466429785083164e-06, generator loss = 15.308012962341309\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 20, Batch: 320/468, discriminator loss real = 2.7085134206572548e-06, disciminator loss fake = 1.4222612207959173e-06, generator loss = 15.617548942565918\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 20, Batch: 321/468, discriminator loss real = 2.680755848171549e-22, disciminator loss fake = 1.0771650522656273e-06, generator loss = 15.491122245788574\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 322/468, discriminator loss real = 2.3693691695955023e-24, disciminator loss fake = 5.09578740093275e-07, generator loss = 15.286640167236328\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 323/468, discriminator loss real = 7.342730691010291e-29, disciminator loss fake = 1.2067905572621385e-06, generator loss = 15.39590072631836\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 20, Batch: 324/468, discriminator loss real = 1.3854860003882705e-22, disciminator loss fake = 8.237448128056712e-07, generator loss = 15.488550186157227\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 325/468, discriminator loss real = 1.7417664277542074e-19, disciminator loss fake = 4.776932769345876e-07, generator loss = 15.40591812133789\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 20, Batch: 326/468, discriminator loss real = 5.501432339430133e-17, disciminator loss fake = 1.2453605222617625e-06, generator loss = 15.371866226196289\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 20, Batch: 327/468, discriminator loss real = 4.276409666057822e-22, disciminator loss fake = 5.440173254100955e-07, generator loss = 15.07800006866455\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 328/468, discriminator loss real = 9.5785413021382e-13, disciminator loss fake = 6.398583991540363e-07, generator loss = 15.726470947265625\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 20, Batch: 329/468, discriminator loss real = 2.5516308669105216e-23, disciminator loss fake = 6.828228151789517e-07, generator loss = 15.367918014526367\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 20, Batch: 330/468, discriminator loss real = 2.045241349868908e-14, disciminator loss fake = 6.367606601997977e-07, generator loss = 15.505090713500977\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 20, Batch: 331/468, discriminator loss real = 5.885806072001769e-23, disciminator loss fake = 5.364313437894452e-07, generator loss = 15.4569091796875\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 332/468, discriminator loss real = 9.235623757754825e-23, disciminator loss fake = 6.961344070077757e-07, generator loss = 15.34815788269043\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 333/468, discriminator loss real = 6.050967434259086e-24, disciminator loss fake = 1.8767524352369946e-06, generator loss = 15.287825584411621\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 334/468, discriminator loss real = 2.239324147749325e-23, disciminator loss fake = 8.489400329381169e-07, generator loss = 15.622724533081055\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 335/468, discriminator loss real = 1.9579332787387487e-21, disciminator loss fake = 3.43374040312483e-07, generator loss = 15.129749298095703\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 20, Batch: 336/468, discriminator loss real = 5.855795848219714e-09, disciminator loss fake = 5.361265493775136e-07, generator loss = 15.669021606445312\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 337/468, discriminator loss real = 1.0667733480791402e-24, disciminator loss fake = 5.472051043398096e-07, generator loss = 15.509546279907227\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 20, Batch: 338/468, discriminator loss real = 4.341107547585456e-18, disciminator loss fake = 9.864390904112952e-07, generator loss = 15.525104522705078\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 339/468, discriminator loss real = 6.479542311783056e-18, disciminator loss fake = 6.175667977004196e-07, generator loss = 15.733803749084473\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 20, Batch: 340/468, discriminator loss real = 1.8412874205214497e-15, disciminator loss fake = 4.7552941850881325e-07, generator loss = 15.12548542022705\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 20, Batch: 341/468, discriminator loss real = 7.549952706429421e-22, disciminator loss fake = 8.414622243435588e-07, generator loss = 15.524255752563477\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 342/468, discriminator loss real = 7.445443904795794e-19, disciminator loss fake = 8.882631163942278e-07, generator loss = 15.35715103149414\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 20, Batch: 343/468, discriminator loss real = 5.114624544201585e-13, disciminator loss fake = 6.44304577690491e-07, generator loss = 15.487190246582031\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 20, Batch: 344/468, discriminator loss real = 1.5683708373474928e-16, disciminator loss fake = 5.695140998795978e-07, generator loss = 15.58108901977539\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 345/468, discriminator loss real = 2.6970026672433435e-15, disciminator loss fake = 4.234682080550556e-07, generator loss = 15.156926155090332\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 20, Batch: 346/468, discriminator loss real = 2.220110371085933e-18, disciminator loss fake = 4.661917216708389e-07, generator loss = 15.214082717895508\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Epoch: 20, Batch: 347/468, discriminator loss real = 5.469871517532754e-13, disciminator loss fake = 9.892323760141153e-07, generator loss = 15.465836524963379\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 20, Batch: 348/468, discriminator loss real = 2.596086632511874e-16, disciminator loss fake = 7.057538482513337e-07, generator loss = 15.696806907653809\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 349/468, discriminator loss real = 6.015548059679077e-10, disciminator loss fake = 7.805961104168091e-07, generator loss = 15.341812133789062\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 20, Batch: 350/468, discriminator loss real = 6.754017845861545e-16, disciminator loss fake = 1.4640783092545462e-06, generator loss = 15.679454803466797\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 20, Batch: 351/468, discriminator loss real = 1.2406205144860926e-26, disciminator loss fake = 4.729300826511462e-07, generator loss = 15.492149353027344\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 20, Batch: 352/468, discriminator loss real = 6.841639958548938e-24, disciminator loss fake = 7.489614972655545e-07, generator loss = 15.628923416137695\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 20, Batch: 353/468, discriminator loss real = 2.136518636704568e-14, disciminator loss fake = 1.0590403007881832e-06, generator loss = 15.53687572479248\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 354/468, discriminator loss real = 3.39696925433282e-16, disciminator loss fake = 8.9447780737828e-07, generator loss = 15.44056224822998\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 20, Batch: 355/468, discriminator loss real = 5.4667598508629465e-28, disciminator loss fake = 8.551263590561575e-07, generator loss = 15.335073471069336\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 356/468, discriminator loss real = 1.1951710986374533e-17, disciminator loss fake = 8.80467041497468e-07, generator loss = 15.524124145507812\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 357/468, discriminator loss real = 8.916181115178792e-20, disciminator loss fake = 8.50341564273549e-07, generator loss = 15.333677291870117\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 20, Batch: 358/468, discriminator loss real = 3.054968240871354e-27, disciminator loss fake = 1.0580711204966065e-06, generator loss = 15.559209823608398\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 20, Batch: 359/468, discriminator loss real = 2.011952063285527e-11, disciminator loss fake = 2.7451812911749585e-07, generator loss = 15.63378620147705\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 20, Batch: 360/468, discriminator loss real = 1.795672592739809e-21, disciminator loss fake = 6.360835982377466e-07, generator loss = 15.427061080932617\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 361/468, discriminator loss real = 5.327866116616114e-28, disciminator loss fake = 5.950432750978507e-07, generator loss = 15.238393783569336\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 362/468, discriminator loss real = 1.8668511651191028e-25, disciminator loss fake = 9.649245384935057e-07, generator loss = 15.57937240600586\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 20, Batch: 363/468, discriminator loss real = 1.5709549592859218e-27, disciminator loss fake = 5.247665058050188e-07, generator loss = 15.318963050842285\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 364/468, discriminator loss real = 3.5165313959091126e-17, disciminator loss fake = 8.677401979184651e-07, generator loss = 15.433234214782715\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 365/468, discriminator loss real = 8.10299794955381e-20, disciminator loss fake = 5.795477022729756e-07, generator loss = 15.45380687713623\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 20, Batch: 366/468, discriminator loss real = 4.328078829574436e-14, disciminator loss fake = 6.757080655006575e-07, generator loss = 15.57359790802002\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 20, Batch: 367/468, discriminator loss real = 1.5188960614646838e-21, disciminator loss fake = 6.17787122791924e-07, generator loss = 15.55514907836914\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 20, Batch: 368/468, discriminator loss real = 2.4686109344712892e-26, disciminator loss fake = 6.679790658381535e-07, generator loss = 15.740657806396484\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 369/468, discriminator loss real = 5.940646550413947e-18, disciminator loss fake = 7.781135309414822e-07, generator loss = 15.3806791305542\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 20, Batch: 370/468, discriminator loss real = 1.4494265666015527e-17, disciminator loss fake = 9.677229400040233e-07, generator loss = 15.540790557861328\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 371/468, discriminator loss real = 4.683540055257402e-19, disciminator loss fake = 6.81660026202735e-07, generator loss = 15.503868103027344\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 20, Batch: 372/468, discriminator loss real = 6.835725290931655e-14, disciminator loss fake = 9.447958291275427e-07, generator loss = 15.937691688537598\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 20, Batch: 373/468, discriminator loss real = 3.3257525273454416e-26, disciminator loss fake = 6.504567977572151e-07, generator loss = 15.421091079711914\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 374/468, discriminator loss real = 3.2971978924933865e-08, disciminator loss fake = 4.7579004558429006e-07, generator loss = 15.598382949829102\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 20, Batch: 375/468, discriminator loss real = 5.067367562988948e-20, disciminator loss fake = 5.071765372122172e-07, generator loss = 15.581371307373047\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 20, Batch: 376/468, discriminator loss real = 2.6116645070841613e-22, disciminator loss fake = 7.979261908985791e-07, generator loss = 15.426801681518555\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 20, Batch: 377/468, discriminator loss real = 4.2720353486249074e-32, disciminator loss fake = 5.008947141504905e-07, generator loss = 15.362579345703125\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 378/468, discriminator loss real = 6.621108826140865e-13, disciminator loss fake = 4.829311137655168e-07, generator loss = 15.656839370727539\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 379/468, discriminator loss real = 1.797423911281054e-24, disciminator loss fake = 4.38013159964612e-07, generator loss = 15.48931884765625\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 20, Batch: 380/468, discriminator loss real = 4.6057899315732516e-15, disciminator loss fake = 8.332287961820839e-07, generator loss = 15.54749870300293\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 20, Batch: 381/468, discriminator loss real = 1.953578138608648e-24, disciminator loss fake = 1.1622277042988571e-06, generator loss = 15.525919914245605\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 20, Batch: 382/468, discriminator loss real = 4.725081437229051e-10, disciminator loss fake = 1.1753297712857602e-06, generator loss = 15.687789916992188\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 20, Batch: 383/468, discriminator loss real = 2.2170929963446704e-28, disciminator loss fake = 4.991206878912635e-07, generator loss = 15.668122291564941\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 20, Batch: 384/468, discriminator loss real = 1.0053990382201047e-13, disciminator loss fake = 5.10953327648167e-07, generator loss = 15.720008850097656\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 20, Batch: 385/468, discriminator loss real = 6.194966596936196e-25, disciminator loss fake = 5.13784243594273e-07, generator loss = 15.612399101257324\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 386/468, discriminator loss real = 6.284336620771157e-17, disciminator loss fake = 6.109183914304595e-07, generator loss = 15.755505561828613\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 387/468, discriminator loss real = 3.7764811724686704e-30, disciminator loss fake = 4.977208618583973e-07, generator loss = 15.90616226196289\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 388/468, discriminator loss real = 1.3529446660220934e-11, disciminator loss fake = 5.407715661931434e-07, generator loss = 15.66972541809082\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 389/468, discriminator loss real = 1.0995304161232973e-33, disciminator loss fake = 6.744544407411013e-07, generator loss = 15.602218627929688\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 390/468, discriminator loss real = 1.1674825873103725e-19, disciminator loss fake = 5.278557182464283e-07, generator loss = 15.660200119018555\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 20, Batch: 391/468, discriminator loss real = 4.721813222435475e-16, disciminator loss fake = 5.335662081051851e-07, generator loss = 15.581205368041992\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 20, Batch: 392/468, discriminator loss real = 3.345262977218211e-13, disciminator loss fake = 7.474624226233573e-07, generator loss = 15.660808563232422\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 393/468, discriminator loss real = 5.241108901967013e-19, disciminator loss fake = 1.1634163001872366e-06, generator loss = 15.596763610839844\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 20, Batch: 394/468, discriminator loss real = 6.363463243379264e-23, disciminator loss fake = 2.5239725687242753e-07, generator loss = 15.68089485168457\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 20, Batch: 395/468, discriminator loss real = 7.377561986178387e-22, disciminator loss fake = 5.312573421178968e-07, generator loss = 15.607810974121094\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 20, Batch: 396/468, discriminator loss real = 3.846799600559813e-16, disciminator loss fake = 3.4997594866581494e-07, generator loss = 15.787972450256348\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 397/468, discriminator loss real = 6.251003232730957e-23, disciminator loss fake = 7.901836625023861e-07, generator loss = 15.511970520019531\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 398/468, discriminator loss real = 1.0454066908984285e-20, disciminator loss fake = 5.367978701542597e-07, generator loss = 15.698123931884766\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 399/468, discriminator loss real = 2.160644887899449e-15, disciminator loss fake = 6.836294232925866e-07, generator loss = 15.82457160949707\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 400/468, discriminator loss real = 1.2462352970032953e-05, disciminator loss fake = 8.722493021195987e-07, generator loss = 15.870369911193848\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 20, Batch: 401/468, discriminator loss real = 3.6300569718983403e-17, disciminator loss fake = 8.255838110926561e-07, generator loss = 15.288835525512695\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 20, Batch: 402/468, discriminator loss real = 3.788552760397579e-07, disciminator loss fake = 4.1239275105908746e-07, generator loss = 15.52865219116211\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 20, Batch: 403/468, discriminator loss real = 3.948798666682103e-24, disciminator loss fake = 3.960203969199938e-07, generator loss = 15.482166290283203\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 404/468, discriminator loss real = 1.601651256066816e-08, disciminator loss fake = 6.830236998212058e-07, generator loss = 15.710226058959961\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 405/468, discriminator loss real = 4.159602909548306e-25, disciminator loss fake = 6.113330073276302e-07, generator loss = 15.7256441116333\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 20, Batch: 406/468, discriminator loss real = 5.313867398454447e-18, disciminator loss fake = 5.294115794640675e-07, generator loss = 15.450201034545898\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 407/468, discriminator loss real = 3.5326268819912965e-12, disciminator loss fake = 4.812741281057242e-07, generator loss = 15.817651748657227\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 20, Batch: 408/468, discriminator loss real = 2.3937962546969997e-14, disciminator loss fake = 5.215662781665742e-07, generator loss = 15.720314025878906\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 20, Batch: 409/468, discriminator loss real = 1.7831770279231727e-18, disciminator loss fake = 5.449111313282629e-07, generator loss = 15.638433456420898\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 20, Batch: 410/468, discriminator loss real = 1.3712464497217525e-09, disciminator loss fake = 5.435688308352837e-07, generator loss = 15.564807891845703\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 20, Batch: 411/468, discriminator loss real = 6.272141833685296e-11, disciminator loss fake = 4.3754855028055317e-07, generator loss = 15.702156066894531\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 412/468, discriminator loss real = 1.6248303117824154e-21, disciminator loss fake = 9.277131880480738e-07, generator loss = 15.44924545288086\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 20, Batch: 413/468, discriminator loss real = 5.360212663313252e-23, disciminator loss fake = 7.432558959408198e-07, generator loss = 15.31869888305664\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 20, Batch: 414/468, discriminator loss real = 6.2055757373129544e-30, disciminator loss fake = 5.306591788212245e-07, generator loss = 15.682191848754883\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 20, Batch: 415/468, discriminator loss real = 1.0243349002131072e-13, disciminator loss fake = 7.375394943665015e-07, generator loss = 15.63521957397461\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 20, Batch: 416/468, discriminator loss real = 2.0960068507824077e-17, disciminator loss fake = 5.930374982199282e-07, generator loss = 15.690258026123047\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 417/468, discriminator loss real = 1.7944138215953686e-17, disciminator loss fake = 4.486240072765213e-07, generator loss = 15.451494216918945\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 418/468, discriminator loss real = 4.270843352196629e-17, disciminator loss fake = 5.804926672681177e-07, generator loss = 15.495638847351074\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 419/468, discriminator loss real = 1.0206607612417429e-06, disciminator loss fake = 4.2688748180808034e-07, generator loss = 15.658685684204102\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 20, Batch: 420/468, discriminator loss real = 4.457155978120856e-15, disciminator loss fake = 5.153644906386035e-07, generator loss = 15.75259017944336\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 20, Batch: 421/468, discriminator loss real = 2.07594803214306e-05, disciminator loss fake = 5.564622824749677e-07, generator loss = 15.720436096191406\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 20, Batch: 422/468, discriminator loss real = 9.158967672251056e-20, disciminator loss fake = 4.750066295855504e-07, generator loss = 15.733870506286621\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 20, Batch: 423/468, discriminator loss real = 3.7652522023650867e-14, disciminator loss fake = 1.4640252175013302e-06, generator loss = 15.383279800415039\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 424/468, discriminator loss real = 2.355531211094286e-18, disciminator loss fake = 4.812974339074572e-07, generator loss = 15.730744361877441\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 425/468, discriminator loss real = 8.628816616163673e-17, disciminator loss fake = 8.321391078425222e-07, generator loss = 15.744881629943848\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 20, Batch: 426/468, discriminator loss real = 7.969654269857074e-09, disciminator loss fake = 4.585284898439568e-07, generator loss = 16.055068969726562\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 427/468, discriminator loss real = 2.546127205255848e-22, disciminator loss fake = 5.334419483915553e-07, generator loss = 15.405105590820312\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 20, Batch: 428/468, discriminator loss real = 1.0321944499745615e-26, disciminator loss fake = 3.916435673545493e-07, generator loss = 15.632024765014648\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 429/468, discriminator loss real = 1.6446796385189387e-16, disciminator loss fake = 5.392883508648083e-07, generator loss = 15.818573951721191\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 20, Batch: 430/468, discriminator loss real = 2.8507952631027546e-17, disciminator loss fake = 4.036294001252827e-07, generator loss = 15.650596618652344\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 20, Batch: 431/468, discriminator loss real = 5.815798642522367e-21, disciminator loss fake = 7.075631174302544e-07, generator loss = 15.547080993652344\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 20, Batch: 432/468, discriminator loss real = 5.267494081671561e-16, disciminator loss fake = 4.873331818089355e-07, generator loss = 15.510156631469727\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 20, Batch: 433/468, discriminator loss real = 9.124070856486588e-14, disciminator loss fake = 5.915395036026894e-07, generator loss = 15.713770866394043\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 20, Batch: 434/468, discriminator loss real = 9.500418135590142e-21, disciminator loss fake = 4.6211641802074155e-07, generator loss = 15.569948196411133\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 20, Batch: 435/468, discriminator loss real = 2.2939537302590907e-05, disciminator loss fake = 6.274956376728369e-07, generator loss = 15.746139526367188\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 20, Batch: 436/468, discriminator loss real = 4.496239878252182e-16, disciminator loss fake = 1.0979846365444246e-06, generator loss = 15.506446838378906\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 20, Batch: 437/468, discriminator loss real = 6.9468535091044e-11, disciminator loss fake = 1.1269976312178187e-06, generator loss = 15.69943618774414\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 20, Batch: 438/468, discriminator loss real = 1.0047927823109148e-08, disciminator loss fake = 1.3202608215578948e-06, generator loss = 15.310881614685059\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 20, Batch: 439/468, discriminator loss real = 1.5443324393511098e-16, disciminator loss fake = 9.528561690785864e-07, generator loss = 15.505472183227539\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 20, Batch: 440/468, discriminator loss real = 2.0042137916730205e-21, disciminator loss fake = 6.434798365262395e-07, generator loss = 15.550416946411133\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 20, Batch: 441/468, discriminator loss real = 4.735979312070654e-33, disciminator loss fake = 7.150435408220801e-07, generator loss = 15.636259078979492\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 20, Batch: 442/468, discriminator loss real = 7.687395287191526e-26, disciminator loss fake = 6.321498631223221e-07, generator loss = 15.434835433959961\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 20, Batch: 443/468, discriminator loss real = 7.000848655301548e-24, disciminator loss fake = 8.738287533560651e-07, generator loss = 15.506049156188965\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 20, Batch: 444/468, discriminator loss real = 1.870791715985476e-11, disciminator loss fake = 1.5483102515645442e-06, generator loss = 15.691993713378906\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 20, Batch: 445/468, discriminator loss real = 9.27389730978191e-20, disciminator loss fake = 5.033708703194861e-07, generator loss = 15.483390808105469\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 20, Batch: 446/468, discriminator loss real = 1.900865664060875e-24, disciminator loss fake = 6.248775434869458e-07, generator loss = 15.53480339050293\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 20, Batch: 447/468, discriminator loss real = 3.338952080812294e-26, disciminator loss fake = 4.3932510607191944e-07, generator loss = 15.76043701171875\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 20, Batch: 448/468, discriminator loss real = 2.2149224623050623e-20, disciminator loss fake = 1.1809786428784719e-06, generator loss = 15.589001655578613\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 20, Batch: 449/468, discriminator loss real = 1.5262471040929303e-20, disciminator loss fake = 5.982143989058386e-07, generator loss = 15.779691696166992\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 20, Batch: 450/468, discriminator loss real = 4.33264970569269e-24, disciminator loss fake = 7.574007554467244e-07, generator loss = 15.477651596069336\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 20, Batch: 451/468, discriminator loss real = 4.797841607869222e-35, disciminator loss fake = 1.0709775324357906e-06, generator loss = 15.494178771972656\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 20, Batch: 452/468, discriminator loss real = 3.8121851156225124e-26, disciminator loss fake = 3.715522325364873e-07, generator loss = 15.529693603515625\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 20, Batch: 453/468, discriminator loss real = 8.613568203315748e-18, disciminator loss fake = 6.658640927525994e-07, generator loss = 15.45335865020752\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 20, Batch: 454/468, discriminator loss real = 8.924631911950451e-25, disciminator loss fake = 3.8101060795270314e-07, generator loss = 15.620388984680176\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 20, Batch: 455/468, discriminator loss real = 1.3819175723062852e-22, disciminator loss fake = 4.434861580193683e-07, generator loss = 15.492149353027344\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 20, Batch: 456/468, discriminator loss real = 6.06512331916678e-21, disciminator loss fake = 7.588860171381384e-07, generator loss = 15.610271453857422\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 20, Batch: 457/468, discriminator loss real = 7.221787191858526e-18, disciminator loss fake = 6.394553224708943e-07, generator loss = 15.704479217529297\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 20, Batch: 458/468, discriminator loss real = 6.035565797146702e-11, disciminator loss fake = 5.374226930143777e-07, generator loss = 15.687347412109375\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 20, Batch: 459/468, discriminator loss real = 9.337210116200367e-08, disciminator loss fake = 5.927469146627118e-07, generator loss = 15.701866149902344\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 20, Batch: 460/468, discriminator loss real = 4.095778126137615e-23, disciminator loss fake = 4.590650064528745e-07, generator loss = 15.660551071166992\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 20, Batch: 461/468, discriminator loss real = 3.207225139120588e-16, disciminator loss fake = 3.906336019099399e-07, generator loss = 15.515665054321289\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 20, Batch: 462/468, discriminator loss real = 8.99486648359149e-12, disciminator loss fake = 3.711465410560777e-07, generator loss = 15.669164657592773\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 20, Batch: 463/468, discriminator loss real = 1.0421590701525929e-08, disciminator loss fake = 3.46934513117958e-07, generator loss = 15.802769660949707\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 20, Batch: 464/468, discriminator loss real = 3.927854565562741e-17, disciminator loss fake = 2.8479598768171854e-07, generator loss = 15.435648918151855\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 20, Batch: 465/468, discriminator loss real = 7.213891882158678e-20, disciminator loss fake = 3.9338345914075035e-07, generator loss = 15.714253425598145\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 20, Batch: 466/468, discriminator loss real = 5.273190576959063e-22, disciminator loss fake = 4.670108069149137e-07, generator loss = 15.734755516052246\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 20, Batch: 467/468, discriminator loss real = 9.958128947760891e-17, disciminator loss fake = 5.104300271341344e-07, generator loss = 15.807246208190918\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 20, Batch: 468/468, discriminator loss real = 3.511362717138779e-21, disciminator loss fake = 3.217006110389775e-07, generator loss = 15.315875053405762\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 21, Batch: 1/468, discriminator loss real = 2.393231620332759e-24, disciminator loss fake = 5.727642928832211e-07, generator loss = 15.632972717285156\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 2/468, discriminator loss real = 1.2169566991868696e-18, disciminator loss fake = 5.042791144660441e-07, generator loss = 15.871628761291504\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 21, Batch: 3/468, discriminator loss real = 1.1074949969236295e-20, disciminator loss fake = 4.1524313587615325e-07, generator loss = 15.467390060424805\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 21, Batch: 4/468, discriminator loss real = 1.3224107018907158e-22, disciminator loss fake = 7.30816907434928e-07, generator loss = 15.47978401184082\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 5/468, discriminator loss real = 1.5870764188789738e-24, disciminator loss fake = 9.80015329332673e-07, generator loss = 15.702598571777344\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 6/468, discriminator loss real = 7.335731550201299e-14, disciminator loss fake = 8.084510909611708e-07, generator loss = 15.503137588500977\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 21, Batch: 7/468, discriminator loss real = 1.9474157307664608e-22, disciminator loss fake = 4.3537755800571176e-07, generator loss = 15.736379623413086\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 21, Batch: 8/468, discriminator loss real = 7.674592476614954e-18, disciminator loss fake = 7.026640105323168e-07, generator loss = 15.747596740722656\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 21, Batch: 9/468, discriminator loss real = 4.770965601378744e-18, disciminator loss fake = 4.748376909446961e-07, generator loss = 15.731464385986328\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 21, Batch: 10/468, discriminator loss real = 4.2649643816616845e-09, disciminator loss fake = 4.654437191220495e-07, generator loss = 15.434381484985352\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 21, Batch: 11/468, discriminator loss real = 1.946010161191225e-05, disciminator loss fake = 4.7286945914493117e-07, generator loss = 15.916780471801758\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 12/468, discriminator loss real = 4.126143599968851e-13, disciminator loss fake = 3.4142803428949264e-07, generator loss = 15.651620864868164\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 21, Batch: 13/468, discriminator loss real = 2.2725959802074462e-29, disciminator loss fake = 1.002016915663262e-06, generator loss = 15.549554824829102\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 21, Batch: 14/468, discriminator loss real = 9.941619055764406e-11, disciminator loss fake = 8.344134130311431e-07, generator loss = 15.729965209960938\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 21, Batch: 15/468, discriminator loss real = 6.650834542158292e-17, disciminator loss fake = 6.2989607840791e-07, generator loss = 15.681893348693848\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 21, Batch: 16/468, discriminator loss real = 1.5821809736926012e-14, disciminator loss fake = 7.408300461975159e-07, generator loss = 15.613088607788086\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 17/468, discriminator loss real = 1.1991219872465844e-19, disciminator loss fake = 5.803921112601529e-07, generator loss = 15.860757827758789\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 21, Batch: 18/468, discriminator loss real = 9.763651905814186e-05, disciminator loss fake = 6.930787321834941e-07, generator loss = 15.668861389160156\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 19/468, discriminator loss real = 0.0003165092202834785, disciminator loss fake = 1.072592908712977e-06, generator loss = 15.063407897949219\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 21, Batch: 20/468, discriminator loss real = 2.6708067588706568e-18, disciminator loss fake = 3.1873280477157095e-06, generator loss = 14.992212295532227\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 21, Batch: 21/468, discriminator loss real = 6.612610760797027e-24, disciminator loss fake = 1.1409453009036952e-06, generator loss = 14.590107917785645\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 21, Batch: 22/468, discriminator loss real = 4.0392341868888225e-18, disciminator loss fake = 1.5326951370298048e-06, generator loss = 14.645442962646484\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 23/468, discriminator loss real = 2.9953519915632688e-24, disciminator loss fake = 4.708707365352893e-06, generator loss = 14.198333740234375\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 21, Batch: 24/468, discriminator loss real = 1.4965580703574233e-05, disciminator loss fake = 1.702987674434553e-06, generator loss = 14.227421760559082\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 21, Batch: 25/468, discriminator loss real = 4.9549443533280275e-27, disciminator loss fake = 3.316784841445042e-06, generator loss = 13.697776794433594\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 21, Batch: 26/468, discriminator loss real = 1.1917041239344801e-21, disciminator loss fake = 4.661949333240045e-06, generator loss = 13.671953201293945\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 27/468, discriminator loss real = 3.66957312619305e-21, disciminator loss fake = 2.472655523888534e-06, generator loss = 13.963722229003906\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 21, Batch: 28/468, discriminator loss real = 2.796483747694034e-12, disciminator loss fake = 3.1163071980699897e-06, generator loss = 13.717039108276367\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 21, Batch: 29/468, discriminator loss real = 1.5021291130220704e-32, disciminator loss fake = 3.178588940500049e-06, generator loss = 13.61266040802002\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 21, Batch: 30/468, discriminator loss real = 2.3181726872980148e-15, disciminator loss fake = 4.745477781398222e-06, generator loss = 13.548933029174805\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 21, Batch: 31/468, discriminator loss real = 2.070166258373977e-24, disciminator loss fake = 6.873582606203854e-06, generator loss = 13.973669052124023\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 21, Batch: 32/468, discriminator loss real = 6.329806183202891e-06, disciminator loss fake = 2.4074875000223983e-06, generator loss = 13.576358795166016\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 21, Batch: 33/468, discriminator loss real = 6.493098457854305e-19, disciminator loss fake = 2.1314158402674366e-06, generator loss = 13.760321617126465\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 21, Batch: 34/468, discriminator loss real = 2.2130961379854247e-19, disciminator loss fake = 7.824639396858402e-06, generator loss = 13.565773963928223\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 35/468, discriminator loss real = 2.5512034151908836e-10, disciminator loss fake = 3.4640456760826055e-06, generator loss = 13.808364868164062\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 21, Batch: 36/468, discriminator loss real = 4.986587251417697e-16, disciminator loss fake = 5.880569005967118e-06, generator loss = 13.560887336730957\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 37/468, discriminator loss real = 3.571007896395299e-15, disciminator loss fake = 5.567345851886785e-06, generator loss = 13.694823265075684\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 21, Batch: 38/468, discriminator loss real = 7.975485459610354e-06, disciminator loss fake = 4.7040161916811485e-06, generator loss = 13.884803771972656\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 39/468, discriminator loss real = 2.980218678718012e-14, disciminator loss fake = 3.8627913454547524e-06, generator loss = 13.72070598602295\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 21, Batch: 40/468, discriminator loss real = 2.6214652670830674e-10, disciminator loss fake = 4.371526301838458e-06, generator loss = 13.743321418762207\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 41/468, discriminator loss real = 1.329639192137437e-22, disciminator loss fake = 5.775556928711012e-06, generator loss = 13.68310546875\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 42/468, discriminator loss real = 2.9472030708515813e-15, disciminator loss fake = 4.918143531540409e-06, generator loss = 13.884056091308594\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 43/468, discriminator loss real = 9.04570776279797e-27, disciminator loss fake = 3.6741575968335383e-06, generator loss = 13.932550430297852\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 21, Batch: 44/468, discriminator loss real = 1.4535640282381162e-30, disciminator loss fake = 4.2571668927848805e-06, generator loss = 13.856463432312012\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 21, Batch: 45/468, discriminator loss real = 2.1948468276124915e-17, disciminator loss fake = 2.966054580610944e-06, generator loss = 13.827332496643066\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 46/468, discriminator loss real = 1.1816921410574138e-13, disciminator loss fake = 2.263073383801384e-06, generator loss = 14.106206893920898\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 47/468, discriminator loss real = 5.589654894751185e-19, disciminator loss fake = 4.286555395083269e-06, generator loss = 13.8432035446167\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 48/468, discriminator loss real = 1.0444606014938666e-27, disciminator loss fake = 2.9892821657995228e-06, generator loss = 13.835533142089844\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 49/468, discriminator loss real = 1.499700784435178e-17, disciminator loss fake = 2.7046489776694216e-06, generator loss = 14.040643692016602\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 21, Batch: 50/468, discriminator loss real = 2.705587420770428e-10, disciminator loss fake = 3.077230303460965e-06, generator loss = 14.02180290222168\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 51/468, discriminator loss real = 2.874226601519391e-18, disciminator loss fake = 7.946600817376748e-06, generator loss = 13.974903106689453\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 21, Batch: 52/468, discriminator loss real = 6.643379787367107e-25, disciminator loss fake = 5.41536519449437e-06, generator loss = 13.98822021484375\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 21, Batch: 53/468, discriminator loss real = 1.9025467914426594e-14, disciminator loss fake = 1.788467557162221e-06, generator loss = 14.202631950378418\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 54/468, discriminator loss real = 2.1550550565318654e-26, disciminator loss fake = 8.317484571307432e-06, generator loss = 14.055839538574219\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 21, Batch: 55/468, discriminator loss real = 1.4326248192309718e-21, disciminator loss fake = 2.325844889128348e-06, generator loss = 14.198480606079102\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 56/468, discriminator loss real = 2.473482982562765e-25, disciminator loss fake = 3.590027517930139e-06, generator loss = 14.048700332641602\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 57/468, discriminator loss real = 5.3894582379143685e-05, disciminator loss fake = 3.5430302887107246e-06, generator loss = 14.115402221679688\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 58/468, discriminator loss real = 3.003294280833031e-19, disciminator loss fake = 1.9964450075349305e-06, generator loss = 14.151931762695312\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 21, Batch: 59/468, discriminator loss real = 1.764455284127424e-23, disciminator loss fake = 2.032803877227707e-06, generator loss = 14.018966674804688\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 60/468, discriminator loss real = 9.858296188759621e-17, disciminator loss fake = 3.565354745660443e-06, generator loss = 13.927282333374023\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 21, Batch: 61/468, discriminator loss real = 6.389337568050506e-20, disciminator loss fake = 4.3671407183865085e-06, generator loss = 13.975408554077148\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 62/468, discriminator loss real = 3.981371264671907e-06, disciminator loss fake = 4.46279864263488e-06, generator loss = 13.936788558959961\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 63/468, discriminator loss real = 4.594502111978963e-22, disciminator loss fake = 2.7628097996057477e-06, generator loss = 14.002050399780273\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 21, Batch: 64/468, discriminator loss real = 3.2567565553815857e-15, disciminator loss fake = 1.7805029983719578e-06, generator loss = 13.944876670837402\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 21, Batch: 65/468, discriminator loss real = 1.5938514123341528e-19, disciminator loss fake = 3.6040082704857923e-06, generator loss = 14.07415771484375\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 21, Batch: 66/468, discriminator loss real = 1.0504807320641267e-15, disciminator loss fake = 4.1992020669567864e-06, generator loss = 13.99049186706543\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 21, Batch: 67/468, discriminator loss real = 6.550692964346013e-28, disciminator loss fake = 1.7560412288730731e-06, generator loss = 14.21127986907959\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 21, Batch: 68/468, discriminator loss real = 6.563052625464871e-22, disciminator loss fake = 2.817877884808695e-06, generator loss = 14.294321060180664\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 69/468, discriminator loss real = 2.180103493565344e-11, disciminator loss fake = 2.4895148271752987e-06, generator loss = 13.922040939331055\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 21, Batch: 70/468, discriminator loss real = 6.565440665197156e-22, disciminator loss fake = 1.844674329731788e-06, generator loss = 14.035425186157227\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 21, Batch: 71/468, discriminator loss real = 2.73747681313891e-16, disciminator loss fake = 3.363489668117836e-06, generator loss = 13.980422973632812\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 72/468, discriminator loss real = 2.4581688356704707e-23, disciminator loss fake = 4.731670287583256e-06, generator loss = 13.935640335083008\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 21, Batch: 73/468, discriminator loss real = 1.903538560203858e-20, disciminator loss fake = 2.950795760625624e-06, generator loss = 14.277517318725586\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 21, Batch: 74/468, discriminator loss real = 5.917800344673379e-15, disciminator loss fake = 1.5126440757740056e-06, generator loss = 14.154500007629395\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 21, Batch: 75/468, discriminator loss real = 2.0660740424281432e-25, disciminator loss fake = 9.287327316087612e-07, generator loss = 14.225932121276855\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 21, Batch: 76/468, discriminator loss real = 2.3342837919748926e-26, disciminator loss fake = 2.236858108517481e-06, generator loss = 13.886283874511719\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 21, Batch: 77/468, discriminator loss real = 2.0955140789755017e-22, disciminator loss fake = 2.568634954513982e-06, generator loss = 13.887762069702148\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 21, Batch: 78/468, discriminator loss real = 1.7922539537543192e-14, disciminator loss fake = 1.559526936034672e-06, generator loss = 14.357501983642578\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 79/468, discriminator loss real = 1.8369059573133197e-16, disciminator loss fake = 1.604536237209686e-06, generator loss = 14.289254188537598\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 21, Batch: 80/468, discriminator loss real = 2.0539488085527893e-22, disciminator loss fake = 1.6701450249456684e-06, generator loss = 14.296092987060547\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 21, Batch: 81/468, discriminator loss real = 1.94095168081569e-20, disciminator loss fake = 1.910800619953079e-06, generator loss = 14.159868240356445\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 82/468, discriminator loss real = 8.405076286858314e-24, disciminator loss fake = 1.6315375432895962e-06, generator loss = 14.238120079040527\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 21, Batch: 83/468, discriminator loss real = 1.0002086535293897e-23, disciminator loss fake = 1.7928349507201347e-06, generator loss = 14.256468772888184\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 21, Batch: 84/468, discriminator loss real = 8.603751058369847e-17, disciminator loss fake = 2.359027803322533e-06, generator loss = 14.435476303100586\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 85/468, discriminator loss real = 2.1916460522322176e-19, disciminator loss fake = 1.3468531960825203e-06, generator loss = 14.273387908935547\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 21, Batch: 86/468, discriminator loss real = 5.387197512288073e-21, disciminator loss fake = 1.8892376374424202e-06, generator loss = 14.263227462768555\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 21, Batch: 87/468, discriminator loss real = 2.7773168653766334e-07, disciminator loss fake = 5.566363142861519e-06, generator loss = 14.451910972595215\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 88/468, discriminator loss real = 2.3985374943636545e-20, disciminator loss fake = 6.363532975228736e-06, generator loss = 14.42378044128418\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 89/468, discriminator loss real = 3.2918596462574256e-28, disciminator loss fake = 2.375121766817756e-06, generator loss = 14.321361541748047\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 21, Batch: 90/468, discriminator loss real = 2.3188369093745337e-24, disciminator loss fake = 1.1666643331409432e-06, generator loss = 14.11796760559082\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 21, Batch: 91/468, discriminator loss real = 4.1942996745654816e-24, disciminator loss fake = 2.6712518774729688e-06, generator loss = 14.433528900146484\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 21, Batch: 92/468, discriminator loss real = 4.462568318889693e-21, disciminator loss fake = 2.6978862024407135e-06, generator loss = 14.473771095275879\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 21, Batch: 93/468, discriminator loss real = 9.336938110445446e-23, disciminator loss fake = 1.8167928601542371e-06, generator loss = 14.562753677368164\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 21, Batch: 94/468, discriminator loss real = 2.775180036331322e-17, disciminator loss fake = 5.549920842895517e-06, generator loss = 14.48879337310791\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 95/468, discriminator loss real = 8.047040139270989e-13, disciminator loss fake = 1.717652594379615e-06, generator loss = 14.421649932861328\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 21, Batch: 96/468, discriminator loss real = 1.1431678574469908e-28, disciminator loss fake = 1.6411520391557133e-06, generator loss = 14.273799896240234\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 97/468, discriminator loss real = 3.031919993812196e-23, disciminator loss fake = 1.129916995523672e-06, generator loss = 14.512165069580078\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 98/468, discriminator loss real = 0.0038923814427107573, disciminator loss fake = 9.192975085170474e-06, generator loss = 11.274147987365723\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 99/468, discriminator loss real = 9.874793699262464e-22, disciminator loss fake = 0.00037244055420160294, generator loss = 7.9574875831604\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 21, Batch: 100/468, discriminator loss real = 4.872825432645524e-16, disciminator loss fake = 0.007848995737731457, generator loss = 10.897313117980957\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 21, Batch: 101/468, discriminator loss real = 7.836787832713064e-23, disciminator loss fake = 2.413125002931338e-06, generator loss = 16.600610733032227\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 21, Batch: 102/468, discriminator loss real = 2.6739702574558877e-13, disciminator loss fake = 7.823508951787517e-08, generator loss = 20.686283111572266\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 21, Batch: 103/468, discriminator loss real = 1.388297810045458e-11, disciminator loss fake = 4.5048098584743457e-10, generator loss = 23.889503479003906\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 104/468, discriminator loss real = 2.414902181601814e-23, disciminator loss fake = 5.8126940760683254e-11, generator loss = 26.64094352722168\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 105/468, discriminator loss real = 2.42467740330099e-10, disciminator loss fake = 3.831447312196978e-12, generator loss = 28.0125675201416\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 21, Batch: 106/468, discriminator loss real = 0.03528567776083946, disciminator loss fake = 4.647683973790784e-11, generator loss = 23.06975555419922\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 21, Batch: 107/468, discriminator loss real = 2.1544349204018005e-22, disciminator loss fake = 6.492539394997721e-09, generator loss = 18.851360321044922\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 21, Batch: 108/468, discriminator loss real = 7.197980287594396e-21, disciminator loss fake = 1.3194912185099383e-07, generator loss = 15.215951919555664\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 109/468, discriminator loss real = 2.0918245845086145e-29, disciminator loss fake = 2.961992322525475e-06, generator loss = 12.44644546508789\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 21, Batch: 110/468, discriminator loss real = 2.1385463830662632e-33, disciminator loss fake = 4.167612496530637e-05, generator loss = 9.944845199584961\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 21, Batch: 111/468, discriminator loss real = 1.717785338963237e-21, disciminator loss fake = 0.0010316898114979267, generator loss = 8.326794624328613\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 21, Batch: 112/468, discriminator loss real = 6.330932802111763e-28, disciminator loss fake = 0.0010428957175463438, generator loss = 8.086236953735352\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 113/468, discriminator loss real = 1.6112204190036846e-25, disciminator loss fake = 0.0006288685835897923, generator loss = 8.424266815185547\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 114/468, discriminator loss real = 8.271142851281167e-23, disciminator loss fake = 0.001100183930248022, generator loss = 9.59929084777832\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 21, Batch: 115/468, discriminator loss real = 2.7100032962162186e-30, disciminator loss fake = 0.00011492072371765971, generator loss = 10.811332702636719\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 21, Batch: 116/468, discriminator loss real = 3.428149893735266e-31, disciminator loss fake = 3.7979996704962105e-05, generator loss = 11.713386535644531\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 21, Batch: 117/468, discriminator loss real = 2.8890176946148085e-29, disciminator loss fake = 6.860002031316981e-06, generator loss = 12.704631805419922\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 118/468, discriminator loss real = 1.1413809488658444e-06, disciminator loss fake = 1.0021469279308803e-05, generator loss = 13.231542587280273\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 119/468, discriminator loss real = 4.325472345083101e-17, disciminator loss fake = 4.240613634465262e-06, generator loss = 14.018038749694824\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 21, Batch: 120/468, discriminator loss real = 1.0477476824264495e-27, disciminator loss fake = 2.697622676350875e-06, generator loss = 14.115967750549316\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 121/468, discriminator loss real = 1.9997799074473608e-23, disciminator loss fake = 1.70724661074928e-06, generator loss = 14.600499153137207\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 21, Batch: 122/468, discriminator loss real = 1.8109339805505442e-07, disciminator loss fake = 1.1732174698408926e-06, generator loss = 14.942005157470703\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 21, Batch: 123/468, discriminator loss real = 3.523632051289057e-20, disciminator loss fake = 6.564010845977464e-07, generator loss = 15.122623443603516\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 21, Batch: 124/468, discriminator loss real = 5.5056131908256395e-14, disciminator loss fake = 5.919926024944289e-07, generator loss = 15.296690940856934\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 125/468, discriminator loss real = 2.6827254641851613e-27, disciminator loss fake = 8.183814088624786e-07, generator loss = 15.690374374389648\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 21, Batch: 126/468, discriminator loss real = 3.2921843309573054e-20, disciminator loss fake = 6.395438276740606e-07, generator loss = 15.519882202148438\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 21, Batch: 127/468, discriminator loss real = 6.19064088017054e-16, disciminator loss fake = 5.50226559425937e-07, generator loss = 15.643937110900879\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 21, Batch: 128/468, discriminator loss real = 4.649222426857141e-23, disciminator loss fake = 1.2042646631016396e-06, generator loss = 15.799959182739258\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 129/468, discriminator loss real = 5.618186082756372e-21, disciminator loss fake = 4.0514362353860633e-07, generator loss = 15.900566101074219\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 21, Batch: 130/468, discriminator loss real = 7.123038658547824e-29, disciminator loss fake = 9.457626788389462e-07, generator loss = 15.699748992919922\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 21, Batch: 131/468, discriminator loss real = 1.9672769764405188e-22, disciminator loss fake = 3.369785304130346e-07, generator loss = 16.041948318481445\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 132/468, discriminator loss real = 2.2237730358484504e-16, disciminator loss fake = 4.907513471152924e-07, generator loss = 15.78373908996582\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 21, Batch: 133/468, discriminator loss real = 5.582137982016954e-35, disciminator loss fake = 3.871182912007498e-07, generator loss = 15.818957328796387\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 21, Batch: 134/468, discriminator loss real = 6.304822983138614e-12, disciminator loss fake = 2.7601129204413155e-07, generator loss = 16.280452728271484\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 21, Batch: 135/468, discriminator loss real = 8.793145442194481e-35, disciminator loss fake = 4.873589318776794e-07, generator loss = 16.124481201171875\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 136/468, discriminator loss real = 1.9143073780471644e-15, disciminator loss fake = 4.6930736630201864e-07, generator loss = 15.985807418823242\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 137/468, discriminator loss real = 2.797783552787703e-24, disciminator loss fake = 2.723534748838574e-07, generator loss = 16.058012008666992\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 138/468, discriminator loss real = 4.597644289301352e-27, disciminator loss fake = 3.136508155421325e-07, generator loss = 16.246795654296875\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 139/468, discriminator loss real = 1.666275349882406e-31, disciminator loss fake = 4.0539200085731864e-07, generator loss = 16.00895118713379\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 21, Batch: 140/468, discriminator loss real = 1.3910328285116778e-23, disciminator loss fake = 2.9993489647495153e-07, generator loss = 15.910649299621582\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 21, Batch: 141/468, discriminator loss real = 5.294036570449101e-19, disciminator loss fake = 2.5090878352784785e-07, generator loss = 15.892538070678711\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 21, Batch: 142/468, discriminator loss real = 4.3157586235631624e-20, disciminator loss fake = 1.7479442249168642e-07, generator loss = 16.330188751220703\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 21, Batch: 143/468, discriminator loss real = 2.7073917681907724e-23, disciminator loss fake = 3.36526284172578e-07, generator loss = 16.173030853271484\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 21, Batch: 144/468, discriminator loss real = 1.55115297515418e-22, disciminator loss fake = 2.110490981976909e-07, generator loss = 16.3662052154541\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 21, Batch: 145/468, discriminator loss real = 1.7184794840532497e-19, disciminator loss fake = 5.108587401991826e-07, generator loss = 16.063655853271484\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 21, Batch: 146/468, discriminator loss real = 2.286598727976093e-24, disciminator loss fake = 2.7903078603230824e-07, generator loss = 16.474952697753906\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 21, Batch: 147/468, discriminator loss real = 1.1862436413703148e-21, disciminator loss fake = 1.8548389846273494e-07, generator loss = 16.16286277770996\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 148/468, discriminator loss real = 6.846951903744488e-33, disciminator loss fake = 3.7288634757715045e-07, generator loss = 16.15239143371582\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 21, Batch: 149/468, discriminator loss real = 4.543330787650066e-24, disciminator loss fake = 2.757363972705207e-07, generator loss = 16.319168090820312\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 150/468, discriminator loss real = 9.588657314414229e-23, disciminator loss fake = 2.591158079212619e-07, generator loss = 16.016956329345703\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 21, Batch: 151/468, discriminator loss real = 4.859483314806019e-35, disciminator loss fake = 3.905216203747841e-07, generator loss = 16.045812606811523\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 21, Batch: 152/468, discriminator loss real = 4.9967435812830414e-24, disciminator loss fake = 1.346950710967576e-07, generator loss = 16.128721237182617\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 153/468, discriminator loss real = 1.7959351453905592e-12, disciminator loss fake = 4.2089234852937807e-07, generator loss = 15.970314979553223\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 21, Batch: 154/468, discriminator loss real = 1.4549041793676807e-26, disciminator loss fake = 4.253544716448232e-07, generator loss = 15.926504135131836\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 155/468, discriminator loss real = 1.8245792352333497e-29, disciminator loss fake = 2.3611978861026728e-07, generator loss = 16.082433700561523\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 156/468, discriminator loss real = 3.261059249237632e-31, disciminator loss fake = 2.4790153929643566e-07, generator loss = 16.08008575439453\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 21, Batch: 157/468, discriminator loss real = 2.6057027785142862e-20, disciminator loss fake = 3.2343518796551507e-07, generator loss = 16.309144973754883\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 21, Batch: 158/468, discriminator loss real = 9.152975319945533e-28, disciminator loss fake = 2.6385288265373674e-07, generator loss = 16.02224349975586\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 159/468, discriminator loss real = 3.4143850799429566e-20, disciminator loss fake = 3.2731983878875326e-07, generator loss = 16.195571899414062\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 21, Batch: 160/468, discriminator loss real = 1.3217789085473441e-09, disciminator loss fake = 2.397637786089035e-07, generator loss = 15.985574722290039\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 21, Batch: 161/468, discriminator loss real = 2.161397899000486e-20, disciminator loss fake = 2.922912756275764e-07, generator loss = 16.381397247314453\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 21, Batch: 162/468, discriminator loss real = 6.860882837676708e-37, disciminator loss fake = 3.8158862025738927e-07, generator loss = 16.38730239868164\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 21, Batch: 163/468, discriminator loss real = 5.410293623670915e-31, disciminator loss fake = 2.3141323879372067e-07, generator loss = 16.05548095703125\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 21, Batch: 164/468, discriminator loss real = 1.4643136359386416e-19, disciminator loss fake = 2.8998096013310715e-07, generator loss = 16.251598358154297\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 21, Batch: 165/468, discriminator loss real = 4.306557854467032e-32, disciminator loss fake = 2.9824462899341597e-07, generator loss = 16.17535972595215\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 166/468, discriminator loss real = 1.2225821844922969e-22, disciminator loss fake = 2.4481181526425644e-07, generator loss = 16.184425354003906\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 21, Batch: 167/468, discriminator loss real = 0.0, disciminator loss fake = 2.7338862196302216e-07, generator loss = 16.32708740234375\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 21, Batch: 168/468, discriminator loss real = 2.603963511885038e-29, disciminator loss fake = 2.893250439228723e-07, generator loss = 15.89638900756836\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 169/468, discriminator loss real = 1.4572708884334935e-14, disciminator loss fake = 3.006779252245906e-07, generator loss = 15.985950469970703\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 170/468, discriminator loss real = 6.711747892980423e-28, disciminator loss fake = 2.691128884180216e-07, generator loss = 16.040058135986328\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 171/468, discriminator loss real = 6.622873273194101e-22, disciminator loss fake = 2.491949544491945e-07, generator loss = 16.07422637939453\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 21, Batch: 172/468, discriminator loss real = 7.058048170678218e-24, disciminator loss fake = 4.890111426902877e-07, generator loss = 16.138765335083008\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 21, Batch: 173/468, discriminator loss real = 4.1799909003104516e-36, disciminator loss fake = 2.6897842531070637e-07, generator loss = 16.401987075805664\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 21, Batch: 174/468, discriminator loss real = 2.6124515545953765e-26, disciminator loss fake = 1.7765009374670626e-07, generator loss = 16.00625228881836\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 175/468, discriminator loss real = 3.690277578949353e-37, disciminator loss fake = 2.2634993968040362e-07, generator loss = 16.016555786132812\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 176/468, discriminator loss real = 1.1011302954841734e-22, disciminator loss fake = 2.645258234679204e-07, generator loss = 16.129518508911133\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 21, Batch: 177/468, discriminator loss real = 5.753940561177874e-28, disciminator loss fake = 2.968499472899566e-07, generator loss = 16.319435119628906\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 178/468, discriminator loss real = 3.5009476440408586e-17, disciminator loss fake = 2.0268666389711143e-07, generator loss = 16.091068267822266\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 21, Batch: 179/468, discriminator loss real = 3.402536363902988e-21, disciminator loss fake = 2.958613833925483e-07, generator loss = 16.49396514892578\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 180/468, discriminator loss real = 6.681243997613912e-36, disciminator loss fake = 2.427586593967135e-07, generator loss = 16.29840850830078\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 181/468, discriminator loss real = 3.3126525485286265e-33, disciminator loss fake = 4.234363473187841e-07, generator loss = 15.990862846374512\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 21, Batch: 182/468, discriminator loss real = 2.152431685865957e-16, disciminator loss fake = 3.727442390299984e-07, generator loss = 16.12126922607422\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 21, Batch: 183/468, discriminator loss real = 4.143636544995388e-09, disciminator loss fake = 2.651374302331533e-07, generator loss = 16.1685791015625\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 21, Batch: 184/468, discriminator loss real = 3.144771503801813e-26, disciminator loss fake = 2.544386461522663e-07, generator loss = 16.26018524169922\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 21, Batch: 185/468, discriminator loss real = 3.2529287779909605e-30, disciminator loss fake = 2.1504334313249274e-07, generator loss = 16.078632354736328\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 21, Batch: 186/468, discriminator loss real = 4.805334371240215e-25, disciminator loss fake = 2.408200145964656e-07, generator loss = 15.97641372680664\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 187/468, discriminator loss real = 1.693056824659409e-24, disciminator loss fake = 3.8801974255875393e-07, generator loss = 16.25716781616211\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 21, Batch: 188/468, discriminator loss real = 1.768753260881838e-27, disciminator loss fake = 1.7347169034565013e-07, generator loss = 16.38420867919922\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 21, Batch: 189/468, discriminator loss real = 2.7755417612321904e-31, disciminator loss fake = 2.795382556541881e-07, generator loss = 16.14796257019043\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 21, Batch: 190/468, discriminator loss real = 4.65333307364819e-18, disciminator loss fake = 2.701610526401055e-07, generator loss = 16.142887115478516\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 191/468, discriminator loss real = 6.269488790814376e-19, disciminator loss fake = 2.587040626167436e-07, generator loss = 16.142301559448242\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 21, Batch: 192/468, discriminator loss real = 8.012605236854629e-29, disciminator loss fake = 1.545554937365523e-07, generator loss = 15.943224906921387\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 193/468, discriminator loss real = 3.881998921081082e-34, disciminator loss fake = 2.2281687961367425e-07, generator loss = 16.17904281616211\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 194/468, discriminator loss real = 5.878565433297108e-24, disciminator loss fake = 2.9260169753797527e-07, generator loss = 16.335500717163086\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 21, Batch: 195/468, discriminator loss real = 4.219687979508662e-25, disciminator loss fake = 2.2477186689684459e-07, generator loss = 16.11428451538086\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 196/468, discriminator loss real = 1.859592022724534e-33, disciminator loss fake = 2.4176577539947175e-07, generator loss = 16.11838722229004\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 197/468, discriminator loss real = 8.242962519153241e-13, disciminator loss fake = 3.549214682152524e-07, generator loss = 16.180156707763672\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 198/468, discriminator loss real = 1.5774377463546757e-32, disciminator loss fake = 4.0642225940246135e-07, generator loss = 16.134384155273438\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 199/468, discriminator loss real = 5.37829236046314e-18, disciminator loss fake = 4.1749581214389764e-07, generator loss = 16.026948928833008\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 200/468, discriminator loss real = 1.4963592591037994e-19, disciminator loss fake = 2.986513152336556e-07, generator loss = 16.144058227539062\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 21, Batch: 201/468, discriminator loss real = 2.213390471707929e-22, disciminator loss fake = 1.951024160007364e-07, generator loss = 16.08956527709961\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 202/468, discriminator loss real = 2.11441017796602e-33, disciminator loss fake = 3.511406703182729e-07, generator loss = 16.137222290039062\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 203/468, discriminator loss real = 3.017019760058652e-33, disciminator loss fake = 2.460545260873914e-07, generator loss = 16.298925399780273\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 204/468, discriminator loss real = 1.6993720198212767e-27, disciminator loss fake = 3.9802773699193494e-07, generator loss = 16.14204216003418\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 21, Batch: 205/468, discriminator loss real = 1.5286893819416582e-15, disciminator loss fake = 2.136265351282418e-07, generator loss = 16.052318572998047\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 21, Batch: 206/468, discriminator loss real = 4.367874238376981e-23, disciminator loss fake = 3.134881012556434e-07, generator loss = 16.28885269165039\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 207/468, discriminator loss real = 4.8966563869791684e-15, disciminator loss fake = 2.1405388395123737e-07, generator loss = 16.12158966064453\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 208/468, discriminator loss real = 5.139676760995232e-28, disciminator loss fake = 3.6884154042127193e-07, generator loss = 16.045654296875\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 21, Batch: 209/468, discriminator loss real = 4.086340484568364e-21, disciminator loss fake = 3.513846706937329e-07, generator loss = 16.127735137939453\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 210/468, discriminator loss real = 2.693906973579366e-15, disciminator loss fake = 2.574423660917091e-07, generator loss = 16.339738845825195\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 211/468, discriminator loss real = 5.43103596057942e-17, disciminator loss fake = 3.222857856144401e-07, generator loss = 16.030380249023438\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 21, Batch: 212/468, discriminator loss real = 9.546285543366824e-30, disciminator loss fake = 3.034152484815422e-07, generator loss = 16.0489444732666\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 213/468, discriminator loss real = 2.722197205802383e-26, disciminator loss fake = 3.6261354807720636e-07, generator loss = 16.08220672607422\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 214/468, discriminator loss real = 1.8657806485150948e-27, disciminator loss fake = 2.590433894056332e-07, generator loss = 16.205883026123047\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 215/468, discriminator loss real = 1.3016664368737896e-22, disciminator loss fake = 2.523458988434868e-07, generator loss = 16.314788818359375\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 216/468, discriminator loss real = 1.912651967053048e-26, disciminator loss fake = 2.180229046189197e-07, generator loss = 16.272689819335938\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 217/468, discriminator loss real = 1.151418721884678e-30, disciminator loss fake = 2.0111508547415724e-07, generator loss = 16.242443084716797\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 21, Batch: 218/468, discriminator loss real = 5.716028870963855e-29, disciminator loss fake = 2.1744975242654618e-07, generator loss = 16.385116577148438\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 219/468, discriminator loss real = 1.316806066040174e-25, disciminator loss fake = 3.3976493796217255e-07, generator loss = 16.405168533325195\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 220/468, discriminator loss real = 1.122617175224613e-21, disciminator loss fake = 2.527820015529869e-07, generator loss = 16.010087966918945\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 221/468, discriminator loss real = 8.17272685983799e-27, disciminator loss fake = 2.8006030561300577e-07, generator loss = 15.970004081726074\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 222/468, discriminator loss real = 1.3698683661393007e-32, disciminator loss fake = 1.9786654092968092e-07, generator loss = 15.938711166381836\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 223/468, discriminator loss real = 1.2951544226417024e-25, disciminator loss fake = 2.793647695398249e-07, generator loss = 16.13963508605957\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 21, Batch: 224/468, discriminator loss real = 2.643458748808279e-36, disciminator loss fake = 2.5484035859335563e-07, generator loss = 16.178539276123047\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 225/468, discriminator loss real = 1.128299131236037e-15, disciminator loss fake = 3.43337063668514e-07, generator loss = 16.21984100341797\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 21, Batch: 226/468, discriminator loss real = 1.8878699127524053e-14, disciminator loss fake = 2.8977373744965007e-07, generator loss = 16.239055633544922\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 21, Batch: 227/468, discriminator loss real = 9.988746108525705e-23, disciminator loss fake = 2.6249938400724204e-07, generator loss = 16.390472412109375\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 228/468, discriminator loss real = 1.6592404274973818e-19, disciminator loss fake = 2.688191500510584e-07, generator loss = 16.270000457763672\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 229/468, discriminator loss real = 1.772493461207264e-22, disciminator loss fake = 3.190043571521528e-07, generator loss = 16.122703552246094\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 21, Batch: 230/468, discriminator loss real = 2.845246852208827e-22, disciminator loss fake = 2.3574033036766195e-07, generator loss = 16.077892303466797\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 231/468, discriminator loss real = 8.455919643313572e-28, disciminator loss fake = 2.322701107004832e-07, generator loss = 16.360858917236328\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 21, Batch: 232/468, discriminator loss real = 6.513248688301699e-31, disciminator loss fake = 3.605804863582307e-07, generator loss = 16.288814544677734\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 21, Batch: 233/468, discriminator loss real = 2.81049133204257e-21, disciminator loss fake = 3.3337698823743267e-07, generator loss = 16.17414665222168\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 234/468, discriminator loss real = 2.6550090211694957e-28, disciminator loss fake = 2.483332934843929e-07, generator loss = 16.23204231262207\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 235/468, discriminator loss real = 3.920649987863527e-20, disciminator loss fake = 2.430665801966825e-07, generator loss = 16.282386779785156\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 21, Batch: 236/468, discriminator loss real = 8.69329532378416e-28, disciminator loss fake = 3.4110945534848724e-07, generator loss = 15.971341133117676\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 21, Batch: 237/468, discriminator loss real = 4.8722108433412316e-24, disciminator loss fake = 2.955843001473113e-07, generator loss = 16.15552520751953\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 21, Batch: 238/468, discriminator loss real = 5.940489253619417e-21, disciminator loss fake = 2.880815941352921e-07, generator loss = 16.407001495361328\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 239/468, discriminator loss real = 7.67312446367222e-20, disciminator loss fake = 3.113280513389327e-07, generator loss = 16.2739200592041\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 21, Batch: 240/468, discriminator loss real = 2.6459783156305925e-22, disciminator loss fake = 2.485031984633679e-07, generator loss = 16.40561294555664\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 21, Batch: 241/468, discriminator loss real = 1.3399112294304068e-19, disciminator loss fake = 2.6914648287856835e-07, generator loss = 16.496829986572266\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 242/468, discriminator loss real = 4.176741467382057e-26, disciminator loss fake = 2.747094356436719e-07, generator loss = 16.142131805419922\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 21, Batch: 243/468, discriminator loss real = 1.414357981353223e-21, disciminator loss fake = 3.4395310422041803e-07, generator loss = 16.215370178222656\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 21, Batch: 244/468, discriminator loss real = 3.7915215821375885e-26, disciminator loss fake = 1.681620744875545e-07, generator loss = 16.250520706176758\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 21, Batch: 245/468, discriminator loss real = 6.129537783204061e-33, disciminator loss fake = 2.990376515299431e-07, generator loss = 16.140588760375977\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 21, Batch: 246/468, discriminator loss real = 5.701911891138344e-26, disciminator loss fake = 2.0045605708673975e-07, generator loss = 16.025527954101562\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 21, Batch: 247/468, discriminator loss real = 1.9805266139184927e-16, disciminator loss fake = 2.790652615658473e-07, generator loss = 16.169921875\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 248/468, discriminator loss real = 7.2893947312740165e-19, disciminator loss fake = 2.41437135173328e-07, generator loss = 16.348339080810547\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Epoch: 21, Batch: 249/468, discriminator loss real = 4.442072799071123e-25, disciminator loss fake = 2.0970620084881375e-07, generator loss = 16.09103775024414\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 21, Batch: 250/468, discriminator loss real = 1.0781943209224406e-19, disciminator loss fake = 3.573110234356136e-07, generator loss = 16.286991119384766\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 21, Batch: 251/468, discriminator loss real = 2.9367843683542576e-30, disciminator loss fake = 3.146494691463886e-07, generator loss = 16.54526138305664\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 252/468, discriminator loss real = 3.535141687901364e-19, disciminator loss fake = 3.7002726571699895e-07, generator loss = 16.26274871826172\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 253/468, discriminator loss real = 1.0553298467946473e-18, disciminator loss fake = 3.09398529907412e-07, generator loss = 16.355087280273438\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 21, Batch: 254/468, discriminator loss real = 1.3573576765772138e-26, disciminator loss fake = 2.0814997014895198e-07, generator loss = 16.189075469970703\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 21, Batch: 255/468, discriminator loss real = 4.900958467318273e-15, disciminator loss fake = 2.9714874472119845e-07, generator loss = 16.57307243347168\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 21, Batch: 256/468, discriminator loss real = 2.5805443720231457e-16, disciminator loss fake = 3.317568371130619e-07, generator loss = 16.257095336914062\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 21, Batch: 257/468, discriminator loss real = 5.823210566090892e-14, disciminator loss fake = 2.542133472616115e-07, generator loss = 16.318878173828125\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 21, Batch: 258/468, discriminator loss real = 2.851456800797644e-18, disciminator loss fake = 4.1023952235264005e-07, generator loss = 16.025632858276367\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 21, Batch: 259/468, discriminator loss real = 2.0489833863239695e-27, disciminator loss fake = 4.7479056775046047e-07, generator loss = 16.145187377929688\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 21, Batch: 260/468, discriminator loss real = 2.5180118464353984e-28, disciminator loss fake = 2.8396505058481125e-07, generator loss = 16.294445037841797\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 21, Batch: 261/468, discriminator loss real = 7.030838584942689e-13, disciminator loss fake = 2.2006886979397677e-07, generator loss = 16.135082244873047\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 262/468, discriminator loss real = 4.335480003035155e-26, disciminator loss fake = 3.520565883263771e-07, generator loss = 16.332578659057617\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 263/468, discriminator loss real = 7.088119592633484e-30, disciminator loss fake = 3.449925713994162e-07, generator loss = 16.21504020690918\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 21, Batch: 264/468, discriminator loss real = 2.418423433004991e-32, disciminator loss fake = 1.3438504709029075e-07, generator loss = 16.24689483642578\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 21, Batch: 265/468, discriminator loss real = 1.462971744626617e-29, disciminator loss fake = 4.865945015808393e-07, generator loss = 16.406757354736328\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 21, Batch: 266/468, discriminator loss real = 2.2647248744118633e-20, disciminator loss fake = 2.9368649734351493e-07, generator loss = 16.08499526977539\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 21, Batch: 267/468, discriminator loss real = 3.6086187199977716e-20, disciminator loss fake = 5.489369527822419e-07, generator loss = 16.17303466796875\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 268/468, discriminator loss real = 7.971242280180268e-29, disciminator loss fake = 2.566063699305232e-07, generator loss = 16.428180694580078\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 21, Batch: 269/468, discriminator loss real = 5.278728042250159e-20, disciminator loss fake = 2.1557490015311487e-07, generator loss = 15.939888000488281\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 270/468, discriminator loss real = 2.13219120493405e-18, disciminator loss fake = 1.8429287251819915e-07, generator loss = 16.122411727905273\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 21, Batch: 271/468, discriminator loss real = 1.7640059343589803e-16, disciminator loss fake = 2.509880232537398e-07, generator loss = 16.100467681884766\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 272/468, discriminator loss real = 4.8325529590701644e-20, disciminator loss fake = 2.224567481334816e-07, generator loss = 16.357851028442383\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 21, Batch: 273/468, discriminator loss real = 7.1591844173225e-34, disciminator loss fake = 2.252320712159417e-07, generator loss = 16.373010635375977\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 274/468, discriminator loss real = 1.999396275452837e-27, disciminator loss fake = 2.1132530036993558e-07, generator loss = 16.23350715637207\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 21, Batch: 275/468, discriminator loss real = 8.261278653490586e-26, disciminator loss fake = 2.249565085321592e-07, generator loss = 16.35284423828125\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 276/468, discriminator loss real = 6.936915777043529e-13, disciminator loss fake = 2.4261007069981133e-07, generator loss = 16.33768081665039\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 21, Batch: 277/468, discriminator loss real = 2.4868370641288433e-15, disciminator loss fake = 1.463569958559674e-07, generator loss = 16.411888122558594\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 278/468, discriminator loss real = 6.2449706404704215e-19, disciminator loss fake = 3.367902650097676e-07, generator loss = 16.206623077392578\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 279/468, discriminator loss real = 3.8597588965280256e-19, disciminator loss fake = 3.7983818401698954e-07, generator loss = 16.161151885986328\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 21, Batch: 280/468, discriminator loss real = 2.29806646802333e-12, disciminator loss fake = 2.1288985863066046e-07, generator loss = 16.341690063476562\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 21, Batch: 281/468, discriminator loss real = 7.48689289131506e-19, disciminator loss fake = 3.121400311556499e-07, generator loss = 16.288257598876953\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 21, Batch: 282/468, discriminator loss real = 8.068148579787326e-12, disciminator loss fake = 3.125470300346933e-07, generator loss = 16.250102996826172\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 283/468, discriminator loss real = 2.685306502743843e-22, disciminator loss fake = 2.343554683648108e-07, generator loss = 16.27239418029785\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 21, Batch: 284/468, discriminator loss real = 3.702889977948097e-26, disciminator loss fake = 3.7885655501668225e-07, generator loss = 16.43848419189453\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 21, Batch: 285/468, discriminator loss real = 2.019063864710978e-21, disciminator loss fake = 2.56915598129126e-07, generator loss = 16.02035903930664\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 286/468, discriminator loss real = 2.341522116498985e-30, disciminator loss fake = 4.385933323192148e-07, generator loss = 16.09499168395996\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 287/468, discriminator loss real = 0.0, disciminator loss fake = 2.6146364007217926e-07, generator loss = 16.142913818359375\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 21, Batch: 288/468, discriminator loss real = 1.5120212558473512e-15, disciminator loss fake = 2.7199268970434787e-07, generator loss = 16.10480499267578\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 289/468, discriminator loss real = 3.31318890240247e-20, disciminator loss fake = 2.744136509136297e-07, generator loss = 16.337812423706055\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 21, Batch: 290/468, discriminator loss real = 3.1033179010775774e-23, disciminator loss fake = 1.436091565665265e-07, generator loss = 16.296810150146484\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 21, Batch: 291/468, discriminator loss real = 1.756476509224675e-30, disciminator loss fake = 1.7880248037727142e-07, generator loss = 16.136184692382812\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 21, Batch: 292/468, discriminator loss real = 1.3766183707764704e-20, disciminator loss fake = 2.340934344147172e-07, generator loss = 16.351634979248047\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 21, Batch: 293/468, discriminator loss real = 1.9271179196066921e-25, disciminator loss fake = 3.4506675206102955e-07, generator loss = 16.550249099731445\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 21, Batch: 294/468, discriminator loss real = 1.7888106442536475e-31, disciminator loss fake = 1.813445607012909e-07, generator loss = 16.332481384277344\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 21, Batch: 295/468, discriminator loss real = 1.4688489531801965e-34, disciminator loss fake = 2.4215782445935474e-07, generator loss = 16.234052658081055\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 296/468, discriminator loss real = 8.796036510651858e-15, disciminator loss fake = 5.221046990300238e-07, generator loss = 15.966711044311523\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 21, Batch: 297/468, discriminator loss real = 4.0693397684434946e-24, disciminator loss fake = 1.475011828233619e-07, generator loss = 16.168563842773438\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 298/468, discriminator loss real = 1.753778406762665e-24, disciminator loss fake = 2.6692231358538265e-07, generator loss = 16.23986053466797\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 299/468, discriminator loss real = 8.481998214904252e-09, disciminator loss fake = 3.1032794822749565e-07, generator loss = 16.258342742919922\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 21, Batch: 300/468, discriminator loss real = 7.070500340067132e-24, disciminator loss fake = 3.0269995932030724e-07, generator loss = 16.378814697265625\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 301/468, discriminator loss real = 6.898863938328708e-33, disciminator loss fake = 2.817877771121857e-07, generator loss = 16.230484008789062\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 21, Batch: 302/468, discriminator loss real = 4.070148821512073e-17, disciminator loss fake = 1.9178776256012497e-07, generator loss = 16.132781982421875\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 21, Batch: 303/468, discriminator loss real = 8.158104996668775e-14, disciminator loss fake = 2.0808761291846167e-07, generator loss = 16.057846069335938\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 21, Batch: 304/468, discriminator loss real = 2.5638403632474566e-19, disciminator loss fake = 2.686531388462754e-07, generator loss = 16.261241912841797\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 305/468, discriminator loss real = 7.73425066673326e-25, disciminator loss fake = 2.4399909648309404e-07, generator loss = 16.28567886352539\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 306/468, discriminator loss real = 1.0630330614046923e-34, disciminator loss fake = 2.373215863826772e-07, generator loss = 16.292734146118164\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 307/468, discriminator loss real = 2.80003482006276e-27, disciminator loss fake = 3.0366936698555946e-07, generator loss = 16.480161666870117\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 21, Batch: 308/468, discriminator loss real = 7.076615170481308e-30, disciminator loss fake = 2.156268124053895e-07, generator loss = 16.15579605102539\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 309/468, discriminator loss real = 5.768783399979927e-17, disciminator loss fake = 3.3445041935920017e-07, generator loss = 16.49176788330078\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 21, Batch: 310/468, discriminator loss real = 1.5048658219832384e-25, disciminator loss fake = 3.265533621288341e-07, generator loss = 16.443939208984375\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 311/468, discriminator loss real = 4.1263404151830025e-29, disciminator loss fake = 2.6089247739946586e-07, generator loss = 16.377838134765625\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 312/468, discriminator loss real = 1.094706162626733e-35, disciminator loss fake = 2.4979738100228133e-07, generator loss = 16.16733169555664\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 21, Batch: 313/468, discriminator loss real = 3.35494571643188e-18, disciminator loss fake = 2.988484482102649e-07, generator loss = 16.33570671081543\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 314/468, discriminator loss real = 1.1112254351786728e-16, disciminator loss fake = 3.220631015210529e-07, generator loss = 16.40729522705078\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 21, Batch: 315/468, discriminator loss real = 2.4389730099471847e-23, disciminator loss fake = 2.480383329839242e-07, generator loss = 16.25640106201172\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 21, Batch: 316/468, discriminator loss real = 6.473679274606136e-35, disciminator loss fake = 1.675459486705222e-07, generator loss = 16.383440017700195\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 21, Batch: 317/468, discriminator loss real = 2.341510831753217e-30, disciminator loss fake = 2.195188528730796e-07, generator loss = 16.382556915283203\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 21, Batch: 318/468, discriminator loss real = 1.0997731197948113e-10, disciminator loss fake = 1.6107858868963376e-07, generator loss = 16.346332550048828\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 319/468, discriminator loss real = 1.347733074738512e-15, disciminator loss fake = 2.9804641599184833e-07, generator loss = 16.28705596923828\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 320/468, discriminator loss real = 9.956323294232397e-23, disciminator loss fake = 2.1336231270652206e-07, generator loss = 16.2269229888916\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 21, Batch: 321/468, discriminator loss real = 2.078128088879001e-37, disciminator loss fake = 2.36321540114659e-07, generator loss = 16.515151977539062\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 21, Batch: 322/468, discriminator loss real = 1.3398866993832022e-27, disciminator loss fake = 2.831218068877206e-07, generator loss = 16.073877334594727\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 323/468, discriminator loss real = 3.4044683915449574e-23, disciminator loss fake = 2.5012346327457635e-07, generator loss = 16.3487491607666\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 324/468, discriminator loss real = 1.4142036031168503e-18, disciminator loss fake = 3.556900765033788e-07, generator loss = 16.45983123779297\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 325/468, discriminator loss real = 3.377709478161256e-30, disciminator loss fake = 3.0304778420031653e-07, generator loss = 16.38006591796875\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 326/468, discriminator loss real = 2.164222955052489e-21, disciminator loss fake = 1.91500149071544e-07, generator loss = 16.172760009765625\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 327/468, discriminator loss real = 1.6752486841544973e-24, disciminator loss fake = 2.809297825479007e-07, generator loss = 16.412677764892578\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 328/468, discriminator loss real = 8.011375787380693e-16, disciminator loss fake = 3.190324946444889e-07, generator loss = 16.151195526123047\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 21, Batch: 329/468, discriminator loss real = 4.2313882928157276e-16, disciminator loss fake = 2.37258774404836e-07, generator loss = 16.355077743530273\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 330/468, discriminator loss real = 0.0, disciminator loss fake = 2.0802946210096707e-07, generator loss = 16.25836181640625\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 331/468, discriminator loss real = 5.836442299290336e-32, disciminator loss fake = 4.220144944611093e-07, generator loss = 16.244478225708008\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 332/468, discriminator loss real = 1.6822991695156772e-21, disciminator loss fake = 2.6309552936254477e-07, generator loss = 16.295949935913086\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Epoch: 21, Batch: 333/468, discriminator loss real = 9.21041298784786e-10, disciminator loss fake = 2.1313653064680693e-07, generator loss = 16.250656127929688\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 334/468, discriminator loss real = 9.509733611004167e-20, disciminator loss fake = 4.10163380593076e-07, generator loss = 16.420509338378906\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 335/468, discriminator loss real = 1.6861837873685781e-37, disciminator loss fake = 4.40248840050117e-07, generator loss = 16.389789581298828\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 336/468, discriminator loss real = 3.1242906419221077e-19, disciminator loss fake = 1.249802465963512e-07, generator loss = 16.408199310302734\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 21, Batch: 337/468, discriminator loss real = 6.106151484724925e-31, disciminator loss fake = 2.6917143713944824e-07, generator loss = 16.266845703125\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 21, Batch: 338/468, discriminator loss real = 1.8805372840532963e-13, disciminator loss fake = 2.1988228127156617e-07, generator loss = 16.46381187438965\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 21, Batch: 339/468, discriminator loss real = 1.2941475280801644e-30, disciminator loss fake = 2.4048864588621655e-07, generator loss = 16.31105613708496\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 21, Batch: 340/468, discriminator loss real = 7.997918869895727e-19, disciminator loss fake = 2.863580164103041e-07, generator loss = 16.43668556213379\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 21, Batch: 341/468, discriminator loss real = 7.081676894384931e-36, disciminator loss fake = 1.8656257338989235e-07, generator loss = 16.18765640258789\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 21, Batch: 342/468, discriminator loss real = 7.818010418813907e-22, disciminator loss fake = 1.710678247945907e-07, generator loss = 16.35443115234375\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 21, Batch: 343/468, discriminator loss real = 3.442161223301119e-20, disciminator loss fake = 2.913269554483122e-07, generator loss = 16.404325485229492\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 344/468, discriminator loss real = 3.2723141035496388e-25, disciminator loss fake = 1.911138838295301e-07, generator loss = 16.478946685791016\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 345/468, discriminator loss real = 2.4944257411550933e-21, disciminator loss fake = 1.8197111728568416e-07, generator loss = 16.28083038330078\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 346/468, discriminator loss real = 4.30633610368214e-12, disciminator loss fake = 2.9034862336629885e-07, generator loss = 16.66382598876953\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 347/468, discriminator loss real = 3.809267856561274e-20, disciminator loss fake = 2.859083849671151e-07, generator loss = 16.37749481201172\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 21, Batch: 348/468, discriminator loss real = 2.412066463305816e-24, disciminator loss fake = 3.714663421305886e-07, generator loss = 16.27869415283203\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 21, Batch: 349/468, discriminator loss real = 1.2734480599774386e-31, disciminator loss fake = 4.183177679806249e-07, generator loss = 16.27602195739746\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 21, Batch: 350/468, discriminator loss real = 1.3190184202858905e-26, disciminator loss fake = 3.3545308042448596e-07, generator loss = 16.659770965576172\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 21, Batch: 351/468, discriminator loss real = 2.841367827500351e-21, disciminator loss fake = 2.1424276042125712e-07, generator loss = 16.105712890625\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 21, Batch: 352/468, discriminator loss real = 1.713575240061348e-20, disciminator loss fake = 1.767803041730076e-07, generator loss = 16.185447692871094\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 21, Batch: 353/468, discriminator loss real = 1.8382838000316882e-26, disciminator loss fake = 2.491976829332998e-07, generator loss = 16.252883911132812\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 354/468, discriminator loss real = 1.5935788356428013e-17, disciminator loss fake = 1.6410730552252062e-07, generator loss = 16.335683822631836\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 355/468, discriminator loss real = 2.808751028295463e-30, disciminator loss fake = 2.1698207319786889e-07, generator loss = 16.445117950439453\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 21, Batch: 356/468, discriminator loss real = 1.98775652340348e-24, disciminator loss fake = 1.8620420405568439e-07, generator loss = 16.625755310058594\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 21, Batch: 357/468, discriminator loss real = 2.6030667507546827e-29, disciminator loss fake = 1.452635558507609e-07, generator loss = 16.39923095703125\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 21, Batch: 358/468, discriminator loss real = 5.947336526168591e-34, disciminator loss fake = 1.9882202195731224e-07, generator loss = 16.464576721191406\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 359/468, discriminator loss real = 9.542663892291715e-29, disciminator loss fake = 2.463954444920091e-07, generator loss = 16.333154678344727\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 360/468, discriminator loss real = 5.068260336439137e-20, disciminator loss fake = 1.758282905939268e-07, generator loss = 16.469615936279297\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 21, Batch: 361/468, discriminator loss real = 1.3048501394644509e-25, disciminator loss fake = 1.7076199299026484e-07, generator loss = 16.304401397705078\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 362/468, discriminator loss real = 1.788332980390535e-20, disciminator loss fake = 2.3037668483993912e-07, generator loss = 16.136714935302734\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 363/468, discriminator loss real = 4.76177697459633e-22, disciminator loss fake = 1.4505681633636414e-07, generator loss = 16.0311279296875\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 21, Batch: 364/468, discriminator loss real = 2.1983301890391616e-33, disciminator loss fake = 8.912877547118114e-07, generator loss = 16.366729736328125\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 365/468, discriminator loss real = 1.5043300128652703e-25, disciminator loss fake = 2.425910565762024e-07, generator loss = 16.307987213134766\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 21, Batch: 366/468, discriminator loss real = 7.594769810877894e-14, disciminator loss fake = 1.9158142094966024e-07, generator loss = 16.270498275756836\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 21, Batch: 367/468, discriminator loss real = 3.515210736458237e-24, disciminator loss fake = 2.355587298552564e-07, generator loss = 16.43370246887207\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 368/468, discriminator loss real = 6.430681089041672e-20, disciminator loss fake = 2.6662729624149506e-07, generator loss = 16.579875946044922\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 21, Batch: 369/468, discriminator loss real = 2.0525651965072586e-19, disciminator loss fake = 2.646409029694041e-07, generator loss = 16.24616050720215\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 21, Batch: 370/468, discriminator loss real = 7.691595471374014e-21, disciminator loss fake = 3.588082790884073e-07, generator loss = 16.466598510742188\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 21, Batch: 371/468, discriminator loss real = 1.517229058270255e-20, disciminator loss fake = 2.0094026353945083e-07, generator loss = 16.412952423095703\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 21, Batch: 372/468, discriminator loss real = 5.911928394645657e-16, disciminator loss fake = 1.940184120030608e-07, generator loss = 16.338146209716797\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 373/468, discriminator loss real = 2.5642487917528403e-21, disciminator loss fake = 2.982489490932494e-07, generator loss = 16.323848724365234\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 374/468, discriminator loss real = 4.298887421940137e-18, disciminator loss fake = 2.567223873484181e-07, generator loss = 16.132076263427734\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 375/468, discriminator loss real = 1.676430306913742e-20, disciminator loss fake = 4.321757103298296e-07, generator loss = 16.39059829711914\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 376/468, discriminator loss real = 8.358381363069139e-16, disciminator loss fake = 2.01911120711884e-07, generator loss = 16.281753540039062\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 21, Batch: 377/468, discriminator loss real = 5.313740433513184e-25, disciminator loss fake = 1.864669911810779e-07, generator loss = 16.54842185974121\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 378/468, discriminator loss real = 5.275204925658805e-11, disciminator loss fake = 3.508156680709362e-07, generator loss = 16.385330200195312\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 379/468, discriminator loss real = 1.0979248010426694e-32, disciminator loss fake = 1.6393296675687452e-07, generator loss = 16.643497467041016\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 21, Batch: 380/468, discriminator loss real = 3.3871143045871577e-07, disciminator loss fake = 3.206539815892029e-07, generator loss = 16.532550811767578\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 381/468, discriminator loss real = 8.590993632473923e-37, disciminator loss fake = 2.8167721666250145e-07, generator loss = 16.14490509033203\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 21, Batch: 382/468, discriminator loss real = 2.0371989414413177e-16, disciminator loss fake = 1.7353417547383287e-07, generator loss = 16.243064880371094\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 21, Batch: 383/468, discriminator loss real = 7.04162205975023e-15, disciminator loss fake = 2.5746024334694084e-07, generator loss = 16.38888168334961\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 21, Batch: 384/468, discriminator loss real = 4.498223721089528e-23, disciminator loss fake = 2.325609216313751e-07, generator loss = 16.15392303466797\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 385/468, discriminator loss real = 6.944234556758086e-21, disciminator loss fake = 2.8098619964112004e-07, generator loss = 16.299531936645508\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 21, Batch: 386/468, discriminator loss real = 3.1260266872327034e-20, disciminator loss fake = 1.655799621858023e-07, generator loss = 16.240142822265625\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 21, Batch: 387/468, discriminator loss real = 5.947388279201407e-19, disciminator loss fake = 1.246769869567288e-07, generator loss = 16.283851623535156\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 21, Batch: 388/468, discriminator loss real = 4.960458410849076e-19, disciminator loss fake = 1.676429803865176e-07, generator loss = 16.455516815185547\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 21, Batch: 389/468, discriminator loss real = 1.3577838559695501e-22, disciminator loss fake = 1.0456346899445634e-07, generator loss = 16.499771118164062\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 390/468, discriminator loss real = 1.8561593388401898e-24, disciminator loss fake = 1.9575924170567305e-07, generator loss = 16.519119262695312\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 391/468, discriminator loss real = 1.605638365320683e-11, disciminator loss fake = 2.0790500343537133e-07, generator loss = 16.44050407409668\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 392/468, discriminator loss real = 4.20434656354792e-34, disciminator loss fake = 1.6760368737323006e-07, generator loss = 16.488384246826172\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 393/468, discriminator loss real = 4.525986526824152e-30, disciminator loss fake = 4.972254714630253e-07, generator loss = 16.41667938232422\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 21, Batch: 394/468, discriminator loss real = 4.934834017979414e-32, disciminator loss fake = 1.8817760860656563e-07, generator loss = 16.587392807006836\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 395/468, discriminator loss real = 8.179583295815597e-16, disciminator loss fake = 2.61311214444504e-07, generator loss = 16.251174926757812\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 396/468, discriminator loss real = 2.0669214847247875e-18, disciminator loss fake = 3.1676881917519495e-07, generator loss = 16.4611873626709\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 397/468, discriminator loss real = 1.5581422288483997e-27, disciminator loss fake = 2.8134013518865686e-07, generator loss = 16.386520385742188\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 21, Batch: 398/468, discriminator loss real = 2.1418489715629584e-20, disciminator loss fake = 2.055894867680763e-07, generator loss = 16.51520347595215\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 399/468, discriminator loss real = 6.339373274112889e-20, disciminator loss fake = 3.665752501547104e-07, generator loss = 16.37122344970703\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 21, Batch: 400/468, discriminator loss real = 1.3229993925597895e-19, disciminator loss fake = 1.8566449000445573e-07, generator loss = 16.112396240234375\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 401/468, discriminator loss real = 2.7666554207868668e-28, disciminator loss fake = 2.1754129875262151e-07, generator loss = 16.398609161376953\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 21, Batch: 402/468, discriminator loss real = 0.0, disciminator loss fake = 2.728995696088532e-07, generator loss = 16.291013717651367\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 403/468, discriminator loss real = 9.086060463290353e-26, disciminator loss fake = 3.869744205076131e-07, generator loss = 16.146854400634766\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 21, Batch: 404/468, discriminator loss real = 9.886059430685167e-20, disciminator loss fake = 1.4003197179590643e-07, generator loss = 16.273639678955078\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 21, Batch: 405/468, discriminator loss real = 1.235509531326024e-14, disciminator loss fake = 1.5948037912494328e-07, generator loss = 16.244998931884766\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 21, Batch: 406/468, discriminator loss real = 6.202732084207079e-20, disciminator loss fake = 2.0173928305666777e-07, generator loss = 16.510765075683594\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 407/468, discriminator loss real = 7.077164258341205e-21, disciminator loss fake = 2.3835490026158368e-07, generator loss = 16.59869384765625\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 408/468, discriminator loss real = 2.1669125542207347e-23, disciminator loss fake = 1.9442474297193257e-07, generator loss = 16.533113479614258\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 409/468, discriminator loss real = 6.074874448990444e-35, disciminator loss fake = 1.43153712883759e-07, generator loss = 16.351482391357422\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 21, Batch: 410/468, discriminator loss real = 2.588835812389334e-09, disciminator loss fake = 2.271105756790348e-07, generator loss = 16.415603637695312\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 21, Batch: 411/468, discriminator loss real = 6.104929858911182e-24, disciminator loss fake = 2.306662594264708e-07, generator loss = 16.44727325439453\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 21, Batch: 412/468, discriminator loss real = 5.086207198041864e-30, disciminator loss fake = 2.0042671167175286e-07, generator loss = 16.65359878540039\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Epoch: 21, Batch: 413/468, discriminator loss real = 5.5110545543951516e-30, disciminator loss fake = 1.7866071289063257e-07, generator loss = 16.45459747314453\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 414/468, discriminator loss real = 6.776186523728206e-27, disciminator loss fake = 1.9334052581143624e-07, generator loss = 16.529348373413086\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 21, Batch: 415/468, discriminator loss real = 6.813560159237684e-17, disciminator loss fake = 3.0364083158929134e-07, generator loss = 16.310382843017578\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 21, Batch: 416/468, discriminator loss real = 1.8852813407632674e-11, disciminator loss fake = 1.7594604173609696e-07, generator loss = 16.582748413085938\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 417/468, discriminator loss real = 2.2050348561679467e-31, disciminator loss fake = 2.6682519660425896e-07, generator loss = 16.417098999023438\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 418/468, discriminator loss real = 7.38087924094815e-23, disciminator loss fake = 3.4129203640986816e-07, generator loss = 16.570232391357422\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 419/468, discriminator loss real = 2.411754198802423e-28, disciminator loss fake = 5.16952070483967e-07, generator loss = 16.473865509033203\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 21, Batch: 420/468, discriminator loss real = 3.058710784976485e-26, disciminator loss fake = 1.6482476894452702e-07, generator loss = 16.176822662353516\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 421/468, discriminator loss real = 1.088609049454705e-30, disciminator loss fake = 2.3847798047427204e-07, generator loss = 16.492029190063477\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 422/468, discriminator loss real = 3.1207053309545732e-18, disciminator loss fake = 2.2848840330880194e-07, generator loss = 16.307205200195312\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 21, Batch: 423/468, discriminator loss real = 0.0, disciminator loss fake = 3.085655180257163e-07, generator loss = 16.39923667907715\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 21, Batch: 424/468, discriminator loss real = 3.449290876531412e-17, disciminator loss fake = 3.2288886586684384e-07, generator loss = 16.426929473876953\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 21, Batch: 425/468, discriminator loss real = 1.4950681031662932e-15, disciminator loss fake = 3.4529858794485335e-07, generator loss = 16.243452072143555\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 21, Batch: 426/468, discriminator loss real = 2.1054067658273378e-17, disciminator loss fake = 2.6101744765583135e-07, generator loss = 16.339744567871094\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 21, Batch: 427/468, discriminator loss real = 4.400857281963654e-25, disciminator loss fake = 1.7015048570101499e-07, generator loss = 16.57308578491211\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 428/468, discriminator loss real = 1.877317771609575e-24, disciminator loss fake = 1.9859723465742718e-07, generator loss = 16.21269416809082\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 21, Batch: 429/468, discriminator loss real = 3.6025963116826056e-31, disciminator loss fake = 1.7435442600799433e-07, generator loss = 16.158992767333984\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 21, Batch: 430/468, discriminator loss real = 1.9864112164150096e-29, disciminator loss fake = 2.45762095119062e-07, generator loss = 15.991207122802734\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 21, Batch: 431/468, discriminator loss real = 1.862123404079175e-19, disciminator loss fake = 2.926753950305283e-07, generator loss = 16.32191276550293\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 21, Batch: 432/468, discriminator loss real = 1.111402116171778e-11, disciminator loss fake = 1.8679367030927096e-07, generator loss = 16.47499656677246\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 433/468, discriminator loss real = 3.3225767844229437e-28, disciminator loss fake = 1.854645006460487e-07, generator loss = 16.020652770996094\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 21, Batch: 434/468, discriminator loss real = 7.511793108112147e-16, disciminator loss fake = 2.1115525328241347e-07, generator loss = 16.567230224609375\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 435/468, discriminator loss real = 2.1071291372749646e-26, disciminator loss fake = 2.63553033619246e-07, generator loss = 16.610145568847656\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 436/468, discriminator loss real = 1.3199757880434425e-23, disciminator loss fake = 2.3634740387024067e-07, generator loss = 16.620874404907227\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 437/468, discriminator loss real = 3.481705437759405e-17, disciminator loss fake = 1.9052750133141672e-07, generator loss = 16.545509338378906\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 438/468, discriminator loss real = 2.6957814398041335e-37, disciminator loss fake = 2.3515262626006006e-07, generator loss = 16.575054168701172\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 21, Batch: 439/468, discriminator loss real = 5.193553206742006e-28, disciminator loss fake = 1.9001407736141118e-07, generator loss = 16.466033935546875\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 21, Batch: 440/468, discriminator loss real = 2.9829136164549888e-27, disciminator loss fake = 2.154091873762809e-07, generator loss = 16.544719696044922\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 441/468, discriminator loss real = 5.4183170324404696e-20, disciminator loss fake = 2.682301385448227e-07, generator loss = 16.441110610961914\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 21, Batch: 442/468, discriminator loss real = 2.805291992513355e-26, disciminator loss fake = 5.333610033630976e-07, generator loss = 16.55169677734375\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 443/468, discriminator loss real = 9.762004875709e-34, disciminator loss fake = 1.6839496197462722e-07, generator loss = 16.2595157623291\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 444/468, discriminator loss real = 7.231999445154244e-27, disciminator loss fake = 6.043542271072511e-07, generator loss = 16.475788116455078\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 445/468, discriminator loss real = 1.8551462442226597e-24, disciminator loss fake = 2.386956339250901e-07, generator loss = 16.29643440246582\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 21, Batch: 446/468, discriminator loss real = 1.1467757840525009e-34, disciminator loss fake = 1.9466730805106636e-07, generator loss = 16.556764602661133\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 21, Batch: 447/468, discriminator loss real = 1.6555644008486858e-11, disciminator loss fake = 3.3599442872400687e-07, generator loss = 16.378812789916992\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 448/468, discriminator loss real = 1.8243053920693822e-29, disciminator loss fake = 2.185786343034124e-07, generator loss = 16.363842010498047\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 449/468, discriminator loss real = 1.4437954165558153e-09, disciminator loss fake = 3.832837478512374e-07, generator loss = 16.40105438232422\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 450/468, discriminator loss real = 2.108987328652089e-29, disciminator loss fake = 2.892259658437979e-07, generator loss = 16.350135803222656\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 21, Batch: 451/468, discriminator loss real = 3.337971912764637e-11, disciminator loss fake = 3.7103919225955906e-07, generator loss = 16.30084991455078\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 21, Batch: 452/468, discriminator loss real = 2.9251226110194726e-20, disciminator loss fake = 1.9916041082979064e-07, generator loss = 16.20711898803711\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 21, Batch: 453/468, discriminator loss real = 2.7116932689347616e-23, disciminator loss fake = 1.6795826240922906e-07, generator loss = 16.518653869628906\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 454/468, discriminator loss real = 4.028244059586006e-24, disciminator loss fake = 1.9805570161679498e-07, generator loss = 16.475439071655273\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 455/468, discriminator loss real = 1.8697734214564035e-23, disciminator loss fake = 1.452188769235363e-07, generator loss = 16.380611419677734\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 21, Batch: 456/468, discriminator loss real = 1.3323950756030247e-32, disciminator loss fake = 1.637988020775083e-07, generator loss = 16.75234603881836\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 457/468, discriminator loss real = 4.315438251970699e-13, disciminator loss fake = 1.3204309823322546e-07, generator loss = 16.419231414794922\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 458/468, discriminator loss real = 5.139473787238393e-26, disciminator loss fake = 2.342600282645435e-07, generator loss = 16.61549949645996\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 21, Batch: 459/468, discriminator loss real = 2.6997197880018753e-11, disciminator loss fake = 1.9876254953032912e-07, generator loss = 16.3863525390625\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 21, Batch: 460/468, discriminator loss real = 5.090154566111959e-35, disciminator loss fake = 1.484228135950616e-07, generator loss = 16.369972229003906\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 461/468, discriminator loss real = 1.5698325703010893e-22, disciminator loss fake = 1.8087732200910978e-07, generator loss = 16.310829162597656\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 21, Batch: 462/468, discriminator loss real = 4.0572701751365965e-20, disciminator loss fake = 1.9578766341510345e-07, generator loss = 16.496055603027344\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 21, Batch: 463/468, discriminator loss real = 0.0, disciminator loss fake = 2.504978908746125e-07, generator loss = 16.389278411865234\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 21, Batch: 464/468, discriminator loss real = 1.6035512347971323e-37, disciminator loss fake = 3.1861083016337943e-07, generator loss = 16.27606201171875\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 465/468, discriminator loss real = 6.579428785154124e-32, disciminator loss fake = 1.4092304922996846e-07, generator loss = 15.9851655960083\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 21, Batch: 466/468, discriminator loss real = 2.9621712551738984e-20, disciminator loss fake = 2.6999211399925116e-07, generator loss = 16.52564239501953\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 21, Batch: 467/468, discriminator loss real = 1.2386965104716497e-27, disciminator loss fake = 2.1038337649770256e-07, generator loss = 16.147682189941406\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 21, Batch: 468/468, discriminator loss real = 5.343844941205211e-13, disciminator loss fake = 3.7298235611160635e-07, generator loss = 16.392723083496094\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 22, Batch: 1/468, discriminator loss real = 1.776146163299754e-24, disciminator loss fake = 2.408758064120775e-07, generator loss = 16.301952362060547\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 2/468, discriminator loss real = 1.1846350723293542e-13, disciminator loss fake = 2.445419795549242e-07, generator loss = 16.35375213623047\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 22, Batch: 3/468, discriminator loss real = 6.153487819386493e-32, disciminator loss fake = 2.173637625446645e-07, generator loss = 16.407184600830078\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 4/468, discriminator loss real = 3.136483090280683e-20, disciminator loss fake = 1.3973067325423472e-07, generator loss = 16.466609954833984\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 22, Batch: 5/468, discriminator loss real = 8.116938269320802e-19, disciminator loss fake = 1.8938681023428217e-07, generator loss = 16.508338928222656\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 22, Batch: 6/468, discriminator loss real = 1.5869860149570123e-28, disciminator loss fake = 2.191165293652375e-07, generator loss = 16.322235107421875\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 22, Batch: 7/468, discriminator loss real = 5.8715634313703355e-37, disciminator loss fake = 1.5212526704999618e-07, generator loss = 16.486913681030273\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 8/468, discriminator loss real = 4.90565696509293e-07, disciminator loss fake = 1.715379198685696e-07, generator loss = 16.576723098754883\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 22, Batch: 9/468, discriminator loss real = 3.2647305174271937e-22, disciminator loss fake = 2.0939314993029257e-07, generator loss = 16.692943572998047\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 10/468, discriminator loss real = 3.072328731038982e-22, disciminator loss fake = 1.5743978565296857e-07, generator loss = 16.41452407836914\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 11/468, discriminator loss real = 1.3436132775290943e-27, disciminator loss fake = 1.471146617859631e-07, generator loss = 16.321308135986328\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 12/468, discriminator loss real = 2.064139133495548e-32, disciminator loss fake = 2.0324287675066444e-07, generator loss = 16.426448822021484\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 13/468, discriminator loss real = 1.897649260424679e-21, disciminator loss fake = 2.110576815539389e-07, generator loss = 16.498088836669922\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 14/468, discriminator loss real = 5.576758137240041e-23, disciminator loss fake = 1.7752026337802818e-07, generator loss = 16.58095932006836\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 22, Batch: 15/468, discriminator loss real = 3.554523314997695e-38, disciminator loss fake = 3.3354774586769054e-07, generator loss = 16.504316329956055\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 22, Batch: 16/468, discriminator loss real = 1.636682800463911e-14, disciminator loss fake = 2.349659808942306e-07, generator loss = 16.65723991394043\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 17/468, discriminator loss real = 8.868608570669259e-37, disciminator loss fake = 2.009571602457072e-07, generator loss = 16.51971435546875\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 18/468, discriminator loss real = 2.9395215297253504e-34, disciminator loss fake = 2.1535213079459936e-07, generator loss = 16.45655059814453\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 19/468, discriminator loss real = 3.9109229635174436e-13, disciminator loss fake = 1.755355185650842e-07, generator loss = 16.420536041259766\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 20/468, discriminator loss real = 4.849006032638094e-35, disciminator loss fake = 1.4667497794107476e-07, generator loss = 16.61318588256836\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 22, Batch: 21/468, discriminator loss real = 5.213640415320722e-29, disciminator loss fake = 2.1928036630924908e-07, generator loss = 16.491416931152344\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 22/468, discriminator loss real = 2.608237311728266e-26, disciminator loss fake = 2.3176654906365002e-07, generator loss = 16.605396270751953\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 22, Batch: 23/468, discriminator loss real = 1.398100302125076e-31, disciminator loss fake = 2.737529598562105e-07, generator loss = 16.5080509185791\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 24/468, discriminator loss real = 2.6112107072725468e-31, disciminator loss fake = 2.0255083654774353e-07, generator loss = 16.232864379882812\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 25/468, discriminator loss real = 4.393023325088482e-33, disciminator loss fake = 2.206427609507955e-07, generator loss = 16.528038024902344\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 26/468, discriminator loss real = 4.444139614642802e-25, disciminator loss fake = 2.0058759275798366e-07, generator loss = 16.518306732177734\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 27/468, discriminator loss real = 1.4472990383143352e-28, disciminator loss fake = 2.5542792059241037e-07, generator loss = 16.524431228637695\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 28/468, discriminator loss real = 1.5412407461390387e-11, disciminator loss fake = 4.320390303291788e-07, generator loss = 16.361770629882812\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 29/468, discriminator loss real = 9.669869995833533e-34, disciminator loss fake = 2.6675058961700415e-07, generator loss = 16.514877319335938\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 22, Batch: 30/468, discriminator loss real = 1.1562918675982958e-20, disciminator loss fake = 1.8765823028843442e-07, generator loss = 16.310283660888672\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 22, Batch: 31/468, discriminator loss real = 5.1003758660595785e-21, disciminator loss fake = 2.1962574692224734e-07, generator loss = 16.660205841064453\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 32/468, discriminator loss real = 9.471128739329599e-27, disciminator loss fake = 3.23134855761964e-07, generator loss = 16.443389892578125\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 33/468, discriminator loss real = 4.0233259062724056e-24, disciminator loss fake = 1.412842038917006e-07, generator loss = 16.59597396850586\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 22, Batch: 34/468, discriminator loss real = 1.0380017450544712e-26, disciminator loss fake = 2.754657089099055e-07, generator loss = 16.59929656982422\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 35/468, discriminator loss real = 8.679948558395334e-24, disciminator loss fake = 2.669717105163727e-07, generator loss = 16.733083724975586\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 36/468, discriminator loss real = 7.85056101904047e-07, disciminator loss fake = 1.5504377870456665e-07, generator loss = 16.643245697021484\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 22, Batch: 37/468, discriminator loss real = 4.585316907010099e-18, disciminator loss fake = 2.832098005001171e-07, generator loss = 16.47341537475586\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 38/468, discriminator loss real = 4.082142685112392e-25, disciminator loss fake = 2.5577730866643833e-07, generator loss = 16.396238327026367\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 39/468, discriminator loss real = 2.968047504038261e-23, disciminator loss fake = 2.3779107038990333e-07, generator loss = 16.640634536743164\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 40/468, discriminator loss real = 2.094888021795505e-19, disciminator loss fake = 1.6168115735126776e-07, generator loss = 16.49903678894043\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 22, Batch: 41/468, discriminator loss real = 1.924467127967896e-18, disciminator loss fake = 1.567134830793293e-07, generator loss = 16.525482177734375\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 22, Batch: 42/468, discriminator loss real = 7.779178776839979e-13, disciminator loss fake = 1.7541290731060144e-07, generator loss = 16.56415557861328\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 43/468, discriminator loss real = 1.7958716381234145e-22, disciminator loss fake = 3.7567207300526206e-07, generator loss = 16.470932006835938\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 44/468, discriminator loss real = 1.2721731451356102e-28, disciminator loss fake = 3.324590238662495e-07, generator loss = 16.654178619384766\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 45/468, discriminator loss real = 1.668730010950294e-23, disciminator loss fake = 1.6189524387755228e-07, generator loss = 16.085880279541016\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 22, Batch: 46/468, discriminator loss real = 4.5130840934954644e-21, disciminator loss fake = 1.7492735082669242e-07, generator loss = 16.328622817993164\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 47/468, discriminator loss real = 3.8249959398495957e-34, disciminator loss fake = 2.548621864661982e-07, generator loss = 16.58205795288086\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 48/468, discriminator loss real = 2.1487234925062143e-25, disciminator loss fake = 1.6369128275073308e-07, generator loss = 16.618783950805664\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 49/468, discriminator loss real = 2.2545953240281155e-18, disciminator loss fake = 2.55437669238745e-07, generator loss = 16.478771209716797\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 22, Batch: 50/468, discriminator loss real = 2.0453657848094636e-20, disciminator loss fake = 1.5195614366803056e-07, generator loss = 16.660179138183594\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 51/468, discriminator loss real = 3.851981395441981e-20, disciminator loss fake = 1.3581325220002327e-07, generator loss = 16.37822723388672\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 52/468, discriminator loss real = 1.7976974661814572e-29, disciminator loss fake = 1.9536665263331088e-07, generator loss = 16.446338653564453\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 53/468, discriminator loss real = 3.7996991577186544e-27, disciminator loss fake = 1.8188035255661816e-07, generator loss = 16.65511703491211\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 22, Batch: 54/468, discriminator loss real = 6.337990230552081e-22, disciminator loss fake = 1.5804690178811143e-07, generator loss = 16.415525436401367\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 55/468, discriminator loss real = 3.66747407460934e-21, disciminator loss fake = 3.345310233271448e-07, generator loss = 16.389911651611328\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 22, Batch: 56/468, discriminator loss real = 4.513074717883606e-25, disciminator loss fake = 1.3187261060920719e-07, generator loss = 16.47713851928711\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 57/468, discriminator loss real = 1.0495299420654192e-06, disciminator loss fake = 2.458449159803422e-07, generator loss = 16.659339904785156\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 58/468, discriminator loss real = 5.094768840616417e-31, disciminator loss fake = 2.2863218873681035e-07, generator loss = 16.593719482421875\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 22, Batch: 59/468, discriminator loss real = 4.1444034334493474e-24, disciminator loss fake = 2.0303193082327198e-07, generator loss = 16.64733123779297\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 22, Batch: 60/468, discriminator loss real = 2.356254675595016e-28, disciminator loss fake = 2.783657464533462e-07, generator loss = 16.809356689453125\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 22, Batch: 61/468, discriminator loss real = 3.8482866727778363e-16, disciminator loss fake = 1.6938206215399987e-07, generator loss = 16.446313858032227\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 62/468, discriminator loss real = 6.861686132151842e-20, disciminator loss fake = 3.116354889698414e-07, generator loss = 16.68914794921875\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 22, Batch: 63/468, discriminator loss real = 5.218660170669409e-09, disciminator loss fake = 2.0320456428635225e-07, generator loss = 16.54029083251953\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 64/468, discriminator loss real = 9.650736247414789e-29, disciminator loss fake = 1.686017299107334e-07, generator loss = 16.629920959472656\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 22, Batch: 65/468, discriminator loss real = 9.470625224204939e-25, disciminator loss fake = 1.0385863902229175e-07, generator loss = 16.237760543823242\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 66/468, discriminator loss real = 6.787168212382289e-30, disciminator loss fake = 1.6378024270125024e-07, generator loss = 16.36593246459961\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 67/468, discriminator loss real = 7.632548962384057e-27, disciminator loss fake = 2.8488170755736064e-07, generator loss = 16.47391128540039\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 68/468, discriminator loss real = 9.433950331303354e-23, disciminator loss fake = 1.241964042719701e-07, generator loss = 16.425556182861328\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 69/468, discriminator loss real = 1.5937281334053865e-13, disciminator loss fake = 3.0150087582114793e-07, generator loss = 16.480796813964844\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 70/468, discriminator loss real = 2.0120355034847215e-12, disciminator loss fake = 2.9733007522736443e-07, generator loss = 16.561819076538086\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 22, Batch: 71/468, discriminator loss real = 4.206133223125674e-34, disciminator loss fake = 2.6179623091593385e-07, generator loss = 16.735836029052734\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 72/468, discriminator loss real = 1.945354923159436e-21, disciminator loss fake = 1.7876070046440873e-07, generator loss = 16.506389617919922\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 22, Batch: 73/468, discriminator loss real = 5.627831911029398e-24, disciminator loss fake = 1.5646494944121514e-07, generator loss = 16.453147888183594\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 74/468, discriminator loss real = 8.729073524665279e-32, disciminator loss fake = 3.210544718967867e-07, generator loss = 16.37845230102539\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 22, Batch: 75/468, discriminator loss real = 1.4622833751347756e-29, disciminator loss fake = 1.4747088528110908e-07, generator loss = 16.407814025878906\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 22, Batch: 76/468, discriminator loss real = 3.3238528276177987e-21, disciminator loss fake = 2.35692226624451e-07, generator loss = 16.369522094726562\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 77/468, discriminator loss real = 1.695695247085939e-14, disciminator loss fake = 2.90840659999958e-07, generator loss = 16.260725021362305\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 78/468, discriminator loss real = 0.0, disciminator loss fake = 1.71364803236429e-07, generator loss = 16.52870750427246\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 79/468, discriminator loss real = 5.6751249817685485e-15, disciminator loss fake = 2.0852800730608578e-07, generator loss = 16.63739776611328\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 80/468, discriminator loss real = 1.174380239643299e-19, disciminator loss fake = 1.542273651011783e-07, generator loss = 16.50455093383789\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 22, Batch: 81/468, discriminator loss real = 7.599426607439485e-16, disciminator loss fake = 1.5716435086687852e-07, generator loss = 16.42711639404297\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 82/468, discriminator loss real = 2.57595850752257e-18, disciminator loss fake = 2.2804447041835374e-07, generator loss = 16.72482681274414\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 22, Batch: 83/468, discriminator loss real = 2.9225235023026015e-26, disciminator loss fake = 2.0563071245760511e-07, generator loss = 16.535226821899414\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 22, Batch: 84/468, discriminator loss real = 2.1553145202213857e-29, disciminator loss fake = 1.6222415410993563e-07, generator loss = 16.510339736938477\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 22, Batch: 85/468, discriminator loss real = 3.0654432197644806e-25, disciminator loss fake = 1.6860366258697468e-07, generator loss = 16.48033905029297\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 86/468, discriminator loss real = 2.1938943739696797e-22, disciminator loss fake = 1.1131587740464965e-07, generator loss = 16.439348220825195\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 22, Batch: 87/468, discriminator loss real = 5.088751110786046e-22, disciminator loss fake = 2.0854739091191732e-07, generator loss = 16.54541778564453\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 88/468, discriminator loss real = 4.672294121239437e-18, disciminator loss fake = 1.669363598466589e-07, generator loss = 16.482988357543945\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 22, Batch: 89/468, discriminator loss real = 4.408943310390743e-28, disciminator loss fake = 1.3917720309564174e-07, generator loss = 16.285402297973633\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 22, Batch: 90/468, discriminator loss real = 6.500286267775322e-15, disciminator loss fake = 1.520628387652323e-07, generator loss = 16.629552841186523\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 91/468, discriminator loss real = 4.223352837832778e-33, disciminator loss fake = 1.3544838850521046e-07, generator loss = 16.93946075439453\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 22, Batch: 92/468, discriminator loss real = 4.3897619659706356e-30, disciminator loss fake = 1.891586549618296e-07, generator loss = 16.394508361816406\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 22, Batch: 93/468, discriminator loss real = 5.694807455157499e-31, disciminator loss fake = 1.2734311383155728e-07, generator loss = 16.52058219909668\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 22, Batch: 94/468, discriminator loss real = 2.0094226128172784e-25, disciminator loss fake = 1.567755418818706e-07, generator loss = 16.49618148803711\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 22, Batch: 95/468, discriminator loss real = 1.1607916327300671e-15, disciminator loss fake = 1.4878763465731026e-07, generator loss = 16.35074234008789\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 22, Batch: 96/468, discriminator loss real = 1.1074904963373142e-13, disciminator loss fake = 1.5312090795305267e-07, generator loss = 16.537513732910156\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 97/468, discriminator loss real = 3.6314624562580082e-31, disciminator loss fake = 1.3925227904110216e-07, generator loss = 16.698835372924805\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 98/468, discriminator loss real = 1.1144088818682838e-21, disciminator loss fake = 1.3615202476557897e-07, generator loss = 16.59884262084961\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 99/468, discriminator loss real = 8.6429630357351e-22, disciminator loss fake = 7.012798164396372e-07, generator loss = 16.491315841674805\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 100/468, discriminator loss real = 8.355959064375013e-28, disciminator loss fake = 1.6722535178814724e-07, generator loss = 16.32005500793457\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 22, Batch: 101/468, discriminator loss real = 3.2807221037494423e-21, disciminator loss fake = 1.4951572779864364e-07, generator loss = 16.644973754882812\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 102/468, discriminator loss real = 5.5005872917163485e-17, disciminator loss fake = 2.3404962234963023e-07, generator loss = 16.501815795898438\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 22, Batch: 103/468, discriminator loss real = 2.2925553014977246e-20, disciminator loss fake = 1.2748969879794458e-07, generator loss = 16.858444213867188\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 22, Batch: 104/468, discriminator loss real = 2.604680840552953e-16, disciminator loss fake = 1.7495742099526979e-07, generator loss = 16.52022933959961\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 105/468, discriminator loss real = 1.8536837380896527e-28, disciminator loss fake = 1.5063039882079465e-07, generator loss = 16.71335792541504\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 106/468, discriminator loss real = 7.548643805878037e-17, disciminator loss fake = 4.028725015814416e-07, generator loss = 16.819034576416016\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 22, Batch: 107/468, discriminator loss real = 1.2562691452307777e-21, disciminator loss fake = 1.2897405099465686e-07, generator loss = 16.575021743774414\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 108/468, discriminator loss real = 1.273177829687e-22, disciminator loss fake = 1.509543494648824e-07, generator loss = 16.535213470458984\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 109/468, discriminator loss real = 0.0, disciminator loss fake = 2.2957119938382675e-07, generator loss = 16.424488067626953\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 22, Batch: 110/468, discriminator loss real = 2.5271605102000516e-30, disciminator loss fake = 2.1427806018436968e-07, generator loss = 16.76382064819336\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 22, Batch: 111/468, discriminator loss real = 1.1980360138089888e-21, disciminator loss fake = 1.6142153924647573e-07, generator loss = 16.514663696289062\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 112/468, discriminator loss real = 2.045911287321429e-28, disciminator loss fake = 1.238196887243248e-07, generator loss = 16.460323333740234\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 22, Batch: 113/468, discriminator loss real = 7.204995133994816e-26, disciminator loss fake = 2.1188851917486318e-07, generator loss = 16.76205062866211\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 22, Batch: 114/468, discriminator loss real = 9.037664220359569e-20, disciminator loss fake = 2.557852383233694e-07, generator loss = 16.512924194335938\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 115/468, discriminator loss real = 2.0872078957092063e-27, disciminator loss fake = 3.3857634207379306e-07, generator loss = 16.41045379638672\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 116/468, discriminator loss real = 1.1306035844908392e-25, disciminator loss fake = 1.777221996235312e-07, generator loss = 16.59894561767578\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 117/468, discriminator loss real = 1.5777706425428376e-14, disciminator loss fake = 1.312721167323616e-07, generator loss = 16.4613037109375\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 118/468, discriminator loss real = 5.719017411507997e-34, disciminator loss fake = 1.2975877439203032e-07, generator loss = 16.763065338134766\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 119/468, discriminator loss real = 1.6258324079676477e-32, disciminator loss fake = 2.1108483849729964e-07, generator loss = 16.47519874572754\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 120/468, discriminator loss real = 4.1698618965259946e-21, disciminator loss fake = 1.1662326926398237e-07, generator loss = 16.45211410522461\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 121/468, discriminator loss real = 6.21245860143334e-25, disciminator loss fake = 1.7015426578836923e-07, generator loss = 16.65496063232422\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 122/468, discriminator loss real = 1.2918390852946106e-18, disciminator loss fake = 2.228550783911487e-07, generator loss = 16.782682418823242\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 123/468, discriminator loss real = 1.529152963735435e-19, disciminator loss fake = 1.6028641880438954e-07, generator loss = 16.48133087158203\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 124/468, discriminator loss real = 3.231901644093829e-14, disciminator loss fake = 2.0213363427501463e-07, generator loss = 16.458295822143555\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 22, Batch: 125/468, discriminator loss real = 1.0510249507327376e-16, disciminator loss fake = 1.4633050682277826e-07, generator loss = 16.428226470947266\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 126/468, discriminator loss real = 1.6355430421973894e-27, disciminator loss fake = 1.7094123450078769e-07, generator loss = 16.951915740966797\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 127/468, discriminator loss real = 2.0017757649806153e-24, disciminator loss fake = 2.0055175298239192e-07, generator loss = 16.370637893676758\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 22, Batch: 128/468, discriminator loss real = 5.301078586511521e-12, disciminator loss fake = 1.8896474784924067e-07, generator loss = 16.62032699584961\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 129/468, discriminator loss real = 3.768470261849696e-18, disciminator loss fake = 2.579137685643218e-07, generator loss = 16.652807235717773\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 130/468, discriminator loss real = 2.951632255233698e-23, disciminator loss fake = 2.2887424222517438e-07, generator loss = 16.727710723876953\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 131/468, discriminator loss real = 1.597231235093917e-16, disciminator loss fake = 1.3471350257532322e-07, generator loss = 16.62230682373047\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 132/468, discriminator loss real = 2.3510010670017845e-13, disciminator loss fake = 1.9618458679815376e-07, generator loss = 16.519699096679688\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 133/468, discriminator loss real = 3.96029946981932e-23, disciminator loss fake = 3.0161783115545404e-07, generator loss = 16.58850860595703\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 22, Batch: 134/468, discriminator loss real = 7.160801184778909e-22, disciminator loss fake = 2.1537678662753024e-07, generator loss = 16.573638916015625\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 22, Batch: 135/468, discriminator loss real = 1.1467477801424765e-18, disciminator loss fake = 1.590886142821546e-07, generator loss = 16.512287139892578\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 136/468, discriminator loss real = 4.820986275119732e-14, disciminator loss fake = 2.2967019219777285e-07, generator loss = 16.550487518310547\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 22, Batch: 137/468, discriminator loss real = 2.5401179784242365e-22, disciminator loss fake = 2.634016027514008e-07, generator loss = 16.593338012695312\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 138/468, discriminator loss real = 4.5941463672651445e-23, disciminator loss fake = 2.639712874952238e-07, generator loss = 16.66891860961914\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 22, Batch: 139/468, discriminator loss real = 2.4655628258069267e-16, disciminator loss fake = 1.3776394780506962e-07, generator loss = 16.527122497558594\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 22, Batch: 140/468, discriminator loss real = 3.815139092056812e-22, disciminator loss fake = 2.664087901393941e-07, generator loss = 16.350631713867188\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 141/468, discriminator loss real = 8.762223658475137e-22, disciminator loss fake = 3.206620249329717e-07, generator loss = 16.697803497314453\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 22, Batch: 142/468, discriminator loss real = 6.445603602227204e-33, disciminator loss fake = 1.5716484824679355e-07, generator loss = 16.62961196899414\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 143/468, discriminator loss real = 3.1056777837140755e-27, disciminator loss fake = 1.816818269162468e-07, generator loss = 16.631799697875977\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 22, Batch: 144/468, discriminator loss real = 8.951041988981119e-26, disciminator loss fake = 1.4655643099104054e-07, generator loss = 16.444625854492188\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 145/468, discriminator loss real = 5.326467960713106e-34, disciminator loss fake = 1.8091674292008975e-07, generator loss = 16.589933395385742\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 146/468, discriminator loss real = 2.555973033434175e-24, disciminator loss fake = 2.3688247097197745e-07, generator loss = 16.7689266204834\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 22, Batch: 147/468, discriminator loss real = 1.34663775791376e-27, disciminator loss fake = 1.0123541471784847e-07, generator loss = 16.28942108154297\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 148/468, discriminator loss real = 7.423406929563841e-25, disciminator loss fake = 1.3941938448169822e-07, generator loss = 16.396026611328125\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 149/468, discriminator loss real = 1.2705330226720415e-20, disciminator loss fake = 2.3431513795912906e-07, generator loss = 16.78077507019043\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 150/468, discriminator loss real = 6.17577622083564e-33, disciminator loss fake = 2.1870037869575754e-07, generator loss = 16.4625244140625\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 151/468, discriminator loss real = 2.080199448905903e-22, disciminator loss fake = 1.5375695738839568e-07, generator loss = 16.418161392211914\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 22, Batch: 152/468, discriminator loss real = 1.2301320319836142e-18, disciminator loss fake = 2.022587892724914e-07, generator loss = 16.468673706054688\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 153/468, discriminator loss real = 1.882340179362925e-27, disciminator loss fake = 1.6743389608109283e-07, generator loss = 16.644750595092773\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 154/468, discriminator loss real = 2.7216201971910448e-27, disciminator loss fake = 1.1151151824151384e-07, generator loss = 16.602964401245117\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 155/468, discriminator loss real = 3.078190522216032e-17, disciminator loss fake = 3.778484938266047e-07, generator loss = 16.578826904296875\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 156/468, discriminator loss real = 3.1447661913166545e-24, disciminator loss fake = 1.2072008814811852e-07, generator loss = 16.71173858642578\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 157/468, discriminator loss real = 4.98124525284738e-18, disciminator loss fake = 1.503270112834798e-07, generator loss = 16.572006225585938\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 158/468, discriminator loss real = 1.6830270991990094e-25, disciminator loss fake = 1.078246754104839e-07, generator loss = 16.455596923828125\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 159/468, discriminator loss real = 1.7150772851829747e-26, disciminator loss fake = 2.08334341778027e-07, generator loss = 16.442668914794922\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 22, Batch: 160/468, discriminator loss real = 1.6414378406994606e-21, disciminator loss fake = 1.6233404664944828e-07, generator loss = 16.545215606689453\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 161/468, discriminator loss real = 1.0992024715665171e-33, disciminator loss fake = 1.29386151570543e-07, generator loss = 16.599979400634766\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 22, Batch: 162/468, discriminator loss real = 1.1859107919740077e-35, disciminator loss fake = 2.451400860081776e-07, generator loss = 16.577899932861328\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 22, Batch: 163/468, discriminator loss real = 2.5411907686708195e-20, disciminator loss fake = 1.5510133266616322e-07, generator loss = 16.748916625976562\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 164/468, discriminator loss real = 3.489167440305451e-23, disciminator loss fake = 1.259128055153269e-07, generator loss = 16.577293395996094\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 22, Batch: 165/468, discriminator loss real = 5.714891590455362e-16, disciminator loss fake = 1.8942213841910416e-07, generator loss = 16.697662353515625\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 22, Batch: 166/468, discriminator loss real = 2.3654027826455444e-29, disciminator loss fake = 1.453580722454717e-07, generator loss = 16.61313247680664\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 167/468, discriminator loss real = 8.190540090504805e-15, disciminator loss fake = 2.130827567725646e-07, generator loss = 16.48747444152832\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 168/468, discriminator loss real = 6.739011915792853e-25, disciminator loss fake = 3.4121723047064734e-07, generator loss = 16.648181915283203\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 22, Batch: 169/468, discriminator loss real = 1.758652834363099e-14, disciminator loss fake = 1.696880502777276e-07, generator loss = 16.54234504699707\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 170/468, discriminator loss real = 5.6869449593932586e-08, disciminator loss fake = 2.2346816308527195e-07, generator loss = 16.637826919555664\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 171/468, discriminator loss real = 2.8694378461581684e-19, disciminator loss fake = 1.3939224174919218e-07, generator loss = 16.48583221435547\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 172/468, discriminator loss real = 1.6961806755449737e-33, disciminator loss fake = 3.296997022061987e-07, generator loss = 16.820146560668945\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 173/468, discriminator loss real = 5.310976130794936e-22, disciminator loss fake = 1.455333347166743e-07, generator loss = 16.738080978393555\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 174/468, discriminator loss real = 2.9560017731794667e-31, disciminator loss fake = 1.877149600204575e-07, generator loss = 16.702617645263672\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 175/468, discriminator loss real = 1.0482674918157689e-20, disciminator loss fake = 1.7237042015949555e-07, generator loss = 16.70001792907715\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 176/468, discriminator loss real = 1.7059718970813265e-08, disciminator loss fake = 2.485128618445742e-07, generator loss = 16.835716247558594\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 22, Batch: 177/468, discriminator loss real = 4.925085065929011e-22, disciminator loss fake = 2.905818234921753e-07, generator loss = 16.67452621459961\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 178/468, discriminator loss real = 3.09734273124684e-17, disciminator loss fake = 1.878016888667844e-07, generator loss = 16.520938873291016\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 179/468, discriminator loss real = 3.284307697444725e-20, disciminator loss fake = 1.416128725395538e-07, generator loss = 16.65790557861328\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 180/468, discriminator loss real = 2.062668736999463e-32, disciminator loss fake = 2.2655834186480206e-07, generator loss = 16.562442779541016\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 181/468, discriminator loss real = 9.530705218085966e-13, disciminator loss fake = 2.1017521589783428e-07, generator loss = 16.33272933959961\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 182/468, discriminator loss real = 2.2210404424477007e-24, disciminator loss fake = 1.509077094397071e-07, generator loss = 16.56052017211914\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 183/468, discriminator loss real = 3.370339760316171e-13, disciminator loss fake = 1.6801510582808987e-07, generator loss = 16.708908081054688\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 184/468, discriminator loss real = 1.1199452423239618e-16, disciminator loss fake = 2.3003683224942506e-07, generator loss = 16.678295135498047\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 185/468, discriminator loss real = 8.47492480819697e-22, disciminator loss fake = 2.962830762953672e-07, generator loss = 16.699981689453125\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 22, Batch: 186/468, discriminator loss real = 5.373656638478323e-14, disciminator loss fake = 1.864015644059691e-07, generator loss = 16.738231658935547\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 187/468, discriminator loss real = 3.559233322652297e-27, disciminator loss fake = 2.48254849566365e-07, generator loss = 16.807064056396484\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 22, Batch: 188/468, discriminator loss real = 1.6711542495373674e-25, disciminator loss fake = 1.864388536887418e-07, generator loss = 16.762836456298828\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 189/468, discriminator loss real = 1.551088155333748e-29, disciminator loss fake = 2.7705902994057396e-07, generator loss = 16.645872116088867\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 190/468, discriminator loss real = 3.0337838300033208e-28, disciminator loss fake = 2.0315884796673345e-07, generator loss = 16.619464874267578\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 191/468, discriminator loss real = 2.35170955394623e-17, disciminator loss fake = 2.7725982931769977e-07, generator loss = 16.713401794433594\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 192/468, discriminator loss real = 9.898406963873563e-13, disciminator loss fake = 3.035812596863252e-07, generator loss = 16.784862518310547\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 22, Batch: 193/468, discriminator loss real = 9.654628030375534e-08, disciminator loss fake = 1.6861618234997877e-07, generator loss = 16.467880249023438\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 194/468, discriminator loss real = 7.321420427938926e-24, disciminator loss fake = 3.128447474409768e-07, generator loss = 16.768692016601562\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 22, Batch: 195/468, discriminator loss real = 1.7053923235399244e-19, disciminator loss fake = 1.6149090242834063e-07, generator loss = 16.67070770263672\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 196/468, discriminator loss real = 4.2993217208422955e-22, disciminator loss fake = 1.3097407247641968e-07, generator loss = 16.743377685546875\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 22, Batch: 197/468, discriminator loss real = 2.4557745343547505e-25, disciminator loss fake = 1.386324584018439e-07, generator loss = 16.679649353027344\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 198/468, discriminator loss real = 1.6362939437937785e-23, disciminator loss fake = 1.205868613851635e-07, generator loss = 16.820213317871094\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 199/468, discriminator loss real = 6.174901212228247e-33, disciminator loss fake = 1.6204393205043743e-07, generator loss = 16.57318115234375\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 22, Batch: 200/468, discriminator loss real = 0.0, disciminator loss fake = 2.22744390043772e-07, generator loss = 16.744274139404297\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 22, Batch: 201/468, discriminator loss real = 1.0917805531035315e-17, disciminator loss fake = 1.8434019466440077e-07, generator loss = 16.522165298461914\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 202/468, discriminator loss real = 5.53001438044487e-12, disciminator loss fake = 1.6414082892879378e-07, generator loss = 16.705440521240234\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 22, Batch: 203/468, discriminator loss real = 4.439401065688296e-35, disciminator loss fake = 1.6799450008875283e-07, generator loss = 16.58612060546875\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 204/468, discriminator loss real = 1.6953109063436567e-21, disciminator loss fake = 1.60134206339535e-07, generator loss = 16.52752113342285\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 22, Batch: 205/468, discriminator loss real = 1.4199432645314869e-12, disciminator loss fake = 2.3093207346391864e-07, generator loss = 16.723989486694336\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 206/468, discriminator loss real = 3.652835090748327e-15, disciminator loss fake = 1.915996108436957e-07, generator loss = 16.716976165771484\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 22, Batch: 207/468, discriminator loss real = 9.251095644201811e-15, disciminator loss fake = 1.1302160629611535e-07, generator loss = 16.699947357177734\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 22, Batch: 208/468, discriminator loss real = 7.903297808872756e-20, disciminator loss fake = 1.945120828850122e-07, generator loss = 16.745298385620117\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 209/468, discriminator loss real = 3.509740068019518e-11, disciminator loss fake = 1.2453551789803896e-07, generator loss = 16.517192840576172\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 210/468, discriminator loss real = 3.413748797531646e-11, disciminator loss fake = 1.4337641118800093e-07, generator loss = 16.751052856445312\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 22, Batch: 211/468, discriminator loss real = 3.9740108921914397e-19, disciminator loss fake = 1.8730230522123748e-07, generator loss = 16.926422119140625\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 22, Batch: 212/468, discriminator loss real = 1.944976396701663e-34, disciminator loss fake = 1.6688352388882777e-07, generator loss = 16.865062713623047\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 213/468, discriminator loss real = 5.844251471320386e-18, disciminator loss fake = 1.2471795685087272e-07, generator loss = 16.84627342224121\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 214/468, discriminator loss real = 6.159157760501434e-20, disciminator loss fake = 1.8015617797573213e-07, generator loss = 16.60626983642578\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 215/468, discriminator loss real = 2.1995015215533437e-21, disciminator loss fake = 1.4881629795127083e-07, generator loss = 16.576570510864258\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 22, Batch: 216/468, discriminator loss real = 1.6828993727576928e-23, disciminator loss fake = 2.1562220808846178e-07, generator loss = 16.775718688964844\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 22, Batch: 217/468, discriminator loss real = 9.328265427894361e-14, disciminator loss fake = 2.631601603297895e-07, generator loss = 16.552688598632812\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 218/468, discriminator loss real = 3.6323805719881206e-35, disciminator loss fake = 2.4190018166336813e-07, generator loss = 16.713176727294922\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 219/468, discriminator loss real = 2.1736974420959516e-26, disciminator loss fake = 2.2309656344532414e-07, generator loss = 16.537452697753906\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 220/468, discriminator loss real = 1.5094420780501354e-25, disciminator loss fake = 2.40404744999978e-07, generator loss = 16.508695602416992\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 221/468, discriminator loss real = 1.6575623090634719e-21, disciminator loss fake = 1.4418266403026792e-07, generator loss = 16.649520874023438\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 22, Batch: 222/468, discriminator loss real = 1.5352929574695906e-26, disciminator loss fake = 1.855283642271388e-07, generator loss = 16.584747314453125\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 223/468, discriminator loss real = 3.055766919129235e-31, disciminator loss fake = 1.2075457789251232e-07, generator loss = 16.5093936920166\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 224/468, discriminator loss real = 5.53199885509259e-19, disciminator loss fake = 1.5102693851076765e-07, generator loss = 16.773681640625\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 225/468, discriminator loss real = 1.8532674663877666e-31, disciminator loss fake = 1.893558021492936e-07, generator loss = 16.532623291015625\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 226/468, discriminator loss real = 2.9321518367685833e-19, disciminator loss fake = 1.756460079604949e-07, generator loss = 16.779935836791992\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 22, Batch: 227/468, discriminator loss real = 9.331949312371505e-32, disciminator loss fake = 2.6589694357426197e-07, generator loss = 16.87441635131836\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 22, Batch: 228/468, discriminator loss real = 8.513758439935507e-17, disciminator loss fake = 1.2837827512157673e-07, generator loss = 16.452350616455078\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 229/468, discriminator loss real = 2.433432195422547e-29, disciminator loss fake = 1.7093525173095259e-07, generator loss = 16.719303131103516\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 230/468, discriminator loss real = 3.0744770580302758e-21, disciminator loss fake = 1.9152605545968981e-07, generator loss = 16.806682586669922\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 231/468, discriminator loss real = 3.841492111964652e-18, disciminator loss fake = 1.7535535334900487e-07, generator loss = 16.5709171295166\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 232/468, discriminator loss real = 2.085278380276141e-19, disciminator loss fake = 1.6455950913041306e-07, generator loss = 16.586185455322266\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 233/468, discriminator loss real = 3.1326906610425837e-19, disciminator loss fake = 8.779796445423926e-08, generator loss = 16.63748550415039\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 234/468, discriminator loss real = 2.032502519181938e-30, disciminator loss fake = 1.5153463550632296e-07, generator loss = 16.350448608398438\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 235/468, discriminator loss real = 3.1261591653776826e-20, disciminator loss fake = 1.3695174061467696e-07, generator loss = 16.560256958007812\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 22, Batch: 236/468, discriminator loss real = 2.5387983179921024e-35, disciminator loss fake = 2.1086103174638993e-07, generator loss = 16.494287490844727\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 237/468, discriminator loss real = 3.1172282290091536e-32, disciminator loss fake = 1.7498712168162456e-07, generator loss = 16.72182846069336\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 22, Batch: 238/468, discriminator loss real = 7.944723563367367e-26, disciminator loss fake = 5.812080416944809e-07, generator loss = 16.528656005859375\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 239/468, discriminator loss real = 1.6970977646464037e-24, disciminator loss fake = 1.503447606410191e-07, generator loss = 16.580821990966797\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 22, Batch: 240/468, discriminator loss real = 4.376643545993743e-33, disciminator loss fake = 2.1731742094743822e-07, generator loss = 16.608856201171875\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 241/468, discriminator loss real = 7.318638407668719e-32, disciminator loss fake = 1.232460959954551e-07, generator loss = 16.68001365661621\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 242/468, discriminator loss real = 4.618736739402694e-23, disciminator loss fake = 1.9177278431925515e-07, generator loss = 16.646318435668945\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 22, Batch: 243/468, discriminator loss real = 3.7742803784722685e-19, disciminator loss fake = 9.759423846844584e-08, generator loss = 16.63961410522461\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 22, Batch: 244/468, discriminator loss real = 6.526393194237028e-25, disciminator loss fake = 1.9309206322759565e-07, generator loss = 16.55948257446289\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 22, Batch: 245/468, discriminator loss real = 2.2087802879842532e-15, disciminator loss fake = 1.4318956687020545e-07, generator loss = 16.788555145263672\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 22, Batch: 246/468, discriminator loss real = 5.999438412451153e-17, disciminator loss fake = 1.6006887904040923e-07, generator loss = 16.5252628326416\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 22, Batch: 247/468, discriminator loss real = 5.352633540171378e-22, disciminator loss fake = 2.0565686043028109e-07, generator loss = 16.811382293701172\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 22, Batch: 248/468, discriminator loss real = 7.555967136696484e-12, disciminator loss fake = 1.8601923557071132e-07, generator loss = 16.804668426513672\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 249/468, discriminator loss real = 5.876886415435548e-21, disciminator loss fake = 1.6159606275323313e-07, generator loss = 16.546356201171875\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 250/468, discriminator loss real = 1.028359486171388e-31, disciminator loss fake = 1.533837092893009e-07, generator loss = 16.848129272460938\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 251/468, discriminator loss real = 1.1515920916908593e-26, disciminator loss fake = 1.2103249957817752e-07, generator loss = 16.785282135009766\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 22, Batch: 252/468, discriminator loss real = 4.67207364782769e-15, disciminator loss fake = 1.5437539957474655e-07, generator loss = 17.036014556884766\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 253/468, discriminator loss real = 2.6475010143928954e-26, disciminator loss fake = 1.3808210042043356e-07, generator loss = 16.86751937866211\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 254/468, discriminator loss real = 8.72499585736564e-15, disciminator loss fake = 1.3597562542599917e-07, generator loss = 16.636259078979492\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 255/468, discriminator loss real = 2.2476261199158709e-23, disciminator loss fake = 1.5449703028025397e-07, generator loss = 16.680301666259766\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 256/468, discriminator loss real = 4.3943265692902855e-11, disciminator loss fake = 1.5140210507524898e-07, generator loss = 16.656230926513672\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 257/468, discriminator loss real = 5.594906845406043e-20, disciminator loss fake = 1.9880408785866166e-07, generator loss = 16.806224822998047\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 258/468, discriminator loss real = 1.1753103915448926e-12, disciminator loss fake = 1.4194532127476123e-07, generator loss = 16.671287536621094\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 259/468, discriminator loss real = 4.3988863545449424e-38, disciminator loss fake = 1.5944689835123427e-07, generator loss = 16.892396926879883\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 22, Batch: 260/468, discriminator loss real = 1.7145934373467574e-23, disciminator loss fake = 1.3868755388557474e-07, generator loss = 16.454811096191406\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 261/468, discriminator loss real = 3.092770407692892e-19, disciminator loss fake = 1.4216540478173556e-07, generator loss = 16.65463638305664\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 22, Batch: 262/468, discriminator loss real = 1.4044614933780535e-27, disciminator loss fake = 1.4571482154224213e-07, generator loss = 16.82462501525879\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 263/468, discriminator loss real = 4.541062586058194e-28, disciminator loss fake = 1.6557777371417615e-07, generator loss = 16.869714736938477\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 264/468, discriminator loss real = 1.7901987803270458e-06, disciminator loss fake = 1.923158663430513e-07, generator loss = 16.573841094970703\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 265/468, discriminator loss real = 7.076968546115805e-18, disciminator loss fake = 1.6158665516741166e-07, generator loss = 16.809099197387695\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 266/468, discriminator loss real = 2.0464627232728987e-38, disciminator loss fake = 1.0327810429089368e-07, generator loss = 16.58767318725586\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 267/468, discriminator loss real = 5.130541578740189e-30, disciminator loss fake = 1.65475839253304e-07, generator loss = 16.949800491333008\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 268/468, discriminator loss real = 1.5126255079760988e-15, disciminator loss fake = 3.195350473106373e-07, generator loss = 16.929338455200195\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 269/468, discriminator loss real = 8.479533823950405e-31, disciminator loss fake = 1.5444479117832088e-07, generator loss = 16.9261474609375\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 270/468, discriminator loss real = 6.833833107040945e-22, disciminator loss fake = 1.9121534933219664e-07, generator loss = 16.758563995361328\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 22, Batch: 271/468, discriminator loss real = 1.2738188281957719e-10, disciminator loss fake = 1.335578900807377e-07, generator loss = 16.99076271057129\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 22, Batch: 272/468, discriminator loss real = 2.330828055173011e-34, disciminator loss fake = 1.3005259802412183e-07, generator loss = 16.518836975097656\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 22, Batch: 273/468, discriminator loss real = 3.237340442648149e-15, disciminator loss fake = 1.6928217405620671e-07, generator loss = 16.609004974365234\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 274/468, discriminator loss real = 9.864703953714521e-21, disciminator loss fake = 1.3059454317954078e-07, generator loss = 16.855484008789062\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 275/468, discriminator loss real = 1.846664638259085e-27, disciminator loss fake = 9.761797770124758e-08, generator loss = 16.71426773071289\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 276/468, discriminator loss real = 4.974046782096897e-12, disciminator loss fake = 1.9335593037794752e-07, generator loss = 16.65216827392578\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 277/468, discriminator loss real = 2.796294098368839e-29, disciminator loss fake = 1.2625514500541613e-07, generator loss = 16.665191650390625\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 22, Batch: 278/468, discriminator loss real = 3.445479736751699e-33, disciminator loss fake = 1.0534799343986379e-07, generator loss = 16.651315689086914\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 22, Batch: 279/468, discriminator loss real = 1.7046214466438585e-23, disciminator loss fake = 1.634647901482822e-07, generator loss = 16.468669891357422\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 22, Batch: 280/468, discriminator loss real = 5.348295745909292e-26, disciminator loss fake = 1.6195505736504856e-07, generator loss = 16.670263290405273\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 281/468, discriminator loss real = 5.134320846116388e-27, disciminator loss fake = 1.0495394064946595e-07, generator loss = 16.838680267333984\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 22, Batch: 282/468, discriminator loss real = 2.050304912827594e-14, disciminator loss fake = 1.6864960628026893e-07, generator loss = 16.748701095581055\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 283/468, discriminator loss real = 2.1138721107516158e-24, disciminator loss fake = 9.830860392412433e-08, generator loss = 16.637374877929688\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 284/468, discriminator loss real = 4.2483508224162095e-18, disciminator loss fake = 3.484255444163864e-07, generator loss = 16.600547790527344\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 285/468, discriminator loss real = 1.1725114915892793e-29, disciminator loss fake = 2.0287731672397058e-07, generator loss = 16.85718536376953\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 286/468, discriminator loss real = 2.313640458429128e-19, disciminator loss fake = 1.542158827305684e-07, generator loss = 16.818012237548828\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 287/468, discriminator loss real = 9.364876447707799e-25, disciminator loss fake = 1.7117058348503633e-07, generator loss = 16.768375396728516\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 22, Batch: 288/468, discriminator loss real = 7.414782424663112e-16, disciminator loss fake = 1.249940737579891e-07, generator loss = 16.889549255371094\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 289/468, discriminator loss real = 2.9051570177296426e-11, disciminator loss fake = 2.4284267396978976e-07, generator loss = 16.829299926757812\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 22, Batch: 290/468, discriminator loss real = 1.8189673640768179e-31, disciminator loss fake = 1.6603529218173207e-07, generator loss = 16.64792823791504\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 291/468, discriminator loss real = 2.8666289847062222e-30, disciminator loss fake = 1.2887286970908463e-07, generator loss = 16.412389755249023\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 22, Batch: 292/468, discriminator loss real = 4.102504925635334e-29, disciminator loss fake = 1.6045487427618355e-07, generator loss = 16.919815063476562\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 293/468, discriminator loss real = 1.6399615553573773e-24, disciminator loss fake = 8.537770668226585e-08, generator loss = 16.709754943847656\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 294/468, discriminator loss real = 3.709842443298891e-24, disciminator loss fake = 1.464631793623994e-07, generator loss = 16.809913635253906\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 22, Batch: 295/468, discriminator loss real = 4.48894642102129e-25, disciminator loss fake = 3.8527684864675393e-07, generator loss = 16.62584114074707\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 22, Batch: 296/468, discriminator loss real = 8.309917512290594e-30, disciminator loss fake = 1.7167070609502844e-07, generator loss = 16.793140411376953\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 297/468, discriminator loss real = 1.522246716995944e-16, disciminator loss fake = 2.776342284960265e-07, generator loss = 16.63475227355957\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 22, Batch: 298/468, discriminator loss real = 4.5911641433626595e-19, disciminator loss fake = 2.480213368016848e-07, generator loss = 16.817245483398438\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 299/468, discriminator loss real = 1.832795332890074e-17, disciminator loss fake = 2.3784465952303435e-07, generator loss = 16.926097869873047\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 22, Batch: 300/468, discriminator loss real = 5.170469491911067e-28, disciminator loss fake = 2.534684142574406e-07, generator loss = 16.82212257385254\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 22, Batch: 301/468, discriminator loss real = 1.774946529543072e-15, disciminator loss fake = 2.076017295848942e-07, generator loss = 16.665870666503906\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 302/468, discriminator loss real = 2.7216267426410923e-06, disciminator loss fake = 1.5761557392579562e-07, generator loss = 16.72970962524414\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 303/468, discriminator loss real = 5.300615652350493e-28, disciminator loss fake = 1.0319371313016745e-07, generator loss = 16.65224838256836\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 22, Batch: 304/468, discriminator loss real = 1.2276682504240995e-26, disciminator loss fake = 1.3523552411243145e-07, generator loss = 16.76042366027832\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 305/468, discriminator loss real = 3.598544566933622e-16, disciminator loss fake = 1.7420066455997585e-07, generator loss = 16.618257522583008\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 22, Batch: 306/468, discriminator loss real = 2.381044764356682e-28, disciminator loss fake = 1.9863308864387363e-07, generator loss = 16.708919525146484\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 22, Batch: 307/468, discriminator loss real = 1.6450763045540396e-37, disciminator loss fake = 1.0696298602397292e-07, generator loss = 16.902252197265625\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 308/468, discriminator loss real = 1.685134654929767e-28, disciminator loss fake = 4.1755424717848655e-07, generator loss = 16.85371971130371\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 22, Batch: 309/468, discriminator loss real = 2.6078353535310245e-20, disciminator loss fake = 2.2606474203712423e-07, generator loss = 16.670557022094727\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 22, Batch: 310/468, discriminator loss real = 4.041812722901248e-31, disciminator loss fake = 1.5391391627872508e-07, generator loss = 16.644996643066406\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 311/468, discriminator loss real = 4.579725674373342e-24, disciminator loss fake = 1.113936463070786e-07, generator loss = 16.80032730102539\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 312/468, discriminator loss real = 1.1026374918675112e-20, disciminator loss fake = 1.6509456202129513e-07, generator loss = 16.80331802368164\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 313/468, discriminator loss real = 3.534790737442365e-23, disciminator loss fake = 1.193145067190926e-07, generator loss = 16.812103271484375\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 314/468, discriminator loss real = 1.8077934015985228e-26, disciminator loss fake = 1.3980044855088636e-07, generator loss = 16.5422306060791\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 315/468, discriminator loss real = 1.1090103444952315e-13, disciminator loss fake = 2.155642704337879e-07, generator loss = 16.829795837402344\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 316/468, discriminator loss real = 2.802643312462856e-32, disciminator loss fake = 1.7076237668334215e-07, generator loss = 16.694093704223633\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 317/468, discriminator loss real = 6.3436381915018186e-18, disciminator loss fake = 8.555137753774034e-08, generator loss = 16.693180084228516\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 22, Batch: 318/468, discriminator loss real = 3.8840777096729487e-22, disciminator loss fake = 1.5601736436110514e-07, generator loss = 16.856857299804688\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 319/468, discriminator loss real = 3.245970340138816e-25, disciminator loss fake = 2.1272937544836168e-07, generator loss = 16.82402229309082\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 320/468, discriminator loss real = 2.720037940002161e-15, disciminator loss fake = 1.3580725521933346e-07, generator loss = 16.878219604492188\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 321/468, discriminator loss real = 3.9369129610528964e-26, disciminator loss fake = 1.3326140901881445e-07, generator loss = 16.78082275390625\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 322/468, discriminator loss real = 8.390441970433378e-23, disciminator loss fake = 2.2638784002992907e-07, generator loss = 16.850595474243164\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 323/468, discriminator loss real = 6.917827115558221e-27, disciminator loss fake = 1.1614764616751927e-07, generator loss = 16.83452606201172\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 22, Batch: 324/468, discriminator loss real = 1.0670584011905715e-29, disciminator loss fake = 1.2807512916879205e-07, generator loss = 16.61728858947754\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 325/468, discriminator loss real = 9.939420507163176e-29, disciminator loss fake = 2.70448140327062e-07, generator loss = 16.774059295654297\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 326/468, discriminator loss real = 8.678446850041155e-10, disciminator loss fake = 1.1722286785698088e-07, generator loss = 16.567256927490234\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 22, Batch: 327/468, discriminator loss real = 5.947677404674888e-20, disciminator loss fake = 1.207908439937455e-07, generator loss = 16.79946517944336\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 328/468, discriminator loss real = 1.2600088581825233e-14, disciminator loss fake = 1.6895707233288704e-07, generator loss = 16.75019645690918\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 329/468, discriminator loss real = 4.380956293477191e-25, disciminator loss fake = 1.71732551734749e-07, generator loss = 16.805042266845703\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 330/468, discriminator loss real = 1.29520541356291e-27, disciminator loss fake = 2.0367090769468632e-07, generator loss = 16.638568878173828\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 331/468, discriminator loss real = 4.120991436916435e-37, disciminator loss fake = 1.658653729919024e-07, generator loss = 16.47420883178711\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 22, Batch: 332/468, discriminator loss real = 1.0220140971359883e-30, disciminator loss fake = 1.7121301709721592e-07, generator loss = 16.811552047729492\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 333/468, discriminator loss real = 1.550594856063736e-25, disciminator loss fake = 1.1176165770621083e-07, generator loss = 16.65847396850586\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 334/468, discriminator loss real = 3.108412995892219e-23, disciminator loss fake = 2.1143202388884674e-07, generator loss = 16.73440170288086\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 22, Batch: 335/468, discriminator loss real = 1.4164400734640062e-29, disciminator loss fake = 2.0799205913135665e-07, generator loss = 16.446609497070312\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 336/468, discriminator loss real = 0.0, disciminator loss fake = 2.3010011318547186e-07, generator loss = 16.831260681152344\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 337/468, discriminator loss real = 9.825992676528863e-19, disciminator loss fake = 1.7533099594402302e-07, generator loss = 16.755834579467773\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 22, Batch: 338/468, discriminator loss real = 9.67568527773759e-36, disciminator loss fake = 3.107215604813973e-07, generator loss = 16.686546325683594\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 339/468, discriminator loss real = 2.811644437110351e-30, disciminator loss fake = 1.3190316394684487e-07, generator loss = 17.044586181640625\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 22, Batch: 340/468, discriminator loss real = 1.121414543656047e-37, disciminator loss fake = 1.3503003515324963e-07, generator loss = 16.694610595703125\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 341/468, discriminator loss real = 2.552574790359503e-37, disciminator loss fake = 1.527419613012171e-07, generator loss = 16.706069946289062\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 342/468, discriminator loss real = 4.1972280464236905e-27, disciminator loss fake = 2.001291221631618e-07, generator loss = 16.762096405029297\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 343/468, discriminator loss real = 2.3576336560572122e-17, disciminator loss fake = 1.830312186257288e-07, generator loss = 16.755142211914062\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 344/468, discriminator loss real = 2.188730757560851e-19, disciminator loss fake = 2.3382528979709605e-07, generator loss = 16.76702117919922\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 345/468, discriminator loss real = 1.3840007961847928e-20, disciminator loss fake = 1.4212156429493916e-07, generator loss = 16.876140594482422\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 346/468, discriminator loss real = 7.278424510828219e-31, disciminator loss fake = 1.597404661879409e-07, generator loss = 16.4591121673584\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 22, Batch: 347/468, discriminator loss real = 5.408889893079988e-27, disciminator loss fake = 1.4860974317798537e-07, generator loss = 16.837913513183594\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 22, Batch: 348/468, discriminator loss real = 7.845727259033364e-28, disciminator loss fake = 1.375179721208042e-07, generator loss = 16.885608673095703\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 22, Batch: 349/468, discriminator loss real = 4.8900820911282174e-18, disciminator loss fake = 1.5321650437272183e-07, generator loss = 17.052928924560547\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 350/468, discriminator loss real = 1.4774183654253648e-08, disciminator loss fake = 2.3153924644248036e-07, generator loss = 16.852766036987305\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 351/468, discriminator loss real = 1.5943851376997056e-20, disciminator loss fake = 1.295332907602642e-07, generator loss = 16.855436325073242\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 352/468, discriminator loss real = 7.475004349630525e-16, disciminator loss fake = 8.957533736975165e-08, generator loss = 16.68716049194336\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 353/468, discriminator loss real = 8.542510647689788e-26, disciminator loss fake = 1.4232318790163845e-07, generator loss = 16.98729705810547\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 354/468, discriminator loss real = 3.356154601192457e-14, disciminator loss fake = 1.621931033923829e-07, generator loss = 16.507423400878906\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 355/468, discriminator loss real = 2.4307227042571807e-19, disciminator loss fake = 1.2822856376715208e-07, generator loss = 16.810405731201172\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 22, Batch: 356/468, discriminator loss real = 2.3331769806818223e-23, disciminator loss fake = 1.6420565884800453e-07, generator loss = 16.760604858398438\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 22, Batch: 357/468, discriminator loss real = 9.848793853568338e-22, disciminator loss fake = 6.595143986487528e-08, generator loss = 16.68029022216797\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 22, Batch: 358/468, discriminator loss real = 1.0180037481681953e-19, disciminator loss fake = 1.1722086412646604e-07, generator loss = 16.651138305664062\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 359/468, discriminator loss real = 9.807071203237992e-29, disciminator loss fake = 1.7539271368605114e-07, generator loss = 16.796672821044922\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 360/468, discriminator loss real = 2.9957280146125642e-12, disciminator loss fake = 1.1491042783973171e-07, generator loss = 17.270984649658203\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 22, Batch: 361/468, discriminator loss real = 8.807654041861901e-13, disciminator loss fake = 1.3233818663138663e-07, generator loss = 16.7672119140625\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 22, Batch: 362/468, discriminator loss real = 3.7658528969554557e-16, disciminator loss fake = 1.2389313042149297e-07, generator loss = 16.72917938232422\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 363/468, discriminator loss real = 2.8807979234132937e-30, disciminator loss fake = 1.7823023767959967e-07, generator loss = 16.604530334472656\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 364/468, discriminator loss real = 4.1373572462820066e-17, disciminator loss fake = 2.380297843274093e-07, generator loss = 16.931365966796875\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 365/468, discriminator loss real = 0.0, disciminator loss fake = 1.3519539265871572e-07, generator loss = 16.80400848388672\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 366/468, discriminator loss real = 4.141981202465672e-11, disciminator loss fake = 1.1095283980466775e-07, generator loss = 16.58511734008789\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 367/468, discriminator loss real = 1.9157397468693439e-22, disciminator loss fake = 1.989741775787479e-07, generator loss = 16.93414306640625\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 368/468, discriminator loss real = 7.055998414223615e-25, disciminator loss fake = 2.90007164949202e-07, generator loss = 16.803852081298828\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 369/468, discriminator loss real = 1.5601524877690488e-18, disciminator loss fake = 1.2350659517323948e-07, generator loss = 16.809329986572266\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 370/468, discriminator loss real = 3.0932748182299e-21, disciminator loss fake = 1.6603296160155878e-07, generator loss = 17.175352096557617\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 371/468, discriminator loss real = 1.2883441438089975e-19, disciminator loss fake = 1.6045994755131687e-07, generator loss = 16.680805206298828\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 372/468, discriminator loss real = 2.670866999787691e-14, disciminator loss fake = 1.4920053104106046e-07, generator loss = 17.037736892700195\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 22, Batch: 373/468, discriminator loss real = 6.064849881044369e-21, disciminator loss fake = 1.6895417331852514e-07, generator loss = 16.870220184326172\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 374/468, discriminator loss real = 1.545220076940273e-15, disciminator loss fake = 2.377053363034065e-07, generator loss = 16.959239959716797\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 375/468, discriminator loss real = 7.949206203622479e-19, disciminator loss fake = 1.844218360247396e-07, generator loss = 16.914358139038086\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 376/468, discriminator loss real = 2.3709844851338424e-11, disciminator loss fake = 1.606942419130064e-07, generator loss = 16.93341827392578\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 377/468, discriminator loss real = 4.800397164217429e-06, disciminator loss fake = 6.515248429650455e-08, generator loss = 16.877643585205078\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 22, Batch: 378/468, discriminator loss real = 2.039598623417607e-19, disciminator loss fake = 1.9269262452326075e-07, generator loss = 16.728435516357422\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 379/468, discriminator loss real = 9.904593203947113e-22, disciminator loss fake = 2.0100938513678557e-07, generator loss = 16.79526710510254\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 380/468, discriminator loss real = 2.565352090396211e-26, disciminator loss fake = 1.9243871918206423e-07, generator loss = 16.55249786376953\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 381/468, discriminator loss real = 7.862082096465883e-10, disciminator loss fake = 1.6622425391688012e-07, generator loss = 16.83493423461914\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 22, Batch: 382/468, discriminator loss real = 5.060154312817999e-17, disciminator loss fake = 1.640313769257773e-07, generator loss = 16.73221206665039\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 22, Batch: 383/468, discriminator loss real = 2.2286453281797347e-16, disciminator loss fake = 1.0331409328045993e-07, generator loss = 16.874256134033203\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 384/468, discriminator loss real = 7.993490289652725e-17, disciminator loss fake = 1.1385436948785355e-07, generator loss = 16.81755828857422\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 385/468, discriminator loss real = 1.7063110370773446e-29, disciminator loss fake = 2.4773214590823045e-07, generator loss = 17.073745727539062\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 22, Batch: 386/468, discriminator loss real = 1.112675840353461e-09, disciminator loss fake = 1.4134025150269736e-07, generator loss = 16.94759750366211\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 22, Batch: 387/468, discriminator loss real = 4.2135149851531266e-23, disciminator loss fake = 1.6618710674265458e-07, generator loss = 16.891693115234375\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 22, Batch: 388/468, discriminator loss real = 3.2860894961829527e-19, disciminator loss fake = 2.3077521404957224e-07, generator loss = 16.835491180419922\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 389/468, discriminator loss real = 3.613352803890383e-18, disciminator loss fake = 2.0801246591872768e-07, generator loss = 16.835285186767578\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 390/468, discriminator loss real = 3.1241762822432764e-32, disciminator loss fake = 1.5688570442762284e-07, generator loss = 16.888633728027344\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 391/468, discriminator loss real = 1.0675718471313087e-33, disciminator loss fake = 9.258477717821734e-08, generator loss = 16.834625244140625\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 392/468, discriminator loss real = 2.6531206033985073e-17, disciminator loss fake = 1.4731270425727416e-07, generator loss = 16.743629455566406\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 22, Batch: 393/468, discriminator loss real = 6.762006479326666e-28, disciminator loss fake = 1.634120678772888e-07, generator loss = 16.72983169555664\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 22, Batch: 394/468, discriminator loss real = 4.9604995630845504e-18, disciminator loss fake = 1.862741498825926e-07, generator loss = 16.873001098632812\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 395/468, discriminator loss real = 3.268565012515292e-21, disciminator loss fake = 1.2839811347475916e-07, generator loss = 16.846036911010742\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 396/468, discriminator loss real = 4.2900295406408065e-34, disciminator loss fake = 1.0601016242617334e-07, generator loss = 16.76010513305664\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 397/468, discriminator loss real = 1.605632748307948e-30, disciminator loss fake = 1.262479258912208e-07, generator loss = 16.927967071533203\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 398/468, discriminator loss real = 3.1870750499172373e-22, disciminator loss fake = 1.521275265758959e-07, generator loss = 16.88259506225586\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 399/468, discriminator loss real = 4.387952023214078e-21, disciminator loss fake = 1.5012831511285185e-07, generator loss = 16.61920738220215\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 400/468, discriminator loss real = 3.288996777542135e-20, disciminator loss fake = 1.3898883821639174e-07, generator loss = 16.712200164794922\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 22, Batch: 401/468, discriminator loss real = 4.3811104449099395e-27, disciminator loss fake = 1.435537200222825e-07, generator loss = 16.668935775756836\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 402/468, discriminator loss real = 3.493653850045624e-23, disciminator loss fake = 2.5881990950438194e-07, generator loss = 16.801937103271484\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 22, Batch: 403/468, discriminator loss real = 1.1050273245266987e-15, disciminator loss fake = 2.700402887967357e-07, generator loss = 16.910385131835938\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 22, Batch: 404/468, discriminator loss real = 1.7845349496089196e-23, disciminator loss fake = 1.462217369407881e-07, generator loss = 16.768695831298828\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 405/468, discriminator loss real = 3.0791504640128543e-30, disciminator loss fake = 8.514083305044551e-08, generator loss = 16.898740768432617\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 406/468, discriminator loss real = 2.52994058727428e-21, disciminator loss fake = 1.0146283102585585e-07, generator loss = 16.64017677307129\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 407/468, discriminator loss real = 4.72961092448828e-31, disciminator loss fake = 2.841487685145694e-07, generator loss = 16.611431121826172\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 408/468, discriminator loss real = 1.786443139856374e-32, disciminator loss fake = 1.110992826625079e-07, generator loss = 16.813936233520508\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 22, Batch: 409/468, discriminator loss real = 9.59526832871777e-26, disciminator loss fake = 1.3561569289777253e-07, generator loss = 16.83526039123535\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 410/468, discriminator loss real = 1.4082036760703935e-30, disciminator loss fake = 1.5439943013006996e-07, generator loss = 16.647258758544922\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 411/468, discriminator loss real = 2.3525130751955575e-28, disciminator loss fake = 1.3361959361191111e-07, generator loss = 17.16180419921875\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 412/468, discriminator loss real = 3.4672755829933278e-15, disciminator loss fake = 1.012959245372258e-07, generator loss = 16.762081146240234\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 22, Batch: 413/468, discriminator loss real = 4.1563271447058077e-16, disciminator loss fake = 1.5567357536383497e-07, generator loss = 16.64801788330078\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 414/468, discriminator loss real = 2.417480575935719e-26, disciminator loss fake = 1.8206077356808237e-07, generator loss = 16.621938705444336\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 415/468, discriminator loss real = 9.479652356758609e-24, disciminator loss fake = 1.5304331668630766e-07, generator loss = 16.891437530517578\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 416/468, discriminator loss real = 4.56084387810958e-33, disciminator loss fake = 1.3546969057642855e-07, generator loss = 16.521533966064453\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 417/468, discriminator loss real = 2.4911906181637597e-31, disciminator loss fake = 1.6331331664787285e-07, generator loss = 16.69808578491211\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 418/468, discriminator loss real = 1.4474088594340628e-11, disciminator loss fake = 1.835227294577635e-07, generator loss = 16.914932250976562\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 419/468, discriminator loss real = 1.9025439724524909e-19, disciminator loss fake = 1.4510152368529816e-07, generator loss = 16.695138931274414\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 22, Batch: 420/468, discriminator loss real = 6.512409118501326e-21, disciminator loss fake = 1.528948132545338e-07, generator loss = 16.81315040588379\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 421/468, discriminator loss real = 3.9677757081315916e-18, disciminator loss fake = 1.1088883411503048e-07, generator loss = 16.786418914794922\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 422/468, discriminator loss real = 2.50055455095139e-16, disciminator loss fake = 1.5851722423576575e-07, generator loss = 16.883399963378906\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 423/468, discriminator loss real = 1.8177777835420908e-28, disciminator loss fake = 1.255843926628586e-07, generator loss = 16.771026611328125\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 22, Batch: 424/468, discriminator loss real = 6.5266150613666215e-25, disciminator loss fake = 1.8204400475951843e-07, generator loss = 16.624433517456055\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 425/468, discriminator loss real = 1.3009280457764892e-15, disciminator loss fake = 1.5396229002817563e-07, generator loss = 16.914417266845703\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 22, Batch: 426/468, discriminator loss real = 1.4435198463108343e-32, disciminator loss fake = 1.0548460949166838e-07, generator loss = 16.79351806640625\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 427/468, discriminator loss real = 3.172460888197653e-33, disciminator loss fake = 1.4414354154723696e-07, generator loss = 16.974212646484375\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 428/468, discriminator loss real = 3.562760239640855e-26, disciminator loss fake = 1.9175664078829868e-07, generator loss = 16.892337799072266\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 429/468, discriminator loss real = 1.812097069794002e-31, disciminator loss fake = 1.734118342255897e-07, generator loss = 16.69169807434082\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 430/468, discriminator loss real = 1.1662296985285867e-26, disciminator loss fake = 1.2603817367562442e-07, generator loss = 17.085887908935547\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 431/468, discriminator loss real = 2.227531903370569e-15, disciminator loss fake = 1.3649426477968518e-07, generator loss = 17.061437606811523\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 432/468, discriminator loss real = 1.4856230886183757e-24, disciminator loss fake = 1.374223472794256e-07, generator loss = 17.001323699951172\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 433/468, discriminator loss real = 3.23786756767679e-26, disciminator loss fake = 2.478107035130961e-07, generator loss = 16.696773529052734\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 434/468, discriminator loss real = 1.858915305320445e-32, disciminator loss fake = 1.5757079552258801e-07, generator loss = 16.875595092773438\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 435/468, discriminator loss real = 6.912022011130254e-20, disciminator loss fake = 1.937882672109481e-07, generator loss = 16.887693405151367\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 436/468, discriminator loss real = 3.399849009189168e-18, disciminator loss fake = 2.160033574227782e-07, generator loss = 16.812896728515625\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 437/468, discriminator loss real = 3.656232013929383e-27, disciminator loss fake = 1.2070256616425468e-07, generator loss = 16.942272186279297\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 438/468, discriminator loss real = 3.215558131796029e-18, disciminator loss fake = 1.431965301890159e-07, generator loss = 16.921106338500977\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 439/468, discriminator loss real = 7.579744123317639e-26, disciminator loss fake = 1.8218543118564412e-07, generator loss = 16.922679901123047\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 440/468, discriminator loss real = 4.830730641406619e-19, disciminator loss fake = 2.0065374428668292e-07, generator loss = 16.864093780517578\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 22, Batch: 441/468, discriminator loss real = 4.7093761474377734e-24, disciminator loss fake = 1.5441823109085817e-07, generator loss = 16.74736976623535\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 22, Batch: 442/468, discriminator loss real = 1.0948849141118243e-27, disciminator loss fake = 1.5841663980609155e-07, generator loss = 16.859600067138672\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 22, Batch: 443/468, discriminator loss real = 6.337024412368601e-23, disciminator loss fake = 1.3714347346649447e-07, generator loss = 16.943334579467773\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 22, Batch: 444/468, discriminator loss real = 1.0154185393928465e-30, disciminator loss fake = 1.6271715708171541e-07, generator loss = 16.873807907104492\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 445/468, discriminator loss real = 2.245063086547816e-07, disciminator loss fake = 1.385857189006856e-07, generator loss = 16.95816421508789\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 446/468, discriminator loss real = 9.744412535895963e-23, disciminator loss fake = 1.2406916027885018e-07, generator loss = 17.159873962402344\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 22, Batch: 447/468, discriminator loss real = 1.3027151891857936e-30, disciminator loss fake = 1.6312523598571715e-07, generator loss = 16.836971282958984\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 22, Batch: 448/468, discriminator loss real = 8.86374565513323e-25, disciminator loss fake = 1.4957004168536514e-07, generator loss = 16.714771270751953\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 449/468, discriminator loss real = 9.434442631572892e-07, disciminator loss fake = 1.421834809889333e-07, generator loss = 16.80398941040039\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 22, Batch: 450/468, discriminator loss real = 2.154695909115836e-25, disciminator loss fake = 1.5373507267213427e-07, generator loss = 16.7965145111084\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 451/468, discriminator loss real = 2.2658819094022116e-25, disciminator loss fake = 9.950698398597524e-08, generator loss = 16.919803619384766\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 22, Batch: 452/468, discriminator loss real = 3.955916393583688e-34, disciminator loss fake = 2.914435981438146e-07, generator loss = 16.817256927490234\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 453/468, discriminator loss real = 1.768099334813921e-19, disciminator loss fake = 1.5184163260073547e-07, generator loss = 16.8697509765625\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 454/468, discriminator loss real = 2.5920798044890376e-22, disciminator loss fake = 1.6100446487143927e-07, generator loss = 16.78186798095703\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 22, Batch: 455/468, discriminator loss real = 1.8683900727010885e-19, disciminator loss fake = 1.1054639514895825e-07, generator loss = 16.854257583618164\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 456/468, discriminator loss real = 2.5013040024034453e-22, disciminator loss fake = 1.1472326377770514e-07, generator loss = 17.053546905517578\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 22, Batch: 457/468, discriminator loss real = 4.73538421805555e-33, disciminator loss fake = 1.433808733963815e-07, generator loss = 16.975406646728516\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 22, Batch: 458/468, discriminator loss real = 1.5806240297123317e-23, disciminator loss fake = 1.2313751085457625e-07, generator loss = 16.962377548217773\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 22, Batch: 459/468, discriminator loss real = 2.0280127957160655e-19, disciminator loss fake = 1.6755397780343628e-07, generator loss = 16.843687057495117\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 22, Batch: 460/468, discriminator loss real = 4.3722796163249694e-21, disciminator loss fake = 1.1557088441804808e-07, generator loss = 16.756696701049805\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 461/468, discriminator loss real = 1.0078482482239029e-20, disciminator loss fake = 1.610970343790541e-07, generator loss = 16.88874626159668\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 462/468, discriminator loss real = 1.0656885657268482e-24, disciminator loss fake = 1.4060616138067417e-07, generator loss = 17.007915496826172\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 22, Batch: 463/468, discriminator loss real = 1.1869015831015372e-31, disciminator loss fake = 1.2471133459257544e-07, generator loss = 16.976659774780273\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 22, Batch: 464/468, discriminator loss real = 2.5081318144191866e-23, disciminator loss fake = 1.6750216502714466e-07, generator loss = 16.814876556396484\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 22, Batch: 465/468, discriminator loss real = 1.2255390876005549e-22, disciminator loss fake = 2.6918863227365364e-07, generator loss = 16.734405517578125\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 22, Batch: 466/468, discriminator loss real = 5.037549471997109e-35, disciminator loss fake = 2.32537274769129e-07, generator loss = 16.71238136291504\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 22, Batch: 467/468, discriminator loss real = 9.572502863024932e-24, disciminator loss fake = 1.1668868182823644e-07, generator loss = 16.903961181640625\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 22, Batch: 468/468, discriminator loss real = 1.2019110884315229e-32, disciminator loss fake = 1.1848526071389642e-07, generator loss = 16.544689178466797\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 23, Batch: 1/468, discriminator loss real = 2.017431143518224e-23, disciminator loss fake = 1.1568632629632702e-07, generator loss = 16.824325561523438\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 23, Batch: 2/468, discriminator loss real = 1.4614058661127638e-12, disciminator loss fake = 8.246348670581938e-08, generator loss = 17.132761001586914\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 23, Batch: 3/468, discriminator loss real = 5.759445953550233e-22, disciminator loss fake = 1.9991217925507954e-07, generator loss = 16.961668014526367\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 23, Batch: 4/468, discriminator loss real = 7.722547052387691e-26, disciminator loss fake = 1.5137609921112016e-07, generator loss = 16.781028747558594\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 23, Batch: 5/468, discriminator loss real = 3.337428204188618e-35, disciminator loss fake = 1.3606489801532007e-07, generator loss = 16.78254508972168\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 23, Batch: 6/468, discriminator loss real = 3.4138345072399917e-29, disciminator loss fake = 1.0666755656529858e-07, generator loss = 16.84051513671875\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 23, Batch: 7/468, discriminator loss real = 1.6162721294676885e-07, disciminator loss fake = 1.869593404535408e-07, generator loss = 16.781089782714844\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 23, Batch: 8/468, discriminator loss real = 8.021363236407011e-19, disciminator loss fake = 1.201602231049037e-07, generator loss = 16.8699893951416\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 23, Batch: 9/468, discriminator loss real = 7.177951687938917e-27, disciminator loss fake = 8.577026022749124e-08, generator loss = 16.957094192504883\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 23, Batch: 10/468, discriminator loss real = 7.186980101640746e-32, disciminator loss fake = 1.5492943816752813e-07, generator loss = 16.81306266784668\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 23, Batch: 11/468, discriminator loss real = 1.6404773741483614e-21, disciminator loss fake = 1.428041827011839e-07, generator loss = 16.91265106201172\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 23, Batch: 12/468, discriminator loss real = 2.714435538767927e-22, disciminator loss fake = 1.0246352388776359e-07, generator loss = 16.717010498046875\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 23, Batch: 13/468, discriminator loss real = 2.5586907609417623e-27, disciminator loss fake = 1.1558804402511669e-07, generator loss = 16.63817024230957\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 23, Batch: 14/468, discriminator loss real = 6.402996767288358e-28, disciminator loss fake = 1.1627211904396972e-07, generator loss = 17.149803161621094\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 23, Batch: 15/468, discriminator loss real = 8.018797075237671e-07, disciminator loss fake = 9.800736222587147e-08, generator loss = 16.84958267211914\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 23, Batch: 16/468, discriminator loss real = 3.128623296739619e-23, disciminator loss fake = 1.9612420487646887e-07, generator loss = 16.63378143310547\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 23, Batch: 17/468, discriminator loss real = 2.9424834964431046e-12, disciminator loss fake = 1.2012061745281244e-07, generator loss = 16.71303939819336\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 23, Batch: 18/468, discriminator loss real = 8.392121423746158e-22, disciminator loss fake = 1.995427965084673e-07, generator loss = 16.73058319091797\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 23, Batch: 19/468, discriminator loss real = 4.636917834671703e-30, disciminator loss fake = 8.890824432228328e-08, generator loss = 17.140949249267578\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 23, Batch: 20/468, discriminator loss real = 4.750980119376496e-23, disciminator loss fake = 2.3197391385565425e-07, generator loss = 16.720609664916992\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 23, Batch: 21/468, discriminator loss real = 5.1798494448157135e-27, disciminator loss fake = 2.5140010961877124e-07, generator loss = 16.653030395507812\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 23, Batch: 22/468, discriminator loss real = 1.7943081079130844e-17, disciminator loss fake = 1.5356359028828592e-07, generator loss = 16.842790603637695\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 23, Batch: 23/468, discriminator loss real = 9.231330185062934e-25, disciminator loss fake = 2.642581762302143e-07, generator loss = 16.675186157226562\n",
      "2/2 [==============================] - 0s 91ms/step\n",
      "Epoch: 23, Batch: 24/468, discriminator loss real = 4.839217514491413e-18, disciminator loss fake = 2.388379414242081e-07, generator loss = 16.761775970458984\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 23, Batch: 25/468, discriminator loss real = 9.258297200417043e-20, disciminator loss fake = 2.3440962593213044e-07, generator loss = 16.899978637695312\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 23, Batch: 26/468, discriminator loss real = 4.602230791315553e-25, disciminator loss fake = 2.5229769562429283e-07, generator loss = 16.64557456970215\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 23, Batch: 27/468, discriminator loss real = 2.9072005105493985e-16, disciminator loss fake = 1.42269769298764e-07, generator loss = 16.81346893310547\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 23, Batch: 28/468, discriminator loss real = 5.96222776105596e-23, disciminator loss fake = 1.2502553659032856e-07, generator loss = 16.882007598876953\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 23, Batch: 29/468, discriminator loss real = 3.995566001951243e-26, disciminator loss fake = 1.6759098286911467e-07, generator loss = 16.67236328125\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 23, Batch: 30/468, discriminator loss real = 2.1943829860840024e-19, disciminator loss fake = 1.6819001302792458e-07, generator loss = 16.911623001098633\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 23, Batch: 31/468, discriminator loss real = 4.7864692590026455e-15, disciminator loss fake = 2.3404625437706272e-07, generator loss = 16.94881820678711\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 23, Batch: 32/468, discriminator loss real = 5.20548935987325e-13, disciminator loss fake = 1.346870419638435e-07, generator loss = 17.125560760498047\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 23, Batch: 33/468, discriminator loss real = 3.8685160531572617e-28, disciminator loss fake = 2.1100353819747397e-07, generator loss = 16.644079208374023\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 23, Batch: 34/468, discriminator loss real = 1.49141006472696e-34, disciminator loss fake = 1.2072526089923485e-07, generator loss = 17.067981719970703\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 23, Batch: 35/468, discriminator loss real = 2.9075308533988277e-16, disciminator loss fake = 1.4035381923349632e-07, generator loss = 16.691072463989258\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 23, Batch: 36/468, discriminator loss real = 6.214702614885854e-24, disciminator loss fake = 1.1386764242615754e-07, generator loss = 17.13520050048828\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 23, Batch: 37/468, discriminator loss real = 4.342833505548641e-24, disciminator loss fake = 3.818848881564918e-07, generator loss = 16.689109802246094\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 23, Batch: 38/468, discriminator loss real = 1.8407322549446123e-19, disciminator loss fake = 1.2163332030468155e-07, generator loss = 16.94954490661621\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 23, Batch: 39/468, discriminator loss real = 3.3141992299061023e-28, disciminator loss fake = 1.655934340760723e-07, generator loss = 16.746906280517578\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 23, Batch: 40/468, discriminator loss real = 7.855562501776864e-29, disciminator loss fake = 1.4755227084606304e-07, generator loss = 16.909748077392578\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 23, Batch: 41/468, discriminator loss real = 2.822591465645819e-26, disciminator loss fake = 1.0590100885110587e-07, generator loss = 16.969768524169922\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 23, Batch: 42/468, discriminator loss real = 3.566233125484979e-38, disciminator loss fake = 2.3228248835494014e-07, generator loss = 16.572296142578125\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 23, Batch: 43/468, discriminator loss real = 1.831171687414456e-27, disciminator loss fake = 1.805880316396724e-07, generator loss = 17.050682067871094\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 23, Batch: 44/468, discriminator loss real = 5.93029008370866e-17, disciminator loss fake = 1.3279429822432576e-07, generator loss = 16.51131820678711\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 23, Batch: 45/468, discriminator loss real = 2.927861403843879e-13, disciminator loss fake = 1.704898267007593e-07, generator loss = 16.666828155517578\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 23, Batch: 46/468, discriminator loss real = 1.4697276598876763e-12, disciminator loss fake = 1.1863852478199988e-07, generator loss = 16.770626068115234\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 23, Batch: 47/468, discriminator loss real = 6.988816942211794e-19, disciminator loss fake = 8.715302612927189e-08, generator loss = 16.948556900024414\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 23, Batch: 48/468, discriminator loss real = 5.630196422985185e-25, disciminator loss fake = 1.7330664547898778e-07, generator loss = 17.08108901977539\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 23, Batch: 49/468, discriminator loss real = 4.248786155294134e-21, disciminator loss fake = 1.630997701340675e-07, generator loss = 16.899105072021484\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 23, Batch: 50/468, discriminator loss real = 8.227954826923238e-26, disciminator loss fake = 1.4956717109271267e-07, generator loss = 16.754913330078125\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 23, Batch: 51/468, discriminator loss real = 4.753440851408602e-27, disciminator loss fake = 1.5246300222315767e-07, generator loss = 17.012060165405273\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 23, Batch: 52/468, discriminator loss real = 5.052751164809778e-26, disciminator loss fake = 1.3055182535026688e-07, generator loss = 16.842077255249023\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 23, Batch: 53/468, discriminator loss real = 1.4157887179382834e-29, disciminator loss fake = 1.6723170404020493e-07, generator loss = 16.960617065429688\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 23, Batch: 54/468, discriminator loss real = 8.323618386525676e-26, disciminator loss fake = 9.281256296844731e-08, generator loss = 16.889982223510742\n",
      "2/2 [==============================] - 0s 96ms/step\n",
      "Epoch: 23, Batch: 55/468, discriminator loss real = 2.897376907658195e-30, disciminator loss fake = 1.4925747393590427e-07, generator loss = 17.183494567871094\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 23, Batch: 56/468, discriminator loss real = 4.02093472071652e-30, disciminator loss fake = 1.8468639950697252e-07, generator loss = 16.883113861083984\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 23, Batch: 57/468, discriminator loss real = 0.0, disciminator loss fake = 1.0202737854569932e-07, generator loss = 17.080726623535156\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 23, Batch: 58/468, discriminator loss real = 2.3682063807325975e-21, disciminator loss fake = 1.611579989457823e-07, generator loss = 16.943740844726562\n",
      "2/2 [==============================] - 0s 100ms/step\n",
      "Epoch: 23, Batch: 59/468, discriminator loss real = 5.599611994520828e-15, disciminator loss fake = 1.0542434125682121e-07, generator loss = 16.967456817626953\n",
      "2/2 [==============================] - 0s 98ms/step\n",
      "Epoch: 23, Batch: 60/468, discriminator loss real = 5.4659724300589645e-16, disciminator loss fake = 9.476860896029393e-08, generator loss = 16.98546600341797\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 23, Batch: 61/468, discriminator loss real = 1.237332797996628e-26, disciminator loss fake = 1.430783811429137e-07, generator loss = 16.599761962890625\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Epoch: 23, Batch: 62/468, discriminator loss real = 7.3196724699451375e-22, disciminator loss fake = 2.0519017596143385e-07, generator loss = 17.16730499267578\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 23, Batch: 63/468, discriminator loss real = 1.687247775591571e-17, disciminator loss fake = 1.4346477428262006e-07, generator loss = 16.69617462158203\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 23, Batch: 64/468, discriminator loss real = 2.0992789208086478e-31, disciminator loss fake = 1.213320928172834e-07, generator loss = 16.91401481628418\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 23, Batch: 65/468, discriminator loss real = 1.3082829090904635e-12, disciminator loss fake = 1.861107392642225e-07, generator loss = 16.995315551757812\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 23, Batch: 66/468, discriminator loss real = 5.940912273913923e-16, disciminator loss fake = 1.8276257662819262e-07, generator loss = 16.871875762939453\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 23, Batch: 67/468, discriminator loss real = 1.9856906307739765e-35, disciminator loss fake = 1.3732312709180405e-07, generator loss = 17.2481746673584\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 23, Batch: 68/468, discriminator loss real = 4.810073437351112e-22, disciminator loss fake = 1.3121803021931555e-07, generator loss = 16.87639808654785\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 23, Batch: 69/468, discriminator loss real = 2.150268575196703e-24, disciminator loss fake = 1.2408662541929516e-07, generator loss = 16.729270935058594\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 23, Batch: 70/468, discriminator loss real = 2.25183697566684e-30, disciminator loss fake = 1.3145012189852423e-07, generator loss = 17.167022705078125\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 23, Batch: 71/468, discriminator loss real = 3.625165046435217e-19, disciminator loss fake = 1.9762885017371445e-07, generator loss = 16.897380828857422\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 23, Batch: 72/468, discriminator loss real = 1.0124594267292005e-22, disciminator loss fake = 1.455705387343187e-07, generator loss = 17.2149658203125\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 23, Batch: 73/468, discriminator loss real = 1.3093101618073442e-25, disciminator loss fake = 1.351313443365143e-07, generator loss = 16.767913818359375\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 23, Batch: 74/468, discriminator loss real = 3.738275161268267e-21, disciminator loss fake = 1.0093683044942736e-07, generator loss = 16.888629913330078\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 23, Batch: 75/468, discriminator loss real = 1.370739242598229e-12, disciminator loss fake = 8.991834477001248e-08, generator loss = 16.982093811035156\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 23, Batch: 76/468, discriminator loss real = 5.485367415613638e-27, disciminator loss fake = 1.1919473053012553e-07, generator loss = 16.836109161376953\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "Epoch: 23, Batch: 77/468, discriminator loss real = 3.0698149882936023e-25, disciminator loss fake = 1.3455581893140334e-07, generator loss = 16.958541870117188\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 23, Batch: 78/468, discriminator loss real = 8.990934315179596e-28, disciminator loss fake = 1.2692339623754378e-07, generator loss = 17.05925750732422\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 23, Batch: 79/468, discriminator loss real = 8.169612462599045e-29, disciminator loss fake = 7.086417497248476e-08, generator loss = 17.13842010498047\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 23, Batch: 80/468, discriminator loss real = 1.553673657659773e-17, disciminator loss fake = 9.695099123518958e-08, generator loss = 16.750104904174805\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 23, Batch: 81/468, discriminator loss real = 2.3712309893397787e-09, disciminator loss fake = 1.354749770143826e-07, generator loss = 16.9768123626709\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 23, Batch: 82/468, discriminator loss real = 7.587959832311604e-27, disciminator loss fake = 7.078469366206264e-08, generator loss = 16.99102783203125\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 23, Batch: 83/468, discriminator loss real = 8.55513621332128e-33, disciminator loss fake = 9.864915284651943e-08, generator loss = 17.036130905151367\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 23, Batch: 84/468, discriminator loss real = 6.1516642634776565e-21, disciminator loss fake = 1.217476892634295e-07, generator loss = 17.119020462036133\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 23, Batch: 85/468, discriminator loss real = 1.0389548966704863e-17, disciminator loss fake = 9.187824190348692e-08, generator loss = 16.856233596801758\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 23, Batch: 86/468, discriminator loss real = 1.1265944774296877e-14, disciminator loss fake = 9.825013336239863e-08, generator loss = 16.91994857788086\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 23, Batch: 87/468, discriminator loss real = 1.6742566757889638e-22, disciminator loss fake = 1.4860728470011964e-07, generator loss = 16.813335418701172\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 23, Batch: 88/468, discriminator loss real = 6.133956376549099e-15, disciminator loss fake = 1.0141189221712921e-07, generator loss = 17.033687591552734\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 23, Batch: 89/468, discriminator loss real = 5.4015219048606216e-15, disciminator loss fake = 3.913410751010815e-07, generator loss = 17.06371307373047\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "Epoch: 23, Batch: 90/468, discriminator loss real = 6.085259217809044e-25, disciminator loss fake = 8.260951034344544e-08, generator loss = 16.820905685424805\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 23, Batch: 91/468, discriminator loss real = 2.715466241642456e-31, disciminator loss fake = 1.5694264732246666e-07, generator loss = 16.905704498291016\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 23, Batch: 92/468, discriminator loss real = 5.862107509010838e-20, disciminator loss fake = 1.141308416663378e-07, generator loss = 16.826068878173828\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 23, Batch: 93/468, discriminator loss real = 2.748761233819369e-13, disciminator loss fake = 1.1488137374726648e-07, generator loss = 17.0762939453125\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 23, Batch: 94/468, discriminator loss real = 5.763321270961866e-14, disciminator loss fake = 1.7726586065691663e-07, generator loss = 16.979679107666016\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 23, Batch: 95/468, discriminator loss real = 1.7072521425565903e-32, disciminator loss fake = 1.7493493942311034e-07, generator loss = 17.04094696044922\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 23, Batch: 96/468, discriminator loss real = 1.1323223605475915e-22, disciminator loss fake = 1.1443333391980559e-07, generator loss = 16.95564842224121\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 23, Batch: 97/468, discriminator loss real = 2.3422355715292786e-26, disciminator loss fake = 1.644526150812453e-07, generator loss = 16.834209442138672\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 23, Batch: 98/468, discriminator loss real = 2.2991470989523983e-22, disciminator loss fake = 9.763077457591862e-08, generator loss = 16.610736846923828\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 23, Batch: 99/468, discriminator loss real = 1.7333862351190386e-18, disciminator loss fake = 1.667702491658929e-07, generator loss = 16.842044830322266\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 23, Batch: 100/468, discriminator loss real = 3.315457836409505e-31, disciminator loss fake = 1.0841148423423874e-07, generator loss = 16.788719177246094\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 23, Batch: 101/468, discriminator loss real = 3.46757000770966e-35, disciminator loss fake = 8.300527554183645e-08, generator loss = 16.92566680908203\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 23, Batch: 102/468, discriminator loss real = 3.958620872420623e-25, disciminator loss fake = 1.118565648994263e-07, generator loss = 16.747955322265625\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 23, Batch: 103/468, discriminator loss real = 2.703760294345242e-22, disciminator loss fake = 1.4446129625866888e-07, generator loss = 17.107425689697266\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 23, Batch: 104/468, discriminator loss real = 4.748754801927435e-25, disciminator loss fake = 1.1296769741875323e-07, generator loss = 16.89168930053711\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 23, Batch: 105/468, discriminator loss real = 1.8575033872147984e-11, disciminator loss fake = 1.3421620792541944e-07, generator loss = 16.854053497314453\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 23, Batch: 106/468, discriminator loss real = 1.535478771190625e-26, disciminator loss fake = 2.2288668333203532e-07, generator loss = 16.892139434814453\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 23, Batch: 107/468, discriminator loss real = 9.309864484148209e-15, disciminator loss fake = 9.034347669967246e-08, generator loss = 17.161502838134766\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 23, Batch: 108/468, discriminator loss real = 5.61805051264852e-13, disciminator loss fake = 3.6458501995184633e-07, generator loss = 16.914287567138672\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 23, Batch: 109/468, discriminator loss real = 0.00014926119183655828, disciminator loss fake = 1.7822330278249865e-07, generator loss = 16.609416961669922\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 23, Batch: 110/468, discriminator loss real = 5.406547577081624e-26, disciminator loss fake = 1.8842887072878511e-07, generator loss = 16.487762451171875\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 23, Batch: 111/468, discriminator loss real = 8.925163037206795e-26, disciminator loss fake = 2.3801445081517159e-07, generator loss = 16.54511260986328\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 23, Batch: 112/468, discriminator loss real = 3.516521539292788e-22, disciminator loss fake = 1.735105570332962e-07, generator loss = 16.214609146118164\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 23, Batch: 113/468, discriminator loss real = 3.243422891374692e-11, disciminator loss fake = 1.932888977762559e-07, generator loss = 16.176179885864258\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 23, Batch: 114/468, discriminator loss real = 8.121236244550742e-25, disciminator loss fake = 3.603225025017309e-07, generator loss = 16.171356201171875\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 23, Batch: 115/468, discriminator loss real = 1.1882181367744581e-31, disciminator loss fake = 2.1350582812829089e-07, generator loss = 16.228038787841797\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 23, Batch: 116/468, discriminator loss real = 1.7411532837741106e-07, disciminator loss fake = 2.994450483129185e-07, generator loss = 16.457923889160156\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 23, Batch: 117/468, discriminator loss real = 4.418800447845408e-22, disciminator loss fake = 3.289977428266866e-07, generator loss = 16.106586456298828\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "Epoch: 23, Batch: 118/468, discriminator loss real = 1.354515087486417e-30, disciminator loss fake = 2.2805524224622786e-07, generator loss = 15.915644645690918\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 23, Batch: 119/468, discriminator loss real = 2.4697597131645173e-26, disciminator loss fake = 3.1329977900895756e-07, generator loss = 16.15451431274414\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 23, Batch: 120/468, discriminator loss real = 2.6476265377845024e-35, disciminator loss fake = 3.0017730523468344e-07, generator loss = 15.961091995239258\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 23, Batch: 121/468, discriminator loss real = 1.9850626351014533e-11, disciminator loss fake = 2.8102866167500906e-07, generator loss = 15.998419761657715\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 23, Batch: 122/468, discriminator loss real = 3.0034375712949035e-22, disciminator loss fake = 3.2837121466400276e-07, generator loss = 15.901729583740234\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 23, Batch: 123/468, discriminator loss real = 9.135315952136221e-25, disciminator loss fake = 2.1026697538673034e-07, generator loss = 15.899569511413574\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 23, Batch: 124/468, discriminator loss real = 3.431438244660967e-08, disciminator loss fake = 2.8787570727217826e-07, generator loss = 15.811361312866211\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 23, Batch: 125/468, discriminator loss real = 1.7215931947449446e-15, disciminator loss fake = 5.985522193441284e-07, generator loss = 15.961389541625977\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 23, Batch: 126/468, discriminator loss real = 2.1491545063833045e-23, disciminator loss fake = 3.1639581266063033e-07, generator loss = 15.703512191772461\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 23, Batch: 127/468, discriminator loss real = 2.8203047008901194e-08, disciminator loss fake = 4.672400280014699e-07, generator loss = 16.16980743408203\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 23, Batch: 128/468, discriminator loss real = 9.119476421908898e-22, disciminator loss fake = 1.9827879782496893e-07, generator loss = 16.08724021911621\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 23, Batch: 129/468, discriminator loss real = 1.662884282379565e-15, disciminator loss fake = 2.9099271614541067e-07, generator loss = 15.641268730163574\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 23, Batch: 130/468, discriminator loss real = 6.791376563342055e-07, disciminator loss fake = 3.678067628243298e-07, generator loss = 16.09420394897461\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 23, Batch: 131/468, discriminator loss real = 1.0714506029938088e-25, disciminator loss fake = 2.3198229825993621e-07, generator loss = 15.999313354492188\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 23, Batch: 132/468, discriminator loss real = 3.135286127942116e-11, disciminator loss fake = 4.88070895698911e-07, generator loss = 16.27785873413086\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 23, Batch: 133/468, discriminator loss real = 4.1439636521854455e-31, disciminator loss fake = 3.3721107683959417e-07, generator loss = 16.215198516845703\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 23, Batch: 134/468, discriminator loss real = 3.2369979717883e-26, disciminator loss fake = 2.343958556139114e-07, generator loss = 16.195226669311523\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 23, Batch: 135/468, discriminator loss real = 4.020956537891671e-28, disciminator loss fake = 3.9066011936483847e-07, generator loss = 15.840621948242188\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 23, Batch: 136/468, discriminator loss real = 2.140951512910081e-19, disciminator loss fake = 4.324893438933941e-07, generator loss = 16.054094314575195\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 23, Batch: 137/468, discriminator loss real = 9.185530871036462e-06, disciminator loss fake = 2.672070991138753e-07, generator loss = 16.128189086914062\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 23, Batch: 138/468, discriminator loss real = 5.900944613055832e-32, disciminator loss fake = 5.643898930429714e-07, generator loss = 16.042816162109375\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 23, Batch: 139/468, discriminator loss real = 2.2827364091327787e-20, disciminator loss fake = 5.044336148785078e-07, generator loss = 15.804325103759766\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 23, Batch: 140/468, discriminator loss real = 5.447870887048678e-13, disciminator loss fake = 2.000206791308301e-07, generator loss = 15.888336181640625\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 23, Batch: 141/468, discriminator loss real = 8.448570132867675e-24, disciminator loss fake = 4.664735513415508e-07, generator loss = 15.88479232788086\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 23, Batch: 142/468, discriminator loss real = 5.794696263112974e-30, disciminator loss fake = 2.704279609133664e-07, generator loss = 16.01087188720703\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 23, Batch: 143/468, discriminator loss real = 1.1636663160451446e-21, disciminator loss fake = 3.514719537633937e-07, generator loss = 15.961938858032227\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 23, Batch: 144/468, discriminator loss real = 1.8989628642884782e-06, disciminator loss fake = 2.800966854010767e-07, generator loss = 15.976945877075195\n",
      "2/2 [==============================] - 0s 84ms/step\n",
      "Epoch: 23, Batch: 145/468, discriminator loss real = 1.8014168882938997e-28, disciminator loss fake = 4.55330564363976e-07, generator loss = 15.785743713378906\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 23, Batch: 146/468, discriminator loss real = 3.2006587936219716e-33, disciminator loss fake = 3.543676143635821e-07, generator loss = 15.828303337097168\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 23, Batch: 147/468, discriminator loss real = 1.591458771732828e-17, disciminator loss fake = 2.5816240167841897e-07, generator loss = 15.97886848449707\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 23, Batch: 148/468, discriminator loss real = 1.5114339674158213e-21, disciminator loss fake = 7.268612307598232e-07, generator loss = 16.068374633789062\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 23, Batch: 149/468, discriminator loss real = 1.623447449830253e-29, disciminator loss fake = 2.4927027197918505e-07, generator loss = 16.159160614013672\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Epoch: 23, Batch: 150/468, discriminator loss real = 4.419585517780941e-28, disciminator loss fake = 4.2841878666877165e-07, generator loss = 16.065759658813477\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 23, Batch: 151/468, discriminator loss real = 2.4927255780347414e-19, disciminator loss fake = 3.4461299946997315e-07, generator loss = 15.89133071899414\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 23, Batch: 152/468, discriminator loss real = 4.049989404868876e-24, disciminator loss fake = 2.664115754669183e-07, generator loss = 15.722922325134277\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 23, Batch: 153/468, discriminator loss real = 2.87848213012564e-23, disciminator loss fake = 4.363321295386413e-07, generator loss = 16.012611389160156\n",
      "2/2 [==============================] - 0s 94ms/step\n",
      "Epoch: 23, Batch: 154/468, discriminator loss real = 1.921803701715116e-21, disciminator loss fake = 2.801696155074751e-07, generator loss = 15.942654609680176\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 23, Batch: 155/468, discriminator loss real = 1.6144064265535024e-31, disciminator loss fake = 3.3185659731316264e-07, generator loss = 15.866557121276855\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 23, Batch: 156/468, discriminator loss real = 4.029670777010882e-20, disciminator loss fake = 3.2873634836505516e-07, generator loss = 16.041677474975586\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 23, Batch: 157/468, discriminator loss real = 2.470606818705155e-30, disciminator loss fake = 1.9553957031348546e-07, generator loss = 15.997581481933594\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 23, Batch: 158/468, discriminator loss real = 3.1448023049188535e-15, disciminator loss fake = 3.7890910675741907e-07, generator loss = 16.125377655029297\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 23, Batch: 159/468, discriminator loss real = 5.6167132528617505e-31, disciminator loss fake = 2.746151039900724e-07, generator loss = 15.706183433532715\n",
      "2/2 [==============================] - 0s 83ms/step\n",
      "Epoch: 23, Batch: 160/468, discriminator loss real = 1.70453812828557e-29, disciminator loss fake = 2.9068900175843737e-07, generator loss = 15.89887523651123\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 23, Batch: 161/468, discriminator loss real = 6.66971794634208e-13, disciminator loss fake = 3.338465432989324e-07, generator loss = 15.830747604370117\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 23, Batch: 162/468, discriminator loss real = 7.736366424022088e-16, disciminator loss fake = 3.3049002468032995e-07, generator loss = 15.994878768920898\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 23, Batch: 163/468, discriminator loss real = 2.2519766878081647e-23, disciminator loss fake = 4.00543143541654e-07, generator loss = 15.947771072387695\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 23, Batch: 164/468, discriminator loss real = 1.4782818591269386e-32, disciminator loss fake = 3.5760132277573575e-07, generator loss = 15.985252380371094\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 23, Batch: 165/468, discriminator loss real = 3.2836857800174325e-25, disciminator loss fake = 3.2474306976837397e-07, generator loss = 15.995245933532715\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 23, Batch: 166/468, discriminator loss real = 4.1118972858621643e-25, disciminator loss fake = 3.851931751341908e-07, generator loss = 16.034076690673828\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 23, Batch: 167/468, discriminator loss real = 9.10750761915105e-25, disciminator loss fake = 3.973175068949786e-07, generator loss = 15.896705627441406\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 23, Batch: 168/468, discriminator loss real = 5.487832654090703e-29, disciminator loss fake = 3.2312703979187063e-07, generator loss = 15.899764060974121\n",
      "2/2 [==============================] - 0s 95ms/step\n",
      "Epoch: 23, Batch: 169/468, discriminator loss real = 3.3519767584182742e-18, disciminator loss fake = 4.3653483317029895e-07, generator loss = 16.056745529174805\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 23, Batch: 170/468, discriminator loss real = 3.588163741003298e-22, disciminator loss fake = 2.6221559323857946e-07, generator loss = 15.667737007141113\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "Epoch: 23, Batch: 171/468, discriminator loss real = 6.308525589433089e-25, disciminator loss fake = 2.9867106832170975e-07, generator loss = 15.97119140625\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 23, Batch: 172/468, discriminator loss real = 8.91265461433477e-09, disciminator loss fake = 2.641287153437588e-07, generator loss = 15.914091110229492\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 23, Batch: 173/468, discriminator loss real = 5.957635351270683e-17, disciminator loss fake = 4.018534411898145e-07, generator loss = 16.080888748168945\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 23, Batch: 174/468, discriminator loss real = 1.2965283204883855e-19, disciminator loss fake = 2.6917675199911173e-07, generator loss = 15.974885940551758\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 23, Batch: 175/468, discriminator loss real = 3.963658856072309e-21, disciminator loss fake = 2.0892136376460257e-07, generator loss = 16.104434967041016\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 23, Batch: 176/468, discriminator loss real = 5.271384658026561e-27, disciminator loss fake = 3.594964823605551e-07, generator loss = 16.006196975708008\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 23, Batch: 177/468, discriminator loss real = 8.999865685281075e-19, disciminator loss fake = 5.573034513872699e-07, generator loss = 16.092851638793945\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 23, Batch: 178/468, discriminator loss real = 8.755723327486049e-19, disciminator loss fake = 3.466350335656898e-07, generator loss = 15.825201034545898\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 23, Batch: 179/468, discriminator loss real = 3.6258945163379122e-19, disciminator loss fake = 2.639395120240806e-07, generator loss = 16.12886619567871\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "Epoch: 23, Batch: 180/468, discriminator loss real = 1.9836939760232533e-27, disciminator loss fake = 2.9231262033135863e-07, generator loss = 16.06854820251465\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 23, Batch: 181/468, discriminator loss real = 1.8422599410117757e-22, disciminator loss fake = 3.014004619217303e-07, generator loss = 16.130844116210938\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Epoch: 23, Batch: 182/468, discriminator loss real = 2.1768478404397829e-13, disciminator loss fake = 3.3721795489327633e-07, generator loss = 15.847312927246094\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 23, Batch: 183/468, discriminator loss real = 2.453564870271923e-37, disciminator loss fake = 2.6382809892311343e-07, generator loss = 16.02000617980957\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 23, Batch: 184/468, discriminator loss real = 4.443821979799315e-23, disciminator loss fake = 2.2184765668953332e-07, generator loss = 15.959972381591797\n",
      "2/2 [==============================] - 0s 89ms/step\n",
      "Epoch: 23, Batch: 185/468, discriminator loss real = 3.725927552600261e-12, disciminator loss fake = 5.082068241790694e-07, generator loss = 16.119461059570312\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 23, Batch: 186/468, discriminator loss real = 3.319316063308324e-24, disciminator loss fake = 3.632885068327596e-07, generator loss = 16.024673461914062\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 23, Batch: 187/468, discriminator loss real = 5.186274614484732e-21, disciminator loss fake = 3.7350108073042065e-07, generator loss = 16.066267013549805\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 23, Batch: 188/468, discriminator loss real = 1.8311484318103777e-28, disciminator loss fake = 2.869006721084588e-07, generator loss = 15.91937255859375\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 23, Batch: 189/468, discriminator loss real = 1.5890867517886787e-38, disciminator loss fake = 4.039718248805002e-07, generator loss = 15.983147621154785\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 23, Batch: 190/468, discriminator loss real = 2.045679693389579e-18, disciminator loss fake = 3.863329425257689e-07, generator loss = 16.237079620361328\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 23, Batch: 191/468, discriminator loss real = 2.813615148929721e-17, disciminator loss fake = 3.3412442235203343e-07, generator loss = 15.798686981201172\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 23, Batch: 192/468, discriminator loss real = 2.923581403884918e-32, disciminator loss fake = 2.5731355890457053e-07, generator loss = 16.055694580078125\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 23, Batch: 193/468, discriminator loss real = 1.1356309457360061e-24, disciminator loss fake = 3.359416211878852e-07, generator loss = 16.265859603881836\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "Epoch: 23, Batch: 194/468, discriminator loss real = 1.79849679833382e-15, disciminator loss fake = 3.8606657426498714e-07, generator loss = 15.889750480651855\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 23, Batch: 195/468, discriminator loss real = 1.5912147831877633e-25, disciminator loss fake = 4.629507657227805e-07, generator loss = 16.021156311035156\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 23, Batch: 196/468, discriminator loss real = 3.141549579287389e-17, disciminator loss fake = 2.918396546647273e-07, generator loss = 16.04784393310547\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "Epoch: 23, Batch: 197/468, discriminator loss real = 0.0, disciminator loss fake = 2.592823307168146e-07, generator loss = 16.24489402770996\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 23, Batch: 198/468, discriminator loss real = 5.843652816214741e-24, disciminator loss fake = 4.796479515789542e-07, generator loss = 15.715216636657715\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 23, Batch: 199/468, discriminator loss real = 1.5657658801624408e-17, disciminator loss fake = 3.8895586840226315e-07, generator loss = 16.06814193725586\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 23, Batch: 200/468, discriminator loss real = 7.211282224261301e-21, disciminator loss fake = 3.036176110526867e-07, generator loss = 16.03701400756836\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 23, Batch: 201/468, discriminator loss real = 1.1827504359088077e-23, disciminator loss fake = 2.979026305638399e-07, generator loss = 15.976455688476562\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 23, Batch: 202/468, discriminator loss real = 8.306073257176946e-25, disciminator loss fake = 2.670906269486295e-07, generator loss = 16.05031967163086\n",
      "2/2 [==============================] - 0s 85ms/step\n",
      "Epoch: 23, Batch: 203/468, discriminator loss real = 1.1178091619433684e-27, disciminator loss fake = 2.499811557754583e-07, generator loss = 16.26640510559082\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 23, Batch: 204/468, discriminator loss real = 1.5875703972984904e-19, disciminator loss fake = 1.28766419038584e-06, generator loss = 16.057348251342773\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Epoch: 23, Batch: 205/468, discriminator loss real = 5.94031095685534e-25, disciminator loss fake = 4.037767951103888e-07, generator loss = 16.117708206176758\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 23, Batch: 206/468, discriminator loss real = 4.774319606326571e-09, disciminator loss fake = 2.7993044682261825e-07, generator loss = 16.105907440185547\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 23, Batch: 207/468, discriminator loss real = 5.019087938691069e-18, disciminator loss fake = 3.4324091302551096e-07, generator loss = 16.106361389160156\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 23, Batch: 208/468, discriminator loss real = 4.5880046737963495e-35, disciminator loss fake = 2.853885234799236e-07, generator loss = 15.84729290008545\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Epoch: 23, Batch: 209/468, discriminator loss real = 4.5510454528726746e-24, disciminator loss fake = 3.044092977688706e-07, generator loss = 15.894243240356445\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 23, Batch: 210/468, discriminator loss real = 3.5408323487415487e-36, disciminator loss fake = 2.9646380994563515e-07, generator loss = 16.057559967041016\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "Epoch: 23, Batch: 211/468, discriminator loss real = 1.0027297128838085e-16, disciminator loss fake = 4.0658574107510503e-07, generator loss = 16.0172176361084\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 23, Batch: 212/468, discriminator loss real = 0.0, disciminator loss fake = 5.096701443108032e-07, generator loss = 16.21934700012207\n",
      "2/2 [==============================] - 0s 81ms/step\n",
      "Epoch: 23, Batch: 213/468, discriminator loss real = 1.5910932637811979e-15, disciminator loss fake = 4.550525432023278e-07, generator loss = 16.184371948242188\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 23, Batch: 214/468, discriminator loss real = 4.6247983938751774e-30, disciminator loss fake = 4.192111191514414e-07, generator loss = 16.104503631591797\n",
      "2/2 [==============================] - 0s 90ms/step\n",
      "Epoch: 23, Batch: 215/468, discriminator loss real = 4.1642658878331867e-29, disciminator loss fake = 3.31731683900216e-07, generator loss = 16.290529251098633\n",
      "2/2 [==============================] - 0s 82ms/step\n",
      "Epoch: 23, Batch: 216/468, discriminator loss real = 2.516316044420819e-10, disciminator loss fake = 3.5041034607274923e-07, generator loss = 16.11573028564453\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "Epoch: 23, Batch: 217/468, discriminator loss real = 1.567685270055809e-17, disciminator loss fake = 3.1507317999057705e-07, generator loss = 15.998260498046875\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 23, Batch: 218/468, discriminator loss real = 1.0251156744342948e-24, disciminator loss fake = 4.30486693403509e-07, generator loss = 16.01815414428711\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 23, Batch: 219/468, discriminator loss real = 2.3241671072056896e-19, disciminator loss fake = 2.1780783754365984e-07, generator loss = 15.978232383728027\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 23, Batch: 220/468, discriminator loss real = 5.70830755627552e-24, disciminator loss fake = 3.8517171674357087e-07, generator loss = 16.350276947021484\n",
      "2/2 [==============================] - 0s 102ms/step\n",
      "Epoch: 23, Batch: 221/468, discriminator loss real = 2.8888126793722284e-27, disciminator loss fake = 2.546479436205118e-07, generator loss = 16.16118812561035\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 23, Batch: 222/468, discriminator loss real = 3.4599678985204493e-38, disciminator loss fake = 3.56227218389904e-07, generator loss = 16.2533016204834\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 23, Batch: 223/468, discriminator loss real = 6.967843402955198e-12, disciminator loss fake = 2.1148852624719439e-07, generator loss = 15.992570877075195\n",
      "2/2 [==============================] - 0s 144ms/step\n",
      "Epoch: 23, Batch: 224/468, discriminator loss real = 3.4597139280416793e-25, disciminator loss fake = 2.3089765477379842e-07, generator loss = 15.949029922485352\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 23, Batch: 225/468, discriminator loss real = 2.5001075293134764e-14, disciminator loss fake = 3.045680330160394e-07, generator loss = 16.04168128967285\n",
      "2/2 [==============================] - 0s 174ms/step\n",
      "Epoch: 23, Batch: 226/468, discriminator loss real = 7.249321420559681e-16, disciminator loss fake = 2.9813338642270537e-07, generator loss = 16.02737808227539\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 23, Batch: 227/468, discriminator loss real = 2.370108109772673e-09, disciminator loss fake = 3.9904267623569467e-07, generator loss = 16.16754913330078\n",
      "2/2 [==============================] - 0s 179ms/step\n",
      "Epoch: 23, Batch: 228/468, discriminator loss real = 4.834689734613451e-21, disciminator loss fake = 2.2936265509088116e-07, generator loss = 15.819087028503418\n",
      "2/2 [==============================] - 0s 136ms/step\n",
      "Epoch: 23, Batch: 229/468, discriminator loss real = 1.3682462754640166e-18, disciminator loss fake = 3.2175870501305326e-07, generator loss = 16.132102966308594\n",
      "2/2 [==============================] - 0s 263ms/step\n",
      "Epoch: 23, Batch: 230/468, discriminator loss real = 1.4381655005502055e-22, disciminator loss fake = 2.067493767299311e-07, generator loss = 16.15683937072754\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 23, Batch: 231/468, discriminator loss real = 2.423521294865118e-33, disciminator loss fake = 3.8894091858310276e-07, generator loss = 16.416839599609375\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 23, Batch: 232/468, discriminator loss real = 3.208276002289414e-24, disciminator loss fake = 1.8362172227170959e-07, generator loss = 16.143508911132812\n",
      "2/2 [==============================] - 0s 137ms/step\n",
      "Epoch: 23, Batch: 233/468, discriminator loss real = 1.8653756859928646e-21, disciminator loss fake = 3.4079172905876476e-07, generator loss = 16.275432586669922\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 23, Batch: 234/468, discriminator loss real = 6.687837041589882e-22, disciminator loss fake = 3.7509735761886986e-07, generator loss = 16.052043914794922\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 23, Batch: 235/468, discriminator loss real = 3.033093661066984e-24, disciminator loss fake = 1.7142802732905693e-07, generator loss = 16.06904411315918\n",
      "2/2 [==============================] - 0s 183ms/step\n",
      "Epoch: 23, Batch: 236/468, discriminator loss real = 3.257301311347488e-32, disciminator loss fake = 3.7700650068472896e-07, generator loss = 16.300350189208984\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 23, Batch: 237/468, discriminator loss real = 9.43844700817606e-29, disciminator loss fake = 1.838196226344735e-07, generator loss = 15.924633026123047\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 23, Batch: 238/468, discriminator loss real = 8.431325967956567e-21, disciminator loss fake = 3.6262400726627675e-07, generator loss = 16.251197814941406\n",
      "2/2 [==============================] - 0s 195ms/step\n",
      "Epoch: 23, Batch: 239/468, discriminator loss real = 3.3396076901011874e-34, disciminator loss fake = 3.757270974347193e-07, generator loss = 16.350921630859375\n",
      "2/2 [==============================] - 0s 169ms/step\n",
      "Epoch: 23, Batch: 240/468, discriminator loss real = 2.2777942032536913e-10, disciminator loss fake = 3.111458681814838e-07, generator loss = 16.07698631286621\n",
      "2/2 [==============================] - 0s 209ms/step\n",
      "Epoch: 23, Batch: 241/468, discriminator loss real = 1.24492195864626e-28, disciminator loss fake = 2.9403389589788276e-07, generator loss = 15.959579467773438\n",
      "2/2 [==============================] - 0s 171ms/step\n",
      "Epoch: 23, Batch: 242/468, discriminator loss real = 3.808362130915514e-31, disciminator loss fake = 1.7026260934471793e-07, generator loss = 16.324867248535156\n",
      "2/2 [==============================] - 1s 277ms/step\n",
      "Epoch: 23, Batch: 243/468, discriminator loss real = 1.0908555951861141e-24, disciminator loss fake = 2.522787099223933e-07, generator loss = 16.150588989257812\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 23, Batch: 244/468, discriminator loss real = 2.369768767087042e-23, disciminator loss fake = 3.520316340654972e-07, generator loss = 16.148651123046875\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 23, Batch: 245/468, discriminator loss real = 8.614698182939027e-30, disciminator loss fake = 4.771221142618742e-07, generator loss = 16.105941772460938\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 23, Batch: 246/468, discriminator loss real = 3.6559762439000137e-22, disciminator loss fake = 1.9685214169840037e-07, generator loss = 15.944217681884766\n",
      "2/2 [==============================] - 0s 185ms/step\n",
      "Epoch: 23, Batch: 247/468, discriminator loss real = 6.646437393746816e-27, disciminator loss fake = 3.5574649359659816e-07, generator loss = 16.12221908569336\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 23, Batch: 248/468, discriminator loss real = 6.405896043703199e-20, disciminator loss fake = 4.4009360067320813e-07, generator loss = 16.378273010253906\n",
      "2/2 [==============================] - 0s 148ms/step\n",
      "Epoch: 23, Batch: 249/468, discriminator loss real = 4.0690896376852477e-35, disciminator loss fake = 4.4337778604131017e-07, generator loss = 16.206314086914062\n",
      "2/2 [==============================] - 0s 160ms/step\n",
      "Epoch: 23, Batch: 250/468, discriminator loss real = 1.808515298763905e-21, disciminator loss fake = 2.991170902078011e-07, generator loss = 16.14739990234375\n",
      "2/2 [==============================] - 0s 227ms/step\n",
      "Epoch: 23, Batch: 251/468, discriminator loss real = 3.923910242699722e-20, disciminator loss fake = 1.8711466509557795e-07, generator loss = 16.105506896972656\n",
      "2/2 [==============================] - 0s 190ms/step\n",
      "Epoch: 23, Batch: 252/468, discriminator loss real = 4.1863305628975707e-35, disciminator loss fake = 2.8125674589318805e-07, generator loss = 16.110361099243164\n",
      "2/2 [==============================] - 0s 249ms/step\n",
      "Epoch: 23, Batch: 253/468, discriminator loss real = 2.0603866616541354e-33, disciminator loss fake = 2.663244629275141e-07, generator loss = 16.407024383544922\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 23, Batch: 254/468, discriminator loss real = 1.430725546716638e-12, disciminator loss fake = 2.1290665586093382e-07, generator loss = 16.217052459716797\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 23, Batch: 255/468, discriminator loss real = 6.163601747044556e-12, disciminator loss fake = 2.8467715651459e-07, generator loss = 16.185039520263672\n",
      "2/2 [==============================] - 0s 169ms/step\n",
      "Epoch: 23, Batch: 256/468, discriminator loss real = 4.8762555603942404e-20, disciminator loss fake = 1.822119628513974e-07, generator loss = 16.17819595336914\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 23, Batch: 257/468, discriminator loss real = 7.262315123222855e-25, disciminator loss fake = 4.98764393341844e-07, generator loss = 16.08816909790039\n",
      "2/2 [==============================] - 1s 240ms/step\n",
      "Epoch: 23, Batch: 258/468, discriminator loss real = 3.1804438851479494e-23, disciminator loss fake = 2.677477652923699e-07, generator loss = 16.400964736938477\n",
      "2/2 [==============================] - 0s 153ms/step\n",
      "Epoch: 23, Batch: 259/468, discriminator loss real = 1.2218585516557254e-31, disciminator loss fake = 1.8677592095173168e-07, generator loss = 16.319124221801758\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 23, Batch: 260/468, discriminator loss real = 1.7638673854847298e-09, disciminator loss fake = 4.295444568924722e-07, generator loss = 16.230907440185547\n",
      "2/2 [==============================] - 0s 147ms/step\n",
      "Epoch: 23, Batch: 261/468, discriminator loss real = 5.622200463877823e-37, disciminator loss fake = 1.5617669646417198e-07, generator loss = 16.297893524169922\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 23, Batch: 262/468, discriminator loss real = 5.073056609838152e-16, disciminator loss fake = 2.8065426249668235e-07, generator loss = 16.42209815979004\n",
      "2/2 [==============================] - 0s 166ms/step\n",
      "Epoch: 23, Batch: 263/468, discriminator loss real = 8.925395687078886e-23, disciminator loss fake = 2.768123863461369e-07, generator loss = 16.179515838623047\n",
      "2/2 [==============================] - 0s 155ms/step\n",
      "Epoch: 23, Batch: 264/468, discriminator loss real = 8.312826342979026e-17, disciminator loss fake = 2.1831050389664597e-07, generator loss = 16.033023834228516\n",
      "2/2 [==============================] - 0s 193ms/step\n",
      "Epoch: 23, Batch: 265/468, discriminator loss real = 7.304305711946922e-22, disciminator loss fake = 2.6489399829188187e-07, generator loss = 16.083328247070312\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 23, Batch: 266/468, discriminator loss real = 2.082426142917243e-25, disciminator loss fake = 3.5047298752033385e-07, generator loss = 16.457717895507812\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 23, Batch: 267/468, discriminator loss real = 1.4100266928332e-36, disciminator loss fake = 2.3112004043923662e-07, generator loss = 16.324962615966797\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 23, Batch: 268/468, discriminator loss real = 1.2506382868548854e-24, disciminator loss fake = 4.1903945202648174e-07, generator loss = 16.396018981933594\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 23, Batch: 269/468, discriminator loss real = 4.5487983825841525e-24, disciminator loss fake = 2.9605146778521885e-07, generator loss = 16.359336853027344\n",
      "2/2 [==============================] - 0s 209ms/step\n",
      "Epoch: 23, Batch: 270/468, discriminator loss real = 1.0700703429287049e-25, disciminator loss fake = 2.659719200437394e-07, generator loss = 16.332965850830078\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 23, Batch: 271/468, discriminator loss real = 7.196186392652375e-24, disciminator loss fake = 1.932765485435084e-07, generator loss = 16.449615478515625\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 23, Batch: 272/468, discriminator loss real = 4.253759142342807e-14, disciminator loss fake = 1.9490985891934542e-07, generator loss = 16.18971824645996\n",
      "2/2 [==============================] - 0s 136ms/step\n",
      "Epoch: 23, Batch: 273/468, discriminator loss real = 2.1224355918859643e-19, disciminator loss fake = 2.8270176244404865e-07, generator loss = 16.498958587646484\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 23, Batch: 274/468, discriminator loss real = 4.250473696558156e-33, disciminator loss fake = 4.262460038262361e-07, generator loss = 16.119979858398438\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 23, Batch: 275/468, discriminator loss real = 1.7518058184617935e-11, disciminator loss fake = 2.897766648857214e-07, generator loss = 16.21223258972168\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 23, Batch: 276/468, discriminator loss real = 4.892660170237317e-13, disciminator loss fake = 2.8955554398635286e-07, generator loss = 16.516368865966797\n",
      "2/2 [==============================] - 0s 261ms/step\n",
      "Epoch: 23, Batch: 277/468, discriminator loss real = 5.002205807494815e-29, disciminator loss fake = 2.3243092073244043e-07, generator loss = 16.226097106933594\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 23, Batch: 278/468, discriminator loss real = 2.0954275311176136e-31, disciminator loss fake = 3.6557443650053756e-07, generator loss = 16.37847137451172\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 23, Batch: 279/468, discriminator loss real = 1.5200884215674817e-24, disciminator loss fake = 1.5485858284591814e-07, generator loss = 16.18629264831543\n",
      "2/2 [==============================] - 0s 164ms/step\n",
      "Epoch: 23, Batch: 280/468, discriminator loss real = 3.893361753146072e-27, disciminator loss fake = 2.9124808520464285e-07, generator loss = 16.327239990234375\n",
      "2/2 [==============================] - 0s 130ms/step\n",
      "Epoch: 23, Batch: 281/468, discriminator loss real = 8.617516730582725e-21, disciminator loss fake = 2.1831141339134774e-07, generator loss = 16.297927856445312\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 23, Batch: 282/468, discriminator loss real = 1.4254692020614087e-20, disciminator loss fake = 1.5518401141889626e-07, generator loss = 16.48311996459961\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 23, Batch: 283/468, discriminator loss real = 3.3988856102951104e-06, disciminator loss fake = 1.8568920268080547e-07, generator loss = 16.267187118530273\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 23, Batch: 284/468, discriminator loss real = 2.328548563356935e-21, disciminator loss fake = 2.760827442216396e-07, generator loss = 16.433818817138672\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 23, Batch: 285/468, discriminator loss real = 2.3730385008758745e-22, disciminator loss fake = 2.2224031681616907e-07, generator loss = 16.344539642333984\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 23, Batch: 286/468, discriminator loss real = 2.7169411587193154e-38, disciminator loss fake = 2.136648618034087e-07, generator loss = 16.185115814208984\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 23, Batch: 287/468, discriminator loss real = 1.0666523901437749e-31, disciminator loss fake = 2.3597598897140415e-07, generator loss = 16.344398498535156\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 23, Batch: 288/468, discriminator loss real = 8.583529624047025e-22, disciminator loss fake = 1.9506003923197568e-07, generator loss = 16.264137268066406\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 23, Batch: 289/468, discriminator loss real = 1.3848501702102254e-33, disciminator loss fake = 2.716105029776372e-07, generator loss = 16.38099479675293\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 23, Batch: 290/468, discriminator loss real = 1.8039522874743916e-23, disciminator loss fake = 1.5552292609299911e-07, generator loss = 16.324234008789062\n",
      "2/2 [==============================] - 0s 147ms/step\n",
      "Epoch: 23, Batch: 291/468, discriminator loss real = 7.129666264968947e-30, disciminator loss fake = 2.7658114731821115e-07, generator loss = 16.507125854492188\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 23, Batch: 292/468, discriminator loss real = 6.630247051632263e-31, disciminator loss fake = 2.820115412305313e-07, generator loss = 16.269271850585938\n",
      "2/2 [==============================] - 0s 231ms/step\n",
      "Epoch: 23, Batch: 293/468, discriminator loss real = 9.230974274895831e-13, disciminator loss fake = 2.579620854703535e-07, generator loss = 16.256507873535156\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 23, Batch: 294/468, discriminator loss real = 9.616872241140537e-20, disciminator loss fake = 2.553638296376448e-07, generator loss = 16.470090866088867\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 23, Batch: 295/468, discriminator loss real = 2.5402755385594693e-19, disciminator loss fake = 3.588746722016367e-07, generator loss = 16.47515869140625\n",
      "2/2 [==============================] - 0s 186ms/step\n",
      "Epoch: 23, Batch: 296/468, discriminator loss real = 1.4020905764736597e-32, disciminator loss fake = 2.139153707503283e-07, generator loss = 15.992960929870605\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 23, Batch: 297/468, discriminator loss real = 5.859619360936415e-25, disciminator loss fake = 2.487180381649523e-07, generator loss = 16.26291275024414\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 23, Batch: 298/468, discriminator loss real = 0.0, disciminator loss fake = 1.9570472886698553e-07, generator loss = 16.32861328125\n",
      "2/2 [==============================] - 0s 184ms/step\n",
      "Epoch: 23, Batch: 299/468, discriminator loss real = 6.86131616269818e-21, disciminator loss fake = 2.1666207317139197e-07, generator loss = 16.36545181274414\n",
      "2/2 [==============================] - 0s 148ms/step\n",
      "Epoch: 23, Batch: 300/468, discriminator loss real = 1.3097570022063453e-24, disciminator loss fake = 2.528036588955729e-07, generator loss = 16.46792984008789\n",
      "2/2 [==============================] - 0s 210ms/step\n",
      "Epoch: 23, Batch: 301/468, discriminator loss real = 2.8249118876725748e-24, disciminator loss fake = 2.367704183825481e-07, generator loss = 16.183874130249023\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 23, Batch: 302/468, discriminator loss real = 2.1080886632208854e-32, disciminator loss fake = 4.163999278716801e-07, generator loss = 16.293010711669922\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 23, Batch: 303/468, discriminator loss real = 1.4397481139944836e-30, disciminator loss fake = 4.7482674858656537e-07, generator loss = 16.617874145507812\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 23, Batch: 304/468, discriminator loss real = 6.621379738619464e-23, disciminator loss fake = 2.090478687932773e-07, generator loss = 16.376956939697266\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 23, Batch: 305/468, discriminator loss real = 1.46386644141998e-19, disciminator loss fake = 2.581936655587924e-07, generator loss = 16.383407592773438\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 23, Batch: 306/468, discriminator loss real = 4.785960255556778e-26, disciminator loss fake = 3.08853145725152e-07, generator loss = 16.078166961669922\n",
      "2/2 [==============================] - 0s 153ms/step\n",
      "Epoch: 23, Batch: 307/468, discriminator loss real = 1.0626582551670548e-25, disciminator loss fake = 2.0827704361181532e-07, generator loss = 16.16864013671875\n",
      "2/2 [==============================] - 1s 242ms/step\n",
      "Epoch: 23, Batch: 308/468, discriminator loss real = 6.489279829515975e-34, disciminator loss fake = 1.8928190570477454e-07, generator loss = 16.38970184326172\n",
      "2/2 [==============================] - 0s 145ms/step\n",
      "Epoch: 23, Batch: 309/468, discriminator loss real = 1.7361716545755202e-32, disciminator loss fake = 1.575900370198724e-07, generator loss = 16.32777976989746\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 23, Batch: 310/468, discriminator loss real = 9.922604518301944e-16, disciminator loss fake = 2.3354519385065942e-07, generator loss = 16.49209976196289\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 23, Batch: 311/468, discriminator loss real = 1.0441332043401377e-20, disciminator loss fake = 1.977728487645436e-07, generator loss = 16.30663299560547\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 23, Batch: 312/468, discriminator loss real = 1.3176612236983068e-31, disciminator loss fake = 3.033771918126149e-07, generator loss = 16.459423065185547\n",
      "2/2 [==============================] - 0s 205ms/step\n",
      "Epoch: 23, Batch: 313/468, discriminator loss real = 2.3067518695400226e-21, disciminator loss fake = 1.6926547630191635e-07, generator loss = 16.192893981933594\n",
      "2/2 [==============================] - 0s 130ms/step\n",
      "Epoch: 23, Batch: 314/468, discriminator loss real = 3.5392099682808877e-26, disciminator loss fake = 3.432889741361578e-07, generator loss = 16.182292938232422\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 23, Batch: 315/468, discriminator loss real = 1.608304483132842e-34, disciminator loss fake = 3.0977895448813797e-07, generator loss = 16.41118049621582\n",
      "2/2 [==============================] - 0s 203ms/step\n",
      "Epoch: 23, Batch: 316/468, discriminator loss real = 0.0, disciminator loss fake = 2.410616559700429e-07, generator loss = 16.303569793701172\n",
      "2/2 [==============================] - 0s 162ms/step\n",
      "Epoch: 23, Batch: 317/468, discriminator loss real = 3.2335679977524397e-34, disciminator loss fake = 1.9990244481959962e-07, generator loss = 16.27403450012207\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 23, Batch: 318/468, discriminator loss real = 3.166234633999441e-17, disciminator loss fake = 2.605227109597763e-07, generator loss = 16.19249153137207\n",
      "2/2 [==============================] - 1s 287ms/step\n",
      "Epoch: 23, Batch: 319/468, discriminator loss real = 1.0702069479995097e-22, disciminator loss fake = 4.6742383119635633e-07, generator loss = 16.378475189208984\n",
      "2/2 [==============================] - 0s 146ms/step\n",
      "Epoch: 23, Batch: 320/468, discriminator loss real = 9.07820713391536e-18, disciminator loss fake = 2.382934951583593e-07, generator loss = 16.50082015991211\n",
      "2/2 [==============================] - 0s 88ms/step\n",
      "Epoch: 23, Batch: 321/468, discriminator loss real = 1.211946125054264e-12, disciminator loss fake = 2.3027983786505501e-07, generator loss = 16.208541870117188\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 23, Batch: 322/468, discriminator loss real = 4.42711436311954e-27, disciminator loss fake = 1.7991996514865605e-07, generator loss = 16.29189682006836\n",
      "2/2 [==============================] - 0s 181ms/step\n",
      "Epoch: 23, Batch: 323/468, discriminator loss real = 2.969177434843963e-14, disciminator loss fake = 2.0960936808478436e-07, generator loss = 16.438373565673828\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 23, Batch: 324/468, discriminator loss real = 8.191998189067512e-19, disciminator loss fake = 1.9070928658493358e-07, generator loss = 16.320640563964844\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 23, Batch: 325/468, discriminator loss real = 4.619642017375634e-31, disciminator loss fake = 2.667928811206366e-07, generator loss = 16.205402374267578\n",
      "2/2 [==============================] - 0s 175ms/step\n",
      "Epoch: 23, Batch: 326/468, discriminator loss real = 2.3536813885962115e-25, disciminator loss fake = 1.9619274382876029e-07, generator loss = 16.150836944580078\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 23, Batch: 327/468, discriminator loss real = 2.8702133961202976e-28, disciminator loss fake = 1.5336974001911585e-07, generator loss = 16.26652717590332\n",
      "2/2 [==============================] - 0s 137ms/step\n",
      "Epoch: 23, Batch: 328/468, discriminator loss real = 2.8795479497404033e-30, disciminator loss fake = 1.6407463476753037e-07, generator loss = 16.241924285888672\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 23, Batch: 329/468, discriminator loss real = 1.5363091166268482e-27, disciminator loss fake = 1.968432030707845e-07, generator loss = 16.491939544677734\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 23, Batch: 330/468, discriminator loss real = 8.063152095793095e-31, disciminator loss fake = 1.7340747149319213e-07, generator loss = 16.521575927734375\n",
      "2/2 [==============================] - 0s 236ms/step\n",
      "Epoch: 23, Batch: 331/468, discriminator loss real = 7.310772538564325e-14, disciminator loss fake = 2.3934893533805734e-07, generator loss = 16.444929122924805\n",
      "2/2 [==============================] - 0s 152ms/step\n",
      "Epoch: 23, Batch: 332/468, discriminator loss real = 2.886819185574592e-18, disciminator loss fake = 1.8784567146212794e-07, generator loss = 16.354639053344727\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 23, Batch: 333/468, discriminator loss real = 5.748125704897003e-24, disciminator loss fake = 2.3585344877119496e-07, generator loss = 16.38676643371582\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 23, Batch: 334/468, discriminator loss real = 5.098033163741238e-23, disciminator loss fake = 2.6964241328641947e-07, generator loss = 16.310077667236328\n",
      "2/2 [==============================] - 0s 130ms/step\n",
      "Epoch: 23, Batch: 335/468, discriminator loss real = 6.3343881969955336e-24, disciminator loss fake = 1.330930103904393e-07, generator loss = 16.250492095947266\n",
      "2/2 [==============================] - 0s 162ms/step\n",
      "Epoch: 23, Batch: 336/468, discriminator loss real = 1.8020020532185526e-26, disciminator loss fake = 1.781675393885962e-07, generator loss = 16.349552154541016\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 23, Batch: 337/468, discriminator loss real = 1.8572338413488107e-25, disciminator loss fake = 1.484509652982524e-07, generator loss = 16.364376068115234\n",
      "2/2 [==============================] - 1s 276ms/step\n",
      "Epoch: 23, Batch: 338/468, discriminator loss real = 1.5569856486043158e-21, disciminator loss fake = 2.2579018832402653e-07, generator loss = 16.452974319458008\n",
      "2/2 [==============================] - 0s 146ms/step\n",
      "Epoch: 23, Batch: 339/468, discriminator loss real = 8.540674235323493e-17, disciminator loss fake = 1.8908249899141083e-07, generator loss = 16.246896743774414\n",
      "2/2 [==============================] - 0s 161ms/step\n",
      "Epoch: 23, Batch: 340/468, discriminator loss real = 1.427913749538641e-17, disciminator loss fake = 2.9584299454654683e-07, generator loss = 16.299110412597656\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 23, Batch: 341/468, discriminator loss real = 3.35146477062378e-26, disciminator loss fake = 4.577846652864537e-07, generator loss = 16.51689910888672\n",
      "2/2 [==============================] - 0s 194ms/step\n",
      "Epoch: 23, Batch: 342/468, discriminator loss real = 4.7204160151191995e-17, disciminator loss fake = 2.1288555274168175e-07, generator loss = 16.116535186767578\n",
      "2/2 [==============================] - 0s 163ms/step\n",
      "Epoch: 23, Batch: 343/468, discriminator loss real = 9.687331964414998e-33, disciminator loss fake = 1.3270789622765733e-07, generator loss = 16.38567352294922\n",
      "2/2 [==============================] - 0s 130ms/step\n",
      "Epoch: 23, Batch: 344/468, discriminator loss real = 4.4550311883995164e-08, disciminator loss fake = 3.0001734785400913e-07, generator loss = 16.547927856445312\n",
      "2/2 [==============================] - 1s 202ms/step\n",
      "Epoch: 23, Batch: 345/468, discriminator loss real = 1.6497754416934974e-34, disciminator loss fake = 1.7882062763874274e-07, generator loss = 16.372024536132812\n",
      "2/2 [==============================] - 0s 155ms/step\n",
      "Epoch: 23, Batch: 346/468, discriminator loss real = 1.8815002391752004e-19, disciminator loss fake = 2.2327449755721318e-07, generator loss = 16.396686553955078\n",
      "2/2 [==============================] - 0s 160ms/step\n",
      "Epoch: 23, Batch: 347/468, discriminator loss real = 1.1572023656797068e-31, disciminator loss fake = 3.201014351361664e-07, generator loss = 16.31649398803711\n",
      "2/2 [==============================] - 0s 152ms/step\n",
      "Epoch: 23, Batch: 348/468, discriminator loss real = 2.2052515189474898e-18, disciminator loss fake = 2.485576260369271e-07, generator loss = 16.306842803955078\n",
      "2/2 [==============================] - 0s 169ms/step\n",
      "Epoch: 23, Batch: 349/468, discriminator loss real = 4.296862494301923e-22, disciminator loss fake = 2.991889118675317e-07, generator loss = 16.465007781982422\n",
      "2/2 [==============================] - 0s 162ms/step\n",
      "Epoch: 23, Batch: 350/468, discriminator loss real = 3.3705984994352784e-27, disciminator loss fake = 1.6927417334500205e-07, generator loss = 16.33464241027832\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 23, Batch: 351/468, discriminator loss real = 3.9787867091231006e-22, disciminator loss fake = 1.5394181218653102e-07, generator loss = 16.2930908203125\n",
      "2/2 [==============================] - 0s 173ms/step\n",
      "Epoch: 23, Batch: 352/468, discriminator loss real = 6.666914474669493e-34, disciminator loss fake = 2.4875461690498923e-07, generator loss = 16.238685607910156\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 23, Batch: 353/468, discriminator loss real = 5.725301529217371e-22, disciminator loss fake = 2.1858487286863237e-07, generator loss = 16.482685089111328\n",
      "2/2 [==============================] - 0s 163ms/step\n",
      "Epoch: 23, Batch: 354/468, discriminator loss real = 5.769676796400515e-19, disciminator loss fake = 3.4956400440933066e-07, generator loss = 16.446819305419922\n",
      "2/2 [==============================] - 0s 153ms/step\n",
      "Epoch: 23, Batch: 355/468, discriminator loss real = 4.0532360540632666e-20, disciminator loss fake = 2.8530669737847347e-07, generator loss = 16.539026260375977\n",
      "2/2 [==============================] - 0s 148ms/step\n",
      "Epoch: 23, Batch: 356/468, discriminator loss real = 4.466887560921307e-30, disciminator loss fake = 1.6649340750518604e-07, generator loss = 16.49484634399414\n",
      "2/2 [==============================] - 0s 185ms/step\n",
      "Epoch: 23, Batch: 357/468, discriminator loss real = 1.2126537621282019e-11, disciminator loss fake = 1.528578934539837e-07, generator loss = 16.250347137451172\n",
      "2/2 [==============================] - 0s 227ms/step\n",
      "Epoch: 23, Batch: 358/468, discriminator loss real = 3.835585205516888e-21, disciminator loss fake = 2.931816993623215e-07, generator loss = 16.330913543701172\n",
      "2/2 [==============================] - 0s 193ms/step\n",
      "Epoch: 23, Batch: 359/468, discriminator loss real = 1.114562272008996e-30, disciminator loss fake = 1.9940219431191508e-07, generator loss = 16.685434341430664\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 23, Batch: 360/468, discriminator loss real = 7.221521015725318e-14, disciminator loss fake = 1.702002236925182e-07, generator loss = 16.40485191345215\n",
      "2/2 [==============================] - 0s 173ms/step\n",
      "Epoch: 23, Batch: 361/468, discriminator loss real = 1.7405603919587566e-20, disciminator loss fake = 2.9970428272463323e-07, generator loss = 16.518491744995117\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 23, Batch: 362/468, discriminator loss real = 5.360816042514422e-15, disciminator loss fake = 1.639341746795253e-07, generator loss = 16.338878631591797\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 23, Batch: 363/468, discriminator loss real = 7.356114813265025e-31, disciminator loss fake = 1.3212709859544702e-07, generator loss = 16.67462158203125\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 23, Batch: 364/468, discriminator loss real = 9.167821501385119e-33, disciminator loss fake = 2.1645436731887457e-07, generator loss = 16.57939910888672\n",
      "2/2 [==============================] - 0s 171ms/step\n",
      "Epoch: 23, Batch: 365/468, discriminator loss real = 8.79666327434321e-32, disciminator loss fake = 1.8613602037476085e-07, generator loss = 16.491762161254883\n",
      "2/2 [==============================] - 1s 161ms/step\n",
      "Epoch: 23, Batch: 366/468, discriminator loss real = 3.1305160688726e-29, disciminator loss fake = 3.9067862189767766e-07, generator loss = 16.282665252685547\n",
      "2/2 [==============================] - 0s 200ms/step\n",
      "Epoch: 23, Batch: 367/468, discriminator loss real = 4.439633395259074e-30, disciminator loss fake = 2.748433871602174e-07, generator loss = 16.40264892578125\n",
      "2/2 [==============================] - 0s 185ms/step\n",
      "Epoch: 23, Batch: 368/468, discriminator loss real = 7.960966353175767e-21, disciminator loss fake = 2.3054229814079008e-07, generator loss = 16.28158950805664\n",
      "2/2 [==============================] - 1s 303ms/step\n",
      "Epoch: 23, Batch: 369/468, discriminator loss real = 1.2073980021875737e-35, disciminator loss fake = 3.745215622075193e-07, generator loss = 16.4235897064209\n",
      "2/2 [==============================] - 0s 182ms/step\n",
      "Epoch: 23, Batch: 370/468, discriminator loss real = 6.7642301680732875e-18, disciminator loss fake = 1.813747587675607e-07, generator loss = 16.464759826660156\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 23, Batch: 371/468, discriminator loss real = 1.714001352863963e-25, disciminator loss fake = 1.4709962670167442e-07, generator loss = 16.219348907470703\n",
      "2/2 [==============================] - 0s 148ms/step\n",
      "Epoch: 23, Batch: 372/468, discriminator loss real = 2.059218073332624e-31, disciminator loss fake = 1.3960658407086157e-07, generator loss = 16.723445892333984\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 23, Batch: 373/468, discriminator loss real = 5.350563132204382e-14, disciminator loss fake = 1.6342747244380007e-07, generator loss = 16.60373306274414\n",
      "2/2 [==============================] - 1s 306ms/step\n",
      "Epoch: 23, Batch: 374/468, discriminator loss real = 3.185852711151239e-17, disciminator loss fake = 1.754262370923243e-07, generator loss = 16.501178741455078\n",
      "2/2 [==============================] - 0s 181ms/step\n",
      "Epoch: 23, Batch: 375/468, discriminator loss real = 2.753351719272848e-31, disciminator loss fake = 1.617930820430047e-07, generator loss = 16.739097595214844\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 23, Batch: 376/468, discriminator loss real = 3.985295248669419e-27, disciminator loss fake = 2.0126755373439664e-07, generator loss = 16.291549682617188\n",
      "2/2 [==============================] - 0s 146ms/step\n",
      "Epoch: 23, Batch: 377/468, discriminator loss real = 0.0, disciminator loss fake = 2.0427279423529399e-07, generator loss = 16.43405532836914\n",
      "2/2 [==============================] - 0s 148ms/step\n",
      "Epoch: 23, Batch: 378/468, discriminator loss real = 3.457304767741948e-21, disciminator loss fake = 2.4208455329244316e-07, generator loss = 16.458171844482422\n",
      "2/2 [==============================] - 0s 162ms/step\n",
      "Epoch: 23, Batch: 379/468, discriminator loss real = 1.2337930156702814e-12, disciminator loss fake = 1.705063823465025e-07, generator loss = 16.382465362548828\n",
      "2/2 [==============================] - 0s 182ms/step\n",
      "Epoch: 23, Batch: 380/468, discriminator loss real = 6.373393448576459e-30, disciminator loss fake = 2.133445775598375e-07, generator loss = 16.66863441467285\n",
      "2/2 [==============================] - 1s 296ms/step\n",
      "Epoch: 23, Batch: 381/468, discriminator loss real = 9.657832933681113e-33, disciminator loss fake = 1.593487866102805e-07, generator loss = 16.326087951660156\n",
      "2/2 [==============================] - 0s 177ms/step\n",
      "Epoch: 23, Batch: 382/468, discriminator loss real = 1.7458039904158734e-16, disciminator loss fake = 2.6984787382389186e-07, generator loss = 16.50101661682129\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 23, Batch: 383/468, discriminator loss real = 3.6206650970489643e-16, disciminator loss fake = 1.9054417066399765e-07, generator loss = 16.27823257446289\n",
      "2/2 [==============================] - 0s 145ms/step\n",
      "Epoch: 23, Batch: 384/468, discriminator loss real = 7.125960515755403e-25, disciminator loss fake = 2.078991769849381e-07, generator loss = 16.435535430908203\n",
      "2/2 [==============================] - 0s 147ms/step\n",
      "Epoch: 23, Batch: 385/468, discriminator loss real = 6.95524914034083e-31, disciminator loss fake = 2.263154357251551e-07, generator loss = 16.355453491210938\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 23, Batch: 386/468, discriminator loss real = 4.500447191128808e-29, disciminator loss fake = 1.7436755683775118e-07, generator loss = 16.54898452758789\n",
      "2/2 [==============================] - 0s 153ms/step\n",
      "Epoch: 23, Batch: 387/468, discriminator loss real = 5.622941841164024e-23, disciminator loss fake = 2.7392735546527547e-07, generator loss = 16.52610206604004\n",
      "2/2 [==============================] - 1s 298ms/step\n",
      "Epoch: 23, Batch: 388/468, discriminator loss real = 1.4905517242621194e-33, disciminator loss fake = 1.8930660417026957e-07, generator loss = 16.64273452758789\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 23, Batch: 389/468, discriminator loss real = 1.8293087168534594e-33, disciminator loss fake = 1.7276610719818564e-07, generator loss = 16.528966903686523\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 23, Batch: 390/468, discriminator loss real = 8.743679577767277e-18, disciminator loss fake = 1.5422051546920557e-07, generator loss = 16.59139633178711\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 23, Batch: 391/468, discriminator loss real = 1.896171140368835e-18, disciminator loss fake = 2.1952310191863944e-07, generator loss = 16.515981674194336\n",
      "2/2 [==============================] - 0s 151ms/step\n",
      "Epoch: 23, Batch: 392/468, discriminator loss real = 4.4326876191926075e-28, disciminator loss fake = 1.5015866949852352e-07, generator loss = 16.621051788330078\n",
      "2/2 [==============================] - 0s 175ms/step\n",
      "Epoch: 23, Batch: 393/468, discriminator loss real = 1.018228395559163e-20, disciminator loss fake = 2.045274527517904e-07, generator loss = 16.343435287475586\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 23, Batch: 394/468, discriminator loss real = 2.758855670350146e-33, disciminator loss fake = 1.0393401339570119e-07, generator loss = 16.513343811035156\n",
      "2/2 [==============================] - 0s 224ms/step\n",
      "Epoch: 23, Batch: 395/468, discriminator loss real = 1.3959212026242829e-15, disciminator loss fake = 1.791734831613212e-07, generator loss = 16.411697387695312\n",
      "2/2 [==============================] - 0s 176ms/step\n",
      "Epoch: 23, Batch: 396/468, discriminator loss real = 6.4615226968103755e-25, disciminator loss fake = 3.290514030140912e-07, generator loss = 16.691089630126953\n",
      "2/2 [==============================] - 1s 135ms/step\n",
      "Epoch: 23, Batch: 397/468, discriminator loss real = 0.0, disciminator loss fake = 1.787920780316199e-07, generator loss = 16.63296127319336\n",
      "2/2 [==============================] - 0s 187ms/step\n",
      "Epoch: 23, Batch: 398/468, discriminator loss real = 6.417352954272298e-16, disciminator loss fake = 1.2610158250936365e-07, generator loss = 16.44599151611328\n",
      "2/2 [==============================] - 0s 168ms/step\n",
      "Epoch: 23, Batch: 399/468, discriminator loss real = 5.984493577042572e-26, disciminator loss fake = 2.9163311410229653e-07, generator loss = 16.771669387817383\n",
      "2/2 [==============================] - 0s 144ms/step\n",
      "Epoch: 23, Batch: 400/468, discriminator loss real = 6.514690197024113e-32, disciminator loss fake = 1.7590852507964883e-07, generator loss = 16.377714157104492\n",
      "2/2 [==============================] - 0s 167ms/step\n",
      "Epoch: 23, Batch: 401/468, discriminator loss real = 3.749556363553365e-18, disciminator loss fake = 1.0978928344229644e-07, generator loss = 16.6091365814209\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 23, Batch: 402/468, discriminator loss real = 2.7699864624253223e-10, disciminator loss fake = 1.7885119518723513e-07, generator loss = 16.589372634887695\n",
      "2/2 [==============================] - 0s 152ms/step\n",
      "Epoch: 23, Batch: 403/468, discriminator loss real = 3.387119752425464e-28, disciminator loss fake = 2.6290734922440606e-07, generator loss = 16.446731567382812\n",
      "2/2 [==============================] - 1s 311ms/step\n",
      "Epoch: 23, Batch: 404/468, discriminator loss real = 1.4048111903353783e-13, disciminator loss fake = 1.9328220446368505e-07, generator loss = 16.497636795043945\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 23, Batch: 405/468, discriminator loss real = 6.019442189059183e-21, disciminator loss fake = 1.6842908223679842e-07, generator loss = 16.524215698242188\n",
      "2/2 [==============================] - 1s 124ms/step\n",
      "Epoch: 23, Batch: 406/468, discriminator loss real = 1.692053024110345e-30, disciminator loss fake = 1.631548087743795e-07, generator loss = 16.47922134399414\n",
      "2/2 [==============================] - 0s 193ms/step\n",
      "Epoch: 23, Batch: 407/468, discriminator loss real = 3.349713684303464e-25, disciminator loss fake = 1.305920278582562e-07, generator loss = 16.273868560791016\n",
      "2/2 [==============================] - 0s 136ms/step\n",
      "Epoch: 23, Batch: 408/468, discriminator loss real = 4.4773687181798276e-33, disciminator loss fake = 1.854345015317449e-07, generator loss = 16.42221450805664\n",
      "2/2 [==============================] - 0s 156ms/step\n",
      "Epoch: 23, Batch: 409/468, discriminator loss real = 1.1159602170049263e-16, disciminator loss fake = 1.6926952639551018e-07, generator loss = 16.74380111694336\n",
      "2/2 [==============================] - 1s 139ms/step\n",
      "Epoch: 23, Batch: 410/468, discriminator loss real = 3.8136222330365735e-32, disciminator loss fake = 2.1264681038246636e-07, generator loss = 16.49290657043457\n",
      "2/2 [==============================] - 0s 179ms/step\n",
      "Epoch: 23, Batch: 411/468, discriminator loss real = 1.9323308674795604e-21, disciminator loss fake = 2.3039916641209857e-07, generator loss = 16.431873321533203\n",
      "2/2 [==============================] - 0s 162ms/step\n",
      "Epoch: 23, Batch: 412/468, discriminator loss real = 2.753205321614361e-17, disciminator loss fake = 1.9088180636117613e-07, generator loss = 16.760772705078125\n",
      "2/2 [==============================] - 0s 192ms/step\n",
      "Epoch: 23, Batch: 413/468, discriminator loss real = 2.730525292222619e-35, disciminator loss fake = 1.3243669627627241e-07, generator loss = 16.81085205078125\n",
      "2/2 [==============================] - 0s 162ms/step\n",
      "Epoch: 23, Batch: 414/468, discriminator loss real = 5.891366005502661e-34, disciminator loss fake = 2.793200906126003e-07, generator loss = 16.815521240234375\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 23, Batch: 415/468, discriminator loss real = 2.268483893308034e-19, disciminator loss fake = 3.1524751875622314e-07, generator loss = 16.57440757751465\n",
      "2/2 [==============================] - 0s 188ms/step\n",
      "Epoch: 23, Batch: 416/468, discriminator loss real = 8.211177015379079e-34, disciminator loss fake = 1.8682581526263675e-07, generator loss = 16.941957473754883\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 23, Batch: 417/468, discriminator loss real = 1.658513986126365e-25, disciminator loss fake = 2.113703914119469e-07, generator loss = 16.508350372314453\n",
      "2/2 [==============================] - 0s 160ms/step\n",
      "Epoch: 23, Batch: 418/468, discriminator loss real = 2.690121805543586e-27, disciminator loss fake = 1.2227971524225723e-07, generator loss = 16.501628875732422\n",
      "2/2 [==============================] - 0s 166ms/step\n",
      "Epoch: 23, Batch: 419/468, discriminator loss real = 5.1748240396990724e-23, disciminator loss fake = 2.3912906499390374e-07, generator loss = 16.605941772460938\n",
      "2/2 [==============================] - 1s 254ms/step\n",
      "Epoch: 23, Batch: 420/468, discriminator loss real = 0.0, disciminator loss fake = 1.2841026375554065e-07, generator loss = 16.744396209716797\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 23, Batch: 421/468, discriminator loss real = 1.4847302390998857e-30, disciminator loss fake = 2.2524244513988378e-07, generator loss = 16.41248321533203\n",
      "2/2 [==============================] - 1s 199ms/step\n",
      "Epoch: 23, Batch: 422/468, discriminator loss real = 7.094574843370911e-31, disciminator loss fake = 2.9343345886445604e-07, generator loss = 16.557571411132812\n",
      "2/2 [==============================] - 0s 163ms/step\n",
      "Epoch: 23, Batch: 423/468, discriminator loss real = 8.688239865162442e-20, disciminator loss fake = 1.3757176020590123e-07, generator loss = 16.602081298828125\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 23, Batch: 424/468, discriminator loss real = 2.0486613707543233e-12, disciminator loss fake = 1.2659563708439237e-07, generator loss = 16.818634033203125\n",
      "2/2 [==============================] - 0s 179ms/step\n",
      "Epoch: 23, Batch: 425/468, discriminator loss real = 4.552531437995437e-17, disciminator loss fake = 1.4987968199875468e-07, generator loss = 16.60955047607422\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 23, Batch: 426/468, discriminator loss real = 3.707593546008512e-21, disciminator loss fake = 1.327429117736756e-07, generator loss = 16.68929672241211\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 23, Batch: 427/468, discriminator loss real = 6.517838786052055e-12, disciminator loss fake = 1.287847055664315e-07, generator loss = 16.545494079589844\n",
      "2/2 [==============================] - 0s 148ms/step\n",
      "Epoch: 23, Batch: 428/468, discriminator loss real = 2.4091343462072e-23, disciminator loss fake = 2.5588661856090766e-07, generator loss = 16.84308624267578\n",
      "2/2 [==============================] - 0s 172ms/step\n",
      "Epoch: 23, Batch: 429/468, discriminator loss real = 1.5885599812040628e-28, disciminator loss fake = 2.290863676535082e-07, generator loss = 16.384275436401367\n",
      "2/2 [==============================] - 0s 151ms/step\n",
      "Epoch: 23, Batch: 430/468, discriminator loss real = 5.441893189192656e-15, disciminator loss fake = 1.6433345706445834e-07, generator loss = 16.764755249023438\n",
      "2/2 [==============================] - 0s 225ms/step\n",
      "Epoch: 23, Batch: 431/468, discriminator loss real = 8.762603826322581e-23, disciminator loss fake = 1.4841840823009989e-07, generator loss = 16.37114143371582\n",
      "2/2 [==============================] - 0s 177ms/step\n",
      "Epoch: 23, Batch: 432/468, discriminator loss real = 6.789492199791441e-14, disciminator loss fake = 2.0916317566843645e-07, generator loss = 16.52743148803711\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 23, Batch: 433/468, discriminator loss real = 1.3458242333064252e-11, disciminator loss fake = 2.25524956931622e-07, generator loss = 16.53134536743164\n",
      "2/2 [==============================] - 0s 155ms/step\n",
      "Epoch: 23, Batch: 434/468, discriminator loss real = 7.015051766566032e-29, disciminator loss fake = 2.1615969103550015e-07, generator loss = 16.674009323120117\n",
      "2/2 [==============================] - 0s 167ms/step\n",
      "Epoch: 23, Batch: 435/468, discriminator loss real = 3.2428234083270992e-22, disciminator loss fake = 1.1669213506593223e-07, generator loss = 16.861103057861328\n",
      "2/2 [==============================] - 0s 157ms/step\n",
      "Epoch: 23, Batch: 436/468, discriminator loss real = 4.6747081912992265e-30, disciminator loss fake = 2.600473578695528e-07, generator loss = 16.58365249633789\n",
      "2/2 [==============================] - 0s 189ms/step\n",
      "Epoch: 23, Batch: 437/468, discriminator loss real = 2.771237058257184e-15, disciminator loss fake = 1.6222024612488894e-07, generator loss = 16.601804733276367\n",
      "2/2 [==============================] - 1s 198ms/step\n",
      "Epoch: 23, Batch: 438/468, discriminator loss real = 5.216784622079125e-19, disciminator loss fake = 1.3363592188397888e-07, generator loss = 16.438997268676758\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 23, Batch: 439/468, discriminator loss real = 8.683116397525531e-32, disciminator loss fake = 1.5189296220796678e-07, generator loss = 16.674121856689453\n",
      "2/2 [==============================] - 0s 163ms/step\n",
      "Epoch: 23, Batch: 440/468, discriminator loss real = 8.319642807534831e-18, disciminator loss fake = 2.6303342792743933e-07, generator loss = 16.6622257232666\n",
      "2/2 [==============================] - 0s 248ms/step\n",
      "Epoch: 23, Batch: 441/468, discriminator loss real = 1.234920182031162e-33, disciminator loss fake = 1.7332570223516086e-07, generator loss = 16.41905975341797\n",
      "2/2 [==============================] - 0s 160ms/step\n",
      "Epoch: 23, Batch: 442/468, discriminator loss real = 2.5142746094709704e-29, disciminator loss fake = 1.2009704164483992e-07, generator loss = 16.401845932006836\n",
      "2/2 [==============================] - 1s 210ms/step\n",
      "Epoch: 23, Batch: 443/468, discriminator loss real = 1.3519324788025417e-16, disciminator loss fake = 1.383531298415619e-07, generator loss = 16.869112014770508\n",
      "2/2 [==============================] - 0s 155ms/step\n",
      "Epoch: 23, Batch: 444/468, discriminator loss real = 2.534445621300984e-18, disciminator loss fake = 2.840824322447588e-07, generator loss = 16.537036895751953\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 23, Batch: 445/468, discriminator loss real = 5.3916597748948636e-12, disciminator loss fake = 1.44481049346723e-07, generator loss = 16.570655822753906\n",
      "2/2 [==============================] - 0s 148ms/step\n",
      "Epoch: 23, Batch: 446/468, discriminator loss real = 2.973910831136073e-12, disciminator loss fake = 1.644641969278382e-07, generator loss = 16.561580657958984\n",
      "2/2 [==============================] - 0s 153ms/step\n",
      "Epoch: 23, Batch: 447/468, discriminator loss real = 1.897106441759255e-16, disciminator loss fake = 1.329758703150219e-07, generator loss = 16.809907913208008\n",
      "2/2 [==============================] - 0s 181ms/step\n",
      "Epoch: 23, Batch: 448/468, discriminator loss real = 1.1098298897390262e-28, disciminator loss fake = 1.6717739015348343e-07, generator loss = 16.43811798095703\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 23, Batch: 449/468, discriminator loss real = 3.4035237102635054e-30, disciminator loss fake = 1.752483456129994e-07, generator loss = 16.593181610107422\n",
      "2/2 [==============================] - 0s 144ms/step\n",
      "Epoch: 23, Batch: 450/468, discriminator loss real = 2.9463303999757984e-25, disciminator loss fake = 1.5727368918305729e-07, generator loss = 16.69656753540039\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 23, Batch: 451/468, discriminator loss real = 3.5015256778529106e-17, disciminator loss fake = 2.2801681609507796e-07, generator loss = 16.831340789794922\n",
      "2/2 [==============================] - 0s 157ms/step\n",
      "Epoch: 23, Batch: 452/468, discriminator loss real = 1.2589819594829854e-12, disciminator loss fake = 1.2694096085397177e-07, generator loss = 16.667606353759766\n",
      "2/2 [==============================] - 1s 295ms/step\n",
      "Epoch: 23, Batch: 453/468, discriminator loss real = 3.570507342626671e-20, disciminator loss fake = 1.0782511594698008e-07, generator loss = 16.507823944091797\n",
      "2/2 [==============================] - 0s 168ms/step\n",
      "Epoch: 23, Batch: 454/468, discriminator loss real = 6.870916560137908e-33, disciminator loss fake = 2.0625293473131023e-07, generator loss = 16.565486907958984\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 23, Batch: 455/468, discriminator loss real = 1.5748854452800834e-21, disciminator loss fake = 1.5355819016349415e-07, generator loss = 16.417396545410156\n",
      "2/2 [==============================] - 0s 180ms/step\n",
      "Epoch: 23, Batch: 456/468, discriminator loss real = 5.277769251870711e-22, disciminator loss fake = 2.5535368308737816e-07, generator loss = 16.68426513671875\n",
      "2/2 [==============================] - 0s 162ms/step\n",
      "Epoch: 23, Batch: 457/468, discriminator loss real = 2.2480334383835204e-25, disciminator loss fake = 1.1430628887865169e-07, generator loss = 16.52661895751953\n",
      "2/2 [==============================] - 0s 222ms/step\n",
      "Epoch: 23, Batch: 458/468, discriminator loss real = 1.2354895621073416e-33, disciminator loss fake = 1.624059393634525e-07, generator loss = 16.70168113708496\n",
      "2/2 [==============================] - 0s 156ms/step\n",
      "Epoch: 23, Batch: 459/468, discriminator loss real = 5.4236087934841444e-34, disciminator loss fake = 1.1525553844649039e-07, generator loss = 16.662155151367188\n",
      "2/2 [==============================] - 1s 131ms/step\n",
      "Epoch: 23, Batch: 460/468, discriminator loss real = 1.5016360220590615e-27, disciminator loss fake = 1.4588280805583054e-07, generator loss = 16.59539031982422\n",
      "2/2 [==============================] - 0s 152ms/step\n",
      "Epoch: 23, Batch: 461/468, discriminator loss real = 9.54472749613447e-30, disciminator loss fake = 2.064922171030048e-07, generator loss = 16.534141540527344\n",
      "2/2 [==============================] - 0s 135ms/step\n",
      "Epoch: 23, Batch: 462/468, discriminator loss real = 1.6285805943911595e-21, disciminator loss fake = 1.967939198266322e-07, generator loss = 16.401514053344727\n",
      "2/2 [==============================] - 0s 292ms/step\n",
      "Epoch: 23, Batch: 463/468, discriminator loss real = 2.1366208254761685e-26, disciminator loss fake = 1.4465685183040478e-07, generator loss = 16.75070571899414\n",
      "2/2 [==============================] - 0s 184ms/step\n",
      "Epoch: 23, Batch: 464/468, discriminator loss real = 2.932870302174706e-07, disciminator loss fake = 2.2812471911493049e-07, generator loss = 16.648317337036133\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 23, Batch: 465/468, discriminator loss real = 2.8272362749548474e-12, disciminator loss fake = 5.677137551174383e-07, generator loss = 16.750926971435547\n",
      "2/2 [==============================] - 0s 175ms/step\n",
      "Epoch: 23, Batch: 466/468, discriminator loss real = 2.6054076939020103e-34, disciminator loss fake = 2.1882107148485375e-07, generator loss = 16.757179260253906\n",
      "2/2 [==============================] - 0s 162ms/step\n",
      "Epoch: 23, Batch: 467/468, discriminator loss real = 2.515639641043066e-10, disciminator loss fake = 3.061534243897768e-07, generator loss = 16.70022201538086\n",
      "2/2 [==============================] - 1s 220ms/step\n",
      "Epoch: 23, Batch: 468/468, discriminator loss real = 2.1802537698498324e-25, disciminator loss fake = 1.6328090168826748e-07, generator loss = 17.024036407470703\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2/2 [==============================] - 0s 156ms/step\n",
      "Epoch: 24, Batch: 1/468, discriminator loss real = 1.5321494931329606e-30, disciminator loss fake = 1.3333065851384163e-07, generator loss = 16.552886962890625\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 24, Batch: 2/468, discriminator loss real = 3.810073926624915e-24, disciminator loss fake = 1.3912838880969502e-07, generator loss = 16.805925369262695\n",
      "2/2 [==============================] - 0s 260ms/step\n",
      "Epoch: 24, Batch: 3/468, discriminator loss real = 1.5143528848197035e-30, disciminator loss fake = 1.394283515310235e-07, generator loss = 16.82619857788086\n",
      "2/2 [==============================] - 0s 151ms/step\n",
      "Epoch: 24, Batch: 4/468, discriminator loss real = 3.829595830468564e-26, disciminator loss fake = 2.6804025310411816e-07, generator loss = 16.598371505737305\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 24, Batch: 5/468, discriminator loss real = 2.533872643630426e-20, disciminator loss fake = 2.2498429075312742e-07, generator loss = 16.504274368286133\n",
      "2/2 [==============================] - 0s 177ms/step\n",
      "Epoch: 24, Batch: 6/468, discriminator loss real = 7.072521401706308e-24, disciminator loss fake = 9.969718917091086e-08, generator loss = 16.498071670532227\n",
      "2/2 [==============================] - 0s 144ms/step\n",
      "Epoch: 24, Batch: 7/468, discriminator loss real = 1.2466044239622868e-29, disciminator loss fake = 1.0259386584721142e-07, generator loss = 16.665767669677734\n",
      "2/2 [==============================] - 1s 255ms/step\n",
      "Epoch: 24, Batch: 8/468, discriminator loss real = 7.165384609865801e-27, disciminator loss fake = 1.7571747434885765e-07, generator loss = 16.70940589904785\n",
      "2/2 [==============================] - 0s 169ms/step\n",
      "Epoch: 24, Batch: 9/468, discriminator loss real = 6.224375449602601e-15, disciminator loss fake = 1.8907692833636247e-07, generator loss = 16.628082275390625\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 24, Batch: 10/468, discriminator loss real = 5.3709263472022154e-27, disciminator loss fake = 1.5901547101293545e-07, generator loss = 16.693092346191406\n",
      "2/2 [==============================] - 0s 168ms/step\n",
      "Epoch: 24, Batch: 11/468, discriminator loss real = 4.8056199020152235e-09, disciminator loss fake = 1.7113366368448624e-07, generator loss = 16.630443572998047\n",
      "2/2 [==============================] - 0s 182ms/step\n",
      "Epoch: 24, Batch: 12/468, discriminator loss real = 1.6214978899291544e-26, disciminator loss fake = 1.0032854902419786e-07, generator loss = 16.663631439208984\n",
      "2/2 [==============================] - 1s 233ms/step\n",
      "Epoch: 24, Batch: 13/468, discriminator loss real = 2.5507960455199827e-17, disciminator loss fake = 1.9244231452830718e-07, generator loss = 16.74433708190918\n",
      "2/2 [==============================] - 0s 141ms/step\n",
      "Epoch: 24, Batch: 14/468, discriminator loss real = 2.826107561412742e-17, disciminator loss fake = 2.3122044012779952e-07, generator loss = 16.723800659179688\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 24, Batch: 15/468, discriminator loss real = 3.7790593654938877e-34, disciminator loss fake = 2.0103377096347685e-07, generator loss = 16.644378662109375\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 24, Batch: 16/468, discriminator loss real = 5.355539980165093e-16, disciminator loss fake = 2.1081059742300567e-07, generator loss = 16.80575942993164\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 24, Batch: 17/468, discriminator loss real = 5.2950287735938584e-18, disciminator loss fake = 1.4578543527932197e-07, generator loss = 16.63921356201172\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 24, Batch: 18/468, discriminator loss real = 1.0071980899310913e-33, disciminator loss fake = 1.6281583725685778e-07, generator loss = 16.648590087890625\n",
      "2/2 [==============================] - 0s 153ms/step\n",
      "Epoch: 24, Batch: 19/468, discriminator loss real = 2.72970682673021e-32, disciminator loss fake = 1.1609705552473315e-07, generator loss = 16.75494956970215\n",
      "2/2 [==============================] - 0s 167ms/step\n",
      "Epoch: 24, Batch: 20/468, discriminator loss real = 4.010252546704507e-11, disciminator loss fake = 1.8306894844499766e-07, generator loss = 16.663776397705078\n",
      "2/2 [==============================] - 1s 238ms/step\n",
      "Epoch: 24, Batch: 21/468, discriminator loss real = 2.7619800452909345e-29, disciminator loss fake = 1.6047144413278147e-07, generator loss = 16.894399642944336\n",
      "2/2 [==============================] - 0s 154ms/step\n",
      "Epoch: 24, Batch: 22/468, discriminator loss real = 4.022617335630118e-22, disciminator loss fake = 1.5164150113378128e-07, generator loss = 16.628223419189453\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 24, Batch: 23/468, discriminator loss real = 1.4153579853604563e-19, disciminator loss fake = 1.2854027886533004e-07, generator loss = 16.67209243774414\n",
      "2/2 [==============================] - 1s 281ms/step\n",
      "Epoch: 24, Batch: 24/468, discriminator loss real = 2.0313636785281237e-18, disciminator loss fake = 2.060288437633062e-07, generator loss = 16.744869232177734\n",
      "2/2 [==============================] - 0s 191ms/step\n",
      "Epoch: 24, Batch: 25/468, discriminator loss real = 4.122403307604827e-09, disciminator loss fake = 1.2652269276713923e-07, generator loss = 16.602975845336914\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 24, Batch: 26/468, discriminator loss real = 5.817337032714151e-26, disciminator loss fake = 1.6939355873546447e-07, generator loss = 16.692325592041016\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 24, Batch: 27/468, discriminator loss real = 3.107180984484881e-22, disciminator loss fake = 1.8644414012669586e-07, generator loss = 16.526723861694336\n",
      "2/2 [==============================] - 0s 169ms/step\n",
      "Epoch: 24, Batch: 28/468, discriminator loss real = 8.285520036916324e-21, disciminator loss fake = 1.1551500733730791e-07, generator loss = 16.706398010253906\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 24, Batch: 29/468, discriminator loss real = 7.638892975620869e-28, disciminator loss fake = 1.3122286190991872e-07, generator loss = 16.904041290283203\n",
      "2/2 [==============================] - 0s 175ms/step\n",
      "Epoch: 24, Batch: 30/468, discriminator loss real = 6.270393828211742e-24, disciminator loss fake = 4.265139921244554e-07, generator loss = 16.82044219970703\n",
      "2/2 [==============================] - 0s 164ms/step\n",
      "Epoch: 24, Batch: 31/468, discriminator loss real = 1.846185055391956e-20, disciminator loss fake = 1.788163785931829e-07, generator loss = 16.716766357421875\n",
      "2/2 [==============================] - 1s 247ms/step\n",
      "Epoch: 24, Batch: 32/468, discriminator loss real = 8.186489062790332e-18, disciminator loss fake = 9.562610614466394e-08, generator loss = 16.663654327392578\n",
      "2/2 [==============================] - 0s 183ms/step\n",
      "Epoch: 24, Batch: 33/468, discriminator loss real = 7.063161641021571e-27, disciminator loss fake = 1.1110472541986383e-07, generator loss = 16.68685531616211\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 24, Batch: 34/468, discriminator loss real = 2.0207545766465968e-21, disciminator loss fake = 1.8477763319424412e-07, generator loss = 16.47977066040039\n",
      "2/2 [==============================] - 0s 174ms/step\n",
      "Epoch: 24, Batch: 35/468, discriminator loss real = 5.496587705433593e-21, disciminator loss fake = 2.41237643194836e-07, generator loss = 16.61731719970703\n",
      "2/2 [==============================] - 0s 164ms/step\n",
      "Epoch: 24, Batch: 36/468, discriminator loss real = 2.9376854681489872e-12, disciminator loss fake = 1.9750014246255887e-07, generator loss = 16.471202850341797\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 24, Batch: 37/468, discriminator loss real = 3.8471538706093516e-33, disciminator loss fake = 1.7725699308357434e-07, generator loss = 16.75049591064453\n",
      "2/2 [==============================] - 0s 174ms/step\n",
      "Epoch: 24, Batch: 38/468, discriminator loss real = 1.514703462602629e-18, disciminator loss fake = 2.1260865423755604e-07, generator loss = 16.899568557739258\n",
      "2/2 [==============================] - 0s 182ms/step\n",
      "Epoch: 24, Batch: 39/468, discriminator loss real = 1.0041920276150923e-31, disciminator loss fake = 1.29780445945471e-07, generator loss = 16.912351608276367\n",
      "2/2 [==============================] - 1s 243ms/step\n",
      "Epoch: 24, Batch: 40/468, discriminator loss real = 8.073502803795929e-12, disciminator loss fake = 2.435368173792085e-07, generator loss = 16.643917083740234\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 24, Batch: 41/468, discriminator loss real = 9.48857460119343e-30, disciminator loss fake = 1.740254447213374e-07, generator loss = 16.7247371673584\n",
      "2/2 [==============================] - 0s 136ms/step\n",
      "Epoch: 24, Batch: 42/468, discriminator loss real = 2.3743882407235044e-18, disciminator loss fake = 1.0974500241900387e-07, generator loss = 16.570270538330078\n",
      "2/2 [==============================] - 0s 146ms/step\n",
      "Epoch: 24, Batch: 43/468, discriminator loss real = 1.9580918917544432e-13, disciminator loss fake = 1.1941840227791545e-07, generator loss = 16.548561096191406\n",
      "2/2 [==============================] - 0s 174ms/step\n",
      "Epoch: 24, Batch: 44/468, discriminator loss real = 3.031349260149141e-12, disciminator loss fake = 1.3385623276462866e-07, generator loss = 16.683486938476562\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 24, Batch: 45/468, discriminator loss real = 7.806130741805362e-12, disciminator loss fake = 1.4433925343837473e-07, generator loss = 16.78106689453125\n",
      "2/2 [==============================] - 0s 176ms/step\n",
      "Epoch: 24, Batch: 46/468, discriminator loss real = 6.087074402529175e-22, disciminator loss fake = 2.0554523416649317e-07, generator loss = 16.7707462310791\n",
      "2/2 [==============================] - 0s 154ms/step\n",
      "Epoch: 24, Batch: 47/468, discriminator loss real = 3.1344621927245753e-21, disciminator loss fake = 2.1421803353405267e-07, generator loss = 16.764785766601562\n",
      "2/2 [==============================] - 0s 158ms/step\n",
      "Epoch: 24, Batch: 48/468, discriminator loss real = 8.036407566221998e-25, disciminator loss fake = 2.1578654241238837e-07, generator loss = 17.01697540283203\n",
      "2/2 [==============================] - 0s 217ms/step\n",
      "Epoch: 24, Batch: 49/468, discriminator loss real = 3.08906038406402e-24, disciminator loss fake = 1.53666775304373e-07, generator loss = 16.81869888305664\n",
      "2/2 [==============================] - 0s 178ms/step\n",
      "Epoch: 24, Batch: 50/468, discriminator loss real = 5.3129261444655444e-21, disciminator loss fake = 1.9134691342514998e-07, generator loss = 16.882801055908203\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 24, Batch: 51/468, discriminator loss real = 2.724369026747764e-21, disciminator loss fake = 2.1296827412697894e-07, generator loss = 16.93108558654785\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 24, Batch: 52/468, discriminator loss real = 1.479795795933778e-29, disciminator loss fake = 1.2302396612540178e-07, generator loss = 16.822118759155273\n",
      "2/2 [==============================] - 0s 167ms/step\n",
      "Epoch: 24, Batch: 53/468, discriminator loss real = 4.631043378638955e-12, disciminator loss fake = 1.9470817846922728e-07, generator loss = 16.73743438720703\n",
      "2/2 [==============================] - 1s 211ms/step\n",
      "Epoch: 24, Batch: 54/468, discriminator loss real = 5.915224903967995e-23, disciminator loss fake = 1.572787482473359e-07, generator loss = 16.71710968017578\n",
      "2/2 [==============================] - 0s 168ms/step\n",
      "Epoch: 24, Batch: 55/468, discriminator loss real = 9.379004204298128e-33, disciminator loss fake = 1.4371286738423805e-07, generator loss = 16.62104034423828\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 24, Batch: 56/468, discriminator loss real = 1.2895045231120446e-19, disciminator loss fake = 2.1454548004840035e-07, generator loss = 16.713966369628906\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 24, Batch: 57/468, discriminator loss real = 2.191631855812481e-25, disciminator loss fake = 1.3114697594573954e-07, generator loss = 16.732322692871094\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 24, Batch: 58/468, discriminator loss real = 0.0, disciminator loss fake = 1.8668542622890527e-07, generator loss = 16.626781463623047\n",
      "2/2 [==============================] - 0s 168ms/step\n",
      "Epoch: 24, Batch: 59/468, discriminator loss real = 1.3151573737112813e-28, disciminator loss fake = 1.0795429261634126e-07, generator loss = 16.749614715576172\n",
      "2/2 [==============================] - 0s 191ms/step\n",
      "Epoch: 24, Batch: 60/468, discriminator loss real = 1.6449694909027532e-25, disciminator loss fake = 1.4951210403069126e-07, generator loss = 16.85205078125\n",
      "2/2 [==============================] - 1s 325ms/step\n",
      "Epoch: 24, Batch: 61/468, discriminator loss real = 8.124441119861103e-10, disciminator loss fake = 1.3250462416181108e-07, generator loss = 16.5368595123291\n",
      "2/2 [==============================] - 0s 146ms/step\n",
      "Epoch: 24, Batch: 62/468, discriminator loss real = 5.742786694290467e-24, disciminator loss fake = 1.0753573320698706e-07, generator loss = 16.901714324951172\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 24, Batch: 63/468, discriminator loss real = 2.442686967088965e-22, disciminator loss fake = 1.279589838532047e-07, generator loss = 16.904510498046875\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 24, Batch: 64/468, discriminator loss real = 2.8518516720066583e-16, disciminator loss fake = 2.2208962491276907e-07, generator loss = 17.13080596923828\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 24, Batch: 65/468, discriminator loss real = 6.547531629382466e-23, disciminator loss fake = 1.6371480171528674e-07, generator loss = 16.66708755493164\n",
      "2/2 [==============================] - 0s 155ms/step\n",
      "Epoch: 24, Batch: 66/468, discriminator loss real = 7.266148573070254e-23, disciminator loss fake = 7.63333645181774e-08, generator loss = 16.887920379638672\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 24, Batch: 67/468, discriminator loss real = 4.283618056128678e-24, disciminator loss fake = 1.1848944581061005e-07, generator loss = 16.77457046508789\n",
      "2/2 [==============================] - 0s 173ms/step\n",
      "Epoch: 24, Batch: 68/468, discriminator loss real = 2.4728540178465754e-20, disciminator loss fake = 1.5531853136963036e-07, generator loss = 16.85748291015625\n",
      "2/2 [==============================] - 0s 164ms/step\n",
      "Epoch: 24, Batch: 69/468, discriminator loss real = 1.681664130680958e-19, disciminator loss fake = 1.580041555371281e-07, generator loss = 16.630577087402344\n",
      "2/2 [==============================] - 1s 287ms/step\n",
      "Epoch: 24, Batch: 70/468, discriminator loss real = 2.2575476805268275e-16, disciminator loss fake = 1.3829738065851416e-07, generator loss = 17.001754760742188\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 24, Batch: 71/468, discriminator loss real = 5.363788919837595e-37, disciminator loss fake = 2.2049223957765207e-07, generator loss = 16.72532081604004\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 24, Batch: 72/468, discriminator loss real = 4.587404884140492e-30, disciminator loss fake = 1.2852579800437525e-07, generator loss = 16.626758575439453\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 24, Batch: 73/468, discriminator loss real = 3.4650771961210506e-25, disciminator loss fake = 1.2810268401608482e-07, generator loss = 16.612516403198242\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 24, Batch: 74/468, discriminator loss real = 4.517215452719415e-22, disciminator loss fake = 1.1615279760235353e-07, generator loss = 16.827125549316406\n",
      "2/2 [==============================] - 0s 175ms/step\n",
      "Epoch: 24, Batch: 75/468, discriminator loss real = 2.1447558627100266e-14, disciminator loss fake = 2.8216538794367807e-07, generator loss = 16.753292083740234\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 24, Batch: 76/468, discriminator loss real = 1.8792364288523533e-16, disciminator loss fake = 2.1646104642059072e-07, generator loss = 16.86676788330078\n",
      "2/2 [==============================] - 0s 134ms/step\n",
      "Epoch: 24, Batch: 77/468, discriminator loss real = 2.3222570528069743e-27, disciminator loss fake = 1.449234900974261e-07, generator loss = 16.93853759765625\n",
      "2/2 [==============================] - 0s 172ms/step\n",
      "Epoch: 24, Batch: 78/468, discriminator loss real = 4.958989839141637e-31, disciminator loss fake = 1.078629523476593e-07, generator loss = 16.836376190185547\n",
      "2/2 [==============================] - 1s 291ms/step\n",
      "Epoch: 24, Batch: 79/468, discriminator loss real = 2.8667204027277293e-11, disciminator loss fake = 9.806088030472893e-08, generator loss = 16.616485595703125\n",
      "2/2 [==============================] - 0s 141ms/step\n",
      "Epoch: 24, Batch: 80/468, discriminator loss real = 1.2585520708251638e-20, disciminator loss fake = 1.4017901150964462e-07, generator loss = 17.07788848876953\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 24, Batch: 81/468, discriminator loss real = 1.2047884794654236e-17, disciminator loss fake = 1.346402882518305e-07, generator loss = 16.856277465820312\n",
      "2/2 [==============================] - 0s 185ms/step\n",
      "Epoch: 24, Batch: 82/468, discriminator loss real = 1.9947646453563277e-23, disciminator loss fake = 1.2698242812803073e-07, generator loss = 16.7882137298584\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 24, Batch: 83/468, discriminator loss real = 2.1485839627336034e-24, disciminator loss fake = 1.046516757696736e-07, generator loss = 16.795595169067383\n",
      "2/2 [==============================] - 0s 225ms/step\n",
      "Epoch: 24, Batch: 84/468, discriminator loss real = 2.6145950096818915e-13, disciminator loss fake = 1.745792133078794e-07, generator loss = 16.74041175842285\n",
      "2/2 [==============================] - 0s 160ms/step\n",
      "Epoch: 24, Batch: 85/468, discriminator loss real = 2.1519412432015848e-14, disciminator loss fake = 1.960216025054251e-07, generator loss = 16.868410110473633\n",
      "2/2 [==============================] - 1s 279ms/step\n",
      "Epoch: 24, Batch: 86/468, discriminator loss real = 9.231795736256531e-26, disciminator loss fake = 1.5250707008362951e-07, generator loss = 16.671117782592773\n",
      "2/2 [==============================] - 0s 160ms/step\n",
      "Epoch: 24, Batch: 87/468, discriminator loss real = 8.745574526614947e-31, disciminator loss fake = 1.550944972450452e-07, generator loss = 16.56867790222168\n",
      "2/2 [==============================] - 1s 208ms/step\n",
      "Epoch: 24, Batch: 88/468, discriminator loss real = 2.455126826461225e-20, disciminator loss fake = 2.055798518085794e-07, generator loss = 16.964269638061523\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 24, Batch: 89/468, discriminator loss real = 5.1149563751184957e-11, disciminator loss fake = 1.6434377414498158e-07, generator loss = 16.815521240234375\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 24, Batch: 90/468, discriminator loss real = 2.2915250617772804e-22, disciminator loss fake = 1.9683901086864353e-07, generator loss = 16.91569709777832\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 24, Batch: 91/468, discriminator loss real = 3.0728532367662545e-24, disciminator loss fake = 1.9418692431827367e-07, generator loss = 17.099342346191406\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 24, Batch: 92/468, discriminator loss real = 1.8742972451857298e-11, disciminator loss fake = 1.0301905462029026e-07, generator loss = 16.82742691040039\n",
      "2/2 [==============================] - 0s 157ms/step\n",
      "Epoch: 24, Batch: 93/468, discriminator loss real = 8.435017502515978e-24, disciminator loss fake = 2.1413248418866715e-07, generator loss = 16.99343490600586\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 24, Batch: 94/468, discriminator loss real = 4.300282939966698e-25, disciminator loss fake = 1.750765363794926e-07, generator loss = 16.642606735229492\n",
      "2/2 [==============================] - 0s 134ms/step\n",
      "Epoch: 24, Batch: 95/468, discriminator loss real = 9.116226662442273e-10, disciminator loss fake = 1.8503381227219506e-07, generator loss = 16.888891220092773\n",
      "2/2 [==============================] - 0s 170ms/step\n",
      "Epoch: 24, Batch: 96/468, discriminator loss real = 9.233897311051289e-20, disciminator loss fake = 7.721278905137297e-08, generator loss = 16.971101760864258\n",
      "2/2 [==============================] - 0s 104ms/step\n",
      "Epoch: 24, Batch: 97/468, discriminator loss real = 3.15008472081379e-29, disciminator loss fake = 1.2226047374497284e-07, generator loss = 16.79415512084961\n",
      "2/2 [==============================] - 0s 151ms/step\n",
      "Epoch: 24, Batch: 98/468, discriminator loss real = 2.3745094838946088e-15, disciminator loss fake = 8.817703900376728e-08, generator loss = 17.015033721923828\n",
      "2/2 [==============================] - 0s 247ms/step\n",
      "Epoch: 24, Batch: 99/468, discriminator loss real = 8.43625686154635e-28, disciminator loss fake = 1.1895703977415906e-07, generator loss = 16.69890022277832\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 24, Batch: 100/468, discriminator loss real = 5.56320119024147e-21, disciminator loss fake = 1.20200127184944e-07, generator loss = 16.648601531982422\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 24, Batch: 101/468, discriminator loss real = 6.457535395298919e-09, disciminator loss fake = 1.972419738649478e-07, generator loss = 17.056976318359375\n",
      "2/2 [==============================] - 0s 141ms/step\n",
      "Epoch: 24, Batch: 102/468, discriminator loss real = 4.178956844296243e-20, disciminator loss fake = 1.2362650636532635e-07, generator loss = 17.009761810302734\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 24, Batch: 103/468, discriminator loss real = 2.693961616333146e-29, disciminator loss fake = 1.7602854995857342e-07, generator loss = 16.773616790771484\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 24, Batch: 104/468, discriminator loss real = 2.1672833188461886e-23, disciminator loss fake = 1.2780805036527454e-07, generator loss = 16.972970962524414\n",
      "2/2 [==============================] - 0s 147ms/step\n",
      "Epoch: 24, Batch: 105/468, discriminator loss real = 3.5332446603891787e-13, disciminator loss fake = 1.555265498609515e-07, generator loss = 16.970458984375\n",
      "2/2 [==============================] - 0s 171ms/step\n",
      "Epoch: 24, Batch: 106/468, discriminator loss real = 5.978297304506129e-20, disciminator loss fake = 8.651576877127809e-08, generator loss = 16.930011749267578\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 24, Batch: 107/468, discriminator loss real = 2.9635891518609014e-09, disciminator loss fake = 1.39801613840973e-07, generator loss = 16.91299057006836\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 24, Batch: 108/468, discriminator loss real = 7.570337484327522e-15, disciminator loss fake = 1.173935331166831e-07, generator loss = 16.902950286865234\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 24, Batch: 109/468, discriminator loss real = 1.0742984563432747e-27, disciminator loss fake = 2.413016773061827e-07, generator loss = 16.852806091308594\n",
      "2/2 [==============================] - 0s 182ms/step\n",
      "Epoch: 24, Batch: 110/468, discriminator loss real = 8.338418721765231e-20, disciminator loss fake = 1.055386178450135e-07, generator loss = 16.874731063842773\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 24, Batch: 111/468, discriminator loss real = 2.166220265036442e-20, disciminator loss fake = 2.0172382164673763e-07, generator loss = 16.89169692993164\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 24, Batch: 112/468, discriminator loss real = 7.82577271056839e-35, disciminator loss fake = 2.516121639928315e-07, generator loss = 16.719663619995117\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 24, Batch: 113/468, discriminator loss real = 2.9879447167208876e-20, disciminator loss fake = 1.5951317777762597e-07, generator loss = 17.023210525512695\n",
      "2/2 [==============================] - 0s 169ms/step\n",
      "Epoch: 24, Batch: 114/468, discriminator loss real = 1.9724766907204736e-18, disciminator loss fake = 1.5701198208262213e-07, generator loss = 16.926414489746094\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 24, Batch: 115/468, discriminator loss real = 3.4704051484230318e-28, disciminator loss fake = 1.1752719331070693e-07, generator loss = 16.918394088745117\n",
      "2/2 [==============================] - 0s 249ms/step\n",
      "Epoch: 24, Batch: 116/468, discriminator loss real = 2.0195141529612843e-30, disciminator loss fake = 7.520095124391446e-08, generator loss = 16.956493377685547\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 24, Batch: 117/468, discriminator loss real = 2.947349212572714e-20, disciminator loss fake = 1.5381506557332614e-07, generator loss = 17.08843994140625\n",
      "2/2 [==============================] - 1s 154ms/step\n",
      "Epoch: 24, Batch: 118/468, discriminator loss real = 1.031468134645768e-23, disciminator loss fake = 8.814671303980504e-08, generator loss = 16.854999542236328\n",
      "2/2 [==============================] - 0s 186ms/step\n",
      "Epoch: 24, Batch: 119/468, discriminator loss real = 5.797733222921826e-25, disciminator loss fake = 1.465115246901405e-07, generator loss = 16.911312103271484\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 24, Batch: 120/468, discriminator loss real = 1.9864908114884925e-27, disciminator loss fake = 1.0567924846327514e-07, generator loss = 16.83895492553711\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 24, Batch: 121/468, discriminator loss real = 1.0970650150871192e-31, disciminator loss fake = 1.4049278718175628e-07, generator loss = 17.047969818115234\n",
      "2/2 [==============================] - 0s 167ms/step\n",
      "Epoch: 24, Batch: 122/468, discriminator loss real = 1.0823709360337614e-30, disciminator loss fake = 1.6261164148545504e-07, generator loss = 16.978744506835938\n",
      "2/2 [==============================] - 1s 170ms/step\n",
      "Epoch: 24, Batch: 123/468, discriminator loss real = 2.521505682202829e-13, disciminator loss fake = 9.746040063873807e-08, generator loss = 16.796390533447266\n",
      "2/2 [==============================] - 0s 147ms/step\n",
      "Epoch: 24, Batch: 124/468, discriminator loss real = 6.296701475386277e-15, disciminator loss fake = 1.5790854490660422e-07, generator loss = 16.760887145996094\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 24, Batch: 125/468, discriminator loss real = 5.48476767529989e-35, disciminator loss fake = 1.8838663606857153e-07, generator loss = 16.81798553466797\n",
      "2/2 [==============================] - 0s 181ms/step\n",
      "Epoch: 24, Batch: 126/468, discriminator loss real = 2.2900748627613118e-36, disciminator loss fake = 1.8847370597541158e-07, generator loss = 16.969676971435547\n",
      "2/2 [==============================] - 0s 154ms/step\n",
      "Epoch: 24, Batch: 127/468, discriminator loss real = 1.3439946840724573e-18, disciminator loss fake = 1.4925353752914816e-07, generator loss = 16.988956451416016\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 24, Batch: 128/468, discriminator loss real = 1.639979960914393e-14, disciminator loss fake = 1.4761690181330778e-07, generator loss = 16.951446533203125\n",
      "2/2 [==============================] - 0s 136ms/step\n",
      "Epoch: 24, Batch: 129/468, discriminator loss real = 2.7688610318703655e-29, disciminator loss fake = 1.6421387272202992e-07, generator loss = 16.863590240478516\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 24, Batch: 130/468, discriminator loss real = 3.1055089227987835e-24, disciminator loss fake = 1.3001631771203392e-07, generator loss = 16.99613380432129\n",
      "2/2 [==============================] - 0s 150ms/step\n",
      "Epoch: 24, Batch: 131/468, discriminator loss real = 3.209724000344002e-30, disciminator loss fake = 1.0966999752781703e-07, generator loss = 17.03439712524414\n",
      "2/2 [==============================] - 1s 277ms/step\n",
      "Epoch: 24, Batch: 132/468, discriminator loss real = 3.793478943258668e-26, disciminator loss fake = 1.1265991162190403e-07, generator loss = 16.918190002441406\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 24, Batch: 133/468, discriminator loss real = 8.537397298270762e-31, disciminator loss fake = 1.72871324366497e-07, generator loss = 16.937637329101562\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 24, Batch: 134/468, discriminator loss real = 2.3659781354085205e-31, disciminator loss fake = 1.7259409901271283e-07, generator loss = 16.979698181152344\n",
      "2/2 [==============================] - 0s 154ms/step\n",
      "Epoch: 24, Batch: 135/468, discriminator loss real = 1.4240678828119382e-38, disciminator loss fake = 9.800811540117138e-08, generator loss = 17.11504364013672\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 24, Batch: 136/468, discriminator loss real = 1.6272802613185422e-23, disciminator loss fake = 1.576005956849258e-07, generator loss = 16.9429931640625\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 24, Batch: 137/468, discriminator loss real = 4.1488490296276784e-14, disciminator loss fake = 1.4044658769307716e-07, generator loss = 16.771034240722656\n",
      "2/2 [==============================] - 0s 160ms/step\n",
      "Epoch: 24, Batch: 138/468, discriminator loss real = 2.0034517985813704e-25, disciminator loss fake = 1.1740190331011036e-07, generator loss = 16.9683895111084\n",
      "2/2 [==============================] - 0s 195ms/step\n",
      "Epoch: 24, Batch: 139/468, discriminator loss real = 2.586563970481486e-15, disciminator loss fake = 8.453684330333999e-08, generator loss = 16.69156265258789\n",
      "2/2 [==============================] - 0s 155ms/step\n",
      "Epoch: 24, Batch: 140/468, discriminator loss real = 3.4117220341286035e-26, disciminator loss fake = 1.422969688746889e-07, generator loss = 16.848024368286133\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 24, Batch: 141/468, discriminator loss real = 9.114277639665616e-30, disciminator loss fake = 1.5783965068294492e-07, generator loss = 17.021793365478516\n",
      "2/2 [==============================] - 0s 275ms/step\n",
      "Epoch: 24, Batch: 142/468, discriminator loss real = 1.6294545197455123e-24, disciminator loss fake = 1.697902263231299e-07, generator loss = 17.032129287719727\n",
      "2/2 [==============================] - 0s 158ms/step\n",
      "Epoch: 24, Batch: 143/468, discriminator loss real = 1.398372219222592e-19, disciminator loss fake = 1.4442525753111113e-07, generator loss = 16.871253967285156\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 24, Batch: 144/468, discriminator loss real = 2.0675276520821366e-34, disciminator loss fake = 1.4515133273107494e-07, generator loss = 16.86148452758789\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 24, Batch: 145/468, discriminator loss real = 3.402373477860254e-36, disciminator loss fake = 1.4196331221683067e-07, generator loss = 16.839866638183594\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 24, Batch: 146/468, discriminator loss real = 4.977386316548456e-35, disciminator loss fake = 2.2326128146232804e-07, generator loss = 16.801572799682617\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 24, Batch: 147/468, discriminator loss real = 3.1085817332398456e-24, disciminator loss fake = 1.333258552449479e-07, generator loss = 17.058727264404297\n",
      "2/2 [==============================] - 0s 174ms/step\n",
      "Epoch: 24, Batch: 148/468, discriminator loss real = 4.551452436440366e-29, disciminator loss fake = 1.4300015038770653e-07, generator loss = 16.980541229248047\n",
      "2/2 [==============================] - 0s 135ms/step\n",
      "Epoch: 24, Batch: 149/468, discriminator loss real = 2.2441531461912453e-14, disciminator loss fake = 1.4053044594675157e-07, generator loss = 16.87884521484375\n",
      "2/2 [==============================] - 0s 191ms/step\n",
      "Epoch: 24, Batch: 150/468, discriminator loss real = 1.461375807865725e-21, disciminator loss fake = 9.75739666841946e-08, generator loss = 17.2852783203125\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 24, Batch: 151/468, discriminator loss real = 6.499194261980938e-19, disciminator loss fake = 7.498730525412611e-08, generator loss = 16.792985916137695\n",
      "2/2 [==============================] - 1s 174ms/step\n",
      "Epoch: 24, Batch: 152/468, discriminator loss real = 1.829639301994905e-26, disciminator loss fake = 9.364418929180829e-08, generator loss = 16.844974517822266\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 24, Batch: 153/468, discriminator loss real = 0.0, disciminator loss fake = 1.2489354617173376e-07, generator loss = 16.840831756591797\n",
      "2/2 [==============================] - 0s 134ms/step\n",
      "Epoch: 24, Batch: 154/468, discriminator loss real = 7.316324506014354e-17, disciminator loss fake = 1.034313896752792e-07, generator loss = 16.766708374023438\n",
      "2/2 [==============================] - 0s 150ms/step\n",
      "Epoch: 24, Batch: 155/468, discriminator loss real = 4.341076166420967e-21, disciminator loss fake = 1.24609314866575e-07, generator loss = 17.091297149658203\n",
      "2/2 [==============================] - 0s 151ms/step\n",
      "Epoch: 24, Batch: 156/468, discriminator loss real = 3.898533399938959e-36, disciminator loss fake = 1.2029570939375844e-07, generator loss = 16.83220863342285\n",
      "2/2 [==============================] - 1s 248ms/step\n",
      "Epoch: 24, Batch: 157/468, discriminator loss real = 3.0283997414656926e-24, disciminator loss fake = 9.843824955169111e-08, generator loss = 17.308631896972656\n",
      "2/2 [==============================] - 0s 134ms/step\n",
      "Epoch: 24, Batch: 158/468, discriminator loss real = 3.204552923943417e-25, disciminator loss fake = 8.853341171288776e-08, generator loss = 16.872453689575195\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 24, Batch: 159/468, discriminator loss real = 2.301360646706531e-29, disciminator loss fake = 1.4697796757445758e-07, generator loss = 16.89480972290039\n",
      "2/2 [==============================] - 0s 152ms/step\n",
      "Epoch: 24, Batch: 160/468, discriminator loss real = 1.2911011930389184e-15, disciminator loss fake = 1.1010933320676486e-07, generator loss = 16.992467880249023\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 24, Batch: 161/468, discriminator loss real = 1.519951134347698e-29, disciminator loss fake = 2.0270185530080198e-07, generator loss = 16.723464965820312\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 24, Batch: 162/468, discriminator loss real = 1.5482446054371213e-12, disciminator loss fake = 9.251714772062769e-08, generator loss = 17.065113067626953\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 24, Batch: 163/468, discriminator loss real = 3.444161281398787e-18, disciminator loss fake = 1.7491313997197722e-07, generator loss = 16.804460525512695\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 24, Batch: 164/468, discriminator loss real = 3.7218350223244227e-23, disciminator loss fake = 1.330382275455122e-07, generator loss = 16.97909927368164\n",
      "2/2 [==============================] - 0s 181ms/step\n",
      "Epoch: 24, Batch: 165/468, discriminator loss real = 1.5940875927374486e-27, disciminator loss fake = 8.931635875342181e-08, generator loss = 17.016788482666016\n",
      "2/2 [==============================] - 0s 130ms/step\n",
      "Epoch: 24, Batch: 166/468, discriminator loss real = 3.6480977332534666e-26, disciminator loss fake = 1.1122980936306703e-07, generator loss = 16.93170738220215\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 24, Batch: 167/468, discriminator loss real = 1.0245338228795182e-28, disciminator loss fake = 1.6043657069531037e-07, generator loss = 17.000837326049805\n",
      "2/2 [==============================] - 0s 161ms/step\n",
      "Epoch: 24, Batch: 168/468, discriminator loss real = 4.355448969144935e-24, disciminator loss fake = 1.7942089414191287e-07, generator loss = 16.98955726623535\n",
      "2/2 [==============================] - 0s 180ms/step\n",
      "Epoch: 24, Batch: 169/468, discriminator loss real = 1.7773788077679685e-25, disciminator loss fake = 1.1819138023838605e-07, generator loss = 17.11554718017578\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 24, Batch: 170/468, discriminator loss real = 2.4951502512052874e-19, disciminator loss fake = 8.767504766638012e-08, generator loss = 17.153045654296875\n",
      "2/2 [==============================] - 0s 144ms/step\n",
      "Epoch: 24, Batch: 171/468, discriminator loss real = 3.3735258473510463e-19, disciminator loss fake = 1.2278125893772085e-07, generator loss = 16.875144958496094\n",
      "2/2 [==============================] - 0s 168ms/step\n",
      "Epoch: 24, Batch: 172/468, discriminator loss real = 2.1661897304396115e-20, disciminator loss fake = 1.471150312681857e-07, generator loss = 17.068355560302734\n",
      "2/2 [==============================] - 0s 257ms/step\n",
      "Epoch: 24, Batch: 173/468, discriminator loss real = 2.4425079336474684e-14, disciminator loss fake = 7.846369243225126e-08, generator loss = 16.963207244873047\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 24, Batch: 174/468, discriminator loss real = 4.0744401979300076e-25, disciminator loss fake = 1.1879434680395207e-07, generator loss = 16.946563720703125\n",
      "2/2 [==============================] - 0s 163ms/step\n",
      "Epoch: 24, Batch: 175/468, discriminator loss real = 2.6637179450981692e-17, disciminator loss fake = 1.0975292497050759e-07, generator loss = 17.180370330810547\n",
      "2/2 [==============================] - 0s 195ms/step\n",
      "Epoch: 24, Batch: 176/468, discriminator loss real = 1.9027080440827868e-29, disciminator loss fake = 1.0437554465170251e-07, generator loss = 16.772659301757812\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 24, Batch: 177/468, discriminator loss real = 1.3033216721567786e-23, disciminator loss fake = 1.462274354935289e-07, generator loss = 17.088136672973633\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 24, Batch: 178/468, discriminator loss real = 2.3315497727548836e-16, disciminator loss fake = 1.1939820865336515e-07, generator loss = 17.12112045288086\n",
      "2/2 [==============================] - 1s 192ms/step\n",
      "Epoch: 24, Batch: 179/468, discriminator loss real = 2.444227785077222e-30, disciminator loss fake = 1.100501521023034e-07, generator loss = 16.96319007873535\n",
      "2/2 [==============================] - 0s 162ms/step\n",
      "Epoch: 24, Batch: 180/468, discriminator loss real = 7.15644634200455e-33, disciminator loss fake = 1.4765980438369297e-07, generator loss = 16.93476104736328\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 24, Batch: 181/468, discriminator loss real = 5.772514286414997e-23, disciminator loss fake = 8.91686013915205e-08, generator loss = 16.998689651489258\n",
      "2/2 [==============================] - 1s 289ms/step\n",
      "Epoch: 24, Batch: 182/468, discriminator loss real = 8.069240737293253e-15, disciminator loss fake = 9.314665305737435e-08, generator loss = 16.896486282348633\n",
      "2/2 [==============================] - 0s 170ms/step\n",
      "Epoch: 24, Batch: 183/468, discriminator loss real = 2.3035347433072375e-23, disciminator loss fake = 1.6180433703993913e-07, generator loss = 16.900854110717773\n",
      "2/2 [==============================] - 0s 151ms/step\n",
      "Epoch: 24, Batch: 184/468, discriminator loss real = 8.70452510071118e-09, disciminator loss fake = 1.3410411270342593e-07, generator loss = 16.938495635986328\n",
      "2/2 [==============================] - 0s 238ms/step\n",
      "Epoch: 24, Batch: 185/468, discriminator loss real = 1.6772356004347555e-32, disciminator loss fake = 1.4449250329562346e-07, generator loss = 17.039669036865234\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 24, Batch: 186/468, discriminator loss real = 3.346857564092305e-23, disciminator loss fake = 9.675740386683174e-08, generator loss = 16.974021911621094\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 24, Batch: 187/468, discriminator loss real = 3.6212893167229694e-32, disciminator loss fake = 1.4104131196290837e-07, generator loss = 16.903684616088867\n",
      "2/2 [==============================] - 0s 231ms/step\n",
      "Epoch: 24, Batch: 188/468, discriminator loss real = 9.470969739518679e-33, disciminator loss fake = 7.047025007977936e-08, generator loss = 16.90000343322754\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 24, Batch: 189/468, discriminator loss real = 0.0, disciminator loss fake = 1.1724904425136629e-07, generator loss = 16.95255470275879\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 24, Batch: 190/468, discriminator loss real = 1.0853370642859272e-18, disciminator loss fake = 1.0810675377115331e-07, generator loss = 16.98609161376953\n",
      "2/2 [==============================] - 0s 165ms/step\n",
      "Epoch: 24, Batch: 191/468, discriminator loss real = 5.403620430403373e-33, disciminator loss fake = 1.721466702520047e-07, generator loss = 16.993324279785156\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 24, Batch: 192/468, discriminator loss real = 1.174579172986839e-28, disciminator loss fake = 9.414529245077574e-08, generator loss = 17.20382308959961\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 24, Batch: 193/468, discriminator loss real = 1.7017819118663604e-35, disciminator loss fake = 1.1993824955425225e-07, generator loss = 17.14948081970215\n",
      "2/2 [==============================] - 1s 267ms/step\n",
      "Epoch: 24, Batch: 194/468, discriminator loss real = 4.540995703834804e-20, disciminator loss fake = 1.378705860588525e-07, generator loss = 16.92373275756836\n",
      "2/2 [==============================] - 0s 167ms/step\n",
      "Epoch: 24, Batch: 195/468, discriminator loss real = 4.395380240420227e-23, disciminator loss fake = 1.592483727108629e-07, generator loss = 17.05405044555664\n",
      "2/2 [==============================] - 0s 186ms/step\n",
      "Epoch: 24, Batch: 196/468, discriminator loss real = 4.4533213639338956e-24, disciminator loss fake = 1.1625355256228431e-07, generator loss = 16.96419906616211\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 24, Batch: 197/468, discriminator loss real = 7.37128320428894e-30, disciminator loss fake = 1.3909033214076771e-07, generator loss = 17.042558670043945\n",
      "2/2 [==============================] - 1s 240ms/step\n",
      "Epoch: 24, Batch: 198/468, discriminator loss real = 2.5709504976002327e-19, disciminator loss fake = 1.4113075508248585e-07, generator loss = 16.892091751098633\n",
      "2/2 [==============================] - 0s 201ms/step\n",
      "Epoch: 24, Batch: 199/468, discriminator loss real = 1.0156473335540562e-20, disciminator loss fake = 1.0678439821276697e-07, generator loss = 16.776626586914062\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 24, Batch: 200/468, discriminator loss real = 5.492425358966102e-08, disciminator loss fake = 1.0762016700027743e-07, generator loss = 17.09834098815918\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 24, Batch: 201/468, discriminator loss real = 3.5037015777561464e-07, disciminator loss fake = 1.0665271332754855e-07, generator loss = 17.171815872192383\n",
      "2/2 [==============================] - 0s 146ms/step\n",
      "Epoch: 24, Batch: 202/468, discriminator loss real = 2.5935271725369136e-12, disciminator loss fake = 6.52298837167109e-08, generator loss = 16.984683990478516\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 24, Batch: 203/468, discriminator loss real = 5.255941299878e-28, disciminator loss fake = 9.791065735953453e-08, generator loss = 16.910160064697266\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 24, Batch: 204/468, discriminator loss real = 6.186466901145987e-30, disciminator loss fake = 2.087182480181582e-07, generator loss = 17.20435333251953\n",
      "2/2 [==============================] - 0s 186ms/step\n",
      "Epoch: 24, Batch: 205/468, discriminator loss real = 1.736156029904609e-29, disciminator loss fake = 1.4284842109191231e-07, generator loss = 17.220516204833984\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 24, Batch: 206/468, discriminator loss real = 4.226091920855879e-09, disciminator loss fake = 9.694791458514374e-08, generator loss = 17.072959899902344\n",
      "2/2 [==============================] - 0s 141ms/step\n",
      "Epoch: 24, Batch: 207/468, discriminator loss real = 2.9972783575381954e-27, disciminator loss fake = 8.761428915704528e-08, generator loss = 16.999267578125\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 24, Batch: 208/468, discriminator loss real = 1.63746172666825e-16, disciminator loss fake = 1.6953444514911098e-07, generator loss = 16.909908294677734\n",
      "2/2 [==============================] - 0s 147ms/step\n",
      "Epoch: 24, Batch: 209/468, discriminator loss real = 1.0800531476118369e-11, disciminator loss fake = 1.2081343925274268e-07, generator loss = 16.979183197021484\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 24, Batch: 210/468, discriminator loss real = 2.7659423163360082e-25, disciminator loss fake = 2.0401627409682987e-07, generator loss = 16.86951446533203\n",
      "2/2 [==============================] - 0s 216ms/step\n",
      "Epoch: 24, Batch: 211/468, discriminator loss real = 1.0542267033523626e-27, disciminator loss fake = 8.885597679864077e-08, generator loss = 17.01970863342285\n",
      "2/2 [==============================] - 0s 146ms/step\n",
      "Epoch: 24, Batch: 212/468, discriminator loss real = 1.141494132843646e-26, disciminator loss fake = 1.702445473483749e-07, generator loss = 17.039989471435547\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 24, Batch: 213/468, discriminator loss real = 4.197334551841055e-21, disciminator loss fake = 1.1960871404426143e-07, generator loss = 17.24736785888672\n",
      "2/2 [==============================] - 0s 200ms/step\n",
      "Epoch: 24, Batch: 214/468, discriminator loss real = 9.025190051344958e-16, disciminator loss fake = 1.2230282209202414e-07, generator loss = 17.039295196533203\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 24, Batch: 215/468, discriminator loss real = 5.162139196732797e-20, disciminator loss fake = 2.1761199775482964e-07, generator loss = 17.03270149230957\n",
      "2/2 [==============================] - 0s 134ms/step\n",
      "Epoch: 24, Batch: 216/468, discriminator loss real = 1.771187580864761e-23, disciminator loss fake = 1.2541026706003322e-07, generator loss = 16.954299926757812\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 24, Batch: 217/468, discriminator loss real = 1.192833748442368e-10, disciminator loss fake = 1.1579942338357796e-07, generator loss = 17.031475067138672\n",
      "2/2 [==============================] - 0s 141ms/step\n",
      "Epoch: 24, Batch: 218/468, discriminator loss real = 1.125753605832605e-34, disciminator loss fake = 1.614232019164774e-07, generator loss = 16.951519012451172\n",
      "2/2 [==============================] - 1s 257ms/step\n",
      "Epoch: 24, Batch: 219/468, discriminator loss real = 1.1960473145167184e-16, disciminator loss fake = 6.29680414476752e-08, generator loss = 17.358489990234375\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 24, Batch: 220/468, discriminator loss real = 2.973435296678433e-28, disciminator loss fake = 1.639584752410883e-07, generator loss = 16.98487091064453\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 24, Batch: 221/468, discriminator loss real = 3.1556691954287836e-28, disciminator loss fake = 1.1310883252235726e-07, generator loss = 17.111330032348633\n",
      "2/2 [==============================] - 0s 160ms/step\n",
      "Epoch: 24, Batch: 222/468, discriminator loss real = 2.761321410989578e-18, disciminator loss fake = 1.2602745869116916e-07, generator loss = 16.621295928955078\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 24, Batch: 223/468, discriminator loss real = 2.466593823722413e-16, disciminator loss fake = 1.4138493042992195e-07, generator loss = 16.92397689819336\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 24, Batch: 224/468, discriminator loss real = 8.298995649200123e-21, disciminator loss fake = 9.530587874451157e-08, generator loss = 17.119108200073242\n",
      "2/2 [==============================] - 0s 191ms/step\n",
      "Epoch: 24, Batch: 225/468, discriminator loss real = 4.639721405836182e-25, disciminator loss fake = 8.728389389034419e-08, generator loss = 17.137554168701172\n",
      "2/2 [==============================] - 0s 145ms/step\n",
      "Epoch: 24, Batch: 226/468, discriminator loss real = 7.794683385126015e-18, disciminator loss fake = 1.1396387122886154e-07, generator loss = 16.847326278686523\n",
      "2/2 [==============================] - 0s 107ms/step\n",
      "Epoch: 24, Batch: 227/468, discriminator loss real = 5.056989983015514e-13, disciminator loss fake = 1.7960476839107287e-07, generator loss = 17.07048797607422\n",
      "2/2 [==============================] - 0s 147ms/step\n",
      "Epoch: 24, Batch: 228/468, discriminator loss real = 0.0, disciminator loss fake = 8.425618602814211e-08, generator loss = 17.03790855407715\n",
      "2/2 [==============================] - 0s 150ms/step\n",
      "Epoch: 24, Batch: 229/468, discriminator loss real = 4.8329613282080565e-30, disciminator loss fake = 8.539820584019253e-08, generator loss = 17.13479995727539\n",
      "2/2 [==============================] - 1s 322ms/step\n",
      "Epoch: 24, Batch: 230/468, discriminator loss real = 9.513049529925709e-17, disciminator loss fake = 1.4441290829836362e-07, generator loss = 17.19719696044922\n",
      "2/2 [==============================] - 0s 150ms/step\n",
      "Epoch: 24, Batch: 231/468, discriminator loss real = 1.2281725658182252e-13, disciminator loss fake = 6.365806370922655e-08, generator loss = 17.203336715698242\n",
      "2/2 [==============================] - 0s 155ms/step\n",
      "Epoch: 24, Batch: 232/468, discriminator loss real = 1.6462208805023693e-06, disciminator loss fake = 7.586434236372952e-08, generator loss = 17.069679260253906\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 24, Batch: 233/468, discriminator loss real = 5.857118671866864e-24, disciminator loss fake = 7.762313458670178e-08, generator loss = 16.982080459594727\n",
      "2/2 [==============================] - 0s 134ms/step\n",
      "Epoch: 24, Batch: 234/468, discriminator loss real = 7.34488719844606e-11, disciminator loss fake = 7.249494160532777e-08, generator loss = 17.17824935913086\n",
      "2/2 [==============================] - 0s 105ms/step\n",
      "Epoch: 24, Batch: 235/468, discriminator loss real = 1.7016661175295787e-37, disciminator loss fake = 8.760079595049319e-08, generator loss = 16.882871627807617\n",
      "2/2 [==============================] - 0s 158ms/step\n",
      "Epoch: 24, Batch: 236/468, discriminator loss real = 4.419388612035024e-18, disciminator loss fake = 1.3946524290986417e-07, generator loss = 17.204456329345703\n",
      "2/2 [==============================] - 0s 157ms/step\n",
      "Epoch: 24, Batch: 237/468, discriminator loss real = 3.312800450631997e-17, disciminator loss fake = 1.213761038343364e-07, generator loss = 16.979278564453125\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 24, Batch: 238/468, discriminator loss real = 7.742806352344143e-21, disciminator loss fake = 6.705492694436543e-08, generator loss = 17.06893539428711\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 24, Batch: 239/468, discriminator loss real = 6.5731349128874544e-15, disciminator loss fake = 8.346064817033039e-08, generator loss = 17.183446884155273\n",
      "2/2 [==============================] - 0s 185ms/step\n",
      "Epoch: 24, Batch: 240/468, discriminator loss real = 1.3914498384514005e-28, disciminator loss fake = 1.924864534430526e-07, generator loss = 17.155559539794922\n",
      "2/2 [==============================] - 0s 136ms/step\n",
      "Epoch: 24, Batch: 241/468, discriminator loss real = 3.978439862760293e-21, disciminator loss fake = 1.059249683521557e-07, generator loss = 16.863685607910156\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 24, Batch: 242/468, discriminator loss real = 1.7503606915426981e-25, disciminator loss fake = 1.320378970603997e-07, generator loss = 17.061656951904297\n",
      "2/2 [==============================] - 0s 130ms/step\n",
      "Epoch: 24, Batch: 243/468, discriminator loss real = 1.0091669030848909e-29, disciminator loss fake = 1.0281101481268706e-07, generator loss = 16.813894271850586\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 24, Batch: 244/468, discriminator loss real = 8.565154345306333e-27, disciminator loss fake = 9.769428288564086e-08, generator loss = 17.009838104248047\n",
      "2/2 [==============================] - 0s 134ms/step\n",
      "Epoch: 24, Batch: 245/468, discriminator loss real = 2.6908201477414208e-27, disciminator loss fake = 1.1954536205394106e-07, generator loss = 17.032791137695312\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 24, Batch: 246/468, discriminator loss real = 3.3409804746177614e-21, disciminator loss fake = 1.4151437710552273e-07, generator loss = 17.141719818115234\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 24, Batch: 247/468, discriminator loss real = 1.0127631490162807e-16, disciminator loss fake = 1.306011085944192e-07, generator loss = 17.056259155273438\n",
      "2/2 [==============================] - 0s 161ms/step\n",
      "Epoch: 24, Batch: 248/468, discriminator loss real = 3.86923328109254e-20, disciminator loss fake = 9.773935971679748e-08, generator loss = 17.285369873046875\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 24, Batch: 249/468, discriminator loss real = 1.4774018914027528e-33, disciminator loss fake = 8.334554024713725e-08, generator loss = 17.00340461730957\n",
      "2/2 [==============================] - 0s 164ms/step\n",
      "Epoch: 24, Batch: 250/468, discriminator loss real = 8.074202495007209e-29, disciminator loss fake = 8.920589777972054e-08, generator loss = 17.045398712158203\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 24, Batch: 251/468, discriminator loss real = 1.6690103090071371e-22, disciminator loss fake = 1.2506066582318454e-07, generator loss = 17.001365661621094\n",
      "2/2 [==============================] - 0s 151ms/step\n",
      "Epoch: 24, Batch: 252/468, discriminator loss real = 4.156354067939723e-32, disciminator loss fake = 9.567520464770496e-08, generator loss = 16.918190002441406\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 24, Batch: 253/468, discriminator loss real = 6.414476155097715e-12, disciminator loss fake = 1.0012526274749689e-07, generator loss = 16.784832000732422\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 24, Batch: 254/468, discriminator loss real = 1.1169071310185297e-14, disciminator loss fake = 5.898026955719615e-08, generator loss = 17.083288192749023\n",
      "2/2 [==============================] - 0s 166ms/step\n",
      "Epoch: 24, Batch: 255/468, discriminator loss real = 1.089106763166798e-28, disciminator loss fake = 1.7379778682879987e-07, generator loss = 16.914196014404297\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 24, Batch: 256/468, discriminator loss real = 3.877969212585024e-24, disciminator loss fake = 8.609313795204798e-08, generator loss = 17.11810302734375\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 24, Batch: 257/468, discriminator loss real = 3.87977716818382e-21, disciminator loss fake = 8.091128478326937e-08, generator loss = 16.905302047729492\n",
      "2/2 [==============================] - 0s 154ms/step\n",
      "Epoch: 24, Batch: 258/468, discriminator loss real = 2.2769264251820687e-09, disciminator loss fake = 1.3064294535070076e-07, generator loss = 17.038381576538086\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 24, Batch: 259/468, discriminator loss real = 1.1435029887092066e-24, disciminator loss fake = 4.692014599072536e-08, generator loss = 17.205806732177734\n",
      "2/2 [==============================] - 0s 144ms/step\n",
      "Epoch: 24, Batch: 260/468, discriminator loss real = 3.918275152324887e-18, disciminator loss fake = 1.1705262181749276e-07, generator loss = 17.142723083496094\n",
      "2/2 [==============================] - 0s 174ms/step\n",
      "Epoch: 24, Batch: 261/468, discriminator loss real = 4.2680404566466934e-13, disciminator loss fake = 1.1524941356810814e-07, generator loss = 17.231895446777344\n",
      "2/2 [==============================] - 1s 168ms/step\n",
      "Epoch: 24, Batch: 262/468, discriminator loss real = 4.848121761824586e-07, disciminator loss fake = 1.73977014128468e-07, generator loss = 16.94194221496582\n",
      "2/2 [==============================] - 0s 159ms/step\n",
      "Epoch: 24, Batch: 263/468, discriminator loss real = 2.0095946831022298e-25, disciminator loss fake = 7.648478828059524e-08, generator loss = 17.12881088256836\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 24, Batch: 264/468, discriminator loss real = 8.818259505284038e-17, disciminator loss fake = 9.792202604330669e-08, generator loss = 16.962600708007812\n",
      "2/2 [==============================] - 1s 248ms/step\n",
      "Epoch: 24, Batch: 265/468, discriminator loss real = 1.2900123177002854e-36, disciminator loss fake = 1.356907262106688e-07, generator loss = 17.26477813720703\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 24, Batch: 266/468, discriminator loss real = 9.527508300651254e-21, disciminator loss fake = 9.577451010045479e-08, generator loss = 17.078060150146484\n",
      "2/2 [==============================] - 0s 154ms/step\n",
      "Epoch: 24, Batch: 267/468, discriminator loss real = 4.681153623034315e-21, disciminator loss fake = 1.8040876170744014e-07, generator loss = 17.28641128540039\n",
      "2/2 [==============================] - 1s 193ms/step\n",
      "Epoch: 24, Batch: 268/468, discriminator loss real = 2.1779102092508274e-21, disciminator loss fake = 7.49980486602908e-08, generator loss = 16.901262283325195\n",
      "2/2 [==============================] - 0s 147ms/step\n",
      "Epoch: 24, Batch: 269/468, discriminator loss real = 1.6279675171317637e-31, disciminator loss fake = 1.4442142060033802e-07, generator loss = 17.081283569335938\n",
      "2/2 [==============================] - 0s 178ms/step\n",
      "Epoch: 24, Batch: 270/468, discriminator loss real = 7.359318051545818e-27, disciminator loss fake = 9.207194295868248e-08, generator loss = 17.332168579101562\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 24, Batch: 271/468, discriminator loss real = 1.386475485841489e-31, disciminator loss fake = 7.199057705520318e-08, generator loss = 17.23396110534668\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 24, Batch: 272/468, discriminator loss real = 2.1612357533745832e-23, disciminator loss fake = 8.070036727758634e-08, generator loss = 17.02553939819336\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 24, Batch: 273/468, discriminator loss real = 2.5591470618938362e-28, disciminator loss fake = 1.327770462467015e-07, generator loss = 17.011507034301758\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 24, Batch: 274/468, discriminator loss real = 4.301019974097116e-28, disciminator loss fake = 9.274964440919575e-08, generator loss = 17.10738754272461\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 24, Batch: 275/468, discriminator loss real = 9.296984839965439e-14, disciminator loss fake = 8.939337448055085e-08, generator loss = 17.082714080810547\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 24, Batch: 276/468, discriminator loss real = 0.0, disciminator loss fake = 9.507449760803866e-08, generator loss = 17.152507781982422\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 24, Batch: 277/468, discriminator loss real = 9.688491057227284e-21, disciminator loss fake = 9.770219122628987e-08, generator loss = 17.032150268554688\n",
      "2/2 [==============================] - 0s 215ms/step\n",
      "Epoch: 24, Batch: 278/468, discriminator loss real = 9.846392771224385e-14, disciminator loss fake = 1.1003344013715832e-07, generator loss = 17.005762100219727\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 24, Batch: 279/468, discriminator loss real = 1.2873330874114277e-33, disciminator loss fake = 9.161303893279182e-08, generator loss = 17.12367057800293\n",
      "2/2 [==============================] - 0s 134ms/step\n",
      "Epoch: 24, Batch: 280/468, discriminator loss real = 4.247991934109982e-33, disciminator loss fake = 6.761557358458958e-08, generator loss = 16.947105407714844\n",
      "2/2 [==============================] - 0s 189ms/step\n",
      "Epoch: 24, Batch: 281/468, discriminator loss real = 1.3501605534122365e-26, disciminator loss fake = 1.0151560303484075e-07, generator loss = 17.11642074584961\n",
      "2/2 [==============================] - 0s 145ms/step\n",
      "Epoch: 24, Batch: 282/468, discriminator loss real = 1.0673799229506873e-22, disciminator loss fake = 1.161715061925861e-07, generator loss = 17.102676391601562\n",
      "2/2 [==============================] - 0s 152ms/step\n",
      "Epoch: 24, Batch: 283/468, discriminator loss real = 6.123686569055011e-31, disciminator loss fake = 1.1554415380032879e-07, generator loss = 17.098461151123047\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 24, Batch: 284/468, discriminator loss real = 7.168280626194621e-20, disciminator loss fake = 1.0346436596364583e-07, generator loss = 17.158851623535156\n",
      "2/2 [==============================] - 0s 201ms/step\n",
      "Epoch: 24, Batch: 285/468, discriminator loss real = 1.197154719105386e-19, disciminator loss fake = 1.389903019344274e-07, generator loss = 17.160017013549805\n",
      "2/2 [==============================] - 0s 148ms/step\n",
      "Epoch: 24, Batch: 286/468, discriminator loss real = 3.077547888906862e-15, disciminator loss fake = 1.4746831311640562e-07, generator loss = 17.103031158447266\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 24, Batch: 287/468, discriminator loss real = 4.792709441313058e-24, disciminator loss fake = 1.1108127750958374e-07, generator loss = 17.14321517944336\n",
      "2/2 [==============================] - 0s 201ms/step\n",
      "Epoch: 24, Batch: 288/468, discriminator loss real = 2.9454660524119167e-31, disciminator loss fake = 1.0878275702452811e-07, generator loss = 17.279481887817383\n",
      "2/2 [==============================] - 0s 153ms/step\n",
      "Epoch: 24, Batch: 289/468, discriminator loss real = 1.295161517617241e-20, disciminator loss fake = 1.0645014469901071e-07, generator loss = 17.086606979370117\n",
      "2/2 [==============================] - 0s 130ms/step\n",
      "Epoch: 24, Batch: 290/468, discriminator loss real = 3.949822917248836e-29, disciminator loss fake = 9.218565111268617e-08, generator loss = 17.181114196777344\n",
      "2/2 [==============================] - 0s 217ms/step\n",
      "Epoch: 24, Batch: 291/468, discriminator loss real = 4.2163476698056274e-20, disciminator loss fake = 6.606880020854078e-08, generator loss = 17.196704864501953\n",
      "2/2 [==============================] - 0s 150ms/step\n",
      "Epoch: 24, Batch: 292/468, discriminator loss real = 4.760242755530442e-10, disciminator loss fake = 8.248476035532804e-08, generator loss = 17.217830657958984\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 24, Batch: 293/468, discriminator loss real = 2.017778847653029e-14, disciminator loss fake = 1.8018552339071903e-07, generator loss = 17.115049362182617\n",
      "2/2 [==============================] - 1s 275ms/step\n",
      "Epoch: 24, Batch: 294/468, discriminator loss real = 2.8371882968003526e-11, disciminator loss fake = 1.166928100815312e-07, generator loss = 17.36989402770996\n",
      "2/2 [==============================] - 0s 148ms/step\n",
      "Epoch: 24, Batch: 295/468, discriminator loss real = 2.130536504633058e-27, disciminator loss fake = 1.429792746421299e-07, generator loss = 17.241641998291016\n",
      "2/2 [==============================] - 0s 134ms/step\n",
      "Epoch: 24, Batch: 296/468, discriminator loss real = 1.9604705601892026e-33, disciminator loss fake = 1.3526434372579388e-07, generator loss = 17.202789306640625\n",
      "2/2 [==============================] - 1s 193ms/step\n",
      "Epoch: 24, Batch: 297/468, discriminator loss real = 3.1544202805378063e-09, disciminator loss fake = 8.545998042563951e-08, generator loss = 17.23967933654785\n",
      "2/2 [==============================] - 0s 159ms/step\n",
      "Epoch: 24, Batch: 298/468, discriminator loss real = 1.803768569126618e-28, disciminator loss fake = 1.286409201384231e-07, generator loss = 17.033193588256836\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 24, Batch: 299/468, discriminator loss real = 6.706142585688468e-11, disciminator loss fake = 7.792124989691729e-08, generator loss = 16.993478775024414\n",
      "2/2 [==============================] - 1s 188ms/step\n",
      "Epoch: 24, Batch: 300/468, discriminator loss real = 1.524173734980395e-24, disciminator loss fake = 1.0994578758527496e-07, generator loss = 17.161909103393555\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 24, Batch: 301/468, discriminator loss real = 1.286445670285667e-29, disciminator loss fake = 9.198943473620602e-08, generator loss = 17.227012634277344\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 24, Batch: 302/468, discriminator loss real = 4.619757928389949e-16, disciminator loss fake = 1.0410649053937959e-07, generator loss = 17.186506271362305\n",
      "2/2 [==============================] - 0s 208ms/step\n",
      "Epoch: 24, Batch: 303/468, discriminator loss real = 1.020321214510633e-22, disciminator loss fake = 7.157794357226521e-08, generator loss = 17.109155654907227\n",
      "2/2 [==============================] - 0s 158ms/step\n",
      "Epoch: 24, Batch: 304/468, discriminator loss real = 3.151206480966847e-33, disciminator loss fake = 1.566611160797038e-07, generator loss = 16.92633819580078\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 24, Batch: 305/468, discriminator loss real = 0.0, disciminator loss fake = 9.227532871136646e-08, generator loss = 17.303438186645508\n",
      "2/2 [==============================] - 0s 222ms/step\n",
      "Epoch: 24, Batch: 306/468, discriminator loss real = 6.476917960296369e-12, disciminator loss fake = 6.710530442433082e-08, generator loss = 17.252840042114258\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 24, Batch: 307/468, discriminator loss real = 9.175030168333442e-25, disciminator loss fake = 1.208678668263019e-07, generator loss = 17.32832908630371\n",
      "2/2 [==============================] - 0s 146ms/step\n",
      "Epoch: 24, Batch: 308/468, discriminator loss real = 1.9025770731428486e-25, disciminator loss fake = 1.316252848937438e-07, generator loss = 17.11417007446289\n",
      "2/2 [==============================] - 1s 184ms/step\n",
      "Epoch: 24, Batch: 309/468, discriminator loss real = 5.724775000323803e-29, disciminator loss fake = 9.074447859802603e-08, generator loss = 17.160131454467773\n",
      "2/2 [==============================] - 0s 157ms/step\n",
      "Epoch: 24, Batch: 310/468, discriminator loss real = 1.920857751214415e-19, disciminator loss fake = 1.1285412426786934e-07, generator loss = 17.337068557739258\n",
      "2/2 [==============================] - 0s 135ms/step\n",
      "Epoch: 24, Batch: 311/468, discriminator loss real = 9.380866729784225e-17, disciminator loss fake = 1.3151893085705524e-07, generator loss = 17.075550079345703\n",
      "2/2 [==============================] - 1s 267ms/step\n",
      "Epoch: 24, Batch: 312/468, discriminator loss real = 0.0, disciminator loss fake = 9.006907930597663e-08, generator loss = 17.04116439819336\n",
      "2/2 [==============================] - 0s 155ms/step\n",
      "Epoch: 24, Batch: 313/468, discriminator loss real = 7.428791951271534e-21, disciminator loss fake = 1.3218057404174033e-07, generator loss = 17.386396408081055\n",
      "2/2 [==============================] - 0s 165ms/step\n",
      "Epoch: 24, Batch: 314/468, discriminator loss real = 9.213867908000142e-21, disciminator loss fake = 8.325725531221906e-08, generator loss = 17.040515899658203\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 24, Batch: 315/468, discriminator loss real = 1.0224015644516582e-12, disciminator loss fake = 7.460003814685479e-08, generator loss = 17.12249755859375\n",
      "2/2 [==============================] - 0s 213ms/step\n",
      "Epoch: 24, Batch: 316/468, discriminator loss real = 1.6151795886274724e-24, disciminator loss fake = 1.1230869745304517e-07, generator loss = 17.43840980529785\n",
      "2/2 [==============================] - 0s 160ms/step\n",
      "Epoch: 24, Batch: 317/468, discriminator loss real = 6.727209782476538e-17, disciminator loss fake = 6.801417384849628e-08, generator loss = 17.20370101928711\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 24, Batch: 318/468, discriminator loss real = 3.1459552755787443e-16, disciminator loss fake = 1.0716831155832551e-07, generator loss = 17.190244674682617\n",
      "2/2 [==============================] - 0s 245ms/step\n",
      "Epoch: 24, Batch: 319/468, discriminator loss real = 7.978759007018465e-33, disciminator loss fake = 6.87795989051665e-08, generator loss = 16.963224411010742\n",
      "2/2 [==============================] - 0s 156ms/step\n",
      "Epoch: 24, Batch: 320/468, discriminator loss real = 2.1576460389749987e-28, disciminator loss fake = 7.509221688906109e-08, generator loss = 17.292232513427734\n",
      "2/2 [==============================] - 0s 145ms/step\n",
      "Epoch: 24, Batch: 321/468, discriminator loss real = 4.111577167290117e-21, disciminator loss fake = 9.723667915295664e-08, generator loss = 17.346424102783203\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 24, Batch: 322/468, discriminator loss real = 1.6903267742816654e-24, disciminator loss fake = 1.4870289533064351e-07, generator loss = 17.169849395751953\n",
      "2/2 [==============================] - 0s 219ms/step\n",
      "Epoch: 24, Batch: 323/468, discriminator loss real = 1.4161116723698797e-11, disciminator loss fake = 1.1341666095177061e-07, generator loss = 17.316091537475586\n",
      "2/2 [==============================] - 0s 130ms/step\n",
      "Epoch: 24, Batch: 324/468, discriminator loss real = 5.8696189930511865e-15, disciminator loss fake = 1.5222543936488364e-07, generator loss = 17.1400146484375\n",
      "2/2 [==============================] - 0s 157ms/step\n",
      "Epoch: 24, Batch: 325/468, discriminator loss real = 3.5018596600678236e-24, disciminator loss fake = 9.787265753402608e-08, generator loss = 17.175992965698242\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 24, Batch: 326/468, discriminator loss real = 2.2053908765004207e-37, disciminator loss fake = 9.007687395978792e-08, generator loss = 17.190650939941406\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 24, Batch: 327/468, discriminator loss real = 2.52073468740325e-15, disciminator loss fake = 9.407942513917078e-08, generator loss = 17.05899429321289\n",
      "2/2 [==============================] - 0s 155ms/step\n",
      "Epoch: 24, Batch: 328/468, discriminator loss real = 1.6896734362089734e-19, disciminator loss fake = 7.823745562518525e-08, generator loss = 17.17662239074707\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 24, Batch: 329/468, discriminator loss real = 1.5335383502006626e-36, disciminator loss fake = 7.777234145578404e-08, generator loss = 17.109296798706055\n",
      "2/2 [==============================] - 1s 266ms/step\n",
      "Epoch: 24, Batch: 330/468, discriminator loss real = 3.840146454910512e-33, disciminator loss fake = 1.2323951636972197e-07, generator loss = 17.39156150817871\n",
      "2/2 [==============================] - 0s 136ms/step\n",
      "Epoch: 24, Batch: 331/468, discriminator loss real = 7.782648599641686e-29, disciminator loss fake = 6.406808239489692e-08, generator loss = 17.33704376220703\n",
      "2/2 [==============================] - 0s 130ms/step\n",
      "Epoch: 24, Batch: 332/468, discriminator loss real = 7.702848271508051e-16, disciminator loss fake = 9.732819705732254e-08, generator loss = 17.186750411987305\n",
      "2/2 [==============================] - 0s 155ms/step\n",
      "Epoch: 24, Batch: 333/468, discriminator loss real = 8.60155156163447e-24, disciminator loss fake = 8.091232928109093e-08, generator loss = 17.370098114013672\n",
      "2/2 [==============================] - 1s 234ms/step\n",
      "Epoch: 24, Batch: 334/468, discriminator loss real = 1.0642950799156302e-26, disciminator loss fake = 2.4478956106577243e-07, generator loss = 17.350906372070312\n",
      "2/2 [==============================] - 0s 150ms/step\n",
      "Epoch: 24, Batch: 335/468, discriminator loss real = 6.197486889770233e-36, disciminator loss fake = 8.653491079257947e-08, generator loss = 17.388322830200195\n",
      "2/2 [==============================] - 0s 148ms/step\n",
      "Epoch: 24, Batch: 336/468, discriminator loss real = 4.904500466359302e-21, disciminator loss fake = 1.0623078594562685e-07, generator loss = 17.131149291992188\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 24, Batch: 337/468, discriminator loss real = 3.3283449573017225e-32, disciminator loss fake = 1.0210010259470437e-07, generator loss = 17.31734848022461\n",
      "2/2 [==============================] - 0s 217ms/step\n",
      "Epoch: 24, Batch: 338/468, discriminator loss real = 0.0, disciminator loss fake = 1.1853482817514305e-07, generator loss = 17.136051177978516\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 24, Batch: 339/468, discriminator loss real = 7.631668497816535e-21, disciminator loss fake = 8.128019857167601e-08, generator loss = 17.15033721923828\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 24, Batch: 340/468, discriminator loss real = 7.14344916552534e-10, disciminator loss fake = 9.143867885086365e-08, generator loss = 17.52142333984375\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 24, Batch: 341/468, discriminator loss real = 3.3012973612617595e-31, disciminator loss fake = 6.807904640027118e-08, generator loss = 17.160728454589844\n",
      "2/2 [==============================] - 0s 239ms/step\n",
      "Epoch: 24, Batch: 342/468, discriminator loss real = 1.2654574624666966e-17, disciminator loss fake = 1.0037843622967557e-07, generator loss = 17.280460357666016\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 24, Batch: 343/468, discriminator loss real = 9.538584174577977e-32, disciminator loss fake = 7.62187539748993e-08, generator loss = 17.248554229736328\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 24, Batch: 344/468, discriminator loss real = 6.365373499469992e-19, disciminator loss fake = 8.78634835999037e-08, generator loss = 17.37449836730957\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 24, Batch: 345/468, discriminator loss real = 1.7756194960936014e-22, disciminator loss fake = 1.248159833266982e-07, generator loss = 17.183034896850586\n",
      "2/2 [==============================] - 0s 157ms/step\n",
      "Epoch: 24, Batch: 346/468, discriminator loss real = 7.36224821952667e-33, disciminator loss fake = 9.121582422721985e-08, generator loss = 17.401538848876953\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 24, Batch: 347/468, discriminator loss real = 6.036142432482874e-20, disciminator loss fake = 8.133397955134569e-08, generator loss = 17.35689926147461\n",
      "2/2 [==============================] - 0s 168ms/step\n",
      "Epoch: 24, Batch: 348/468, discriminator loss real = 1.2993613931973428e-25, disciminator loss fake = 8.16272347492486e-08, generator loss = 17.288137435913086\n",
      "2/2 [==============================] - 0s 134ms/step\n",
      "Epoch: 24, Batch: 349/468, discriminator loss real = 5.733999377209395e-31, disciminator loss fake = 9.058504701897618e-08, generator loss = 17.276187896728516\n",
      "2/2 [==============================] - 0s 152ms/step\n",
      "Epoch: 24, Batch: 350/468, discriminator loss real = 4.667537858566651e-20, disciminator loss fake = 8.932530448646503e-08, generator loss = 17.25741958618164\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 24, Batch: 351/468, discriminator loss real = 6.185997913453576e-21, disciminator loss fake = 1.1652291220798361e-07, generator loss = 17.09068489074707\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 24, Batch: 352/468, discriminator loss real = 1.0443818432000437e-20, disciminator loss fake = 1.3619516892049432e-07, generator loss = 17.374574661254883\n",
      "2/2 [==============================] - 0s 170ms/step\n",
      "Epoch: 24, Batch: 353/468, discriminator loss real = 8.994944070508931e-25, disciminator loss fake = 1.4761846500732645e-07, generator loss = 17.318960189819336\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 24, Batch: 354/468, discriminator loss real = 3.915161353693553e-21, disciminator loss fake = 7.640041843615109e-08, generator loss = 17.32716941833496\n",
      "2/2 [==============================] - 1s 204ms/step\n",
      "Epoch: 24, Batch: 355/468, discriminator loss real = 7.005491179488195e-31, disciminator loss fake = 1.105324116679185e-07, generator loss = 17.260662078857422\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 24, Batch: 356/468, discriminator loss real = 4.8900783850723065e-23, disciminator loss fake = 8.38029876604196e-08, generator loss = 17.104082107543945\n",
      "2/2 [==============================] - 0s 177ms/step\n",
      "Epoch: 24, Batch: 357/468, discriminator loss real = 3.5274374567961786e-06, disciminator loss fake = 6.12496791063677e-08, generator loss = 17.12762451171875\n",
      "2/2 [==============================] - 0s 194ms/step\n",
      "Epoch: 24, Batch: 358/468, discriminator loss real = 1.3847615729915042e-37, disciminator loss fake = 6.089496196182154e-08, generator loss = 17.066434860229492\n",
      "2/2 [==============================] - 0s 170ms/step\n",
      "Epoch: 24, Batch: 359/468, discriminator loss real = 5.762213600682785e-17, disciminator loss fake = 9.595021310815355e-08, generator loss = 17.298612594604492\n",
      "2/2 [==============================] - 0s 150ms/step\n",
      "Epoch: 24, Batch: 360/468, discriminator loss real = 1.3382304959275264e-27, disciminator loss fake = 4.9659078626973496e-08, generator loss = 17.408313751220703\n",
      "2/2 [==============================] - 0s 108ms/step\n",
      "Epoch: 24, Batch: 361/468, discriminator loss real = 4.754472165903641e-15, disciminator loss fake = 9.7610097782308e-08, generator loss = 16.97884750366211\n",
      "2/2 [==============================] - 0s 228ms/step\n",
      "Epoch: 24, Batch: 362/468, discriminator loss real = 1.7312212481961283e-30, disciminator loss fake = 2.036533146565489e-07, generator loss = 17.022294998168945\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 24, Batch: 363/468, discriminator loss real = 1.0211004828672466e-22, disciminator loss fake = 7.317272832096933e-08, generator loss = 17.176422119140625\n",
      "2/2 [==============================] - 0s 137ms/step\n",
      "Epoch: 24, Batch: 364/468, discriminator loss real = 1.766347417975322e-18, disciminator loss fake = 9.688799451623709e-08, generator loss = 17.319067001342773\n",
      "2/2 [==============================] - 1s 218ms/step\n",
      "Epoch: 24, Batch: 365/468, discriminator loss real = 6.1037448095644975e-28, disciminator loss fake = 7.301474624910043e-08, generator loss = 17.076629638671875\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 24, Batch: 366/468, discriminator loss real = 1.572435080364129e-13, disciminator loss fake = 9.942029066678515e-08, generator loss = 16.940868377685547\n",
      "2/2 [==============================] - 0s 136ms/step\n",
      "Epoch: 24, Batch: 367/468, discriminator loss real = 1.0114576760299373e-17, disciminator loss fake = 6.076076175531853e-08, generator loss = 17.252666473388672\n",
      "2/2 [==============================] - 1s 278ms/step\n",
      "Epoch: 24, Batch: 368/468, discriminator loss real = 1.1654452188434346e-20, disciminator loss fake = 9.960103142248045e-08, generator loss = 17.207178115844727\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 24, Batch: 369/468, discriminator loss real = 2.3266392978893435e-10, disciminator loss fake = 1.270671816655522e-07, generator loss = 17.261672973632812\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 24, Batch: 370/468, discriminator loss real = 4.602415973331566e-28, disciminator loss fake = 6.849428757504938e-08, generator loss = 17.357452392578125\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 24, Batch: 371/468, discriminator loss real = 5.206510863407844e-28, disciminator loss fake = 7.863084761083883e-08, generator loss = 17.35083770751953\n",
      "2/2 [==============================] - 0s 136ms/step\n",
      "Epoch: 24, Batch: 372/468, discriminator loss real = 1.2331216173581292e-27, disciminator loss fake = 1.232790936001038e-07, generator loss = 16.786819458007812\n",
      "2/2 [==============================] - 0s 157ms/step\n",
      "Epoch: 24, Batch: 373/468, discriminator loss real = 1.869178944925113e-14, disciminator loss fake = 7.359670206597002e-08, generator loss = 17.042598724365234\n",
      "2/2 [==============================] - 0s 224ms/step\n",
      "Epoch: 24, Batch: 374/468, discriminator loss real = 2.1010078096879728e-28, disciminator loss fake = 1.4542365533998236e-07, generator loss = 17.077266693115234\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 24, Batch: 375/468, discriminator loss real = 2.809487621267553e-29, disciminator loss fake = 1.0831721652948545e-07, generator loss = 17.065641403198242\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 24, Batch: 376/468, discriminator loss real = 1.4496680765906774e-27, disciminator loss fake = 7.984705518992996e-08, generator loss = 17.47123146057129\n",
      "2/2 [==============================] - 1s 270ms/step\n",
      "Epoch: 24, Batch: 377/468, discriminator loss real = 1.1628386558976058e-27, disciminator loss fake = 6.574020261496116e-08, generator loss = 17.326702117919922\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 24, Batch: 378/468, discriminator loss real = 6.45701067287598e-34, disciminator loss fake = 7.519741984651773e-08, generator loss = 17.11149024963379\n",
      "2/2 [==============================] - 0s 137ms/step\n",
      "Epoch: 24, Batch: 379/468, discriminator loss real = 3.796746086921326e-19, disciminator loss fake = 7.792815637230888e-08, generator loss = 17.134654998779297\n",
      "2/2 [==============================] - 0s 156ms/step\n",
      "Epoch: 24, Batch: 380/468, discriminator loss real = 1.1031223668548613e-26, disciminator loss fake = 7.2907361925445e-08, generator loss = 17.191925048828125\n",
      "2/2 [==============================] - 0s 165ms/step\n",
      "Epoch: 24, Batch: 381/468, discriminator loss real = 7.981780027500078e-33, disciminator loss fake = 1.4497223332909925e-07, generator loss = 17.172183990478516\n",
      "2/2 [==============================] - 0s 148ms/step\n",
      "Epoch: 24, Batch: 382/468, discriminator loss real = 1.9865590042667724e-33, disciminator loss fake = 1.245562089025043e-07, generator loss = 17.071029663085938\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 24, Batch: 383/468, discriminator loss real = 1.6564325370586764e-19, disciminator loss fake = 2.1147744178051653e-07, generator loss = 17.174312591552734\n",
      "2/2 [==============================] - 0s 146ms/step\n",
      "Epoch: 24, Batch: 384/468, discriminator loss real = 1.272273179546908e-35, disciminator loss fake = 7.614901420538445e-08, generator loss = 17.173059463500977\n",
      "2/2 [==============================] - 0s 153ms/step\n",
      "Epoch: 24, Batch: 385/468, discriminator loss real = 4.882501954822649e-12, disciminator loss fake = 1.51745652487989e-07, generator loss = 17.260568618774414\n",
      "2/2 [==============================] - 0s 192ms/step\n",
      "Epoch: 24, Batch: 386/468, discriminator loss real = 5.30507521300556e-17, disciminator loss fake = 7.399632551141622e-08, generator loss = 17.45815086364746\n",
      "2/2 [==============================] - 0s 157ms/step\n",
      "Epoch: 24, Batch: 387/468, discriminator loss real = 2.647108191485329e-15, disciminator loss fake = 7.606386276393096e-08, generator loss = 17.168792724609375\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 24, Batch: 388/468, discriminator loss real = 7.158026413876448e-22, disciminator loss fake = 1.151405228938529e-07, generator loss = 17.506206512451172\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 24, Batch: 389/468, discriminator loss real = 1.7174836026431035e-15, disciminator loss fake = 8.744707713503885e-08, generator loss = 17.25412368774414\n",
      "2/2 [==============================] - 0s 147ms/step\n",
      "Epoch: 24, Batch: 390/468, discriminator loss real = 6.851741333225501e-28, disciminator loss fake = 8.993615807639799e-08, generator loss = 17.305423736572266\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 24, Batch: 391/468, discriminator loss real = 6.446481125603129e-14, disciminator loss fake = 4.009181964192976e-08, generator loss = 17.256607055664062\n",
      "2/2 [==============================] - 1s 296ms/step\n",
      "Epoch: 24, Batch: 392/468, discriminator loss real = 8.9308984257663e-25, disciminator loss fake = 7.081911945761021e-08, generator loss = 17.35860824584961\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 24, Batch: 393/468, discriminator loss real = 1.5829959618910083e-25, disciminator loss fake = 1.1476620898065448e-07, generator loss = 17.272216796875\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 24, Batch: 394/468, discriminator loss real = 2.3471112348052293e-35, disciminator loss fake = 9.624245933537168e-08, generator loss = 17.182411193847656\n",
      "2/2 [==============================] - 1s 205ms/step\n",
      "Epoch: 24, Batch: 395/468, discriminator loss real = 1.0710162517769191e-17, disciminator loss fake = 8.218957248118386e-08, generator loss = 17.340797424316406\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 24, Batch: 396/468, discriminator loss real = 8.029828008259813e-20, disciminator loss fake = 1.2291803841435467e-07, generator loss = 17.418867111206055\n",
      "2/2 [==============================] - 0s 148ms/step\n",
      "Epoch: 24, Batch: 397/468, discriminator loss real = 1.3839615172226e-21, disciminator loss fake = 8.377554649996455e-08, generator loss = 17.307327270507812\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 24, Batch: 398/468, discriminator loss real = 1.071126585865112e-12, disciminator loss fake = 7.324885586967866e-08, generator loss = 17.168323516845703\n",
      "2/2 [==============================] - 0s 217ms/step\n",
      "Epoch: 24, Batch: 399/468, discriminator loss real = 1.1427924222488288e-23, disciminator loss fake = 7.826437098401584e-08, generator loss = 16.992475509643555\n",
      "2/2 [==============================] - 0s 151ms/step\n",
      "Epoch: 24, Batch: 400/468, discriminator loss real = 3.435553310364785e-21, disciminator loss fake = 8.436485643414926e-08, generator loss = 17.24256706237793\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 24, Batch: 401/468, discriminator loss real = 3.107205106428636e-16, disciminator loss fake = 7.350386965754296e-08, generator loss = 17.44933319091797\n",
      "2/2 [==============================] - 0s 234ms/step\n",
      "Epoch: 24, Batch: 402/468, discriminator loss real = 8.390078063874334e-18, disciminator loss fake = 8.58659063851519e-08, generator loss = 17.12704849243164\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 24, Batch: 403/468, discriminator loss real = 2.3427681405108565e-29, disciminator loss fake = 8.614706814569217e-08, generator loss = 17.441585540771484\n",
      "2/2 [==============================] - 0s 173ms/step\n",
      "Epoch: 24, Batch: 404/468, discriminator loss real = 4.8302122831777175e-24, disciminator loss fake = 1.197089858351319e-07, generator loss = 17.374794006347656\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 24, Batch: 405/468, discriminator loss real = 3.5685680047558435e-18, disciminator loss fake = 7.225477816064085e-08, generator loss = 17.277088165283203\n",
      "2/2 [==============================] - 0s 199ms/step\n",
      "Epoch: 24, Batch: 406/468, discriminator loss real = 1.8360216712174178e-31, disciminator loss fake = 7.797406453846634e-08, generator loss = 17.57648277282715\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 24, Batch: 407/468, discriminator loss real = 1.840083290395034e-17, disciminator loss fake = 1.025536491283674e-07, generator loss = 17.30339813232422\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 24, Batch: 408/468, discriminator loss real = 4.850078007116527e-26, disciminator loss fake = 1.786293353234214e-07, generator loss = 17.06111717224121\n",
      "2/2 [==============================] - 0s 230ms/step\n",
      "Epoch: 24, Batch: 409/468, discriminator loss real = 1.0085201095205777e-17, disciminator loss fake = 8.055036460064002e-08, generator loss = 17.33013153076172\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 24, Batch: 410/468, discriminator loss real = 5.714023050812181e-19, disciminator loss fake = 8.047310018355347e-08, generator loss = 17.566539764404297\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 24, Batch: 411/468, discriminator loss real = 7.948119141178181e-24, disciminator loss fake = 9.894098695895082e-08, generator loss = 17.411317825317383\n",
      "2/2 [==============================] - 0s 178ms/step\n",
      "Epoch: 24, Batch: 412/468, discriminator loss real = 1.558772336917004e-18, disciminator loss fake = 8.680246565972993e-08, generator loss = 17.31740951538086\n",
      "2/2 [==============================] - 0s 150ms/step\n",
      "Epoch: 24, Batch: 413/468, discriminator loss real = 1.1246405510913843e-18, disciminator loss fake = 1.6788395384992327e-07, generator loss = 17.203235626220703\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 24, Batch: 414/468, discriminator loss real = 4.74811268669967e-35, disciminator loss fake = 1.230353916525928e-07, generator loss = 17.291305541992188\n",
      "2/2 [==============================] - 1s 196ms/step\n",
      "Epoch: 24, Batch: 415/468, discriminator loss real = 1.7083278125440415e-09, disciminator loss fake = 9.548984536422722e-08, generator loss = 17.226417541503906\n",
      "2/2 [==============================] - 0s 148ms/step\n",
      "Epoch: 24, Batch: 416/468, discriminator loss real = 3.2679323741108447e-28, disciminator loss fake = 1.2362482948446996e-07, generator loss = 17.3529052734375\n",
      "2/2 [==============================] - 0s 161ms/step\n",
      "Epoch: 24, Batch: 417/468, discriminator loss real = 7.675023768586339e-17, disciminator loss fake = 1.0488147239584578e-07, generator loss = 17.355247497558594\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 24, Batch: 418/468, discriminator loss real = 3.2595427351364696e-36, disciminator loss fake = 9.212602947172854e-08, generator loss = 17.192733764648438\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 24, Batch: 419/468, discriminator loss real = 4.014700019167929e-33, disciminator loss fake = 9.610070605958754e-08, generator loss = 17.365482330322266\n",
      "2/2 [==============================] - 0s 157ms/step\n",
      "Epoch: 24, Batch: 420/468, discriminator loss real = 7.855018976212573e-22, disciminator loss fake = 7.382637079444976e-08, generator loss = 17.25820541381836\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 24, Batch: 421/468, discriminator loss real = 2.9634518370627152e-24, disciminator loss fake = 7.041685989861435e-08, generator loss = 17.165361404418945\n",
      "2/2 [==============================] - 1s 286ms/step\n",
      "Epoch: 24, Batch: 422/468, discriminator loss real = 2.25305253507811e-26, disciminator loss fake = 6.513261041618534e-08, generator loss = 17.33121109008789\n",
      "2/2 [==============================] - 0s 156ms/step\n",
      "Epoch: 24, Batch: 423/468, discriminator loss real = 2.5678671818669413e-20, disciminator loss fake = 9.318937088664825e-08, generator loss = 17.211881637573242\n",
      "2/2 [==============================] - 0s 153ms/step\n",
      "Epoch: 24, Batch: 424/468, discriminator loss real = 9.59785454448429e-28, disciminator loss fake = 8.718286892417382e-08, generator loss = 17.319080352783203\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 24, Batch: 425/468, discriminator loss real = 2.824946854428475e-37, disciminator loss fake = 2.423278999685863e-07, generator loss = 17.285091400146484\n",
      "2/2 [==============================] - 0s 211ms/step\n",
      "Epoch: 24, Batch: 426/468, discriminator loss real = 6.996594097845691e-31, disciminator loss fake = 9.396022448981967e-08, generator loss = 17.2572021484375\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 24, Batch: 427/468, discriminator loss real = 3.527703101382618e-36, disciminator loss fake = 4.2277196854456633e-08, generator loss = 17.368688583374023\n",
      "2/2 [==============================] - 0s 117ms/step\n",
      "Epoch: 24, Batch: 428/468, discriminator loss real = 3.1632677405572555e-24, disciminator loss fake = 1.0685150897415951e-07, generator loss = 17.180086135864258\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 24, Batch: 429/468, discriminator loss real = 1.6140736276292096e-14, disciminator loss fake = 8.476133217527604e-08, generator loss = 17.52713394165039\n",
      "2/2 [==============================] - 0s 134ms/step\n",
      "Epoch: 24, Batch: 430/468, discriminator loss real = 3.4636373770576026e-24, disciminator loss fake = 1.0355508095472032e-07, generator loss = 17.283296585083008\n",
      "2/2 [==============================] - 0s 180ms/step\n",
      "Epoch: 24, Batch: 431/468, discriminator loss real = 1.2146700312243297e-11, disciminator loss fake = 8.730302880621821e-08, generator loss = 17.1174259185791\n",
      "2/2 [==============================] - 0s 134ms/step\n",
      "Epoch: 24, Batch: 432/468, discriminator loss real = 3.066806739646508e-27, disciminator loss fake = 1.5851685475354316e-07, generator loss = 17.407840728759766\n",
      "2/2 [==============================] - 1s 260ms/step\n",
      "Epoch: 24, Batch: 433/468, discriminator loss real = 7.706973437507971e-21, disciminator loss fake = 8.283943486731005e-08, generator loss = 17.369937896728516\n",
      "2/2 [==============================] - 0s 158ms/step\n",
      "Epoch: 24, Batch: 434/468, discriminator loss real = 8.88971205953447e-27, disciminator loss fake = 1.0782005688270146e-07, generator loss = 17.30288314819336\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 24, Batch: 435/468, discriminator loss real = 1.3910722365476831e-37, disciminator loss fake = 8.433368492433146e-08, generator loss = 17.18096923828125\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 24, Batch: 436/468, discriminator loss real = 3.8182665153383427e-22, disciminator loss fake = 1.2481022793053853e-07, generator loss = 17.471832275390625\n",
      "2/2 [==============================] - 1s 271ms/step\n",
      "Epoch: 24, Batch: 437/468, discriminator loss real = 2.0111641283023833e-20, disciminator loss fake = 6.722092393829371e-08, generator loss = 17.294336318969727\n",
      "2/2 [==============================] - 0s 158ms/step\n",
      "Epoch: 24, Batch: 438/468, discriminator loss real = 7.116708354150771e-16, disciminator loss fake = 5.35011608349123e-08, generator loss = 17.154525756835938\n",
      "2/2 [==============================] - 0s 157ms/step\n",
      "Epoch: 24, Batch: 439/468, discriminator loss real = 6.865373369589812e-33, disciminator loss fake = 5.883736520218008e-08, generator loss = 17.39906883239746\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 24, Batch: 440/468, discriminator loss real = 8.944796737431856e-28, disciminator loss fake = 8.722933841909253e-08, generator loss = 17.125139236450195\n",
      "2/2 [==============================] - 0s 134ms/step\n",
      "Epoch: 24, Batch: 441/468, discriminator loss real = 6.632823351234319e-20, disciminator loss fake = 1.4165657091780304e-07, generator loss = 17.150794982910156\n",
      "2/2 [==============================] - 0s 178ms/step\n",
      "Epoch: 24, Batch: 442/468, discriminator loss real = 3.8369059380985275e-15, disciminator loss fake = 6.034137811639084e-08, generator loss = 17.479042053222656\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 24, Batch: 443/468, discriminator loss real = 7.76214043619159e-31, disciminator loss fake = 6.096107085795666e-08, generator loss = 17.262826919555664\n",
      "2/2 [==============================] - 1s 271ms/step\n",
      "Epoch: 24, Batch: 444/468, discriminator loss real = 2.3779629808539348e-23, disciminator loss fake = 9.938588618751965e-08, generator loss = 17.16511344909668\n",
      "2/2 [==============================] - 0s 144ms/step\n",
      "Epoch: 24, Batch: 445/468, discriminator loss real = 7.159012622496547e-31, disciminator loss fake = 1.6413994785580144e-07, generator loss = 17.08824920654297\n",
      "2/2 [==============================] - 0s 156ms/step\n",
      "Epoch: 24, Batch: 446/468, discriminator loss real = 1.0351389884276873e-19, disciminator loss fake = 1.3242944874036766e-07, generator loss = 17.2958984375\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 24, Batch: 447/468, discriminator loss real = 2.67943173879427e-28, disciminator loss fake = 7.453362371734329e-08, generator loss = 17.395790100097656\n",
      "2/2 [==============================] - 0s 195ms/step\n",
      "Epoch: 24, Batch: 448/468, discriminator loss real = 3.5408031450537704e-33, disciminator loss fake = 6.493390003470267e-08, generator loss = 17.300756454467773\n",
      "2/2 [==============================] - 0s 146ms/step\n",
      "Epoch: 24, Batch: 449/468, discriminator loss real = 1.0880860430439252e-35, disciminator loss fake = 6.863692192382587e-08, generator loss = 17.18088150024414\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 24, Batch: 450/468, discriminator loss real = 5.57113262925177e-16, disciminator loss fake = 9.501398068323397e-08, generator loss = 17.339431762695312\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 24, Batch: 451/468, discriminator loss real = 5.498688675527024e-24, disciminator loss fake = 9.26423311398139e-08, generator loss = 17.372398376464844\n",
      "2/2 [==============================] - 0s 206ms/step\n",
      "Epoch: 24, Batch: 452/468, discriminator loss real = 8.174750596208673e-25, disciminator loss fake = 9.472208262195636e-08, generator loss = 17.268348693847656\n",
      "2/2 [==============================] - 0s 191ms/step\n",
      "Epoch: 24, Batch: 453/468, discriminator loss real = 4.459621995983896e-25, disciminator loss fake = 1.1255999510240144e-07, generator loss = 17.49827766418457\n",
      "2/2 [==============================] - 0s 136ms/step\n",
      "Epoch: 24, Batch: 454/468, discriminator loss real = 1.5110552844763371e-34, disciminator loss fake = 6.799075435992563e-08, generator loss = 17.440799713134766\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 24, Batch: 455/468, discriminator loss real = 6.744587568893737e-22, disciminator loss fake = 7.894776388184255e-08, generator loss = 17.29412841796875\n",
      "2/2 [==============================] - 1s 238ms/step\n",
      "Epoch: 24, Batch: 456/468, discriminator loss real = 3.105899685048185e-23, disciminator loss fake = 9.797931710409102e-08, generator loss = 17.263988494873047\n",
      "2/2 [==============================] - 0s 147ms/step\n",
      "Epoch: 24, Batch: 457/468, discriminator loss real = 2.5997806015369327e-22, disciminator loss fake = 8.140916207821647e-08, generator loss = 17.49903106689453\n",
      "2/2 [==============================] - 0s 137ms/step\n",
      "Epoch: 24, Batch: 458/468, discriminator loss real = 1.5227638206840753e-18, disciminator loss fake = 2.0442539039322583e-07, generator loss = 17.23733139038086\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 24, Batch: 459/468, discriminator loss real = 2.352346832948382e-13, disciminator loss fake = 8.544176921532198e-08, generator loss = 17.56475830078125\n",
      "2/2 [==============================] - 1s 202ms/step\n",
      "Epoch: 24, Batch: 460/468, discriminator loss real = 2.24619013337445e-15, disciminator loss fake = 9.836104197802342e-08, generator loss = 17.578386306762695\n",
      "2/2 [==============================] - 0s 151ms/step\n",
      "Epoch: 24, Batch: 461/468, discriminator loss real = 1.5774143011198485e-30, disciminator loss fake = 4.49916406353168e-08, generator loss = 17.407367706298828\n",
      "2/2 [==============================] - 0s 156ms/step\n",
      "Epoch: 24, Batch: 462/468, discriminator loss real = 2.362716561762955e-29, disciminator loss fake = 1.0341432243876625e-07, generator loss = 17.34242820739746\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 24, Batch: 463/468, discriminator loss real = 5.7893331876867824e-33, disciminator loss fake = 9.854863236569145e-08, generator loss = 17.5216064453125\n",
      "2/2 [==============================] - 0s 237ms/step\n",
      "Epoch: 24, Batch: 464/468, discriminator loss real = 2.4076902574341023e-24, disciminator loss fake = 1.633082149510301e-07, generator loss = 17.458433151245117\n",
      "2/2 [==============================] - 0s 163ms/step\n",
      "Epoch: 24, Batch: 465/468, discriminator loss real = 5.920010449763428e-23, disciminator loss fake = 1.0767280400614254e-07, generator loss = 17.227890014648438\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 24, Batch: 466/468, discriminator loss real = 4.732455456511372e-24, disciminator loss fake = 8.531137041245529e-08, generator loss = 17.48944091796875\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 24, Batch: 467/468, discriminator loss real = 5.404801434883965e-33, disciminator loss fake = 1.07258927073417e-07, generator loss = 17.38344955444336\n",
      "2/2 [==============================] - 0s 175ms/step\n",
      "Epoch: 24, Batch: 468/468, discriminator loss real = 9.027556225720425e-32, disciminator loss fake = 6.85219205820431e-08, generator loss = 17.473129272460938\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2/2 [==============================] - 0s 154ms/step\n",
      "Epoch: 25, Batch: 1/468, discriminator loss real = 7.257351741351844e-35, disciminator loss fake = 1.0487059398656129e-07, generator loss = 17.366329193115234\n",
      "2/2 [==============================] - 0s 161ms/step\n",
      "Epoch: 25, Batch: 2/468, discriminator loss real = 5.2672037738343835e-12, disciminator loss fake = 5.3971572100408594e-08, generator loss = 17.379501342773438\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 25, Batch: 3/468, discriminator loss real = 1.1151066989616696e-16, disciminator loss fake = 8.896385139678387e-08, generator loss = 17.25442886352539\n",
      "2/2 [==============================] - 0s 206ms/step\n",
      "Epoch: 25, Batch: 4/468, discriminator loss real = 7.390136644486543e-18, disciminator loss fake = 8.049145350241815e-08, generator loss = 17.185163497924805\n",
      "2/2 [==============================] - 0s 145ms/step\n",
      "Epoch: 25, Batch: 5/468, discriminator loss real = 1.1318998203908983e-32, disciminator loss fake = 1.0657616655862512e-07, generator loss = 17.591976165771484\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 25, Batch: 6/468, discriminator loss real = 1.9240496840211563e-07, disciminator loss fake = 1.038740649050851e-07, generator loss = 17.323925018310547\n",
      "2/2 [==============================] - 0s 177ms/step\n",
      "Epoch: 25, Batch: 7/468, discriminator loss real = 2.748355764086034e-27, disciminator loss fake = 7.398459445084882e-08, generator loss = 17.462066650390625\n",
      "2/2 [==============================] - 0s 169ms/step\n",
      "Epoch: 25, Batch: 8/468, discriminator loss real = 2.156303209597241e-19, disciminator loss fake = 8.991672473257495e-08, generator loss = 17.61111831665039\n",
      "2/2 [==============================] - 0s 174ms/step\n",
      "Epoch: 25, Batch: 9/468, discriminator loss real = 3.3950045061511115e-24, disciminator loss fake = 1.112894238985973e-07, generator loss = 17.369693756103516\n",
      "2/2 [==============================] - 0s 153ms/step\n",
      "Epoch: 25, Batch: 10/468, discriminator loss real = 1.9911022099990847e-29, disciminator loss fake = 7.084189235229132e-08, generator loss = 17.481338500976562\n",
      "2/2 [==============================] - 1s 281ms/step\n",
      "Epoch: 25, Batch: 11/468, discriminator loss real = 6.938816735791675e-23, disciminator loss fake = 1.0234124658836663e-07, generator loss = 17.577388763427734\n",
      "2/2 [==============================] - 0s 146ms/step\n",
      "Epoch: 25, Batch: 12/468, discriminator loss real = 7.011008314211034e-37, disciminator loss fake = 7.103506050043507e-08, generator loss = 17.357654571533203\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 25, Batch: 13/468, discriminator loss real = 3.7847545681248506e-23, disciminator loss fake = 7.263356849307456e-08, generator loss = 17.43986701965332\n",
      "2/2 [==============================] - 0s 145ms/step\n",
      "Epoch: 25, Batch: 14/468, discriminator loss real = 6.803605196909611e-31, disciminator loss fake = 7.258422840550338e-08, generator loss = 17.317100524902344\n",
      "2/2 [==============================] - 1s 196ms/step\n",
      "Epoch: 25, Batch: 15/468, discriminator loss real = 1.3770653325121395e-26, disciminator loss fake = 7.51198001580633e-08, generator loss = 17.420642852783203\n",
      "2/2 [==============================] - 0s 166ms/step\n",
      "Epoch: 25, Batch: 16/468, discriminator loss real = 1.5177435167494941e-22, disciminator loss fake = 8.925871242126959e-08, generator loss = 17.417377471923828\n",
      "2/2 [==============================] - 0s 170ms/step\n",
      "Epoch: 25, Batch: 17/468, discriminator loss real = 3.753401589534633e-09, disciminator loss fake = 9.283467505838416e-08, generator loss = 17.559528350830078\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 25, Batch: 18/468, discriminator loss real = 1.3138971887838258e-22, disciminator loss fake = 7.25237612186902e-08, generator loss = 17.40475845336914\n",
      "2/2 [==============================] - 1s 258ms/step\n",
      "Epoch: 25, Batch: 19/468, discriminator loss real = 2.6338219690811367e-23, disciminator loss fake = 6.451371348248358e-08, generator loss = 17.25286102294922\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 25, Batch: 20/468, discriminator loss real = 9.753855255165645e-26, disciminator loss fake = 5.504261935129762e-08, generator loss = 17.465240478515625\n",
      "2/2 [==============================] - 0s 158ms/step\n",
      "Epoch: 25, Batch: 21/468, discriminator loss real = 1.9878294832631185e-29, disciminator loss fake = 7.33203080471867e-08, generator loss = 17.63919448852539\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 25, Batch: 22/468, discriminator loss real = 3.534262516180229e-24, disciminator loss fake = 7.573024163320952e-08, generator loss = 17.22234344482422\n",
      "2/2 [==============================] - 0s 160ms/step\n",
      "Epoch: 25, Batch: 23/468, discriminator loss real = 6.146178391961682e-19, disciminator loss fake = 9.336901030110312e-08, generator loss = 17.46121597290039\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 25, Batch: 24/468, discriminator loss real = 5.135282645571246e-21, disciminator loss fake = 6.95764299507573e-08, generator loss = 17.541364669799805\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 25, Batch: 25/468, discriminator loss real = 5.160457616781855e-10, disciminator loss fake = 6.976277688863775e-08, generator loss = 17.25922393798828\n",
      "2/2 [==============================] - 0s 112ms/step\n",
      "Epoch: 25, Batch: 26/468, discriminator loss real = 7.177124308434808e-26, disciminator loss fake = 9.456937988261416e-08, generator loss = 17.68077850341797\n",
      "2/2 [==============================] - 0s 219ms/step\n",
      "Epoch: 25, Batch: 27/468, discriminator loss real = 1.1624097166322518e-25, disciminator loss fake = 5.5530286147131847e-08, generator loss = 17.53803253173828\n",
      "2/2 [==============================] - 0s 156ms/step\n",
      "Epoch: 25, Batch: 28/468, discriminator loss real = 8.748226363008385e-23, disciminator loss fake = 1.4636296441494778e-07, generator loss = 17.534408569335938\n",
      "2/2 [==============================] - 0s 146ms/step\n",
      "Epoch: 25, Batch: 29/468, discriminator loss real = 5.324869880379269e-24, disciminator loss fake = 7.803434698416822e-08, generator loss = 17.371442794799805\n",
      "2/2 [==============================] - 0s 166ms/step\n",
      "Epoch: 25, Batch: 30/468, discriminator loss real = 5.7591487134800445e-09, disciminator loss fake = 8.082112401552877e-08, generator loss = 17.304288864135742\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 25, Batch: 31/468, discriminator loss real = 1.2389325926362037e-17, disciminator loss fake = 7.759079068136998e-08, generator loss = 17.335060119628906\n",
      "2/2 [==============================] - 0s 164ms/step\n",
      "Epoch: 25, Batch: 32/468, discriminator loss real = 2.479891021266861e-13, disciminator loss fake = 7.053078832086612e-08, generator loss = 17.359228134155273\n",
      "2/2 [==============================] - 0s 161ms/step\n",
      "Epoch: 25, Batch: 33/468, discriminator loss real = 4.1763664115644286e-35, disciminator loss fake = 1.5324503976898995e-07, generator loss = 17.34686279296875\n",
      "2/2 [==============================] - 0s 156ms/step\n",
      "Epoch: 25, Batch: 34/468, discriminator loss real = 5.958577771067262e-21, disciminator loss fake = 1.0617526413625455e-07, generator loss = 17.415538787841797\n",
      "2/2 [==============================] - 1s 188ms/step\n",
      "Epoch: 25, Batch: 35/468, discriminator loss real = 3.144810946847074e-26, disciminator loss fake = 1.3697895440145658e-07, generator loss = 17.28681755065918\n",
      "2/2 [==============================] - 0s 156ms/step\n",
      "Epoch: 25, Batch: 36/468, discriminator loss real = 4.183710466345647e-32, disciminator loss fake = 6.72799984613448e-08, generator loss = 17.156185150146484\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 25, Batch: 37/468, discriminator loss real = 7.00981802398875e-20, disciminator loss fake = 1.0161790697793549e-07, generator loss = 17.68742561340332\n",
      "2/2 [==============================] - 0s 134ms/step\n",
      "Epoch: 25, Batch: 38/468, discriminator loss real = 1.8836663380472064e-31, disciminator loss fake = 5.2516003989921956e-08, generator loss = 17.381568908691406\n",
      "2/2 [==============================] - 0s 157ms/step\n",
      "Epoch: 25, Batch: 39/468, discriminator loss real = 5.741548295828958e-12, disciminator loss fake = 1.3449066216253414e-07, generator loss = 17.4988956451416\n",
      "2/2 [==============================] - 1s 132ms/step\n",
      "Epoch: 25, Batch: 40/468, discriminator loss real = 3.103741790785729e-28, disciminator loss fake = 8.259731032467243e-08, generator loss = 17.14373207092285\n",
      "2/2 [==============================] - 0s 153ms/step\n",
      "Epoch: 25, Batch: 41/468, discriminator loss real = 9.413837836458545e-29, disciminator loss fake = 1.064276062834324e-07, generator loss = 17.44179344177246\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 25, Batch: 42/468, discriminator loss real = 1.3063601210067902e-16, disciminator loss fake = 1.0827781693478755e-07, generator loss = 17.33026885986328\n",
      "2/2 [==============================] - 0s 226ms/step\n",
      "Epoch: 25, Batch: 43/468, discriminator loss real = 3.4784032754815295e-25, disciminator loss fake = 8.160603215401352e-08, generator loss = 17.200302124023438\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 25, Batch: 44/468, discriminator loss real = 2.5545882141424225e-13, disciminator loss fake = 5.872281150232084e-08, generator loss = 17.31707191467285\n",
      "2/2 [==============================] - 0s 153ms/step\n",
      "Epoch: 25, Batch: 45/468, discriminator loss real = 7.571419811169596e-36, disciminator loss fake = 5.557287607871331e-08, generator loss = 17.40414047241211\n",
      "2/2 [==============================] - 1s 268ms/step\n",
      "Epoch: 25, Batch: 46/468, discriminator loss real = 0.0, disciminator loss fake = 8.382630767300725e-08, generator loss = 17.281295776367188\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 25, Batch: 47/468, discriminator loss real = 7.083796970767092e-32, disciminator loss fake = 9.711420290159367e-08, generator loss = 17.454349517822266\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 25, Batch: 48/468, discriminator loss real = 0.0, disciminator loss fake = 5.651236278936267e-08, generator loss = 17.378097534179688\n",
      "2/2 [==============================] - 1s 263ms/step\n",
      "Epoch: 25, Batch: 49/468, discriminator loss real = 6.926073936597277e-09, disciminator loss fake = 7.24103728089176e-08, generator loss = 17.562339782714844\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 25, Batch: 50/468, discriminator loss real = 2.7016604370263988e-27, disciminator loss fake = 5.512258383078006e-08, generator loss = 17.271793365478516\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 25, Batch: 51/468, discriminator loss real = 3.1980123223782007e-22, disciminator loss fake = 6.669330332442769e-08, generator loss = 17.3951358795166\n",
      "2/2 [==============================] - 0s 155ms/step\n",
      "Epoch: 25, Batch: 52/468, discriminator loss real = 1.3209875488389303e-27, disciminator loss fake = 3.839998896637553e-08, generator loss = 17.398056030273438\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 25, Batch: 53/468, discriminator loss real = 1.7171926204334902e-21, disciminator loss fake = 7.087349729317793e-08, generator loss = 17.229753494262695\n",
      "2/2 [==============================] - 0s 103ms/step\n",
      "Epoch: 25, Batch: 54/468, discriminator loss real = 3.2549106802743565e-29, disciminator loss fake = 4.218298954583588e-08, generator loss = 17.55973243713379\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 25, Batch: 55/468, discriminator loss real = 5.904229419883114e-21, disciminator loss fake = 1.16280887141329e-07, generator loss = 17.410499572753906\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 25, Batch: 56/468, discriminator loss real = 8.418686346283912e-23, disciminator loss fake = 6.52159073410985e-08, generator loss = 17.509437561035156\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 25, Batch: 57/468, discriminator loss real = 9.196938715379055e-27, disciminator loss fake = 6.008686881386893e-08, generator loss = 17.33277130126953\n",
      "2/2 [==============================] - 0s 166ms/step\n",
      "Epoch: 25, Batch: 58/468, discriminator loss real = 3.77444276395268e-15, disciminator loss fake = 5.146265280586704e-08, generator loss = 17.398290634155273\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 25, Batch: 59/468, discriminator loss real = 5.1967132258794e-22, disciminator loss fake = 1.1431902890990386e-07, generator loss = 17.507482528686523\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 25, Batch: 60/468, discriminator loss real = 5.770965537442207e-35, disciminator loss fake = 6.257615581262144e-08, generator loss = 17.560590744018555\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 25, Batch: 61/468, discriminator loss real = 2.4871177653370307e-31, disciminator loss fake = 7.814158209384914e-08, generator loss = 17.531648635864258\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 25, Batch: 62/468, discriminator loss real = 3.7229561938904188e-28, disciminator loss fake = 9.191242611450434e-08, generator loss = 17.238143920898438\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 25, Batch: 63/468, discriminator loss real = 1.2368675857667014e-25, disciminator loss fake = 7.737182272649079e-08, generator loss = 17.6118221282959\n",
      "2/2 [==============================] - 1s 261ms/step\n",
      "Epoch: 25, Batch: 64/468, discriminator loss real = 3.111628978415132e-37, disciminator loss fake = 7.64035661404705e-08, generator loss = 17.460891723632812\n",
      "2/2 [==============================] - 0s 198ms/step\n",
      "Epoch: 25, Batch: 65/468, discriminator loss real = 8.67148224123403e-28, disciminator loss fake = 1.009349972491691e-07, generator loss = 17.44216537475586\n",
      "2/2 [==============================] - 0s 163ms/step\n",
      "Epoch: 25, Batch: 66/468, discriminator loss real = 1.6151009983597897e-25, disciminator loss fake = 8.315454635976494e-08, generator loss = 17.475252151489258\n",
      "2/2 [==============================] - 0s 219ms/step\n",
      "Epoch: 25, Batch: 67/468, discriminator loss real = 7.02789647707028e-26, disciminator loss fake = 1.1017486656328401e-07, generator loss = 17.5551815032959\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 25, Batch: 68/468, discriminator loss real = 9.684740562809387e-27, disciminator loss fake = 5.574928252372047e-08, generator loss = 17.596050262451172\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 25, Batch: 69/468, discriminator loss real = 3.4233195352873243e-19, disciminator loss fake = 6.69434712108341e-08, generator loss = 17.86795425415039\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 25, Batch: 70/468, discriminator loss real = 1.0219559243296317e-07, disciminator loss fake = 9.506574372153409e-08, generator loss = 17.512462615966797\n",
      "2/2 [==============================] - 0s 150ms/step\n",
      "Epoch: 25, Batch: 71/468, discriminator loss real = 9.244025413868965e-18, disciminator loss fake = 6.742018854311027e-08, generator loss = 17.610855102539062\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 25, Batch: 72/468, discriminator loss real = 0.00010814044799190015, disciminator loss fake = 9.014490842673695e-08, generator loss = 17.186866760253906\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 25, Batch: 73/468, discriminator loss real = 4.3907721425720525e-14, disciminator loss fake = 1.586753484161818e-07, generator loss = 17.04462242126465\n",
      "2/2 [==============================] - 1s 239ms/step\n",
      "Epoch: 25, Batch: 74/468, discriminator loss real = 2.701981308992196e-29, disciminator loss fake = 1.471803727781662e-07, generator loss = 16.507156372070312\n",
      "2/2 [==============================] - 0s 155ms/step\n",
      "Epoch: 25, Batch: 75/468, discriminator loss real = 1.4596712856279263e-32, disciminator loss fake = 1.7789716366678476e-07, generator loss = 16.21318817138672\n",
      "2/2 [==============================] - 0s 152ms/step\n",
      "Epoch: 25, Batch: 76/468, discriminator loss real = 1.7324152801762662e-19, disciminator loss fake = 2.4901882511585427e-07, generator loss = 16.323822021484375\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 25, Batch: 77/468, discriminator loss real = 3.015116913884579e-31, disciminator loss fake = 4.3419643702691246e-07, generator loss = 16.02340316772461\n",
      "2/2 [==============================] - 1s 264ms/step\n",
      "Epoch: 25, Batch: 78/468, discriminator loss real = 5.688644236788658e-26, disciminator loss fake = 4.0546382251704927e-07, generator loss = 15.979585647583008\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 25, Batch: 79/468, discriminator loss real = 2.441049410178862e-24, disciminator loss fake = 3.2418972750747344e-07, generator loss = 16.020771026611328\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 25, Batch: 80/468, discriminator loss real = 8.281820180820997e-20, disciminator loss fake = 3.674012702958862e-07, generator loss = 15.725624084472656\n",
      "2/2 [==============================] - 1s 238ms/step\n",
      "Epoch: 25, Batch: 81/468, discriminator loss real = 4.788406402290304e-25, disciminator loss fake = 4.997704081688426e-07, generator loss = 15.487937927246094\n",
      "2/2 [==============================] - 0s 163ms/step\n",
      "Epoch: 25, Batch: 82/468, discriminator loss real = 1.7181130191614914e-24, disciminator loss fake = 3.7239763628349465e-07, generator loss = 15.695402145385742\n",
      "2/2 [==============================] - 0s 148ms/step\n",
      "Epoch: 25, Batch: 83/468, discriminator loss real = 1.5630328922206718e-21, disciminator loss fake = 3.358189246682741e-07, generator loss = 15.773177146911621\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 25, Batch: 84/468, discriminator loss real = 6.004242833064296e-26, disciminator loss fake = 4.910840516458848e-07, generator loss = 15.512947082519531\n",
      "2/2 [==============================] - 0s 151ms/step\n",
      "Epoch: 25, Batch: 85/468, discriminator loss real = 4.792241021254216e-27, disciminator loss fake = 4.864936613557802e-07, generator loss = 15.687103271484375\n",
      "2/2 [==============================] - 0s 160ms/step\n",
      "Epoch: 25, Batch: 86/468, discriminator loss real = 9.289919993829346e-26, disciminator loss fake = 3.54275357494771e-07, generator loss = 15.651178359985352\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 25, Batch: 87/468, discriminator loss real = 9.184192803524802e-20, disciminator loss fake = 6.99639429058152e-07, generator loss = 15.298808097839355\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 25, Batch: 88/468, discriminator loss real = 1.5797465646666822e-28, disciminator loss fake = 4.0865194250727654e-07, generator loss = 15.453145980834961\n",
      "2/2 [==============================] - 0s 137ms/step\n",
      "Epoch: 25, Batch: 89/468, discriminator loss real = 1.0362796939184114e-21, disciminator loss fake = 3.282270313320623e-07, generator loss = 15.758869171142578\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 25, Batch: 90/468, discriminator loss real = 6.642891186643936e-24, disciminator loss fake = 3.636974952314631e-07, generator loss = 15.445867538452148\n",
      "2/2 [==============================] - 0s 144ms/step\n",
      "Epoch: 25, Batch: 91/468, discriminator loss real = 2.886408920045663e-24, disciminator loss fake = 4.510389715051133e-07, generator loss = 15.534785270690918\n",
      "2/2 [==============================] - 0s 136ms/step\n",
      "Epoch: 25, Batch: 92/468, discriminator loss real = 4.0920807438315025e-38, disciminator loss fake = 5.306889079292887e-07, generator loss = 15.56192398071289\n",
      "2/2 [==============================] - 0s 148ms/step\n",
      "Epoch: 25, Batch: 93/468, discriminator loss real = 8.085208737717095e-17, disciminator loss fake = 7.730873221589718e-07, generator loss = 15.542448043823242\n",
      "2/2 [==============================] - 0s 153ms/step\n",
      "Epoch: 25, Batch: 94/468, discriminator loss real = 3.182844231110356e-22, disciminator loss fake = 8.823210464470321e-07, generator loss = 15.53584098815918\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 25, Batch: 95/468, discriminator loss real = 7.960987554941901e-14, disciminator loss fake = 2.6979157041751023e-07, generator loss = 15.641925811767578\n",
      "2/2 [==============================] - 0s 223ms/step\n",
      "Epoch: 25, Batch: 96/468, discriminator loss real = 7.569020820283698e-31, disciminator loss fake = 5.664544460159959e-07, generator loss = 15.768909454345703\n",
      "2/2 [==============================] - 0s 147ms/step\n",
      "Epoch: 25, Batch: 97/468, discriminator loss real = 5.319673958200386e-16, disciminator loss fake = 6.331450776997372e-07, generator loss = 15.471303939819336\n",
      "2/2 [==============================] - 0s 145ms/step\n",
      "Epoch: 25, Batch: 98/468, discriminator loss real = 9.087764045362634e-35, disciminator loss fake = 5.050996492172999e-07, generator loss = 15.675426483154297\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 25, Batch: 99/468, discriminator loss real = 1.833609809817876e-21, disciminator loss fake = 9.221209325005475e-07, generator loss = 15.498494148254395\n",
      "2/2 [==============================] - 0s 220ms/step\n",
      "Epoch: 25, Batch: 100/468, discriminator loss real = 3.3672024199867406e-35, disciminator loss fake = 4.7082681930987746e-07, generator loss = 15.595146179199219\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 25, Batch: 101/468, discriminator loss real = 1.4037043554425421e-14, disciminator loss fake = 4.2740688854792097e-07, generator loss = 15.78530216217041\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 25, Batch: 102/468, discriminator loss real = 9.92361573270674e-22, disciminator loss fake = 4.498270982367103e-07, generator loss = 15.640557289123535\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 25, Batch: 103/468, discriminator loss real = 1.8600966341481787e-15, disciminator loss fake = 4.734108358661615e-07, generator loss = 15.74844741821289\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 25, Batch: 104/468, discriminator loss real = 2.765054108260536e-25, disciminator loss fake = 3.488243294214044e-07, generator loss = 15.63846206665039\n",
      "2/2 [==============================] - 0s 148ms/step\n",
      "Epoch: 25, Batch: 105/468, discriminator loss real = 7.523415756899366e-25, disciminator loss fake = 4.789377499037073e-07, generator loss = 15.659602165222168\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 25, Batch: 106/468, discriminator loss real = 7.348921775528754e-36, disciminator loss fake = 6.66228118006984e-07, generator loss = 15.80223560333252\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 25, Batch: 107/468, discriminator loss real = 1.1523305875327194e-17, disciminator loss fake = 3.235848566873756e-07, generator loss = 15.49960708618164\n",
      "2/2 [==============================] - 1s 279ms/step\n",
      "Epoch: 25, Batch: 108/468, discriminator loss real = 3.508580567377427e-32, disciminator loss fake = 4.545624108232005e-07, generator loss = 15.721311569213867\n",
      "2/2 [==============================] - 0s 161ms/step\n",
      "Epoch: 25, Batch: 109/468, discriminator loss real = 2.067770592190224e-28, disciminator loss fake = 5.08877519678208e-07, generator loss = 15.68832015991211\n",
      "2/2 [==============================] - 0s 150ms/step\n",
      "Epoch: 25, Batch: 110/468, discriminator loss real = 2.8156891176144096e-23, disciminator loss fake = 3.2313687370333355e-07, generator loss = 15.887723922729492\n",
      "2/2 [==============================] - 0s 137ms/step\n",
      "Epoch: 25, Batch: 111/468, discriminator loss real = 2.7043096545552828e-20, disciminator loss fake = 3.877404708418908e-07, generator loss = 15.785591125488281\n",
      "2/2 [==============================] - 1s 282ms/step\n",
      "Epoch: 25, Batch: 112/468, discriminator loss real = 1.4887322852686912e-24, disciminator loss fake = 3.0722020483153756e-07, generator loss = 15.774171829223633\n",
      "2/2 [==============================] - 0s 145ms/step\n",
      "Epoch: 25, Batch: 113/468, discriminator loss real = 3.519965516678366e-23, disciminator loss fake = 3.876847642914072e-07, generator loss = 15.731098175048828\n",
      "2/2 [==============================] - 0s 135ms/step\n",
      "Epoch: 25, Batch: 114/468, discriminator loss real = 6.9325167032759625e-22, disciminator loss fake = 4.197414682494127e-07, generator loss = 15.745291709899902\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 25, Batch: 115/468, discriminator loss real = 3.217119601423104e-28, disciminator loss fake = 6.939642389625078e-07, generator loss = 15.906984329223633\n",
      "2/2 [==============================] - 0s 211ms/step\n",
      "Epoch: 25, Batch: 116/468, discriminator loss real = 4.9846696887297e-32, disciminator loss fake = 2.8419813702385e-07, generator loss = 15.998741149902344\n",
      "2/2 [==============================] - 0s 148ms/step\n",
      "Epoch: 25, Batch: 117/468, discriminator loss real = 4.106302536410917e-25, disciminator loss fake = 5.628062353935093e-07, generator loss = 15.781917572021484\n",
      "2/2 [==============================] - 0s 151ms/step\n",
      "Epoch: 25, Batch: 118/468, discriminator loss real = 5.1411867863681286e-27, disciminator loss fake = 4.431972229212988e-07, generator loss = 15.58414363861084\n",
      "2/2 [==============================] - 1s 192ms/step\n",
      "Epoch: 25, Batch: 119/468, discriminator loss real = 8.63074192686077e-21, disciminator loss fake = 6.749053795829241e-07, generator loss = 16.027965545654297\n",
      "2/2 [==============================] - 0s 146ms/step\n",
      "Epoch: 25, Batch: 120/468, discriminator loss real = 4.646097010807884e-14, disciminator loss fake = 6.05632067163242e-07, generator loss = 15.996549606323242\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 25, Batch: 121/468, discriminator loss real = 1.6044115633154957e-25, disciminator loss fake = 5.484400844579795e-07, generator loss = 15.951815605163574\n",
      "2/2 [==============================] - 0s 136ms/step\n",
      "Epoch: 25, Batch: 122/468, discriminator loss real = 8.474193435565184e-32, disciminator loss fake = 2.5623788246775803e-07, generator loss = 15.92306137084961\n",
      "2/2 [==============================] - 1s 147ms/step\n",
      "Epoch: 25, Batch: 123/468, discriminator loss real = 7.32004323626541e-28, disciminator loss fake = 4.849036940868245e-07, generator loss = 16.120656967163086\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 25, Batch: 124/468, discriminator loss real = 1.4521086183121643e-20, disciminator loss fake = 4.321273081586696e-07, generator loss = 15.90034008026123\n",
      "2/2 [==============================] - 0s 161ms/step\n",
      "Epoch: 25, Batch: 125/468, discriminator loss real = 2.3159059739374932e-11, disciminator loss fake = 3.4104721180483466e-07, generator loss = 15.938711166381836\n",
      "2/2 [==============================] - 0s 164ms/step\n",
      "Epoch: 25, Batch: 126/468, discriminator loss real = 4.398314314879964e-26, disciminator loss fake = 2.9705768156418344e-07, generator loss = 16.02511978149414\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 25, Batch: 127/468, discriminator loss real = 7.659903003439422e-22, disciminator loss fake = 2.783007744255883e-07, generator loss = 15.852241516113281\n",
      "2/2 [==============================] - 1s 224ms/step\n",
      "Epoch: 25, Batch: 128/468, discriminator loss real = 6.232005388291871e-27, disciminator loss fake = 3.1708947290098877e-07, generator loss = 16.07171630859375\n",
      "2/2 [==============================] - 0s 146ms/step\n",
      "Epoch: 25, Batch: 129/468, discriminator loss real = 1.5513627628511621e-26, disciminator loss fake = 2.9150038471925654e-07, generator loss = 16.119190216064453\n",
      "2/2 [==============================] - 0s 164ms/step\n",
      "Epoch: 25, Batch: 130/468, discriminator loss real = 4.1931253495900254e-18, disciminator loss fake = 3.0752991619920067e-07, generator loss = 16.045923233032227\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 25, Batch: 131/468, discriminator loss real = 2.8846881480748543e-12, disciminator loss fake = 4.279158929421101e-07, generator loss = 16.006357192993164\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 25, Batch: 132/468, discriminator loss real = 2.680606671616143e-26, disciminator loss fake = 5.351676009013318e-07, generator loss = 16.035995483398438\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 25, Batch: 133/468, discriminator loss real = 1.9332945926699087e-18, disciminator loss fake = 3.0726141631021164e-07, generator loss = 15.953479766845703\n",
      "2/2 [==============================] - 0s 144ms/step\n",
      "Epoch: 25, Batch: 134/468, discriminator loss real = 5.506383109893376e-13, disciminator loss fake = 2.518936241813208e-07, generator loss = 16.11754608154297\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 25, Batch: 135/468, discriminator loss real = 8.639773275948424e-35, disciminator loss fake = 8.577802645959309e-07, generator loss = 15.826204299926758\n",
      "2/2 [==============================] - 0s 151ms/step\n",
      "Epoch: 25, Batch: 136/468, discriminator loss real = 1.129569573287074e-29, disciminator loss fake = 3.631625702382735e-07, generator loss = 16.106849670410156\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 25, Batch: 137/468, discriminator loss real = 2.2332764110233327e-11, disciminator loss fake = 3.9867089185463556e-07, generator loss = 16.261066436767578\n",
      "2/2 [==============================] - 0s 158ms/step\n",
      "Epoch: 25, Batch: 138/468, discriminator loss real = 1.3860511029934834e-34, disciminator loss fake = 2.7628706789073476e-07, generator loss = 16.287975311279297\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 25, Batch: 139/468, discriminator loss real = 9.54271632573445e-27, disciminator loss fake = 5.689415729648317e-07, generator loss = 16.063705444335938\n",
      "2/2 [==============================] - 1s 251ms/step\n",
      "Epoch: 25, Batch: 140/468, discriminator loss real = 1.8732555102900342e-21, disciminator loss fake = 2.7980939876215416e-07, generator loss = 15.997682571411133\n",
      "2/2 [==============================] - 0s 130ms/step\n",
      "Epoch: 25, Batch: 141/468, discriminator loss real = 4.671428091862692e-30, disciminator loss fake = 9.243851195606112e-07, generator loss = 16.300609588623047\n",
      "2/2 [==============================] - 0s 147ms/step\n",
      "Epoch: 25, Batch: 142/468, discriminator loss real = 4.390965296027685e-30, disciminator loss fake = 2.1172684228076832e-07, generator loss = 16.182233810424805\n",
      "2/2 [==============================] - 0s 137ms/step\n",
      "Epoch: 25, Batch: 143/468, discriminator loss real = 5.2042930962303235e-20, disciminator loss fake = 3.07453206005448e-07, generator loss = 16.018810272216797\n",
      "2/2 [==============================] - 0s 135ms/step\n",
      "Epoch: 25, Batch: 144/468, discriminator loss real = 1.9212834458034072e-27, disciminator loss fake = 3.3934725252038334e-07, generator loss = 15.815545082092285\n",
      "2/2 [==============================] - 1s 203ms/step\n",
      "Epoch: 25, Batch: 145/468, discriminator loss real = 7.811835047919196e-15, disciminator loss fake = 2.7586031592363724e-07, generator loss = 15.993568420410156\n",
      "2/2 [==============================] - 1s 265ms/step\n",
      "Epoch: 25, Batch: 146/468, discriminator loss real = 1.5332807150488157e-25, disciminator loss fake = 5.017266744289373e-07, generator loss = 16.17161750793457\n",
      "2/2 [==============================] - 0s 146ms/step\n",
      "Epoch: 25, Batch: 147/468, discriminator loss real = 3.260776926250486e-10, disciminator loss fake = 2.552102387198829e-07, generator loss = 16.092208862304688\n",
      "2/2 [==============================] - 0s 163ms/step\n",
      "Epoch: 25, Batch: 148/468, discriminator loss real = 2.5001281894469953e-24, disciminator loss fake = 2.2496945462080475e-07, generator loss = 16.263639450073242\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 25, Batch: 149/468, discriminator loss real = 1.5649212873979935e-19, disciminator loss fake = 2.1251463522276026e-07, generator loss = 16.124582290649414\n",
      "2/2 [==============================] - 0s 222ms/step\n",
      "Epoch: 25, Batch: 150/468, discriminator loss real = 2.354489416356239e-27, disciminator loss fake = 2.0483903995227593e-07, generator loss = 16.158111572265625\n",
      "2/2 [==============================] - 0s 136ms/step\n",
      "Epoch: 25, Batch: 151/468, discriminator loss real = 4.650348682522232e-12, disciminator loss fake = 2.596455033199163e-07, generator loss = 16.23011016845703\n",
      "2/2 [==============================] - 0s 148ms/step\n",
      "Epoch: 25, Batch: 152/468, discriminator loss real = 7.573765938329662e-32, disciminator loss fake = 2.4592378622401156e-07, generator loss = 16.172998428344727\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 25, Batch: 153/468, discriminator loss real = 6.901845750891291e-20, disciminator loss fake = 2.389197106822394e-07, generator loss = 16.101659774780273\n",
      "2/2 [==============================] - 1s 290ms/step\n",
      "Epoch: 25, Batch: 154/468, discriminator loss real = 1.0044720966106979e-07, disciminator loss fake = 2.4027991685215966e-07, generator loss = 16.27237319946289\n",
      "2/2 [==============================] - 0s 154ms/step\n",
      "Epoch: 25, Batch: 155/468, discriminator loss real = 1.0624571784666185e-22, disciminator loss fake = 2.3589257125422591e-07, generator loss = 16.09136199951172\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 25, Batch: 156/468, discriminator loss real = 1.8315162844297556e-28, disciminator loss fake = 3.5863996572516044e-07, generator loss = 16.104225158691406\n",
      "2/2 [==============================] - 0s 141ms/step\n",
      "Epoch: 25, Batch: 157/468, discriminator loss real = 5.670506367216506e-22, disciminator loss fake = 3.331417133267678e-07, generator loss = 16.064910888671875\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 25, Batch: 158/468, discriminator loss real = 1.471727339113876e-20, disciminator loss fake = 2.98898839901085e-07, generator loss = 16.244571685791016\n",
      "2/2 [==============================] - 1s 194ms/step\n",
      "Epoch: 25, Batch: 159/468, discriminator loss real = 3.328750050873862e-24, disciminator loss fake = 2.490057511295163e-07, generator loss = 16.18353271484375\n",
      "2/2 [==============================] - 0s 279ms/step\n",
      "Epoch: 25, Batch: 160/468, discriminator loss real = 3.120501835014894e-29, disciminator loss fake = 3.438732392169186e-07, generator loss = 16.31382942199707\n",
      "2/2 [==============================] - 0s 146ms/step\n",
      "Epoch: 25, Batch: 161/468, discriminator loss real = 7.238664819640936e-17, disciminator loss fake = 3.721810060142161e-07, generator loss = 16.389591217041016\n",
      "2/2 [==============================] - 0s 145ms/step\n",
      "Epoch: 25, Batch: 162/468, discriminator loss real = 1.140015298207125e-30, disciminator loss fake = 3.1859428872849094e-07, generator loss = 16.035518646240234\n",
      "2/2 [==============================] - 0s 170ms/step\n",
      "Epoch: 25, Batch: 163/468, discriminator loss real = 3.764175771719892e-16, disciminator loss fake = 3.568597719549871e-07, generator loss = 16.074865341186523\n",
      "2/2 [==============================] - 0s 141ms/step\n",
      "Epoch: 25, Batch: 164/468, discriminator loss real = 2.7039358770333737e-25, disciminator loss fake = 2.5067180331461714e-07, generator loss = 16.25212860107422\n",
      "2/2 [==============================] - 0s 175ms/step\n",
      "Epoch: 25, Batch: 165/468, discriminator loss real = 1.0073989185348723e-25, disciminator loss fake = 3.3299005508524715e-07, generator loss = 16.307586669921875\n",
      "2/2 [==============================] - 0s 173ms/step\n",
      "Epoch: 25, Batch: 166/468, discriminator loss real = 5.782989097058883e-22, disciminator loss fake = 2.4165538548004406e-07, generator loss = 16.148921966552734\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 25, Batch: 167/468, discriminator loss real = 9.346592777255429e-36, disciminator loss fake = 2.920259021266247e-07, generator loss = 15.994598388671875\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 25, Batch: 168/468, discriminator loss real = 2.5848048302436977e-27, disciminator loss fake = 3.886419221998949e-07, generator loss = 16.19756317138672\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 25, Batch: 169/468, discriminator loss real = 2.679128775222876e-23, disciminator loss fake = 1.606662891617816e-07, generator loss = 16.495206832885742\n",
      "2/2 [==============================] - 0s 241ms/step\n",
      "Epoch: 25, Batch: 170/468, discriminator loss real = 4.686969146128206e-10, disciminator loss fake = 1.6908757061173674e-07, generator loss = 16.226247787475586\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 25, Batch: 171/468, discriminator loss real = 3.805501368343511e-26, disciminator loss fake = 6.254876439015788e-07, generator loss = 16.305482864379883\n",
      "2/2 [==============================] - 0s 157ms/step\n",
      "Epoch: 25, Batch: 172/468, discriminator loss real = 3.023850162838647e-36, disciminator loss fake = 2.482902630163153e-07, generator loss = 16.13062286376953\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 25, Batch: 173/468, discriminator loss real = 6.73959464734354e-23, disciminator loss fake = 1.5108341244740586e-07, generator loss = 16.249080657958984\n",
      "2/2 [==============================] - 1s 166ms/step\n",
      "Epoch: 25, Batch: 174/468, discriminator loss real = 1.4591027682762031e-25, disciminator loss fake = 1.77063355977225e-07, generator loss = 16.313724517822266\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 25, Batch: 175/468, discriminator loss real = 7.184467728854269e-14, disciminator loss fake = 1.9252070160291623e-07, generator loss = 16.180877685546875\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 25, Batch: 176/468, discriminator loss real = 1.5592664659447308e-10, disciminator loss fake = 2.4870610104699153e-07, generator loss = 16.193883895874023\n",
      "2/2 [==============================] - 0s 167ms/step\n",
      "Epoch: 25, Batch: 177/468, discriminator loss real = 1.057836927833719e-18, disciminator loss fake = 2.516919153094932e-07, generator loss = 16.2381591796875\n",
      "2/2 [==============================] - 0s 145ms/step\n",
      "Epoch: 25, Batch: 178/468, discriminator loss real = 2.0603218625280463e-30, disciminator loss fake = 1.7818283026826975e-07, generator loss = 16.357751846313477\n",
      "2/2 [==============================] - 1s 287ms/step\n",
      "Epoch: 25, Batch: 179/468, discriminator loss real = 9.299839067874062e-33, disciminator loss fake = 2.1441113062792283e-07, generator loss = 16.26026153564453\n",
      "2/2 [==============================] - 0s 147ms/step\n",
      "Epoch: 25, Batch: 180/468, discriminator loss real = 2.6521431670820453e-14, disciminator loss fake = 1.8118250011411874e-07, generator loss = 16.27513885498047\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 25, Batch: 181/468, discriminator loss real = 3.251379164935464e-24, disciminator loss fake = 1.9013185692529078e-07, generator loss = 16.064067840576172\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 25, Batch: 182/468, discriminator loss real = 1.8302836411170992e-25, disciminator loss fake = 2.0746897178014478e-07, generator loss = 16.039661407470703\n",
      "2/2 [==============================] - 0s 115ms/step\n",
      "Epoch: 25, Batch: 183/468, discriminator loss real = 1.1431124869610897e-28, disciminator loss fake = 1.429249749662631e-07, generator loss = 16.517221450805664\n",
      "2/2 [==============================] - 0s 165ms/step\n",
      "Epoch: 25, Batch: 184/468, discriminator loss real = 6.974405544720474e-25, disciminator loss fake = 2.0916613152621721e-07, generator loss = 16.10873794555664\n",
      "2/2 [==============================] - 0s 127ms/step\n",
      "Epoch: 25, Batch: 185/468, discriminator loss real = 8.267073591187675e-23, disciminator loss fake = 2.317587615152661e-07, generator loss = 16.540000915527344\n",
      "2/2 [==============================] - 1s 263ms/step\n",
      "Epoch: 25, Batch: 186/468, discriminator loss real = 1.4584157089241678e-19, disciminator loss fake = 2.2971235580371285e-07, generator loss = 16.43592643737793\n",
      "2/2 [==============================] - 0s 145ms/step\n",
      "Epoch: 25, Batch: 187/468, discriminator loss real = 6.374111762852408e-07, disciminator loss fake = 4.0280605162479333e-07, generator loss = 16.245540618896484\n",
      "2/2 [==============================] - 0s 141ms/step\n",
      "Epoch: 25, Batch: 188/468, discriminator loss real = 1.2719136682534698e-24, disciminator loss fake = 3.720987251654151e-07, generator loss = 16.235694885253906\n",
      "2/2 [==============================] - 0s 136ms/step\n",
      "Epoch: 25, Batch: 189/468, discriminator loss real = 3.1977341535678743e-27, disciminator loss fake = 2.329483947960398e-07, generator loss = 16.30834197998047\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 25, Batch: 190/468, discriminator loss real = 0.0, disciminator loss fake = 2.3328207987560745e-07, generator loss = 16.234909057617188\n",
      "2/2 [==============================] - 0s 141ms/step\n",
      "Epoch: 25, Batch: 191/468, discriminator loss real = 8.814325454970251e-20, disciminator loss fake = 1.8378207755631593e-07, generator loss = 16.457992553710938\n",
      "2/2 [==============================] - 1s 240ms/step\n",
      "Epoch: 25, Batch: 192/468, discriminator loss real = 1.2575377871279301e-17, disciminator loss fake = 2.404833594482625e-07, generator loss = 16.534942626953125\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 25, Batch: 193/468, discriminator loss real = 5.7991187369238184e-27, disciminator loss fake = 1.783292589152552e-07, generator loss = 15.942134857177734\n",
      "2/2 [==============================] - 0s 167ms/step\n",
      "Epoch: 25, Batch: 194/468, discriminator loss real = 1.0145921578471988e-14, disciminator loss fake = 2.840783963620197e-07, generator loss = 16.452491760253906\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 25, Batch: 195/468, discriminator loss real = 8.179459681944857e-17, disciminator loss fake = 2.3123143932934909e-07, generator loss = 16.433631896972656\n",
      "2/2 [==============================] - 0s 159ms/step\n",
      "Epoch: 25, Batch: 196/468, discriminator loss real = 4.886418895417898e-34, disciminator loss fake = 1.730057448412481e-07, generator loss = 16.38792610168457\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 25, Batch: 197/468, discriminator loss real = 1.0004319497569979e-36, disciminator loss fake = 3.1329966532211984e-07, generator loss = 16.336898803710938\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 25, Batch: 198/468, discriminator loss real = 6.987473533809352e-12, disciminator loss fake = 3.7573374811472604e-07, generator loss = 16.580371856689453\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 25, Batch: 199/468, discriminator loss real = 6.969864394504603e-28, disciminator loss fake = 1.7136802910044935e-07, generator loss = 16.222570419311523\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 25, Batch: 200/468, discriminator loss real = 8.587497067704189e-35, disciminator loss fake = 1.3664461562257202e-07, generator loss = 16.416790008544922\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 25, Batch: 201/468, discriminator loss real = 1.8928926961956128e-26, disciminator loss fake = 2.3596317078045104e-07, generator loss = 16.319698333740234\n",
      "2/2 [==============================] - 0s 224ms/step\n",
      "Epoch: 25, Batch: 202/468, discriminator loss real = 6.478295005475643e-13, disciminator loss fake = 2.679332453681127e-07, generator loss = 16.38298797607422\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 25, Batch: 203/468, discriminator loss real = 2.1632099323626308e-13, disciminator loss fake = 1.699085743211981e-07, generator loss = 16.382343292236328\n",
      "2/2 [==============================] - 0s 154ms/step\n",
      "Epoch: 25, Batch: 204/468, discriminator loss real = 0.0, disciminator loss fake = 3.1433620506504667e-07, generator loss = 16.37015724182129\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 25, Batch: 205/468, discriminator loss real = 1.768169004610933e-24, disciminator loss fake = 2.633277631503006e-07, generator loss = 16.275455474853516\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 25, Batch: 206/468, discriminator loss real = 3.289532882200241e-11, disciminator loss fake = 2.7065794938607723e-07, generator loss = 16.36164665222168\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 25, Batch: 207/468, discriminator loss real = 7.401287388110579e-21, disciminator loss fake = 1.3228697071099305e-07, generator loss = 16.295337677001953\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 25, Batch: 208/468, discriminator loss real = 6.046906283563255e-28, disciminator loss fake = 2.6198273417321616e-07, generator loss = 16.49215316772461\n",
      "2/2 [==============================] - 0s 234ms/step\n",
      "Epoch: 25, Batch: 209/468, discriminator loss real = 8.044502683464993e-18, disciminator loss fake = 2.450366025641415e-07, generator loss = 16.31926727294922\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 25, Batch: 210/468, discriminator loss real = 1.5781445520648166e-28, disciminator loss fake = 2.073694247428648e-07, generator loss = 16.494976043701172\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 25, Batch: 211/468, discriminator loss real = 1.1531935114674139e-29, disciminator loss fake = 1.6949786640907405e-07, generator loss = 16.450586318969727\n",
      "2/2 [==============================] - 0s 224ms/step\n",
      "Epoch: 25, Batch: 212/468, discriminator loss real = 1.3555251662721915e-30, disciminator loss fake = 1.731801972937319e-07, generator loss = 16.663761138916016\n",
      "2/2 [==============================] - 0s 137ms/step\n",
      "Epoch: 25, Batch: 213/468, discriminator loss real = 8.884809665152137e-34, disciminator loss fake = 2.0799710398478055e-07, generator loss = 16.475112915039062\n",
      "2/2 [==============================] - 0s 153ms/step\n",
      "Epoch: 25, Batch: 214/468, discriminator loss real = 2.0218984628244907e-23, disciminator loss fake = 1.804040437036747e-07, generator loss = 16.35972023010254\n",
      "2/2 [==============================] - 1s 163ms/step\n",
      "Epoch: 25, Batch: 215/468, discriminator loss real = 4.184689634772783e-34, disciminator loss fake = 1.784514296332418e-07, generator loss = 16.368694305419922\n",
      "2/2 [==============================] - 0s 163ms/step\n",
      "Epoch: 25, Batch: 216/468, discriminator loss real = 4.352220890367342e-21, disciminator loss fake = 1.462794045892224e-07, generator loss = 16.68776512145996\n",
      "2/2 [==============================] - 0s 121ms/step\n",
      "Epoch: 25, Batch: 217/468, discriminator loss real = 3.899953988494454e-15, disciminator loss fake = 2.8042626354363165e-07, generator loss = 16.483516693115234\n",
      "2/2 [==============================] - 0s 136ms/step\n",
      "Epoch: 25, Batch: 218/468, discriminator loss real = 3.396344663841866e-11, disciminator loss fake = 1.7215081982158154e-07, generator loss = 16.590801239013672\n",
      "2/2 [==============================] - 1s 238ms/step\n",
      "Epoch: 25, Batch: 219/468, discriminator loss real = 2.6871262697992008e-20, disciminator loss fake = 2.7236623623139167e-07, generator loss = 16.33971405029297\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 25, Batch: 220/468, discriminator loss real = 5.84678139237127e-11, disciminator loss fake = 2.008461876812362e-07, generator loss = 16.396305084228516\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 25, Batch: 221/468, discriminator loss real = 1.355787633589579e-34, disciminator loss fake = 2.994220551499893e-07, generator loss = 16.36723518371582\n",
      "2/2 [==============================] - 1s 255ms/step\n",
      "Epoch: 25, Batch: 222/468, discriminator loss real = 0.0, disciminator loss fake = 2.6851409984374186e-07, generator loss = 16.379554748535156\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 25, Batch: 223/468, discriminator loss real = 5.366137714988491e-27, disciminator loss fake = 1.777846421191498e-07, generator loss = 16.92766761779785\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 25, Batch: 224/468, discriminator loss real = 5.98671299708621e-14, disciminator loss fake = 3.963078256674635e-07, generator loss = 16.43193817138672\n",
      "2/2 [==============================] - 1s 238ms/step\n",
      "Epoch: 25, Batch: 225/468, discriminator loss real = 2.7123605905325644e-18, disciminator loss fake = 3.3801507015596144e-07, generator loss = 16.316064834594727\n",
      "2/2 [==============================] - 0s 150ms/step\n",
      "Epoch: 25, Batch: 226/468, discriminator loss real = 6.144198231435155e-21, disciminator loss fake = 1.9195832123841683e-07, generator loss = 16.487123489379883\n",
      "2/2 [==============================] - 0s 169ms/step\n",
      "Epoch: 25, Batch: 227/468, discriminator loss real = 2.432605198502496e-22, disciminator loss fake = 1.5222207139231614e-07, generator loss = 16.534282684326172\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 25, Batch: 228/468, discriminator loss real = 8.544315608457043e-19, disciminator loss fake = 3.500656475807773e-07, generator loss = 16.489669799804688\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 25, Batch: 229/468, discriminator loss real = 8.76737168487202e-18, disciminator loss fake = 1.773984905639736e-07, generator loss = 16.42850685119629\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 25, Batch: 230/468, discriminator loss real = 1.9781971793689777e-27, disciminator loss fake = 2.560111909133411e-07, generator loss = 16.39386749267578\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 25, Batch: 231/468, discriminator loss real = 5.05732744571219e-09, disciminator loss fake = 3.144062361570832e-07, generator loss = 16.513599395751953\n",
      "2/2 [==============================] - 1s 250ms/step\n",
      "Epoch: 25, Batch: 232/468, discriminator loss real = 4.287944958193815e-22, disciminator loss fake = 2.846600182238035e-07, generator loss = 16.497188568115234\n",
      "2/2 [==============================] - 0s 145ms/step\n",
      "Epoch: 25, Batch: 233/468, discriminator loss real = 9.26093728613464e-13, disciminator loss fake = 2.3289251771529962e-07, generator loss = 16.763904571533203\n",
      "2/2 [==============================] - 0s 174ms/step\n",
      "Epoch: 25, Batch: 234/468, discriminator loss real = 4.240413455752092e-20, disciminator loss fake = 2.156738219127874e-07, generator loss = 16.56519317626953\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 25, Batch: 235/468, discriminator loss real = 4.459388439513409e-21, disciminator loss fake = 1.2273436311716068e-07, generator loss = 16.65233612060547\n",
      "2/2 [==============================] - 1s 266ms/step\n",
      "Epoch: 25, Batch: 236/468, discriminator loss real = 1.3512282072769973e-21, disciminator loss fake = 1.9313387156216777e-07, generator loss = 16.54464340209961\n",
      "2/2 [==============================] - 0s 137ms/step\n",
      "Epoch: 25, Batch: 237/468, discriminator loss real = 7.38447639618886e-21, disciminator loss fake = 1.662101283272932e-07, generator loss = 16.472381591796875\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 25, Batch: 238/468, discriminator loss real = 7.739497931424921e-10, disciminator loss fake = 1.5255186269769183e-07, generator loss = 16.460704803466797\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 25, Batch: 239/468, discriminator loss real = 5.872433695735827e-20, disciminator loss fake = 1.5170128619956813e-07, generator loss = 16.43599510192871\n",
      "2/2 [==============================] - 0s 155ms/step\n",
      "Epoch: 25, Batch: 240/468, discriminator loss real = 2.3048723358581303e-22, disciminator loss fake = 2.3021340211926145e-07, generator loss = 16.559955596923828\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 25, Batch: 241/468, discriminator loss real = 1.5132670741050806e-28, disciminator loss fake = 1.5594835645060812e-07, generator loss = 16.363847732543945\n",
      "2/2 [==============================] - 0s 157ms/step\n",
      "Epoch: 25, Batch: 242/468, discriminator loss real = 0.0, disciminator loss fake = 2.043222622205576e-07, generator loss = 16.726757049560547\n",
      "2/2 [==============================] - 0s 148ms/step\n",
      "Epoch: 25, Batch: 243/468, discriminator loss real = 6.029109577689609e-25, disciminator loss fake = 2.743351217304735e-07, generator loss = 16.464458465576172\n",
      "2/2 [==============================] - 0s 268ms/step\n",
      "Epoch: 25, Batch: 244/468, discriminator loss real = 8.85950724748444e-22, disciminator loss fake = 1.989939875102209e-07, generator loss = 16.66634750366211\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 25, Batch: 245/468, discriminator loss real = 3.812905163585126e-18, disciminator loss fake = 2.023016918428766e-07, generator loss = 16.521780014038086\n",
      "2/2 [==============================] - 0s 155ms/step\n",
      "Epoch: 25, Batch: 246/468, discriminator loss real = 1.8721105007742112e-23, disciminator loss fake = 1.3655498776188324e-07, generator loss = 16.474044799804688\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 25, Batch: 247/468, discriminator loss real = 9.416047882477223e-25, disciminator loss fake = 1.791430008779571e-07, generator loss = 16.786293029785156\n",
      "2/2 [==============================] - 1s 235ms/step\n",
      "Epoch: 25, Batch: 248/468, discriminator loss real = 6.087879813736188e-24, disciminator loss fake = 1.249015326720837e-07, generator loss = 16.959264755249023\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 25, Batch: 249/468, discriminator loss real = 1.1928575044098866e-33, disciminator loss fake = 1.4144556814699172e-07, generator loss = 16.611446380615234\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 25, Batch: 250/468, discriminator loss real = 8.221194627386822e-21, disciminator loss fake = 2.749654868239304e-07, generator loss = 16.59560203552246\n",
      "2/2 [==============================] - 0s 136ms/step\n",
      "Epoch: 25, Batch: 251/468, discriminator loss real = 8.009797200667958e-33, disciminator loss fake = 1.9046035504288739e-07, generator loss = 16.580036163330078\n",
      "2/2 [==============================] - 0s 217ms/step\n",
      "Epoch: 25, Batch: 252/468, discriminator loss real = 1.472758330220425e-12, disciminator loss fake = 1.5377936790628155e-07, generator loss = 16.35226821899414\n",
      "2/2 [==============================] - 0s 187ms/step\n",
      "Epoch: 25, Batch: 253/468, discriminator loss real = 1.2633870093958918e-26, disciminator loss fake = 1.451773670169132e-07, generator loss = 16.576858520507812\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 25, Batch: 254/468, discriminator loss real = 5.350381262697075e-32, disciminator loss fake = 1.9950063290252729e-07, generator loss = 16.59844207763672\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 25, Batch: 255/468, discriminator loss real = 1.3095362067454231e-31, disciminator loss fake = 1.401964766500896e-07, generator loss = 16.742589950561523\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 25, Batch: 256/468, discriminator loss real = 2.189502769533096e-24, disciminator loss fake = 1.3406929610937368e-07, generator loss = 16.768421173095703\n",
      "2/2 [==============================] - 1s 274ms/step\n",
      "Epoch: 25, Batch: 257/468, discriminator loss real = 8.014675335751678e-24, disciminator loss fake = 2.1657763227267424e-07, generator loss = 16.753894805908203\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 25, Batch: 258/468, discriminator loss real = 8.831895790515385e-24, disciminator loss fake = 1.3611841609417752e-07, generator loss = 16.54595184326172\n",
      "2/2 [==============================] - 0s 144ms/step\n",
      "Epoch: 25, Batch: 259/468, discriminator loss real = 4.4171959282847135e-15, disciminator loss fake = 1.5634921624041453e-07, generator loss = 17.02420997619629\n",
      "2/2 [==============================] - 0s 130ms/step\n",
      "Epoch: 25, Batch: 260/468, discriminator loss real = 2.109285938071435e-28, disciminator loss fake = 1.4166968753670517e-07, generator loss = 16.769033432006836\n",
      "2/2 [==============================] - 0s 207ms/step\n",
      "Epoch: 25, Batch: 261/468, discriminator loss real = 6.019732092286408e-24, disciminator loss fake = 1.5562264366053569e-07, generator loss = 16.70370101928711\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 25, Batch: 262/468, discriminator loss real = 1.4647389618698587e-18, disciminator loss fake = 1.3671632359546493e-07, generator loss = 16.61646270751953\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 25, Batch: 263/468, discriminator loss real = 4.997575676306248e-31, disciminator loss fake = 1.175254737972864e-07, generator loss = 16.78894805908203\n",
      "2/2 [==============================] - 1s 255ms/step\n",
      "Epoch: 25, Batch: 264/468, discriminator loss real = 6.811700024790246e-25, disciminator loss fake = 1.1545746758656605e-07, generator loss = 16.747535705566406\n",
      "2/2 [==============================] - 0s 187ms/step\n",
      "Epoch: 25, Batch: 265/468, discriminator loss real = 1.6220248195471139e-28, disciminator loss fake = 1.6868713714757178e-07, generator loss = 16.697195053100586\n",
      "2/2 [==============================] - 0s 130ms/step\n",
      "Epoch: 25, Batch: 266/468, discriminator loss real = 9.326190620690062e-16, disciminator loss fake = 1.1647180997442774e-07, generator loss = 16.651443481445312\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 25, Batch: 267/468, discriminator loss real = 4.260809021161549e-07, disciminator loss fake = 3.1091258279047906e-07, generator loss = 16.815893173217773\n",
      "2/2 [==============================] - 1s 254ms/step\n",
      "Epoch: 25, Batch: 268/468, discriminator loss real = 6.197861670609761e-19, disciminator loss fake = 2.7132466584589565e-07, generator loss = 16.681575775146484\n",
      "2/2 [==============================] - 0s 152ms/step\n",
      "Epoch: 25, Batch: 269/468, discriminator loss real = 4.064768246781846e-31, disciminator loss fake = 1.7245464789539255e-07, generator loss = 16.788867950439453\n",
      "2/2 [==============================] - 0s 137ms/step\n",
      "Epoch: 25, Batch: 270/468, discriminator loss real = 1.5993805782405454e-24, disciminator loss fake = 2.2736647053989145e-07, generator loss = 16.655338287353516\n",
      "2/2 [==============================] - 0s 128ms/step\n",
      "Epoch: 25, Batch: 271/468, discriminator loss real = 1.8629444855603912e-26, disciminator loss fake = 1.0258843730071021e-07, generator loss = 16.801959991455078\n",
      "2/2 [==============================] - 1s 262ms/step\n",
      "Epoch: 25, Batch: 272/468, discriminator loss real = 1.055101263517877e-24, disciminator loss fake = 2.4658925212861504e-07, generator loss = 16.68805694580078\n",
      "2/2 [==============================] - 0s 167ms/step\n",
      "Epoch: 25, Batch: 273/468, discriminator loss real = 3.8700039262528265e-22, disciminator loss fake = 1.431982070698723e-07, generator loss = 16.627090454101562\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 25, Batch: 274/468, discriminator loss real = 9.860715876874507e-21, disciminator loss fake = 1.538137155421282e-07, generator loss = 16.64080810546875\n",
      "2/2 [==============================] - 0s 153ms/step\n",
      "Epoch: 25, Batch: 275/468, discriminator loss real = 4.92534821276138e-19, disciminator loss fake = 1.313668889224573e-07, generator loss = 16.80864906311035\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 25, Batch: 276/468, discriminator loss real = 9.230891026512542e-20, disciminator loss fake = 2.1176772690978396e-07, generator loss = 16.685474395751953\n",
      "2/2 [==============================] - 0s 227ms/step\n",
      "Epoch: 25, Batch: 277/468, discriminator loss real = 6.263402069130869e-15, disciminator loss fake = 1.1495181695408974e-07, generator loss = 16.83575439453125\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 25, Batch: 278/468, discriminator loss real = 1.0329020464820996e-19, disciminator loss fake = 1.006114587198681e-07, generator loss = 16.918027877807617\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 25, Batch: 279/468, discriminator loss real = 5.014047869240366e-29, disciminator loss fake = 4.2052027993122465e-07, generator loss = 16.851760864257812\n",
      "2/2 [==============================] - 0s 139ms/step\n",
      "Epoch: 25, Batch: 280/468, discriminator loss real = 4.470460361064563e-22, disciminator loss fake = 1.1176666703249793e-07, generator loss = 16.642681121826172\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 25, Batch: 281/468, discriminator loss real = 1.9423901672879652e-19, disciminator loss fake = 4.0954270730253484e-07, generator loss = 16.766597747802734\n",
      "2/2 [==============================] - 1s 321ms/step\n",
      "Epoch: 25, Batch: 282/468, discriminator loss real = 2.8017605162053886e-32, disciminator loss fake = 1.7343242575407203e-07, generator loss = 16.705223083496094\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 25, Batch: 283/468, discriminator loss real = 2.227504971594987e-35, disciminator loss fake = 1.5577805356770114e-07, generator loss = 16.911266326904297\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 25, Batch: 284/468, discriminator loss real = 2.6158739011861633e-19, disciminator loss fake = 1.549945665146879e-07, generator loss = 16.771074295043945\n",
      "2/2 [==============================] - 0s 159ms/step\n",
      "Epoch: 25, Batch: 285/468, discriminator loss real = 2.1895118137964115e-29, disciminator loss fake = 1.199506414195639e-07, generator loss = 16.75368881225586\n",
      "2/2 [==============================] - 0s 110ms/step\n",
      "Epoch: 25, Batch: 286/468, discriminator loss real = 1.910506900031512e-16, disciminator loss fake = 2.1654287252204085e-07, generator loss = 16.771453857421875\n",
      "2/2 [==============================] - 0s 183ms/step\n",
      "Epoch: 25, Batch: 287/468, discriminator loss real = 3.3184914378949146e-35, disciminator loss fake = 1.3126711451150186e-07, generator loss = 16.71055030822754\n",
      "2/2 [==============================] - 0s 136ms/step\n",
      "Epoch: 25, Batch: 288/468, discriminator loss real = 1.3918591800251085e-18, disciminator loss fake = 1.3770210216534906e-07, generator loss = 16.650802612304688\n",
      "2/2 [==============================] - 0s 164ms/step\n",
      "Epoch: 25, Batch: 289/468, discriminator loss real = 9.235769843851264e-38, disciminator loss fake = 1.7414858177744463e-07, generator loss = 16.985031127929688\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 25, Batch: 290/468, discriminator loss real = 1.278954054617341e-24, disciminator loss fake = 1.218080001308408e-07, generator loss = 16.83038330078125\n",
      "2/2 [==============================] - 1s 244ms/step\n",
      "Epoch: 25, Batch: 291/468, discriminator loss real = 1.4505834212522841e-31, disciminator loss fake = 1.0652674120592565e-07, generator loss = 16.98168182373047\n",
      "2/2 [==============================] - 0s 148ms/step\n",
      "Epoch: 25, Batch: 292/468, discriminator loss real = 4.212924483322523e-25, disciminator loss fake = 8.139562623910024e-08, generator loss = 16.971099853515625\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 25, Batch: 293/468, discriminator loss real = 1.6922319966272906e-25, disciminator loss fake = 1.3663485276538267e-07, generator loss = 16.771459579467773\n",
      "2/2 [==============================] - 0s 145ms/step\n",
      "Epoch: 25, Batch: 294/468, discriminator loss real = 1.0526259666790852e-27, disciminator loss fake = 1.3954050359643588e-07, generator loss = 17.076587677001953\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 25, Batch: 295/468, discriminator loss real = 3.2695752770943246e-25, disciminator loss fake = 1.1514956810287913e-07, generator loss = 16.78643035888672\n",
      "2/2 [==============================] - 1s 231ms/step\n",
      "Epoch: 25, Batch: 296/468, discriminator loss real = 3.117586940753034e-36, disciminator loss fake = 1.2654749070861726e-07, generator loss = 17.05089569091797\n",
      "2/2 [==============================] - 0s 166ms/step\n",
      "Epoch: 25, Batch: 297/468, discriminator loss real = 1.7821968296726442e-28, disciminator loss fake = 1.6583983608597919e-07, generator loss = 16.943906784057617\n",
      "2/2 [==============================] - 0s 153ms/step\n",
      "Epoch: 25, Batch: 298/468, discriminator loss real = 1.6595821732109002e-32, disciminator loss fake = 1.0519799076291747e-07, generator loss = 16.85216522216797\n",
      "2/2 [==============================] - 0s 135ms/step\n",
      "Epoch: 25, Batch: 299/468, discriminator loss real = 9.059275715933655e-16, disciminator loss fake = 1.7154087572635035e-07, generator loss = 17.027767181396484\n",
      "2/2 [==============================] - 0s 151ms/step\n",
      "Epoch: 25, Batch: 300/468, discriminator loss real = 2.6339426639765406e-08, disciminator loss fake = 1.6558917081965774e-07, generator loss = 17.012786865234375\n",
      "2/2 [==============================] - 1s 199ms/step\n",
      "Epoch: 25, Batch: 301/468, discriminator loss real = 1.0881456954713335e-21, disciminator loss fake = 1.5591400881476147e-07, generator loss = 16.829233169555664\n",
      "2/2 [==============================] - 0s 183ms/step\n",
      "Epoch: 25, Batch: 302/468, discriminator loss real = 8.115178532355743e-27, disciminator loss fake = 1.2462649578992568e-07, generator loss = 17.084291458129883\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 25, Batch: 303/468, discriminator loss real = 2.8780618615702294e-29, disciminator loss fake = 1.3411489874215476e-07, generator loss = 16.788372039794922\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 25, Batch: 304/468, discriminator loss real = 1.7839563698022658e-30, disciminator loss fake = 1.1279052358759145e-07, generator loss = 16.919252395629883\n",
      "2/2 [==============================] - 0s 129ms/step\n",
      "Epoch: 25, Batch: 305/468, discriminator loss real = 2.0864273182703217e-36, disciminator loss fake = 1.5306832779060642e-07, generator loss = 16.67565155029297\n",
      "2/2 [==============================] - 0s 114ms/step\n",
      "Epoch: 25, Batch: 306/468, discriminator loss real = 9.236880129186917e-22, disciminator loss fake = 1.4058772990210855e-07, generator loss = 16.885900497436523\n",
      "2/2 [==============================] - 0s 167ms/step\n",
      "Epoch: 25, Batch: 307/468, discriminator loss real = 4.029312569031555e-18, disciminator loss fake = 1.0736582112258475e-07, generator loss = 16.72251319885254\n",
      "2/2 [==============================] - 0s 153ms/step\n",
      "Epoch: 25, Batch: 308/468, discriminator loss real = 2.5603027727430505e-15, disciminator loss fake = 8.599147349741543e-08, generator loss = 16.902130126953125\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 25, Batch: 309/468, discriminator loss real = 2.8670411226450387e-22, disciminator loss fake = 1.2061624943271454e-07, generator loss = 17.134634017944336\n",
      "2/2 [==============================] - 0s 138ms/step\n",
      "Epoch: 25, Batch: 310/468, discriminator loss real = 3.5062569709622127e-13, disciminator loss fake = 1.4946525084269524e-07, generator loss = 16.753173828125\n",
      "2/2 [==============================] - 0s 116ms/step\n",
      "Epoch: 25, Batch: 311/468, discriminator loss real = 1.6338271757431524e-24, disciminator loss fake = 1.6017480675145634e-07, generator loss = 16.845333099365234\n",
      "2/2 [==============================] - 0s 144ms/step\n",
      "Epoch: 25, Batch: 312/468, discriminator loss real = 2.426178001608862e-23, disciminator loss fake = 1.5623967897226976e-07, generator loss = 17.093582153320312\n",
      "2/2 [==============================] - 0s 145ms/step\n",
      "Epoch: 25, Batch: 313/468, discriminator loss real = 1.2601256314453384e-38, disciminator loss fake = 1.2357592993339495e-07, generator loss = 16.813161849975586\n",
      "2/2 [==============================] - 0s 211ms/step\n",
      "Epoch: 25, Batch: 314/468, discriminator loss real = 1.60685657339938e-16, disciminator loss fake = 1.1070226690890195e-07, generator loss = 17.030162811279297\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 25, Batch: 315/468, discriminator loss real = 4.202255630250892e-21, disciminator loss fake = 1.312133122155501e-07, generator loss = 16.707794189453125\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 25, Batch: 316/468, discriminator loss real = 2.3840529156029974e-19, disciminator loss fake = 1.4705003081871837e-07, generator loss = 17.187847137451172\n",
      "2/2 [==============================] - 0s 229ms/step\n",
      "Epoch: 25, Batch: 317/468, discriminator loss real = 1.3024238114667241e-06, disciminator loss fake = 1.4359790156959207e-07, generator loss = 16.845048904418945\n",
      "2/2 [==============================] - 0s 171ms/step\n",
      "Epoch: 25, Batch: 318/468, discriminator loss real = 2.0358228675450447e-30, disciminator loss fake = 1.0727694643719587e-07, generator loss = 16.929960250854492\n",
      "2/2 [==============================] - 0s 148ms/step\n",
      "Epoch: 25, Batch: 319/468, discriminator loss real = 5.188013929569024e-08, disciminator loss fake = 1.1607307470740125e-07, generator loss = 16.800260543823242\n",
      "2/2 [==============================] - 0s 162ms/step\n",
      "Epoch: 25, Batch: 320/468, discriminator loss real = 2.1567436204254318e-30, disciminator loss fake = 1.194317178487836e-07, generator loss = 16.826208114624023\n",
      "2/2 [==============================] - 0s 154ms/step\n",
      "Epoch: 25, Batch: 321/468, discriminator loss real = 6.725373823377082e-36, disciminator loss fake = 1.1075454153797182e-07, generator loss = 16.623435974121094\n",
      "2/2 [==============================] - 0s 111ms/step\n",
      "Epoch: 25, Batch: 322/468, discriminator loss real = 1.3875576035382586e-13, disciminator loss fake = 8.884695290589661e-08, generator loss = 17.05596351623535\n",
      "2/2 [==============================] - 0s 233ms/step\n",
      "Epoch: 25, Batch: 323/468, discriminator loss real = 1.110253724288544e-23, disciminator loss fake = 1.428118565627301e-07, generator loss = 16.87647247314453\n",
      "2/2 [==============================] - 0s 166ms/step\n",
      "Epoch: 25, Batch: 324/468, discriminator loss real = 2.790192147081535e-25, disciminator loss fake = 1.1313926506772987e-07, generator loss = 16.799314498901367\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 25, Batch: 325/468, discriminator loss real = 1.586727951407006e-22, disciminator loss fake = 1.1884216633006872e-07, generator loss = 16.86324119567871\n",
      "2/2 [==============================] - 0s 168ms/step\n",
      "Epoch: 25, Batch: 326/468, discriminator loss real = 3.017121594318974e-23, disciminator loss fake = 1.8331500939439138e-07, generator loss = 16.924888610839844\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 25, Batch: 327/468, discriminator loss real = 8.141108447101697e-12, disciminator loss fake = 1.0419624629776081e-07, generator loss = 16.895429611206055\n",
      "2/2 [==============================] - 1s 247ms/step\n",
      "Epoch: 25, Batch: 328/468, discriminator loss real = 8.791048671450654e-26, disciminator loss fake = 1.4886715860029653e-07, generator loss = 16.988754272460938\n",
      "2/2 [==============================] - 0s 150ms/step\n",
      "Epoch: 25, Batch: 329/468, discriminator loss real = 4.151304338590263e-18, disciminator loss fake = 1.1223077933664172e-07, generator loss = 16.780960083007812\n",
      "2/2 [==============================] - 0s 151ms/step\n",
      "Epoch: 25, Batch: 330/468, discriminator loss real = 1.3145742996532132e-23, disciminator loss fake = 1.8593568995584064e-07, generator loss = 16.880104064941406\n",
      "2/2 [==============================] - 0s 106ms/step\n",
      "Epoch: 25, Batch: 331/468, discriminator loss real = 2.7057057357780436e-24, disciminator loss fake = 1.2307339147810126e-07, generator loss = 16.72235679626465\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 25, Batch: 332/468, discriminator loss real = 1.043248444555697e-32, disciminator loss fake = 2.4241106189037964e-07, generator loss = 16.943815231323242\n",
      "2/2 [==============================] - 0s 151ms/step\n",
      "Epoch: 25, Batch: 333/468, discriminator loss real = 5.084849483634913e-25, disciminator loss fake = 2.0232035069511767e-07, generator loss = 16.771081924438477\n",
      "2/2 [==============================] - 0s 109ms/step\n",
      "Epoch: 25, Batch: 334/468, discriminator loss real = 3.073128446670259e-21, disciminator loss fake = 1.1065694138778781e-07, generator loss = 16.934581756591797\n",
      "2/2 [==============================] - 0s 189ms/step\n",
      "Epoch: 25, Batch: 335/468, discriminator loss real = 0.0, disciminator loss fake = 1.4593078390134906e-07, generator loss = 16.923389434814453\n",
      "2/2 [==============================] - 0s 123ms/step\n",
      "Epoch: 25, Batch: 336/468, discriminator loss real = 8.571232771745868e-34, disciminator loss fake = 8.930101813575675e-08, generator loss = 16.78226089477539\n",
      "2/2 [==============================] - 0s 130ms/step\n",
      "Epoch: 25, Batch: 337/468, discriminator loss real = 8.772166089621508e-31, disciminator loss fake = 1.4138083770376397e-07, generator loss = 16.95329475402832\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 25, Batch: 338/468, discriminator loss real = 1.0711853485144282e-24, disciminator loss fake = 1.2170298191449547e-07, generator loss = 17.089885711669922\n",
      "2/2 [==============================] - 0s 145ms/step\n",
      "Epoch: 25, Batch: 339/468, discriminator loss real = 4.185848881940273e-28, disciminator loss fake = 8.214213664814451e-08, generator loss = 16.86895751953125\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 25, Batch: 340/468, discriminator loss real = 4.905580842923438e-25, disciminator loss fake = 1.1135374222703831e-07, generator loss = 17.001243591308594\n",
      "2/2 [==============================] - 0s 122ms/step\n",
      "Epoch: 25, Batch: 341/468, discriminator loss real = 2.387958282396583e-24, disciminator loss fake = 1.0939724859326816e-07, generator loss = 17.016874313354492\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 25, Batch: 342/468, discriminator loss real = 1.5718590948020342e-25, disciminator loss fake = 1.3213599459049874e-07, generator loss = 16.946056365966797\n",
      "2/2 [==============================] - 0s 155ms/step\n",
      "Epoch: 25, Batch: 343/468, discriminator loss real = 3.6605500259018967e-26, disciminator loss fake = 8.041092769417446e-08, generator loss = 16.975828170776367\n",
      "2/2 [==============================] - 0s 150ms/step\n",
      "Epoch: 25, Batch: 344/468, discriminator loss real = 7.795310472949629e-24, disciminator loss fake = 1.203113839665093e-07, generator loss = 17.026880264282227\n",
      "2/2 [==============================] - 0s 113ms/step\n",
      "Epoch: 25, Batch: 345/468, discriminator loss real = 2.018241076668844e-37, disciminator loss fake = 1.5484924631437025e-07, generator loss = 17.019771575927734\n",
      "2/2 [==============================] - 0s 219ms/step\n",
      "Epoch: 25, Batch: 346/468, discriminator loss real = 2.399181765976381e-32, disciminator loss fake = 1.2898070167466358e-07, generator loss = 17.14133071899414\n",
      "2/2 [==============================] - 0s 171ms/step\n",
      "Epoch: 25, Batch: 347/468, discriminator loss real = 2.13148083623304e-28, disciminator loss fake = 1.34787612182663e-07, generator loss = 16.959829330444336\n",
      "2/2 [==============================] - 0s 148ms/step\n",
      "Epoch: 25, Batch: 348/468, discriminator loss real = 6.622155410695996e-07, disciminator loss fake = 1.35587526983727e-07, generator loss = 16.999048233032227\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "Epoch: 25, Batch: 349/468, discriminator loss real = 1.3958988627713463e-25, disciminator loss fake = 1.6677989833624451e-07, generator loss = 17.159381866455078\n",
      "2/2 [==============================] - 0s 183ms/step\n",
      "Epoch: 25, Batch: 350/468, discriminator loss real = 1.8823709533601555e-38, disciminator loss fake = 1.401060671923915e-07, generator loss = 17.054458618164062\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 25, Batch: 351/468, discriminator loss real = 4.243438638374973e-34, disciminator loss fake = 1.3214526006777305e-07, generator loss = 16.905925750732422\n",
      "2/2 [==============================] - 0s 145ms/step\n",
      "Epoch: 25, Batch: 352/468, discriminator loss real = 5.239589572446168e-36, disciminator loss fake = 1.1555265189144848e-07, generator loss = 17.066356658935547\n",
      "2/2 [==============================] - 0s 126ms/step\n",
      "Epoch: 25, Batch: 353/468, discriminator loss real = 5.740943676934944e-16, disciminator loss fake = 1.3577447077750548e-07, generator loss = 17.158432006835938\n",
      "2/2 [==============================] - 1s 191ms/step\n",
      "Epoch: 25, Batch: 354/468, discriminator loss real = 3.599640428396502e-36, disciminator loss fake = 1.6348397480214771e-07, generator loss = 16.874448776245117\n",
      "2/2 [==============================] - 0s 135ms/step\n",
      "Epoch: 25, Batch: 355/468, discriminator loss real = 9.214252625671864e-38, disciminator loss fake = 8.322134448235374e-08, generator loss = 16.98710060119629\n",
      "2/2 [==============================] - 0s 145ms/step\n",
      "Epoch: 25, Batch: 356/468, discriminator loss real = 2.1633807361256547e-28, disciminator loss fake = 9.615067853019355e-08, generator loss = 16.887306213378906\n",
      "2/2 [==============================] - 0s 133ms/step\n",
      "Epoch: 25, Batch: 357/468, discriminator loss real = 1.3460259840096204e-37, disciminator loss fake = 9.362609887375584e-08, generator loss = 17.0299129486084\n",
      "2/2 [==============================] - 0s 184ms/step\n",
      "Epoch: 25, Batch: 358/468, discriminator loss real = 8.733869094533363e-23, disciminator loss fake = 8.638068749178274e-08, generator loss = 16.942516326904297\n",
      "2/2 [==============================] - 0s 145ms/step\n",
      "Epoch: 25, Batch: 359/468, discriminator loss real = 4.696286220150225e-13, disciminator loss fake = 1.2501527635322418e-07, generator loss = 16.74216651916504\n",
      "2/2 [==============================] - 0s 142ms/step\n",
      "Epoch: 25, Batch: 360/468, discriminator loss real = 1.004380271280433e-30, disciminator loss fake = 1.0303607922423907e-07, generator loss = 17.073986053466797\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "Epoch: 25, Batch: 361/468, discriminator loss real = 1.6427999321146259e-22, disciminator loss fake = 7.841617843951099e-08, generator loss = 16.9046630859375\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 25, Batch: 362/468, discriminator loss real = 4.487402316518324e-22, disciminator loss fake = 9.009937684822944e-08, generator loss = 17.051279067993164\n",
      "2/2 [==============================] - 1s 152ms/step\n",
      "Epoch: 25, Batch: 363/468, discriminator loss real = 3.2335209593307426e-15, disciminator loss fake = 1.165659000434971e-07, generator loss = 17.149185180664062\n",
      "2/2 [==============================] - 0s 164ms/step\n",
      "Epoch: 25, Batch: 364/468, discriminator loss real = 3.3554949643586154e-18, disciminator loss fake = 9.190538463599296e-08, generator loss = 16.635087966918945\n",
      "2/2 [==============================] - 0s 160ms/step\n",
      "Epoch: 25, Batch: 365/468, discriminator loss real = 1.5428721016104842e-16, disciminator loss fake = 1.0473719669334969e-07, generator loss = 16.64910316467285\n",
      "2/2 [==============================] - 0s 151ms/step\n",
      "Epoch: 25, Batch: 366/468, discriminator loss real = 1.0122395287089008e-28, disciminator loss fake = 2.543429218349047e-07, generator loss = 17.16551399230957\n",
      "2/2 [==============================] - 0s 124ms/step\n",
      "Epoch: 25, Batch: 367/468, discriminator loss real = 8.344198110243894e-10, disciminator loss fake = 1.3169739077056875e-07, generator loss = 16.90903663635254\n",
      "2/2 [==============================] - 0s 153ms/step\n",
      "Epoch: 25, Batch: 368/468, discriminator loss real = 5.241022324305048e-29, disciminator loss fake = 1.730543601752288e-07, generator loss = 16.88064193725586\n",
      "2/2 [==============================] - 0s 140ms/step\n",
      "Epoch: 25, Batch: 369/468, discriminator loss real = 6.148743524186574e-32, disciminator loss fake = 1.086578578224362e-07, generator loss = 16.871238708496094\n",
      "2/2 [==============================] - 0s 131ms/step\n",
      "Epoch: 25, Batch: 370/468, discriminator loss real = 2.7147607584774636e-19, disciminator loss fake = 1.0463691779705186e-07, generator loss = 16.919376373291016\n",
      "2/2 [==============================] - 0s 219ms/step\n",
      "Epoch: 25, Batch: 371/468, discriminator loss real = 2.865789527292412e-20, disciminator loss fake = 8.311326382681727e-08, generator loss = 16.929336547851562\n",
      "2/2 [==============================] - 0s 120ms/step\n",
      "Epoch: 25, Batch: 372/468, discriminator loss real = 1.461068438891522e-16, disciminator loss fake = 1.5417280962992663e-07, generator loss = 17.007963180541992\n",
      "2/2 [==============================] - 0s 125ms/step\n",
      "Epoch: 25, Batch: 373/468, discriminator loss real = 1.3575929830867004e-29, disciminator loss fake = 1.2049250130985456e-07, generator loss = 17.00546646118164\n",
      "2/2 [==============================] - 0s 132ms/step\n",
      "Epoch: 25, Batch: 374/468, discriminator loss real = 4.0599006795316583e-11, disciminator loss fake = 1.1604009131360726e-07, generator loss = 16.992265701293945\n",
      "2/2 [==============================] - 0s 119ms/step\n",
      "Epoch: 25, Batch: 375/468, discriminator loss real = 1.0863938163951115e-26, disciminator loss fake = 1.0137436845525372e-07, generator loss = 17.135690689086914\n",
      "2/2 [==============================] - 1s 264ms/step\n",
      "Epoch: 25, Batch: 376/468, discriminator loss real = 4.570891319703385e-25, disciminator loss fake = 1.6682827208569506e-07, generator loss = 17.078567504882812\n",
      "2/2 [==============================] - 0s 143ms/step\n",
      "Epoch: 25, Batch: 377/468, discriminator loss real = 1.0662843729551878e-28, disciminator loss fake = 1.6931866753111535e-07, generator loss = 17.044675827026367\n",
      "2/2 [==============================] - 0s 163ms/step\n",
      "Epoch: 25, Batch: 378/468, discriminator loss real = 2.6772282750414034e-35, disciminator loss fake = 9.583492044384911e-08, generator loss = 17.05967903137207\n",
      "2/2 [==============================] - 0s 141ms/step\n",
      "Epoch: 25, Batch: 379/468, discriminator loss real = 7.965140493954817e-18, disciminator loss fake = 8.084204239366954e-08, generator loss = 16.681793212890625\n",
      "2/2 [==============================] - 0s 175ms/step\n",
      "Epoch: 25, Batch: 380/468, discriminator loss real = 1.1324710563601175e-17, disciminator loss fake = 9.983467919028044e-08, generator loss = 17.220123291015625\n",
      "2/2 [==============================] - 0s 151ms/step\n",
      "Epoch: 25, Batch: 381/468, discriminator loss real = 2.1115393268877242e-31, disciminator loss fake = 9.456331895307812e-08, generator loss = 17.2308349609375\n",
      "2/2 [==============================] - 0s 137ms/step\n",
      "Epoch: 25, Batch: 382/468, discriminator loss real = 0.0, disciminator loss fake = 1.0566961350377824e-07, generator loss = 17.046144485473633\n",
      "2/2 [==============================] - 0s 118ms/step\n",
      "Epoch: 25, Batch: 383/468, discriminator loss real = 3.0393807850181614e-33, disciminator loss fake = 1.616382974134467e-07, generator loss = 17.066303253173828\n",
      "2/2 [==============================] - 0s 167ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calling required functions\n",
    "\n",
    "latent_dim = 100\n",
    "d_model = discriminator_func()\n",
    "g_model = generator_func(latent_dim)\n",
    "gan_model = gan_func(g_model, d_model)\n",
    "dataset = load_real_samples()\n",
    "train(g_model, d_model, gan_model, dataset, latent_dim, epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "254b92c6-db12-4787-ba27-b8305b3a3547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 86ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 100 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#displaying conditioned images \n",
    "import matplotlib.pyplot as plt\n",
    "model = tf.keras.models.load_model('mnist_conditional_generator.h5', compile=False)\n",
    "\n",
    "latent_points, labels = generate_latent_points(100, 100)\n",
    "\n",
    "labels = np.asarray([x for _ in range(10) for x in range(10)])\n",
    "\n",
    "X = model.predict([latent_points, labels])\n",
    "\n",
    "X = (X+1)/2.0\n",
    "X = (X*255).astype(np.uint8)\n",
    "\n",
    "for i in range(100):\n",
    "    plt.subplot(10, 10, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X[i, :,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dad639-e33d-4e13-9cb8-417a6153034b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
