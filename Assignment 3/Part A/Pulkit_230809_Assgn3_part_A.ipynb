{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ASSIGNMENT 3\n",
        "PART A consists of theoretical questions. Objective answers will receive zero marks. You need to write detailed answers (200-300 words) for the questions that require more in-depth explanations (you should be able to identify these after reading and finding about them). Questions that need less explanation can be answered in 95-150 words. Please ensure the answers are well-written and thorough."
      ],
      "metadata": {
        "id": "wg6hsKMq398n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART A"
      ],
      "metadata": {
        "id": "OFQN0GPrnSd3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q 1)What are optimizers in ML. Give some examples"
      ],
      "metadata": {
        "id": "OuKQGaqx2a5i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* In machine learning, our sole goal or target is to minimise the loss function, thats the point where optimizers come into play, so optimizers are methods or algorithms which are used to minimize the loss function by adjusting parameters(or weights), through iterations.. for example Gradient descent, Adam, RMSprop etc.\n",
        "\n",
        "reference: https://medium.com/analytics-vidhya/this-blog-post-aims-at-explaining-the-behavior-of-different-algorithms-for-optimizing-gradient-46159a97a8c1"
      ],
      "metadata": {
        "id": "RzsXJtWnlOQm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q 2)Explain the difference between Gradient Descent, Stochastic Gradient Descent, Mini-Batch Gradient Descent"
      ],
      "metadata": {
        "id": "X8GPK5j_2n3P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Gradient Descent (GD): An optimization algorithm that computes the gradient of the loss function using the entire dataset to update the model parameters.\n",
        " >it is noiceless and guaranteed to converge but time taking and computationally expensive.\n",
        "\n",
        " formula:\n",
        " θ=θ−α∇\n",
        "θ\n",
        "​\n",
        " J(θ)\n",
        "* Stochastic Gradient Descent (SGD): An optimization algorithm that computes the gradient of the loss function using a single randomly chosen data point to update the model parameters.\n",
        " >It is faster and lighter computationally but noicier and overfits and results in large variance and small bias.\n",
        "\n",
        " formula: θ=θ−α∇\n",
        "θ\n",
        "​\n",
        " J(θ;x\n",
        "i\n",
        "​\n",
        " ,y\n",
        "i\n",
        "​\n",
        " )\n",
        "\n",
        "* Mini-Batch Gradient Descent: An optimization algorithm that computes the gradient of the loss function using a small, random subset of the dataset (mini-batch) to update the model parameters. (like a bridge between GD and SGD).\n",
        " > has balanced efficiency and moderately noicy.\n",
        "\n",
        " formula: θ=θ−α∇\n",
        "θ\n",
        "​\n",
        " J(θ;X\n",
        "batch\n",
        "​\n",
        " ,y\n",
        "batch\n",
        "​\n",
        " )\n",
        "\n",
        "\n",
        "\n",
        " reference: https://www.baeldung.com/cs/gradient-stochastic-and-mini-batch\n",
        "\n"
      ],
      "metadata": {
        "id": "3Xn0bQWpoSEm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q 3)Explain about Adam optimizer in detail"
      ],
      "metadata": {
        "id": "0AG5Rm7c2sAO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Adaptive Moment Estimation(ADAM) is an algorithm for optimization technique for gradient descent. The method is really efficient when working with large problem involving a lot of data or parameters. It requires less memory and is efficient.\n",
        "\n",
        "Adam optimizer involves a combination of two gradient descent methodologies:\n",
        "\n",
        "Momentum:\n",
        "\n",
        "This algorithm is used to accelerate the gradient descent algorithm by taking into consideration the ‘exponentially weighted average’ of the gradients. Using averages makes the algorithm converge towards the minima in a faster pace.\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "Root Mean Square Propagation (RMSP):\n",
        "\n",
        "RMSprop is an adaptive learning algorithm that tries to improve AdaGrad. Instead of taking the cumulative sum of squared gradients like in AdaGrad, it takes the ‘exponential moving average’.\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "Adam Optimizer inherits the strengths or the positive attributes of the above two methods and builds upon them to give a more optimized gradient descent.\n",
        "\n",
        "Taking the formulas used in the above two methods, we get\n",
        "\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "\n",
        "Parameters Used :\n",
        "1. ϵ = a small +ve constant to avoid 'division by 0' error when (vt -> 0). (10-8)\n",
        "2. β1 & β2 = decay rates of average of gradients in the above two methods. (β1 = 0.9 & β2 = 0.999)\n",
        "3. α — Step size parameter / learning rate (0.001)\n",
        "\n",
        "\n",
        "reference: https://www.geeksforgeeks.org/adam-optimizer/"
      ],
      "metadata": {
        "id": "PgjJCptYvhht"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q 4)Explain the difference between Rmsprop and Adam."
      ],
      "metadata": {
        "id": "b0I65BBb2w84"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RMSprop and Adam both are optimization algorithms.\n",
        "RMSprop adjusts the learning rate for each parameter based on a moving average of squared gradients. Its update rule for parameter 𝜃 is:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "On the other hand, Adam combines the benefits of RMSprop and momentum. It maintains an exponentially decaying average of past gradients (first moment) and squared gradients (second moment), and includes bias correction. Its update rule for parameter 𝜃 is:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "In simpler terms, RMSprop adjusts learning rates based on recent gradient magnitudes, while Adam combines this with momentum and bias correction to provide even more reliable updates, typically resulting in faster convergence during training.\n",
        "\n",
        "reference: https://medium.com/analytics-vidhya/a-complete-guide-to-adam-and-rmsprop-optimizer-75f4502d83be"
      ],
      "metadata": {
        "id": "NusJsxX9xn5M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q 5)What do you think is the best optimizer among all and Why? If you cannot come to conclusive answer, you must list them all and tell in which scenario the one is preferred.Also tell the disadvantages."
      ],
      "metadata": {
        "id": "qVYyIYOe2w_k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I think ADAM in the best optimizer as I it is used most widely and:\n",
        "\n",
        "* Adam adjusts learning rates for each parameter individually, leading to faster convergence and improved performance.\n",
        "* Incorporating momentum accelerates optimization, particularly in regions with consistent gradients, overcoming local minima more effectively.\n",
        "* Adam performs well across various architectures and applications, requiring minimal hyperparameter tuning and benefiting from extensive community support."
      ],
      "metadata": {
        "id": "-HED8gJDiLZT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q 6)What is overfitting and underfitting"
      ],
      "metadata": {
        "id": "AKxnf5et2xDF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* overfitting: When the model fits the training set is such an extreme way that it performs well on it but is not flexible enough to perform good on test data and performs badly on test data.\n",
        "* underfitting: when the model does not learn properly and give bad accuracy on both training as well as test set."
      ],
      "metadata": {
        "id": "2wyM0ELgKyHu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q 7)Explain the vanishing and exploding gradients"
      ],
      "metadata": {
        "id": "-UCncA8M2xF5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Vanishing gradients occur when gradients become very small during training, hampering learning in deep networks.\n",
        "* Exploding gradients happen when gradients become extremely large, causing instability.\n",
        "\n",
        "Both hinder training by making it hard to update parameters effectively."
      ],
      "metadata": {
        "id": "4Z-fnLf4K5zC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q 8)Explain batch and layer normalization in detail."
      ],
      "metadata": {
        "id": "fNW8Hmd52xIn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Batch Normalization (BN) normalizes layer activations across mini-batches, stabilizing training by reducing internal covariate shift. It computes batch-wise mean and standard deviation, followed by learnable scaling and shifting. Effective for larger batch sizes and deeper networks, BN accelerates convergence but adds computational overhead. Layer Normalization (LN) normalizes activations per sample across features, making it less sensitive to batch size variations. LN is suitable for smaller or varying batch sizes, simpler than BN, and applicable to recurrent neural networks (RNNs) but may require additional regularization. BN is favored for larger batch sizes and deeper architectures, while LN offers flexibility for varying batch sizes and simpler implementation."
      ],
      "metadata": {
        "id": "hY2tPNVYLj-b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q 9)What are regularization techniques in machine learning?(200 words)"
      ],
      "metadata": {
        "id": "6pMnZ6z52xLa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regularization is a technique used to reduce errors by fitting the function appropriately on the given training set and avoiding overfitting.\n",
        "These techniques add constraints to the model during training to discourage it from learning overly complex patterns that may not generalize well.\n",
        "By applying regularization techniques, machine learning models can achieve better generalization performance and avoid overfitting, leading to more reliable predictions on new, unseen data.\n",
        "\n",
        "The commonly used regularization techniques are :\n",
        "\n",
        "* Lasso Regularization – L1 Regularization\n",
        "* Ridge Regularization – L2 Regularization\n",
        "* Elastic Net Regularization – L1 and L2 Regularization\n",
        "\n",
        "<!-- The commonly used regularization techniques are :  -->\n",
        "\n",
        "<!-- * Lasso Regularization – L1 Regularization\n",
        "\n",
        "Lasso imposes an L1 penalty on the model's coefficients during training. This penalty encourages sparsity in the coefficient values, effectively setting some of them to zero. This feature selection property makes Lasso particularly useful when dealing with high-dimensional data, as it automatically identifies and discards irrelevant features, leading to simpler and more interpretable models.\n",
        "\n",
        "* Ridge Regularization – L2 Regularization\n",
        "\n",
        "It adds an L2 penalty to the model's coefficients. This penalty shrinks the coefficients towards zero but does not set them exactly to zero. By reducing the magnitude of the coefficients, it mitigates the impact of multicollinearity and helps stabilize the model, especially when dealing with highly correlated features or when the number of features exceeds the number of samples in the dataset.\n",
        "\n",
        "* Elastic Net Regularization – L1 and L2 Regularization\n",
        "\n",
        "Elastic Net combines both L1 and L2 penalties in the regularization term. This hybrid approach allows for a more flexible regularization strategy, offering the benefits of both Lasso and Ridge regularization. Elastic Net can handle situations where there are many correlated features and provides a balance between feature selection and stability, making it suitable for a wide range of machine learning tasks. -->\n",
        "\n",
        "\n",
        "reference: https://www.geeksforgeeks.org/regularization-in-machine-learning/"
      ],
      "metadata": {
        "id": "i09GUwinNV4Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q 10)What is dropout layer and explain how it prevents overfitting?"
      ],
      "metadata": {
        "id": "EoVZoLpB3B7X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dropout layer is a regularization technique used in neural networks to prevent overfitting.\n",
        "During training, dropout randomly deactivates (or \"drops out\") a fraction of neurons in the layer by setting their outputs to zero. This means that for each training sample, different neurons are dropped out, effectively creating a different architecture for each sample.\n",
        "\n",
        "By dropping out neurons, dropout prevents the neural network from relying too much on any individual neuron or feature, forcing it to learn more robust and generalized features.\n",
        "Additionally, dropout introduces noise into the training process, which helps the model to learn more robust representations of the data."
      ],
      "metadata": {
        "id": "vEHK8K6zP5OT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q 11)Explain L1 and L2 regularization"
      ],
      "metadata": {
        "id": "CMx3OcJ53CBj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " The commonly used regularization techniques are :\n",
        "\n",
        "Lasso Regularization – L1 Regularization\n",
        "Lasso imposes an L1 penalty on the model's coefficients during training. This penalty encourages sparsity in the coefficient values, effectively setting some of them to zero. This feature selection property makes Lasso particularly useful when dealing with high-dimensional data, as it automatically identifies and discards irrelevant features, leading to simpler and more interpretable models.\n",
        "\n",
        "Ridge Regularization – L2 Regularization\n",
        "It adds an L2 penalty to the model's coefficients. This penalty shrinks the coefficients towards zero but does not set them exactly to zero. By reducing the magnitude of the coefficients, it mitigates the impact of multicollinearity and helps stabilize the model, especially when dealing with highly correlated features or when the number of features exceeds the number of samples in the dataset.\n",
        "\n",
        "<!-- Elastic Net Regularization – L1 and L2 Regularization\n",
        "Elastic Net combines both L1 and L2 penalties in the regularization term. This hybrid approach allows for a more flexible regularization strategy, offering the benefits of both Lasso and Ridge regularization. Elastic Net can handle situations where there are many correlated features and provides a balance between feature selection and stability, making it suitable for a wide range of machine learning tasks. -->\n",
        "\n",
        "reference: https://www.geeksforgeeks.org/regularization-in-machine-learning/"
      ],
      "metadata": {
        "id": "O8qaUN9dO7CW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q 12)Write about validation accuracy and why we need it?"
      ],
      "metadata": {
        "id": "k5TGmHuJ3JTh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation accuracy is a metric used to evaluate the performance of a machine learning model on a validation dataset, which is separate from the training dataset. It measures how well the model generalizes to new, unseen data by comparing its predictions with the true labels in the validation set.\n",
        "\n",
        "Validation accuracy is important because it provides an estimate of how well the model is likely to perform on real-world data.\n",
        "By monitoring validation accuracy, we can detect overfitting and underfitting, allowing us to adjust the model's architecture and training process."
      ],
      "metadata": {
        "id": "6XBZFr1RR_x_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Q 13)What do you mean by data augmentation and explain is advantages and disadvantages in detail?"
      ],
      "metadata": {
        "id": "hCOGr8vl3JXY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Data augmentation is a technique used in machine learning to artificially increase the size of a dataset by applying various transformations to the existing data samples. These transformations include techniques such as rotation, flipping, cropping, scaling, translation, adding noise, and changing brightness or contrast.\n",
        "\n",
        "Advantages:\n",
        "\n",
        "1)Data augmentation allows for the creation of a larger and more diverse dataset, which can help improve the performance of machine learning models\n",
        "\n",
        "2)data augmentation acts as a form of regularization, helping prevent overfitting by encouraging the model to learn more robust\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "1)excessive augmentation can introduce irrelevant variations or distortions, leading to decreased model performance.\n",
        "\n",
        "2)Data augmentation increases the computational cost of training. This can result in longer training times."
      ],
      "metadata": {
        "id": "AFF69XkfSpbe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q 14)What is transfer learning.Explain in detail? Mention various pre-trained model present in the community"
      ],
      "metadata": {
        "id": "CeYHJXKh3O1x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transfer learning is a machine learning technique where a model trained on one task is transferred to a related task. Instead of starting the learning process from scratch, we can use transfer learning that is we can use the knowledge of solving one task in solving the other.\n",
        "\n",
        "Process of Transfer Learning:\n",
        "\n",
        "Pre-trained Model: A pre-trained model, often serves as the base model. This model has already learned rich and generalized features from the data.\n",
        "\n",
        "Feature Extraction: The pre-trained model's parameters are frozen, and only the top layers are modified to adapt the model to the new task. These modified layers are typically responsible for task-specific predictions.\n",
        "\n",
        "pre-trained models:\n",
        "\n",
        "GPT (Generative Pre-trained Transformer)\n",
        "\n",
        "YOLO (You Only Look Once)\n",
        "\n",
        "BERT (Bidirectional Encoder Representations from Transformers)"
      ],
      "metadata": {
        "id": "Sy13ESU3UEkE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q 15) Explain the bias- variance tradeoff."
      ],
      "metadata": {
        "id": "m0x7E-Cg3Vzc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bias-variance tradeoff is a fundamental concept in machine learning that refers to the balance between the bias and variance of a model.\n",
        "\n",
        "The bias-variance tradeoff suggests that as you decrease bias (by increasing model complexity), you tend to increase variance, and vice versa. Finding the right balance between bias and variance is crucial for building a model that generalizes well to new, unseen data"
      ],
      "metadata": {
        "id": "I4cBUQ93ZH0E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q 16)Assume you have dataset of patients who visited AIIMS(Delhi) between the period of 2018-2020.The datasets include features from CBC reports,IGE,weight,temp,etc.There problems were mainly classified into gastrointestinal problems, heart problems, diabetes and misc.\n",
        "You being a experienced ML engineer, the hospital has approached you to make a model which given these features can predict the problem that the patient is suffering.You can either train a separate neural network for each of the diseases or to train a single neural network\n",
        "with one output neuron for each disease. Which method do you prefer.Justify your answer"
      ],
      "metadata": {
        "id": "fUU9eDCa3S2U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I would prefer training a single neural network with one output neuron for each disease because:\n",
        "\n",
        "* By using a single neural network, the model can learn shared representations among different diseases. This means it can capture common patterns or features across various health conditions, potentially leading to better generalization and performance.\n",
        "\n",
        "*  Training and maintaining a single model is simpler and more efficient compared to managing multiple separate models for each disease.\n",
        "\n",
        "* A single model allows for better handling of class imbalances, which might occur if some disease categories are more prevalent in the dataset than others. The model can learn to balance the importance of each disease class during training, leading to more balanced predictions.\n",
        "\n",
        "* Patients often present with symptoms that overlap across different disease categories. By training a single model, it can capture complex interactions between features and diseases, potentially leading to more accurate predictions."
      ],
      "metadata": {
        "id": "6fiD9OA0eAiK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q 17) Assume your input data X has m observations and n0 features (shape: n0 x m), and the output layer Y has shape (n3 x m). Say that you want to have 2 hidden layers in your model: A1- (n1 x m) and A2- (n2 x m).\n",
        "\n",
        "(a) How many weight and bias matrices will you have? Find the shapes of each & verify if the dimensions of matrix multiplications are accurate.\n",
        "\n",
        "(b) If this is a Binary classification problem, what activation functions will you use for (i) the hidden layers, and (ii) the output layer. Why?\n",
        "\n",
        "(c) Repeat part (b) if this is a Multi-class classification problem.\n",
        "\n",
        "(d) Repeat part (b) if this is a Regression problem.\n",
        "\n",
        "-> Give proper reasoning for each part."
      ],
      "metadata": {
        "id": "ZRbqSHnH0Cu5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UelBaEBhh2u0"
      }
    }
  ]
}