{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C_VNR1pMSj9"
      },
      "source": [
        "# **Part B**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAAqcoqsLBgu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.layers import GlobalMaxPooling2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import regularizers, optimizers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eozQe6kXLAEc",
        "outputId": "15e9fb99-43ce-4a19-c6e1-983aa66c2c5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# #dataset\n",
        "(X_train,Y_train),(X_test,Y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X_train,Y_train,test_size=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs93O1uRLUcD"
      },
      "source": [
        "You have learnt about data augmentation in the theoretical assignment, Now you need to use it in the above dataset (You can do it using ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tb8dL13i00hl",
        "outputId": "51ca96e9-f4b8-4e78-fb0c-347bcbf9629e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(35000, 32, 32, 3)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gb8hzzF_LFwb"
      },
      "outputs": [],
      "source": [
        "# Create an ImageDataGenerator object\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    zoom_range=0.05,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "datagen.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1JbL6EzwxV5"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "Y_train = to_categorical(Y_train, num_classes=10)\n",
        "Y_test = to_categorical(Y_test, num_classes=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLN7TW6VxHR8"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding = 'same', activation='relu', input_shape=X_train.shape[1:]))\n",
        "model.add(Conv2D(32, (3, 3), padding = 'same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size= (2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), padding = 'same', activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size= (2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "3subBFfbxl2L",
        "outputId": "5797a87e-c349-45ad-d792-3621f4cc488e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1094/1094 [==============================] - 245s 220ms/step - loss: 1.6105 - accuracy: 0.4115 - val_loss: 1.2323 - val_accuracy: 0.5563\n",
            "Epoch 2/20\n",
            "1094/1094 [==============================] - 239s 218ms/step - loss: 1.2207 - accuracy: 0.5615 - val_loss: 1.0501 - val_accuracy: 0.6315\n",
            "Epoch 3/20\n",
            "1094/1094 [==============================] - 245s 224ms/step - loss: 1.0715 - accuracy: 0.6189 - val_loss: 0.9318 - val_accuracy: 0.6703\n",
            "Epoch 4/20\n",
            "1094/1094 [==============================] - 238s 217ms/step - loss: 0.9732 - accuracy: 0.6569 - val_loss: 0.8228 - val_accuracy: 0.7114\n",
            "Epoch 5/20\n",
            "1094/1094 [==============================] - 241s 220ms/step - loss: 0.9114 - accuracy: 0.6809 - val_loss: 0.8204 - val_accuracy: 0.7157\n",
            "Epoch 6/20\n",
            "1094/1094 [==============================] - 240s 220ms/step - loss: 0.8553 - accuracy: 0.6985 - val_loss: 0.7557 - val_accuracy: 0.7358\n",
            "Epoch 7/20\n",
            "1094/1094 [==============================] - 230s 210ms/step - loss: 0.8155 - accuracy: 0.7142 - val_loss: 0.7636 - val_accuracy: 0.7325\n",
            "Epoch 8/20\n",
            "1094/1094 [==============================] - 235s 215ms/step - loss: 0.7852 - accuracy: 0.7270 - val_loss: 0.7577 - val_accuracy: 0.7375\n",
            "Epoch 9/20\n",
            "1094/1094 [==============================] - 245s 224ms/step - loss: 0.7592 - accuracy: 0.7347 - val_loss: 0.7284 - val_accuracy: 0.7463\n",
            "Epoch 10/20\n",
            "1094/1094 [==============================] - 232s 212ms/step - loss: 0.7423 - accuracy: 0.7403 - val_loss: 0.7332 - val_accuracy: 0.7476\n",
            "Epoch 11/20\n",
            "1094/1094 [==============================] - 233s 213ms/step - loss: 0.7161 - accuracy: 0.7478 - val_loss: 0.7237 - val_accuracy: 0.7516\n",
            "Epoch 12/20\n",
            "1094/1094 [==============================] - 235s 215ms/step - loss: 0.6999 - accuracy: 0.7553 - val_loss: 0.6558 - val_accuracy: 0.7725\n",
            "Epoch 13/20\n",
            "1094/1094 [==============================] - 250s 229ms/step - loss: 0.6848 - accuracy: 0.7596 - val_loss: 0.6783 - val_accuracy: 0.7731\n",
            "Epoch 14/20\n",
            "1094/1094 [==============================] - 228s 208ms/step - loss: 0.6704 - accuracy: 0.7646 - val_loss: 0.6545 - val_accuracy: 0.7771\n",
            "Epoch 15/20\n",
            "1094/1094 [==============================] - 230s 210ms/step - loss: 0.6581 - accuracy: 0.7711 - val_loss: 0.6681 - val_accuracy: 0.7711\n",
            "Epoch 16/20\n",
            "1094/1094 [==============================] - 225s 206ms/step - loss: 0.6423 - accuracy: 0.7768 - val_loss: 0.6511 - val_accuracy: 0.7791\n",
            "Epoch 17/20\n",
            "1094/1094 [==============================] - 226s 207ms/step - loss: 0.6412 - accuracy: 0.7756 - val_loss: 0.6703 - val_accuracy: 0.7742\n",
            "Epoch 18/20\n",
            "1094/1094 [==============================] - 225s 206ms/step - loss: 0.6298 - accuracy: 0.7778 - val_loss: 0.6445 - val_accuracy: 0.7861\n",
            "Epoch 19/20\n",
            "1094/1094 [==============================] - 231s 211ms/step - loss: 0.6166 - accuracy: 0.7842 - val_loss: 0.6274 - val_accuracy: 0.7891\n",
            "Epoch 20/20\n",
            "1094/1094 [==============================] - 249s 227ms/step - loss: 0.6090 - accuracy: 0.7857 - val_loss: 0.6587 - val_accuracy: 0.7775\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(datagen.flow(X_train,Y_train) , epochs = 20,validation_data=(X_test,Y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_IjfGJ_L7sW"
      },
      "source": [
        "Use Visualization libraries to see how data augmentation works."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJxUHrusMEud"
      },
      "source": [
        "Train a CNN model of your choice and evaluate on the test data using weighted F1 scores ( Do not just try with a single model use multiple models, for example- one with transfer learning or with a different model architecture) at the end compare the performance of the models, and write what do you infer from the same"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pmMCe4DXLQoX",
        "outputId": "72d0bfac-7859-47c4-d162-84d1d717b4b9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 0s 0us/step\n",
            "Epoch 1/20\n",
            "1094/1094 [==============================] - 78s 68ms/step - loss: 1.9395 - accuracy: 0.2934 - val_loss: 1.8515 - val_accuracy: 0.3295\n",
            "Epoch 2/20\n",
            "1094/1094 [==============================] - 69s 63ms/step - loss: 1.8357 - accuracy: 0.3328 - val_loss: 1.8238 - val_accuracy: 0.3346\n",
            "Epoch 3/20\n",
            "1094/1094 [==============================] - 76s 70ms/step - loss: 1.7977 - accuracy: 0.3438 - val_loss: 1.8004 - val_accuracy: 0.3478\n",
            "Epoch 4/20\n",
            "1094/1094 [==============================] - 71s 64ms/step - loss: 1.7676 - accuracy: 0.3597 - val_loss: 1.8000 - val_accuracy: 0.3457\n",
            "Epoch 5/20\n",
            "1094/1094 [==============================] - 75s 69ms/step - loss: 1.7435 - accuracy: 0.3678 - val_loss: 1.7948 - val_accuracy: 0.3501\n",
            "Epoch 6/20\n",
            "1094/1094 [==============================] - 70s 64ms/step - loss: 1.7211 - accuracy: 0.3767 - val_loss: 1.7934 - val_accuracy: 0.3527\n",
            "Epoch 7/20\n",
            "1094/1094 [==============================] - 75s 69ms/step - loss: 1.7042 - accuracy: 0.3838 - val_loss: 1.7976 - val_accuracy: 0.3500\n",
            "Epoch 8/20\n",
            "1094/1094 [==============================] - 74s 68ms/step - loss: 1.6850 - accuracy: 0.3884 - val_loss: 1.7941 - val_accuracy: 0.3541\n",
            "Epoch 9/20\n",
            "1094/1094 [==============================] - 74s 68ms/step - loss: 1.6657 - accuracy: 0.3976 - val_loss: 1.8051 - val_accuracy: 0.3525\n",
            "Epoch 10/20\n",
            "1094/1094 [==============================] - 75s 69ms/step - loss: 1.6539 - accuracy: 0.4008 - val_loss: 1.8080 - val_accuracy: 0.3530\n",
            "Epoch 11/20\n",
            "1094/1094 [==============================] - 74s 68ms/step - loss: 1.6414 - accuracy: 0.4068 - val_loss: 1.8101 - val_accuracy: 0.3553\n",
            "Epoch 12/20\n",
            "1094/1094 [==============================] - 73s 67ms/step - loss: 1.6230 - accuracy: 0.4125 - val_loss: 1.8186 - val_accuracy: 0.3495\n",
            "Epoch 13/20\n",
            "1094/1094 [==============================] - 77s 71ms/step - loss: 1.6161 - accuracy: 0.4145 - val_loss: 1.8190 - val_accuracy: 0.3523\n",
            "Epoch 14/20\n",
            "1094/1094 [==============================] - 76s 69ms/step - loss: 1.6007 - accuracy: 0.4220 - val_loss: 1.8314 - val_accuracy: 0.3517\n",
            "Epoch 15/20\n",
            "1094/1094 [==============================] - 69s 64ms/step - loss: 1.5912 - accuracy: 0.4239 - val_loss: 1.8367 - val_accuracy: 0.3531\n",
            "Epoch 16/20\n",
            "1094/1094 [==============================] - 75s 69ms/step - loss: 1.5788 - accuracy: 0.4279 - val_loss: 1.8387 - val_accuracy: 0.3508\n",
            "Epoch 17/20\n",
            "1094/1094 [==============================] - 79s 72ms/step - loss: 1.5690 - accuracy: 0.4311 - val_loss: 1.8537 - val_accuracy: 0.3512\n",
            "Epoch 18/20\n",
            "1094/1094 [==============================] - 75s 68ms/step - loss: 1.5571 - accuracy: 0.4380 - val_loss: 1.8522 - val_accuracy: 0.3555\n",
            "Epoch 19/20\n",
            "1094/1094 [==============================] - 69s 63ms/step - loss: 1.5466 - accuracy: 0.4429 - val_loss: 1.8669 - val_accuracy: 0.3501\n",
            "Epoch 20/20\n",
            "1094/1094 [==============================] - 70s 64ms/step - loss: 1.5353 - accuracy: 0.4460 - val_loss: 1.8701 - val_accuracy: 0.3523\n"
          ]
        }
      ],
      "source": [
        "#transfer learning on MobileNetV2\n",
        "\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "\n",
        "#freeze all layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model1 = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model1.fit(X_train,Y_train , epochs = 20,validation_data=(X_test,Y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hwxBHEZy_6XA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}